<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>RAG - 标签 - siwei.io</title>
        <link>https://siwei.io/tags/rag/</link>
        <description>RAG - 标签 - siwei.io</description>
        <generator>Hugo -- gohugo.io</generator><managingEditor>weyl.gu@gmail.com (Wey Gu)</managingEditor>
            <webMaster>weyl.gu@gmail.com (Wey Gu)</webMaster><lastBuildDate>Tue, 15 Aug 2023 11:10:34 &#43;0800</lastBuildDate><atom:link href="https://siwei.io/tags/rag/" rel="self" type="application/rss+xml" /><item>
    <title>Graph RAG: 知识图谱结合 LLM 的检索增强</title>
    <link>https://siwei.io/graph-rag/</link>
    <pubDate>Tue, 15 Aug 2023 11:10:34 &#43;0800</pubDate><author>
        <name>Wey Gu</name>
    </author><guid>https://siwei.io/graph-rag/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/graph-rag/featured-image.webp" referrerpolicy="no-referrer">
            </div><blockquote>
<p>本文为大家揭示我们优先提出的 Graph RAG 方法，这种结合知识图谱、图数据库作为大模型结合私有知识系统最新的技术栈，作为之前的图上下文学习、text2cypher 文章的第三篇文章。</p>
</blockquote>
<p>本文为大家揭示我们优先提出的 Graph RAG 方法，这种结合知识图谱、图数据库作为大模型结合私有知识系统最新的技术栈，作为之前的图上下文学习、text2cypher 文章的第三篇文章。</p>
<h2 id="graph-rag" class="headerLink">
    <a href="#graph-rag" class="header-mark"></a>1 Graph RAG</h2><p>在<a href="https://siwei.io/en/graph-enabled-llama-index/" target="_blank" rel="noopener noreferrer">第一篇关于上下文学习的博客中</a>我们介绍过， RAG（Retrieval Argumented Generation）这种基于特定任务/问题的文档检索范式中，我们通常先收集必要的上下文，然后利用具有认知能力的机器学习模型进行上下文学习（in-context learning），来合成任务的答案。</p>
<p>借助 LLM 这个只需要“说话”就可以灵活处理复杂问题的感知层，只需要两步，就能搭建一个基于私有知识的智能应用：</p>
<ul>
<li>利用各种搜索方式（比如 Embedding 与向量数据库）从给定的文档中检索相关知识。</li>
<li>利用 LLM 理解并智能地合成答案。</li>
</ul>
<p>而这篇博客中，我们结合最新的探索进展和思考，尝试把 Graph RAG 和其他方法进行比较，说得更透一点。并且，我们决定开始用 Graph RAG 这个叫法来描述它。</p>
<blockquote>
<p>实际上，<a href="https://siwei.io/talks/graph-rag-with-jerry/" target="_blank" rel="noopener noreferrer">Graph RAG</a>，是最先又我<a href="https://www.youtube.com/watch?v=bPoNCkjDmco" target="_blank" rel="noopener noreferrer">和 Jerry Liu 的直播研讨会讨论</a>和<a href="https://twitter.com/wey_gu/status/1673362774930628608" target="_blank" rel="noopener noreferrer">相关的讨论的 Twitter Thread</a>中提到的，差不多的内容我在 <a href="https://www.bilibili.com/video/BV1Pp4y157nt" target="_blank" rel="noopener noreferrer">NebulaGraph 社区直播</a> 中也用中文介绍过。</p>
</blockquote>
<h2 id="在-rag-中知识图谱的价值" class="headerLink">
    <a href="#%e5%9c%a8-rag-%e4%b8%ad%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1%e7%9a%84%e4%bb%b7%e5%80%bc" class="header-mark"></a>2 在 RAG 中知识图谱的价值</h2><p>这部分内容我们在第一篇文章中阐述过，比如一个查询：“告诉我所有关于苹果和乔布斯的事”，基于乔布斯自传这本书进行问答，而这个问题涉及到的上下文分布在自传这本书的 30 页（分块）的时候，传统的“分割数据，Embedding 再向量搜索”方法在多个文档块里用 top-k 去搜索的方法很难得到这种分散，细粒的完整信息。而且，这种方法还很容易遗漏互相关联的文档块，从而导致信息检索不完整。</p>
<p>除此之外，在之后一次技术会议中，我有幸和 leadscloud.com 的徐旭讨论之后（他们因为有知识图谱的技术背景，也做了和我们类似的探索和尝试！），让我意识到知识图谱可以减少基于嵌入的语义搜索所导致的不准确性。徐旭给出的一个有趣的例子是“保温大棚”与“保温杯”，尽管在语义上两者是存在相关性的，但在大多数场景下，这种通用语义（Embedding）下的相关性常常是我们不希望产生的，进而作为错误的上下文而引入“幻觉”。</p>
<p>这时候，保有领域知识的知识图谱则是非常直接可以缓解、消除这种幻觉的手段。</p>
<h2 id="用-nebulagraph-实现-graph-rag" class="headerLink">
    <a href="#%e7%94%a8-nebulagraph-%e5%ae%9e%e7%8e%b0-graph-rag" class="header-mark"></a>3 用 NebulaGraph 实现 Graph RAG</h2><p>一个简单的 Graph RAG 可以如下去简单实现：</p>
<ol>
<li>使用LLM(或其他)模型从问题中提取关键实体。</li>
<li>根据这些实体检索子图，深入到一定的深度（例如，2）。</li>
<li>利用获得的上下文利用LLM产生答案。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 伪代码</span>

<span class="k">def</span> <span class="nf">_get_key_entities</span><span class="p">(</span><span class="n">query_str</span><span class="p">,</span> <span class="n">llm</span><span class="o">=</span><span class="kc">None</span> <span class="p">,</span><span class="n">with_llm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">_expand_synonyms</span><span class="p">(</span><span class="n">entities</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_retrieve_subgraph_context</span><span class="p">(</span><span class="n">entities</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">nebulagraph_store</span><span class="o">.</span><span class="n">get_relations</span><span class="p">(</span><span class="n">entities</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">limit</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_synthesize_answer</span><span class="p">(</span><span class="n">query_str</span><span class="p">,</span> <span class="n">graph_rag_context</span><span class="p">,</span> <span class="n">llm</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">llm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">PROMPT_SYNTHESIZE_AND_REFINE</span><span class="p">,</span> <span class="n">query_str</span><span class="p">,</span> <span class="n">graph_rag_context</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">simple_graph_rag</span><span class="p">(</span><span class="n">query_str</span><span class="p">,</span> <span class="n">nebulagraph_store</span><span class="p">,</span> <span class="n">llm</span><span class="p">):</span>
    <span class="n">entities</span> <span class="o">=</span> <span class="n">_get_key_entities</span><span class="p">(</span><span class="n">query_str</span><span class="p">,</span> <span class="n">llm</span><span class="p">)</span>
    <span class="n">graph_rag_context</span> <span class="o">=</span> <span class="n">_retrieve_subgraph_context</span><span class="p">(</span><span class="n">entities</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_synthesize_answer</span><span class="p">(</span>
        <span class="n">query_str</span><span class="p">,</span> <span class="n">graph_rag_context</span><span class="p">,</span> <span class="n">llm</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>然而，有了像 Llama Index 这样方便的 LLM 编排工具，开发者可以专注于 LLM 的编排逻辑和 pipeline 设计，而不用亲自处理很多细节的抽象与实现。</p>
<p>所以，用 Llama Index，我们可以轻松搭建 Graph RAG，甚至整合更复杂的 RAG 逻辑，比如 <a href="https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html" target="_blank" rel="noopener noreferrer">Graph+Vector RAG</a>。</p>
<p><figure><img
        
        loading="lazy"
        src="https://github.com/siwei-io/talks/assets/1651790/f783b592-7a8f-4eab-bd61-cf0837e83870"
        srcset="https://github.com/siwei-io/talks/assets/1651790/f783b592-7a8f-4eab-bd61-cf0837e83870, https://github.com/siwei-io/talks/assets/1651790/f783b592-7a8f-4eab-bd61-cf0837e83870 1.5x, https://github.com/siwei-io/talks/assets/1651790/f783b592-7a8f-4eab-bd61-cf0837e83870 2x"
        sizes="auto"
        alt="https://github.com/siwei-io/talks/assets/1651790/f783b592-7a8f-4eab-bd61-cf0837e83870"
        title="https://github.com/siwei-io/talks/assets/1651790/f783b592-7a8f-4eab-bd61-cf0837e83870" ></figure></p>
<p>在 Llama Index 中，我们有两种方法实现 Graph RAG：</p>
<ul>
<li><code>KnowledgeGraphIndex</code> 用来从任何私有数据只是从零构建知识图谱（基于 LLM 或者其他语言模型），然后 4 行代码进行 Graph RAG。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">graph_store = NebulaGraphStore(
    space_name=space_name,
    edge_types=edge_types,
    rel_prop_names=rel_prop_names,
    tags=tags,
)
storage_context = StorageContext.from_defaults(graph_store=graph_store)

# Build KG
kg_index = KnowledgeGraphIndex.from_documents(
    documents,
    storage_context=storage_context,
    max_triplets_per_chunk=10,
    space_name=space_name,
    edge_types=edge_types,
    rel_prop_names=rel_prop_names,
    tags=tags,
)

kg_query_engine = kg_index.as_query_engine()
</code></pre></td></tr></table>
</div>
</div><ul>
<li><code>KnowledgeGraphRAGQueryEngine</code> 则可以在任何已经存在的知识图谱上进行 Graph RAG，不过我还没有完成这个 <a href="https://github.com/jerryjliu/llama_index/pull/7204" target="_blank" rel="noopener noreferrer">PR</a>。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">graph_store = NebulaGraphStore(
    space_name=space_name,
    edge_types=edge_types,
    rel_prop_names=rel_prop_names,
    tags=tags,
)
storage_context = StorageContext.from_defaults(graph_store=graph_store)

graph_rag_query_engine = KnowledgeGraphRAGQueryEngine(
    storage_context=storage_context,
)
</code></pre></td></tr></table>
</div>
</div><p>最后，我做了<a href="https://www.siwei.io/demos/graph-rag/" target="_blank" rel="noopener noreferrer">一个 streamlit 的 demo</a>来比较 Graph RAG 与 Vector RAG，从中我们可以看到 Graph RAG 并没有取代 Embedding、向量搜索的方法，而是增强了/补充了它的不足。</p>
<iframe width="800" height="857" src="https://github.com/siwei-io/talks/assets/1651790/102d00bc-6146-4856-a81f-f953c7254b29"> </iframe>
<h2 id="text2cypher" class="headerLink">
    <a href="#text2cypher" class="header-mark"></a>4 text2cypher</h2><p>基于图谱的 LLM 的另一种有趣方法是text2cypher。这种方法不依赖于实体的子图检索，而是将任务/问题翻译成一个面向答案的特定图查询，和我们常说的 text2sql 方法本质是一样的。</p>
<h3 id="在-nebulagraph-上进行-text2cypher" class="headerLink">
    <a href="#%e5%9c%a8-nebulagraph-%e4%b8%8a%e8%bf%9b%e8%a1%8c-text2cypher" class="header-mark"></a>4.1 在 NebulaGraph 上进行 text2cypher</h3><p>在之前的文章中我们已经介绍过，得益于 LLM，实现 text2cypher 比传统的 ML 方法更为简单和便宜。</p>
<p>比如，<a href="https://python.langchain.com/docs/use_cases/more/graph/graph_nebula_qa" target="_blank" rel="noopener noreferrer">LangChain: NebulaGraphQAChain</a> 和 <a href="https://gpt-index.readthedocs.io/en/latest/examples/query_engine/knowledge_graph_query_engine.html" target="_blank" rel="noopener noreferrer">Llama Index: KnowledgeGraphQueryEngine</a> 让我们 3 行代码就能跑起来 text2cypher。</p>
<h3 id="比较-text2cypher-和-subgraph-rag" class="headerLink">
    <a href="#%e6%af%94%e8%be%83-text2cypher-%e5%92%8c-subgraph-rag" class="header-mark"></a>4.2 比较 text2cypher 和 (Sub)Graph RAG</h3><p>这两种方法主要在其检索机制上有所不同。text2cypher 根据 KG 的 Schema 和给定的任务生成图形模式查询，而SubGraph RAG获取相关的子图以提供上下文。</p>
<p>两者都有其优点，为了大家更直观理解他们的特点，我做了这个 demo 视频：</p>
<p>我们可以看到两者的图查询模式在可视化下是有非常清晰的差异的。</p>
<iframe width="800" height="857" src="https://github.com/siwei-io/talks/assets/1651790/05d01e53-d819-4f43-9bf1-75549f7f2be9"> </iframe>
<h3 id="结合text2cypher的graph-rag" class="headerLink">
    <a href="#%e7%bb%93%e5%90%88text2cypher%e7%9a%84graph-rag" class="header-mark"></a>4.3 结合text2cypher的Graph RAG</h3><p>然而，两者并没有绝对的好与坏，不同场景下，它们各有优劣。</p>
<p>在现实世界中，我们可能并不总是知道哪种方法更有效（好帮助区分应该用哪一种），因此，我倾向于考虑同时利用两者，这样获取的两种检索结果作为上下文，一起来生成最终答案的效果可能是最好的。</p>
<p>具体的实现方法在<a href="https://github.com/jerryjliu/llama_index/pull/7204" target="_blank" rel="noopener noreferrer">这个 PR</a>中已经可以做到了，只需要设置<code>with_text2cypher=True</code>，Graph RAG 就会包含text2cypher 上下文，敬请期待它的合并。</p>
<h2 id="结论" class="headerLink">
    <a href="#%e7%bb%93%e8%ae%ba" class="header-mark"></a>5 结论</h2><p>通过将知识图谱、图存储集成到 LLM 技术栈中，Graph RAG 把 RAG 的上下文学习推向了一个新的高度。它能在 LLM 应用中，通过利用现有（或新建）的知识图谱，提取细粒度、精确调整、领域特定且互联的知识。</p>
<p>请继续关注图谱和LLM领域的更深入的探索和进一步的发展。</p>
<blockquote>
<p>题图 prompt： A vast open book serves as the backdrop, with intricately interwoven nodes and lines forming a Graph on its pages. At the center of this graph, there&rsquo;s a glowing brain symbolizing the Knowledge Graph. Rays of light emanate from the brain, reaching every corner of the graph, mirroring neural connections linking diverse information. On the right side of the illustration, a robotic arm with a pen is swiftly writing, representing the input and output of the AI large language model.</p>
</blockquote>]]></description>
</item><item>
    <title>Demo：NebulaGraph 的 Graph RAG</title>
    <link>https://siwei.io/demos/graph-rag/</link>
    <pubDate>Wed, 19 Jul 2023 16:38:34 &#43;0800</pubDate><author>
        <name>Wey Gu</name>
    </author><guid>https://siwei.io/demos/graph-rag/</guid>
    <description><![CDATA[<iframe
  src="https://graph-rag.streamlit.app/?embed=true"
  height="900"
  style="width:100%;border:none;"
></iframe>
]]></description>
</item></channel>
</rss>

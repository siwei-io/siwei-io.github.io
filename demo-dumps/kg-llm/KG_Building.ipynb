{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2816dd42",
   "metadata": {},
   "source": [
    "## Knowledge Graph Building with LLM\n",
    "\n",
    "```\n",
    "                                   ┌─────────────────────────┐\n",
    "                                   │                         │\n",
    "                                   │      Knowledge Graph    │\n",
    "                                   │      on NebulaGraph     │\n",
    "                                   │                         │\n",
    "                                   │                .───.    │\n",
    "                                   │           ┌──▶(     )   │\n",
    "                                   │           │    `───'    │\n",
    "┌────────────────────┐             │  .───.    │             │\n",
    "│ Data Sources       │             │ (     )───┘             │\n",
    "│                    │   Extract   │  `───'                  │\n",
    "│ Database, Wikepedia│━━With LLM━━━▶    │         .───.      │\n",
    "│ CSV, JSON Files    │             │    └───────▶(     )     │\n",
    "│ Web APIs...        │             │              `───'      │\n",
    "└────────────────────┘             │                ▲        │\n",
    "                                   │                │        │\n",
    "                                   │                │  .───. │\n",
    "                                   │                └─(     )│\n",
    "                                   │                   `───' │\n",
    "                                   │                         │\n",
    "                                   │                         │\n",
    "                                   └─────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e900489",
   "metadata": {},
   "source": [
    "# 1. Preparation\n",
    "\n",
    "## 1.1 Prepare for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only For OpenAI\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"INSERT OPENAI KEY\"\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO) # logging.DEBUG for more verbose output\n",
    "\n",
    "from llama_index import (\n",
    "    KnowledgeGraphIndex,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "\n",
    "\n",
    "from langchain import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-002\"))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b21fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only For Azure OpenAI\n",
    "\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    KnowledgeGraphIndex,\n",
    "    LLMPredictor,\n",
    "    ServiceContext\n",
    ")\n",
    "\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO) # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"INSERT AZURE API BASE\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"INSERT OPENAI KEY\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# define LLM\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"INSERT DEPLOYMENT NAME\",\n",
    "    temperature=0,\n",
    "    openai_api_version=openai.api_version,\n",
    "    model_kwargs={\n",
    "        \"api_key\": openai.api_key,\n",
    "        \"api_base\": openai.api_base,\n",
    "        \"api_type\": openai.api_type,\n",
    "        \"api_version\": openai.api_version,\n",
    "    }\n",
    ")\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        deployment=\"INSERT DEPLOYMENT NAME\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "        openai_api_version=openai.api_version,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embedding_llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210dc3d4",
   "metadata": {},
   "source": [
    "## 1.2. Prepare for NebulaGraph as Graph Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6beff",
   "metadata": {},
   "source": [
    "❗Access NebulaGraph Console to **create space** and **graph schema**\n",
    "\n",
    "```sql\n",
    "CREATE SPACE guardians(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);\n",
    ":sleep 10;\n",
    "USE guardians;\n",
    "CREATE TAG entity(name string);\n",
    "CREATE EDGE relationship(relationship string);\n",
    ":sleep 10;\n",
    "CREATE TAG INDEX entity_index ON entity(name(256));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9037c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NEBULA_USER'] = \"root\"\n",
    "os.environ['NEBULA_PASSWORD'] = \"nebula\" # default password\n",
    "os.environ['NEBULA_ADDRESS'] = \"127.0.0.1:9669\" # assumed we have NebulaGraph installed locally\n",
    "\n",
    "space_name = \"guardians\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\"relationship\"] # default, could be omit if create from an empty kg\n",
    "tags = [\"entity\"] # default, could be omit if create from an empty kg\n",
    "\n",
    "graph_store = NebulaGraphStore(space_name=space_name, edge_types=edge_types, rel_prop_names=rel_prop_names, tags=tags)\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38240b",
   "metadata": {},
   "source": [
    "## 2. Build the Knowledge Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af875b5",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess Data\n",
    "\n",
    "We will download and preprecess data from:\n",
    "    https://en.wikipedia.org/wiki/Guardians_of_the_Galaxy_Vol._3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "\n",
    "loader = WikipediaReader()\n",
    "\n",
    "documents = loader.load_data(pages=['Guardians of the Galaxy Vol. 3'], auto_suggest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc16445",
   "metadata": {},
   "source": [
    "### 2.2 Extract Triplets and Save to NebulaGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45cf6f9",
   "metadata": {},
   "source": [
    "We will persist it to disk and NebulaGraph, thus when using it, we don't need to extract again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    service_context=service_context,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d245e9b",
   "metadata": {},
   "source": [
    "Let's persist the context from memory to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36374bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index.storage_context.persist(persist_dir='./storage_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf8fcb2",
   "metadata": {},
   "source": [
    "The files are generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90f2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9120\r\n",
      "-rw-r--r--@ 1 weyl  staff    66922 Jul 12 20:26 docstore.json\r\n",
      "-rw-r--r--@ 1 weyl  staff  4594860 Jul 12 20:26 index_store.json\r\n",
      "-rw-r--r--@ 1 weyl  staff       51 Jul 12 20:26 vector_store.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l storage_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6e3c9",
   "metadata": {},
   "source": [
    "### 2.3 Inspect the Graph we built\n",
    "\n",
    "We will leverage NebulaGraph Jupyter Extension, do remember to install it before next step:\n",
    "\n",
    "```bash\n",
    "$ pip install ipython-ngql\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ngql\n",
    "%ngql --address 127.0.0.1 --port 9669 --user root --password nebula\n",
    "%ngql USE guardians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00485c2",
   "metadata": {},
   "source": [
    "We could query 30 random edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7538a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n",
      "Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"Adam Warlock\")-[:relationship@98688268702526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"Alan F. Horn\")-[:relationship@-3866030880391...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"Alan F. Horn\")-[:relationship@-3866030880391...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(\"Bakalova\")-[:relationship@-78310709996010382...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\"Bakalova\")-[:relationship@-18287293525973127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(\"Bautista\")-[:relationship@262829015229588616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(\"Bautista\")-[:relationship@264209192087427643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(\"Chris Pratt\")-[:relationship@-53886203992796...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(\"Christopher Fairbank\")-[:relationship@704429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(\"Cooper\")-[:relationship@2642091920874276436{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(\"Daniela Melchior\")-[:relationship@5794733688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(\"Dave Bautista\")-[:relationship@-538862039927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(\"Debicki\")-[:relationship@2682825685616935037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(\"Diesel\")-[:relationship@2642091920874276436{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(\"Disney\")-[:relationship@-7269035608107002438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(\"Disney\")-[:relationship@4594936970614874383{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(\"Drax\")-[:relationship@1274897091364343563{re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(\"Elizabeth Debicki\")-[:relationship@704429536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(\"Gamora\")-[:relationship@2108090488737331578{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(\"Gamora\")-[:relationship@4452575226635738814{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(\"Gamora\")-[:relationship@7254563908946132317{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(\"George MacKay\")-[:relationship@2027380399406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(\"Gillan\")-[:relationship@-1827525784919523442...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(\"Gillan\")-[:relationship@1278621438198917644{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(\"Gillan\")-[:relationship@2642091920874276436{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(\"Gillan\")-[:relationship@7823655194542812825{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(\"Gregg Henry\")-[:relationship@704429536949728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(\"Guardians cast\")-[:relationship@-64051353433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(\"Guardians of the Galaxy\")-[:relationship@790...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(\"Guardians of the Galaxy Vol. 3\")-[:relations...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    e\n",
       "0   (\"Adam Warlock\")-[:relationship@98688268702526...\n",
       "1   (\"Alan F. Horn\")-[:relationship@-3866030880391...\n",
       "2   (\"Alan F. Horn\")-[:relationship@-3866030880391...\n",
       "3   (\"Bakalova\")-[:relationship@-78310709996010382...\n",
       "4   (\"Bakalova\")-[:relationship@-18287293525973127...\n",
       "5   (\"Bautista\")-[:relationship@262829015229588616...\n",
       "6   (\"Bautista\")-[:relationship@264209192087427643...\n",
       "7   (\"Chris Pratt\")-[:relationship@-53886203992796...\n",
       "8   (\"Christopher Fairbank\")-[:relationship@704429...\n",
       "9   (\"Cooper\")-[:relationship@2642091920874276436{...\n",
       "10  (\"Daniela Melchior\")-[:relationship@5794733688...\n",
       "11  (\"Dave Bautista\")-[:relationship@-538862039927...\n",
       "12  (\"Debicki\")-[:relationship@2682825685616935037...\n",
       "13  (\"Diesel\")-[:relationship@2642091920874276436{...\n",
       "14  (\"Disney\")-[:relationship@-7269035608107002438...\n",
       "15  (\"Disney\")-[:relationship@4594936970614874383{...\n",
       "16  (\"Drax\")-[:relationship@1274897091364343563{re...\n",
       "17  (\"Elizabeth Debicki\")-[:relationship@704429536...\n",
       "18  (\"Gamora\")-[:relationship@2108090488737331578{...\n",
       "19  (\"Gamora\")-[:relationship@4452575226635738814{...\n",
       "20  (\"Gamora\")-[:relationship@7254563908946132317{...\n",
       "21  (\"George MacKay\")-[:relationship@2027380399406...\n",
       "22  (\"Gillan\")-[:relationship@-1827525784919523442...\n",
       "23  (\"Gillan\")-[:relationship@1278621438198917644{...\n",
       "24  (\"Gillan\")-[:relationship@2642091920874276436{...\n",
       "25  (\"Gillan\")-[:relationship@7823655194542812825{...\n",
       "26  (\"Gregg Henry\")-[:relationship@704429536949728...\n",
       "27  (\"Guardians cast\")-[:relationship@-64051353433...\n",
       "28  (\"Guardians of the Galaxy\")-[:relationship@790...\n",
       "29  (\"Guardians of the Galaxy Vol. 3\")-[:relations..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql MATCH ()-[e]->() RETURN e LIMIT 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28977dd6",
   "metadata": {},
   "source": [
    "And **draw** it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97553264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nebulagraph_draw.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"nebulagraph_draw.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15040c450>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae60f9c",
   "metadata": {},
   "source": [
    "## NL2Cypher\n",
    "\n",
    "Now we have a Knowledge Graph built on top of Wikipedia. With NebulaGraph LLM tooling, we could query the KG in Natural language(NL2Cypher).\n",
    "\n",
    "First, let's use Llma Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import KnowledgeGraphQueryEngine\n",
    "\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "\n",
    "nl2kg_query_engine = KnowledgeGraphQueryEngine(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f4b4d",
   "metadata": {},
   "source": [
    "We could see `KnowledgeGraphQueryEngine` could be used to **Generate Graph Query** and do query for us and fianlly LLM could help with the answer synthesis in one go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e14a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mGraph Store Query: MATCH (p:`entity`)-[:relationship]->(e:`entity`) WHERE p.`entity`.`name` == 'Peter Quill' RETURN e.`entity`.`name`;\n",
      "\u001b[0mINFO:llama_index.query_engine.knowledge_graph_query_engine:Graph Store Query: MATCH (p:`entity`)-[:relationship]->(e:`entity`) WHERE p.`entity`.`name` == 'Peter Quill' RETURN e.`entity`.`name`;\n",
      "Graph Store Query: MATCH (p:`entity`)-[:relationship]->(e:`entity`) WHERE p.`entity`.`name` == 'Peter Quill' RETURN e.`entity`.`name`;\n",
      "\u001b[33;1m\u001b[1;3mGraph Store Response: {'e.entity.name': ['Guardians of the Galaxy']}\n",
      "\u001b[0mINFO:llama_index.query_engine.knowledge_graph_query_engine:Graph Store Response: {'e.entity.name': ['Guardians of the Galaxy']}\n",
      "Graph Store Response: {'e.entity.name': ['Guardians of the Galaxy']}\n",
      "\u001b[32;1m\u001b[1;3mFinal Response: \n",
      "Peter Quill is a character from the Marvel Comics series Guardians of the Galaxy.\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Peter Quill is a character from the Marvel Comics series Guardians of the Galaxy.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = nl2kg_query_engine.query(\n",
    "    \"Tell me about Peter Quill?\",\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce948418",
   "metadata": {},
   "source": [
    "💡 Apart from the e2e KGQA, we could ask for only NL2Cypher like this with `generate_query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51418c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```cypher\n",
       "MATCH (p:`entity`)-[:relationship]->(e:`entity`) \n",
       "  WHERE p.`entity`.`name` == 'Peter Quill' \n",
       "RETURN e.`entity`.`name`;\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_query = nl2kg_query_engine.generate_query(\n",
    "    \"Tell me about Peter Quill?\",\n",
    ")\n",
    "graph_query = graph_query.replace(\"WHERE\", \"\\n  WHERE\").replace(\"RETURN\", \"\\nRETURN\")\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "```cypher\n",
    "{graph_query}\n",
    "```\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9565ca",
   "metadata": {},
   "source": [
    "Then, of course we could run the query by ourselves with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fbfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n",
      "Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e.entity.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             e.entity.name\n",
       "0  Guardians of the Galaxy"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "MATCH (p:`entity`)-[:relationship]->(e:`entity`)\n",
    "  WHERE p.`entity`.`name` == 'Peter Quill'\n",
    "RETURN e.`entity`.`name`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc77cb",
   "metadata": {},
   "source": [
    "Or we changed the return part to whole path, for drawing it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1fe35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n",
      "Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path_0\n",
       "0  (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "MATCH path_0=(p:`entity`)-[:relationship]->(e:`entity`)\n",
    "  WHERE p.`entity`.`name` == 'Peter Quill'\n",
    "RETURN path_0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de504de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nebulagraph_draw.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"nebulagraph_draw.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1504e8f50>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv nebulagraph_draw.html nebulagraph_draw_nl2cypher.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7fe472",
   "metadata": {},
   "source": [
    "### NL2Cypher With Langchain\n",
    "\n",
    "Alternatively, we could do via Langchain **NebulaGraphQAChain**, see [docs](https://python.langchain.com/docs/modules/chains/additional/graph_nebula_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51df174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import NebulaGraphQAChain\n",
    "from langchain.graphs import NebulaGraph\n",
    "\n",
    "graph = NebulaGraph(\n",
    "    space=space_name,\n",
    "    username=\"root\",\n",
    "    password=\"nebula\",\n",
    "    address=\"127.0.0.1\",\n",
    "    port=9669,\n",
    "    session_pool_size=30,\n",
    ")\n",
    "\n",
    "chain = NebulaGraphQAChain.from_llm(\n",
    "    llm, graph=graph, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afe26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Generated nGQL:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "MATCH (p:`entity`)-[e:relationship]->(m:`entity`) WHERE p.`entity`.`name` == 'Peter Quill' RETURN p.`entity`.`name`, e.relationship, m.`entity`.`name`;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m{'p.entity.name': ['Peter Quill'], 'e.relationship': ['is leader of'], 'm.entity.name': ['Guardians of the Galaxy']}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Peter Quill is the leader of the Guardians of the Galaxy.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\n",
    "    \"Tell me about Peter Quill?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c306e4be",
   "metadata": {},
   "source": [
    "## Graph RAG\n",
    "\n",
    "Apart from the NL2Cypher fashion of exploiting KG in QA, especially for complex tasks, we could also do it in the **Retrieval Arguments Generation** way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a4442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import load_index_from_storage\n",
    "\n",
    "storage_context_graph = StorageContext.from_defaults(persist_dir='./storage_graph', graph_store=graph_store)\n",
    "kg_index_new = load_index_from_storage(\n",
    "    storage_context=storage_context_graph,\n",
    "    service_context=service_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1bb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_rag_query_engine = kg_index_new.as_query_engine(\n",
    "    include_text=False,  \n",
    "    retriever_mode='keyword',\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100395cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.knowledge_graph.retriever:> Starting query: Tell me about Peter Quill?\n",
      "> Starting query: Tell me about Peter Quill?\n",
      "INFO:llama_index.indices.knowledge_graph.retriever:> Query keywords: ['biography', 'Peter Quill', 'Peter', 'Quill', 'information']\n",
      "> Query keywords: ['biography', 'Peter Quill', 'Peter', 'Quill', 'information']\n",
      "INFO:llama_index.indices.knowledge_graph.retriever:> Extracted relationships: The following are knowledge triplets in max depth 2 in the form of `subject [predicate, object, predicate_next_hop, object_next_hop ...]`\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'released in', '2014']\n",
      "Peter Quill ['portrays', 'Peter Quill']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'reprised role from', 'Guardians of the Galaxy']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'directed', 'Guardians of the Galaxy']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'wrote', 'Guardians of the Galaxy']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'sequel to', 'Guardians of the Galaxy']\n",
      "Quill ['speaks', ' fuck ']\n",
      "> Extracted relationships: The following are knowledge triplets in max depth 2 in the form of `subject [predicate, object, predicate_next_hop, object_next_hop ...]`\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'released in', '2014']\n",
      "Peter Quill ['portrays', 'Peter Quill']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'reprised role from', 'Guardians of the Galaxy']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'directed', 'Guardians of the Galaxy']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'wrote', 'Guardians of the Galaxy']\n",
      "Peter Quill ['is leader of', 'Guardians of the Galaxy', 'sequel to', 'Guardians of the Galaxy']\n",
      "Quill ['speaks', ' fuck ']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Peter Quill is the leader of the Guardians of the Galaxy, a superhero team released in 2014. He portrays the character of Peter Quill and reprised his role from the Guardians of the Galaxy. He was also the director and writer of the Guardians of the Galaxy and its sequel. Quill is known to speak with profanity.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = kg_rag_query_engine.query(\n",
    "    \"Tell me about Peter Quill?\"\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c453a760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n",
      "Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})&lt;-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path0\n",
       "0   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "1   (\"Peter Quill\" :entity{name: \"Peter Quill\"})<-...\n",
       "2   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "3   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "4   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "5   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "6   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "7   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "8   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "9   (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[...\n",
       "10  (\"Peter Quill\" :entity{name: \"Peter Quill\"})-[..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "MATCH path0=(p:`entity`)-[*1..2]-() WHERE p.`entity`.`name` == 'Peter Quill'\n",
    "RETURN path0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014418d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nebulagraph_draw.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"nebulagraph_draw.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15040df10>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv nebulagraph_draw.html nebulagraph_draw_rag.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

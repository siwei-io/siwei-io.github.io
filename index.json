[{"categories":["Nebula Graph"],"content":"图技术在大型、复杂基础设施之中 SRE/DevOps 的实践参考，本文以 OpenStack 系统之上的图数据库增强的运维案例为例，揭示图数据库、图算法的智能运维方法，全流程示例代码开源。","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/"},{"categories":["Nebula Graph"],"content":" 图技术在大型、复杂基础设施之中 SRE/DevOps 的实践参考，本文以 OpenStack 系统之上的图数据库增强的运维案例为例，揭示图数据库、图算法的智能运维方法，全流程示例代码开源。 因为有一些还未采用图技术的 DevOps/Infra 领域同学在 NebulaGraph 社区询问参考的案例，我最近试着实践了一下如何利用图的能力与优势去帮助在复杂基础设施上构建辅助运维系统，希望能帮助到感兴趣 Infra Ops 领域、同时感兴趣图数据库、图算法的大家，全过程都是可以复现、并且开源的。 复杂的基础设施运维环境通常包含非常多、不同层面的资源（manifest)，为了能够尽量还原真实世界的复杂环境、又保持这个实例项目的复杂度不会失控，我选择了用一个基础设施平台：OpenStack 作为例子。 本文实现了 OpenStack 系统上分别利用 Push 和 Pull 两种模式将资源之中被图谱建模的图中点、边信息加载到 NebulaGraph 里的 Graph ETL 管道的路径。 在图谱之上，本文探索如下用例： 告警、状态的推理与传导； 网络直连与互联关系； 镜像、云盘、快照血缘管理； 高相关性虚机预警； 秘钥泄漏的图上风控分析； 镜像、云盘漏洞范围分析； 宿主机逃离影响范围分析； 脆弱依赖资源检测； ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:0:0","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#"},{"categories":["Nebula Graph"],"content":" 1 试验环境搭建","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:1:0","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#试验环境搭建"},{"categories":["Nebula Graph"],"content":" 1.1 背景知识OpenStack 是一个开源的云计算平台，提供了类似于 AWS 的云服务。它提供了一组可插拔的模块，包括了计算，存储和网络等功能，可以帮助用户构建和管理云环境。OpenStack采用分布式架构，支持多种操作系统和硬件平台，可以在企业级和服务提供商级环境中使用。 最初由 NASA 和 Rackspace Inc. 发起的 nova （虚拟化计算项目）和 swift （兼容 S3 的对象存储）项目组成，OpenStack 现在由非常多不同的子项目组成： 本实验中，我们设计的 OpenStack 主要项目有： Nova 是 OpenStack 的计算服务，用于管理虚拟机。 Cinder 是 OpenStack 的块存储服务，用于管理云存储。 Neutron 是 OpenStack 的网络服务，用于管理云网络。 Glance 是 OpenStack 的镜像服务，用于管理云镜像。 Horizon 是 OpenStack 的可视化控制台服务。 除此之外，我还引入了 Vitrage 项目辅助我们收集部分资源数据： Vitrage 是 OpenStack 中的一个高级分析和可视化工具，用于分析和可视化 OpenStack 环境中的资源和事件。它可以汇集来自 OpenStack 各个服务的数据，并使用图形化方式展示出来。Vitrage 发现和诊断问题，提高 OpenStack 环境的可用性和可维护性。 得益于 OpenStack Decouple 的设计理念，Vitrage 可以很容易、无侵入式（只需要修改需要收集的服务两行配置）就可以在 OpenStack 的消息队列中订阅资源信息的 push 消息。 不过比较遗憾的是 Vitrage 这个项目已经有好多个 release cycle 没有什么大的更新了，应该是比较不活跃的状态了，比如在 zed 里，它的 Vitrage Dashboard 作为 Horizon 插件已经无法正常工作了，本实验只利用它的资源收集能力。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:1:1","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#背景知识"},{"categories":["Nebula Graph"],"content":" 1.2 环境准备搭建 1.2.1 NebulaGraph 集群首次快速试玩安装 NebulaGraph 的话，有这么几个选项： 阿里云上的 NebulaGraph 企业版（带有企业版独有的满血版可视化工具：Explorer，可以图探索、画布内跑图算法），可以获得一个月所有资源免费使用资格： 访问 https://www.siwei.io/try-aliyun 获得 Nebula-Up 一键安装 NebulaGraph 开源社区版本，需要一个带有 Docker、Docker Desktop 环境的机器 访问 https://github.com/wey-gu/nebula-up 有经验的同学可以参考文档进行部署： 访问 https://docs.nebula-graph.com.cn/ 1.2.2 OpenStack 集群 注意：如果大家已经有现成的 OpenStack 集群，这一步可以忽略，您只需要再去安装 OpenStack Vitrage 就好了。 本文需要的 OpenStack 集群是一个多机的环境，为此，我准备了在 Linux Server 上利用 Libvirt 和 Linux Bridge 搭建多个虚拟机用来模拟 OpenStack 的物理机，得益于 CPU 的嵌套虚拟化和 qemu，后边我们完全可以在虚拟机搭建的实验环境中模拟可正常工作的 OpenStack nova instance 虚机。 整个流程我都放在 https://github.com/wey-gu/openstack-graph/#environment-setup 这里了，感兴趣的同学可以访问、获取。 虚拟机搭建之后，我们还需要模拟真实的 Infra 环境，创建很多资源：整个过程也在 https://github.com/wey-gu/openstack-graph/#create-resources-on-openstack 有详细列出，想要动手操作的同学可以参考来亲自上手一下。 参考如上步骤操作之后，我们应该可以通过 Horizon Dashboard 查看集群和资源： 我们创建了几个虚拟机： 几个网盘，其中四个挂载在不同的虚拟机上 集群租户的网络拓扑： 我们还能通过 OpenStack Vitrage 的 API/CLI 获得部分主要资源的拓扑： source openrc admin admin vitrage topology show --all-tenants 它的结果是一个 JSON，里边已经按照边（links）和点（nodes）序列化图结构的数据了。 { \"directed\": true, \"graph\": {}, \"links\": [ { \"vitrage_is_deleted\": false, \"relationship_type\": \"contains\", \"source\": 0, \"target\": 11, \"key\": \"contains\" }, { \"vitrage_is_deleted\": false, \"relationship_type\": \"contains\", \"source\": 0, \"target\": 13, \"key\": \"contains\" }, ... { \"vitrage_is_deleted\": false, \"relationship_type\": \"attached\", \"source\": 27, \"target\": 28, \"key\": \"attached\" } ], \"multigraph\": true, \"nodes\": [ { \"id\": \"node0\", \"vitrage_type\": \"nova.host\", \"vitrage_category\": \"RESOURCE\", \"vitrage_is_deleted\": false, \"update_timestamp\": \"2023-01-13T08:06:48Z\", \"vitrage_sample_timestamp\": \"2023-01-13T08:06:49Z\", \"vitrage_is_placeholder\": false, \"vitrage_id\": \"630b4c2c-5347-4073-91a3-255ec18dadfc\", \"name\": \"node0\", \"vitrage_cached_id\": \"d043d278a6a712909e30e50ca8ec2364\", \"is_real_vitrage_id\": true, \"vitrage_aggregated_state\": \"AVAILABLE\", \"vitrage_operational_state\": \"OK\", \"vitrage_datasource_name\": \"nova.host\", \"state\": \"available\", \"graph_index\": 0 }, { \"id\": \"nova\", \"vitrage_type\": \"nova.zone\", \"vitrage_category\": \"RESOURCE\", \"vitrage_is_deleted\": false, \"vitrage_sample_timestamp\": \"2023-01-12T03:06:48Z\", \"vitrage_is_placeholder\": false, \"vitrage_id\": \"a1e9c808-dac8-4b59-8f80-f21a90e9869d\", \"vitrage_cached_id\": \"125f1d8c4451a6385cc2cfa2b0ba45be\", \"is_real_vitrage_id\": true, \"vitrage_aggregated_state\": \"AVAILABLE\", \"vitrage_operational_state\": \"OK\", \"state\": \"available\", \"update_timestamp\": \"2023-01-12T03:06:48Z\", \"name\": \"nova\", \"vitrage_datasource_name\": \"nova.zone\", \"graph_index\": 1 }, ... \"raw\": true } ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:1:2","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#环境准备搭建"},{"categories":["Nebula Graph"],"content":" 1.2 环境准备搭建 1.2.1 NebulaGraph 集群首次快速试玩安装 NebulaGraph 的话，有这么几个选项： 阿里云上的 NebulaGraph 企业版（带有企业版独有的满血版可视化工具：Explorer，可以图探索、画布内跑图算法），可以获得一个月所有资源免费使用资格： 访问 https://www.siwei.io/try-aliyun 获得 Nebula-Up 一键安装 NebulaGraph 开源社区版本，需要一个带有 Docker、Docker Desktop 环境的机器 访问 https://github.com/wey-gu/nebula-up 有经验的同学可以参考文档进行部署： 访问 https://docs.nebula-graph.com.cn/ 1.2.2 OpenStack 集群 注意：如果大家已经有现成的 OpenStack 集群，这一步可以忽略，您只需要再去安装 OpenStack Vitrage 就好了。 本文需要的 OpenStack 集群是一个多机的环境，为此，我准备了在 Linux Server 上利用 Libvirt 和 Linux Bridge 搭建多个虚拟机用来模拟 OpenStack 的物理机，得益于 CPU 的嵌套虚拟化和 qemu，后边我们完全可以在虚拟机搭建的实验环境中模拟可正常工作的 OpenStack nova instance 虚机。 整个流程我都放在 https://github.com/wey-gu/openstack-graph/#environment-setup 这里了，感兴趣的同学可以访问、获取。 虚拟机搭建之后，我们还需要模拟真实的 Infra 环境，创建很多资源：整个过程也在 https://github.com/wey-gu/openstack-graph/#create-resources-on-openstack 有详细列出，想要动手操作的同学可以参考来亲自上手一下。 参考如上步骤操作之后，我们应该可以通过 Horizon Dashboard 查看集群和资源： 我们创建了几个虚拟机： 几个网盘，其中四个挂载在不同的虚拟机上 集群租户的网络拓扑： 我们还能通过 OpenStack Vitrage 的 API/CLI 获得部分主要资源的拓扑： source openrc admin admin vitrage topology show --all-tenants 它的结果是一个 JSON，里边已经按照边（links）和点（nodes）序列化图结构的数据了。 { \"directed\": true, \"graph\": {}, \"links\": [ { \"vitrage_is_deleted\": false, \"relationship_type\": \"contains\", \"source\": 0, \"target\": 11, \"key\": \"contains\" }, { \"vitrage_is_deleted\": false, \"relationship_type\": \"contains\", \"source\": 0, \"target\": 13, \"key\": \"contains\" }, ... { \"vitrage_is_deleted\": false, \"relationship_type\": \"attached\", \"source\": 27, \"target\": 28, \"key\": \"attached\" } ], \"multigraph\": true, \"nodes\": [ { \"id\": \"node0\", \"vitrage_type\": \"nova.host\", \"vitrage_category\": \"RESOURCE\", \"vitrage_is_deleted\": false, \"update_timestamp\": \"2023-01-13T08:06:48Z\", \"vitrage_sample_timestamp\": \"2023-01-13T08:06:49Z\", \"vitrage_is_placeholder\": false, \"vitrage_id\": \"630b4c2c-5347-4073-91a3-255ec18dadfc\", \"name\": \"node0\", \"vitrage_cached_id\": \"d043d278a6a712909e30e50ca8ec2364\", \"is_real_vitrage_id\": true, \"vitrage_aggregated_state\": \"AVAILABLE\", \"vitrage_operational_state\": \"OK\", \"vitrage_datasource_name\": \"nova.host\", \"state\": \"available\", \"graph_index\": 0 }, { \"id\": \"nova\", \"vitrage_type\": \"nova.zone\", \"vitrage_category\": \"RESOURCE\", \"vitrage_is_deleted\": false, \"vitrage_sample_timestamp\": \"2023-01-12T03:06:48Z\", \"vitrage_is_placeholder\": false, \"vitrage_id\": \"a1e9c808-dac8-4b59-8f80-f21a90e9869d\", \"vitrage_cached_id\": \"125f1d8c4451a6385cc2cfa2b0ba45be\", \"is_real_vitrage_id\": true, \"vitrage_aggregated_state\": \"AVAILABLE\", \"vitrage_operational_state\": \"OK\", \"state\": \"available\", \"update_timestamp\": \"2023-01-12T03:06:48Z\", \"name\": \"nova\", \"vitrage_datasource_name\": \"nova.zone\", \"graph_index\": 1 }, ... \"raw\": true } ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:1:2","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#nebulagraph-集群"},{"categories":["Nebula Graph"],"content":" 1.2 环境准备搭建 1.2.1 NebulaGraph 集群首次快速试玩安装 NebulaGraph 的话，有这么几个选项： 阿里云上的 NebulaGraph 企业版（带有企业版独有的满血版可视化工具：Explorer，可以图探索、画布内跑图算法），可以获得一个月所有资源免费使用资格： 访问 https://www.siwei.io/try-aliyun 获得 Nebula-Up 一键安装 NebulaGraph 开源社区版本，需要一个带有 Docker、Docker Desktop 环境的机器 访问 https://github.com/wey-gu/nebula-up 有经验的同学可以参考文档进行部署： 访问 https://docs.nebula-graph.com.cn/ 1.2.2 OpenStack 集群 注意：如果大家已经有现成的 OpenStack 集群，这一步可以忽略，您只需要再去安装 OpenStack Vitrage 就好了。 本文需要的 OpenStack 集群是一个多机的环境，为此，我准备了在 Linux Server 上利用 Libvirt 和 Linux Bridge 搭建多个虚拟机用来模拟 OpenStack 的物理机，得益于 CPU 的嵌套虚拟化和 qemu，后边我们完全可以在虚拟机搭建的实验环境中模拟可正常工作的 OpenStack nova instance 虚机。 整个流程我都放在 https://github.com/wey-gu/openstack-graph/#environment-setup 这里了，感兴趣的同学可以访问、获取。 虚拟机搭建之后，我们还需要模拟真实的 Infra 环境，创建很多资源：整个过程也在 https://github.com/wey-gu/openstack-graph/#create-resources-on-openstack 有详细列出，想要动手操作的同学可以参考来亲自上手一下。 参考如上步骤操作之后，我们应该可以通过 Horizon Dashboard 查看集群和资源： 我们创建了几个虚拟机： 几个网盘，其中四个挂载在不同的虚拟机上 集群租户的网络拓扑： 我们还能通过 OpenStack Vitrage 的 API/CLI 获得部分主要资源的拓扑： source openrc admin admin vitrage topology show --all-tenants 它的结果是一个 JSON，里边已经按照边（links）和点（nodes）序列化图结构的数据了。 { \"directed\": true, \"graph\": {}, \"links\": [ { \"vitrage_is_deleted\": false, \"relationship_type\": \"contains\", \"source\": 0, \"target\": 11, \"key\": \"contains\" }, { \"vitrage_is_deleted\": false, \"relationship_type\": \"contains\", \"source\": 0, \"target\": 13, \"key\": \"contains\" }, ... { \"vitrage_is_deleted\": false, \"relationship_type\": \"attached\", \"source\": 27, \"target\": 28, \"key\": \"attached\" } ], \"multigraph\": true, \"nodes\": [ { \"id\": \"node0\", \"vitrage_type\": \"nova.host\", \"vitrage_category\": \"RESOURCE\", \"vitrage_is_deleted\": false, \"update_timestamp\": \"2023-01-13T08:06:48Z\", \"vitrage_sample_timestamp\": \"2023-01-13T08:06:49Z\", \"vitrage_is_placeholder\": false, \"vitrage_id\": \"630b4c2c-5347-4073-91a3-255ec18dadfc\", \"name\": \"node0\", \"vitrage_cached_id\": \"d043d278a6a712909e30e50ca8ec2364\", \"is_real_vitrage_id\": true, \"vitrage_aggregated_state\": \"AVAILABLE\", \"vitrage_operational_state\": \"OK\", \"vitrage_datasource_name\": \"nova.host\", \"state\": \"available\", \"graph_index\": 0 }, { \"id\": \"nova\", \"vitrage_type\": \"nova.zone\", \"vitrage_category\": \"RESOURCE\", \"vitrage_is_deleted\": false, \"vitrage_sample_timestamp\": \"2023-01-12T03:06:48Z\", \"vitrage_is_placeholder\": false, \"vitrage_id\": \"a1e9c808-dac8-4b59-8f80-f21a90e9869d\", \"vitrage_cached_id\": \"125f1d8c4451a6385cc2cfa2b0ba45be\", \"is_real_vitrage_id\": true, \"vitrage_aggregated_state\": \"AVAILABLE\", \"vitrage_operational_state\": \"OK\", \"state\": \"available\", \"update_timestamp\": \"2023-01-12T03:06:48Z\", \"name\": \"nova\", \"vitrage_datasource_name\": \"nova.zone\", \"graph_index\": 1 }, ... \"raw\": true } ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:1:2","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#openstack-集群"},{"categories":["Nebula Graph"],"content":" 2 图谱建模本实验环境中，我们考虑纳入如下资源进入图谱： nova instance: 是Nova服务中的虚拟机实例，每个nova instance都有自己的配置信息（如CPU、内存、磁盘等），有时候我们就叫它 server 或者 VM、虚机。 nova host是Nova服务中的物理主机，是nova instance运行的物理环境。nova host上面会运行nova-compute服务，这个服务负责管理和调度nova instance。nova host上面还可能运行其他服务，如网络服务等。 nova keypair: 是Nova服务中的密钥对，用于访问nova instance cinder volume: 是Cinder服务中的云存储卷，可以 attach 到nova instance上做为硬盘 cinder snapshot: 是Cinder服务中的云存储快照，可以在cinder volume上做快照 glance image: 是Glance服务中的镜像，可以作为创建nova instance时候的启动硬盘 neutron network: 是Neutron服务中的网络，可以用于配置nova instance的网络连接 neutron port: 是Neutron服务中的端口，用来连接nova instance和neutron network之间，在 nova instance 虚拟机上，一个 port 常常对应一个网卡（如果不是 trunk port 的话）。 他们之间的关系如下： ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:2:0","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#图谱建模"},{"categories":["Nebula Graph"],"content":" 3 基础设施图 ETL接下来我们解决从基础设施中抽取资源元数据的问题， ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:3:0","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#基础设施图-etl"},{"categories":["Nebula Graph"],"content":" 3.1 push 模式这里的 push 指的是基础设施为主语，从资源方向我们的图谱系统主动、事件驱动地发出资源变动的信息。它的好处是资源中的实时性好，但是坏处是依赖基础设施自身，很多非常瘦的、软件定义/可编程程度不高的组件、比如某些硬件设备没有 push 机制，或者像是古老的软件系统不一定能存在 push 的接口，改造起来有侵入性。 前边提及过，OpenStack 自身是存在 Push hook 的机制的，它的子项目 vitrage 就利用这个机制很优雅地收集系统资源、告警等信息进入图中，类似的机制在其他平台中也是可以实现的。 本实验中我们就利用 vitrage 的机制去收集一部分图谱中的资源信息，如下图，可以看到 vitrage 会在 OpenStack message bus 中订阅 nova/cinder/neutron 等服务中的资源时间，把事件传入 Entity Queue，经过处理，存储到 Entity Graph 中。 在此之上，我们可以通过 vitrage API 获取图谱的拓扑，来消费它。 注意：实际上 Vitrage 服务还提供了推理告警、推理状态、定义决策事件的能力，这里我们并没有采用，后边我们在图上做的一些事情甚至还和它的能力有一些重叠。 这里我只是用它来展示 push 模式的工作机制，如果没有 Virtrage 这个项目存在，我们也可以比较容易通过 OpenStack 的 oslo.messaging 这个库很容易写出在 Message Bus（可能是 Kafka, RabbitMQ 等不同底层实现）上订阅资源时间的应用，然后把事件通过 Flink/ Kafka/ Pulsar 等方式接驳 NebulaGraph。 因为 Vitrage 的存在，我就偷懒不用去实现这部分逻辑，只消写一小部分代码调用 Vitrage API 取这个数据就可以了，讽刺的是，从这个角度来看，这其实是一种 pull 的模式了，不用拘泥它本质上算是哪一种方式，至少在资源发起测，我们把它当做 push 模式的例子看待吧。 这部分从 Vitrage 抓取的代码我放在 https://github.com/wey-gu/openstack-graph/blob/main/utils/vitrage_to_graph.py 了，调用方式很简单，在有 OpenStack 客户端的环境中，执行它就可以了，比如： # 连到 node0 上 ssh stack@node0_ip # 进入 devstack 目录 cd devstack # 下载 vitrage 中图数据，解析为 NeublaGraph DML/DQL 的工具 wget https://raw.githubusercontent.com/wey-gu/openstack-graph/main/utils/vitrage_to_graph.py # 执行它 python3 vitrage_to_graph.py 执行之后，会生成如下文件： schema.ngql 图数据的 Schema 定义 vertices/ 点数据的文件夹 edges/ 边数据的文件夹 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:3:1","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#push-模式"},{"categories":["Nebula Graph"],"content":" 3.2 pull 模式反过来，pull 模式是从资源外部定期或者事件驱动地拉取资源，存入图谱的方式。刚好本实验中 vitrage 抓取的资源是有限的，有一些额外的资源我单独写了 python 的代码来主动全量抓取，pull 模式的好处是对资源方没有任何侵入性，只需要调用它的接口获取信息就可以了，坏处则是有的系统不太容易获得增量变化，可能只能全量去取。 这部分我抓取的关系如下： glance_used_by: image -[:used_by]-\u003e instance (get from instance) glance_created_from: image -[:created_from]-\u003e volume (get from image) nova_keypair_used_by: keypair -[:used_by]-\u003e instance (get from instance) cinder_snapshot_created_from: volume snapshot -[:created_from]-\u003e volume (get from snapshot) cinder_volume_created_from: volume -[:created_from]-\u003e volume snapshot (get from volume) cinder_volume_created_from: volume -[:created_from]-\u003e image (get from volume) 类似的，它的代码放在 https://github.com/wey-gu/openstack-graph/blob/main/utils/pull_resources_to_graph.py 之中，在真实场景下，我们可能会用 Apache Airflow、dagster 甚至是 cron job 等方式定期执行它。 我们手动执行的方式也很简单： # 连到 node0 上 ssh stack@node0_ip # 进入 devstack 目录 cd devstack # 下载抓取 OpenStack 资源，生成 NeublaGraph DML/DQL 的工具 wget https://raw.githubusercontent.com/wey-gu/openstack-graph/main/utils/pull_resources_to_graph.py.py # 执行它 python3 pull_resources_to_graph.py 执行之后，会生成点、边的 ngql 语句在两个文件夹下： vertices/ 点数据的文件夹 edges/ 边数据的文件夹 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:3:2","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#pull-模式"},{"categories":["Nebula Graph"],"content":" 3.3 加载数据到 NebulaGraph我们只需要在 NebulaGraph Studio Console, Explorer Console 或者 NebulaGraph 命令行 Console 中执行上边生成的 .ngql 文件就好了： # DDL from vitrage cat schema.ngql # DDL and DML for both push and pull mode data cat edges/*.ngql cat vertices/*.ngql 之后，在 NebulaGraph 中我们会有一个叫做 openstack 的图空间，用这个查询可以查到所有数据： MATCH (n) WITH n LIMIT 1000 OPTIONAL MATCH p=(n)--() RETURN p, n 然后渲染在 explorer 中，手动设置一下数据的图标，就可以看到我们 OpenStack 集群里的所有租户的资源图了： 接下来我们终于可以在图上看看有意思的洞察了。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:3:3","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#加载数据到-nebulagraph"},{"categories":["Nebula Graph"],"content":" 4 基于图谱的基础设施运维示例作为非 SRE、DevOps 人员，我尝试藉由自己在 OpenStack 和图技术的理解想象出下边的一些实例，希望能帮助到需要的读者们。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:0","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#基于图谱的基础设施运维示例"},{"categories":["Nebula Graph"],"content":" 4.1 告警、状态的推理与传导这部分我收到了 vitrage 项目的启发，参考它们给出的实例文档：这里。 借助资源图谱实时图查询、图计算甚至图可视化能力，我们可以在图上推理、传导一些信息，把重要的时间藉由图上组织好的知识分发到需要收到通知的人、组织、系统。 一个简单的例子是，比如我们在 nova host（虚拟机的宿主机、hypervisor 机器，以下简称宿主机），中获得了一个告警、事件的时候，可能是网卡失败、物理硬盘预警、CPU占用过高之类的告警。我们可以借助图谱查询获得所有相关联的虚机，然后把（WARN）级别的告警发出去或者设置它们为（亚健康）的状态。 这样，获得通知的对象，往往是一些用户的系统，就可以根据他们预先定义好的策略做一些自动化运维，或者通知的 hook： 收到“宿主机 CPU 过高”的告警的情形下，可以根据用户自己设定的不同策略把虚机迁移走，或者更高级复杂的撤离方式（开始不接受新的 traffic，创建新的替代 workload，然后 gracefully 关闭这个 workload） “控制面网络故障”告警情况下，这时候往往无法成功进行主机的车里、迁移，故可以考虑触发备份主机、启动新 workload、关机 其他“（亚健康）状态”，可以作为负载层面出问题的根因分析（RCA）依据 下边，我们给出一个在图谱上进行告警、状态传导的查询例子，我们假设 vid 为 node0 的宿主机出现了高 CPU 的告警，则这个查询可以得到所有其上的虚机，获得时间、告警通知列表： MATCH (vm:nova_instance)\u003c-[:`contains`]-(host_CPU_high:nova_host) WHERE id(host_CPU_high) == \"node0\" RETURN vm.nova_instance.name AS VM_to_raise_CPU_alarms 这其中查询的图模式是从 host_CPU_high 这个 nova_host 向外经由 contains 这个关系指向 vm 这个 nova_instance 的： (vm:nova_instance)\u003c-[:`contains`]-(host_CPU_high:nova_host) 它的结果是： VM_to_raise_CPU_alarms server-4 server-3 server-1 server-0 如果我们把查询改动一下，选择输出全路径，则可以看到这个信息传导的方向： MATCH p=(vm:nova_instance)\u003c-[:`contains`]-(host_CPU_high:nova_host) WHERE id(host_CPU_high) == \"node0\" RETURN p 在 Explorer 中渲染，点击 N 跳检测： 第一个例子比较简单，甚至不是很有必要用图的能力（这种因为一跳查询表结构中也是很轻松地，我们用一两个 nova API call 就可以搞定等价的信息获取了），这里只是一个例子，实际上我们在图上可以做很多更 Graphy（具有图属性的）、复杂、独特的工作，我们慢慢来看。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:1","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#告警状态的推理与传导"},{"categories":["Nebula Graph"],"content":" 4.2 网络可达检测我们来考虑这样的场景，在 OpenStack 中，不同的主机可以连接到相同的子网（VPC），主机也可以连接到多个子网之中，这样，主机之间的网络连通性信息、与网络联通相关的推理、传导都可以在图上进行。 注：在真实世界中，这里可能还要考虑 Security Group、Router、Switch 等因素，本利中我们用到的 OpenStack 是 L2 only 的 Setup，比较简化。 获得与虚机 server_a 同一 VPC 的所有其他虚机看起来很容易表达了： MATCH (server_a)--(:neutron_port)--(:neutron_network)--(:neutron_port)--(server_b:`nova_instance`) WHERE id(server_a) == \"server-0\" RETURN server_b.nova_instance.name AS L2_connected_server 结果如下： L2_connected_server server-1 看起来很初级呀，接下来我们再查询与虚机 server_a 同一 VPC、或者有可能通过跨网络虚机而互联的主机的所有其他虚机，这时候，我们除了共享 neutron network(VPC) 的情况，还要查询所有二层直连的虚机可能通过其他 VPC 连出去的的虚机，这里，我们用到了 OPTIONAL MATCH 的表达，表示可能匹配到的模式： MATCH (server_a)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:`nova_instance`) WHERE id(server_a) == \"server-0\" OPTIONAL MATCH (server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:`nova_instance`) WITH server_a, server_b AS same_subnet_machines, server_c AS routeable_machines WHERE routeable_machines != server_a RETURN same_subnet_machines.nova_instance.name AS L2_connected_server, routeable_machines.nova_instance.name AS cross_vpc_server 可以看到结果里，跨网络潜在的相连主机还有 server-3： L2_connected_server cross_vpc_server server-1 server-3 我们将其可视化，同样，修改输出为路径 p 和 p1。 MATCH p=(server_a)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:`nova_instance`) WHERE id(server_a) == \"server-0\" OPTIONAL MATCH p1=(server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:`nova_instance`) RETURN p, p1 它可能的连接路径一目了然 有了获得这些信息的能力，我们可以可编程地连接告警、状态、安全风控、网络等方方面面系统了，因为这不是本文的重点，这里就不加以赘述了，欢迎大家来 NebulaGraph 社区分享你们的图洞察使用方式。 接下来我们来看看存储相关的例子。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:2","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#网络可达检测"},{"categories":["Nebula Graph"],"content":" 4.3 镜像、云盘、快照的血缘在基础设施中，云盘（iSCSI、Ceph、NFS）、镜像、快照之间有多重复杂的关系，比如： 一个系统镜像可能从某一个虚拟机挂载的云盘或者一个快照创建 一个云盘可能是从一个系统镜像、一个快照或者另一个云盘创建 一个快照是从一个云盘创建的 这种血缘信息的识别和管理是很有必要的。下边的查询可以获得给定的虚机 server-0 的所有存储血缘： MATCH p=(server_a)-[:`attached`|created_from|used_by]-(step1) WHERE id(server_a) == \"server-0\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 我们可以看到结果中： server-0 的启动镜像（这里它是从本地盘启动的，没有挂载云盘）是从 volume-1 创建的 volume-1 是从 cirros-0.5.2-x86_64-disk 这个镜像创建的 此外，还有其他有分叉关系的存储资源和他们也息息相关 接下来，我们不只考虑存储资源，再看看涉及云盘（cinder_volume）挂载（attached）这层关系下的血缘关系： MATCH p=(server_a)-[:`attached`|created_from|used_by]-(step1) WHERE id(server_a) == \"server-4\" OPTIONAL MATCH p1=(step1)-[:created_from|attached*1..5]-(step2) RETURN p, p1 这次，我们可以从渲染图中读出这样的洞察： server-4 的启动镜像（这里它是从本地盘启动的）是从 volume-1 创建的 而 volume-1 现在挂载在 server-6 上 volume-1 是从 cirros-0.5.2-x86_64-disk 这个镜像创建的 同样 cirros-0.5.2-x86_64-disk 镜像被很多其他虚机在采用 server-4 同时挂载了数据盘 volume-2 而 volume-2 是一个多挂载的盘，它同时挂载在 server-3 之上 server-3 的系统启动盘是从快照 snapshot-202301111800-volume-1 克隆创建的 快照 snapshot-202301111800-volume-1 是曾经从 volume-1 创建的 volume-1 现在挂载在 server-6 上 快照不一定是从 server-6 而来，因为镜像可能被重新挂载过 而这些血缘信息可以被用在资源生命周期管理、根因分析、安全告警、状态传导上，这里不加以赘述。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:3","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#镜像云盘快照的血缘"},{"categories":["Nebula Graph"],"content":" 4.4 高相关性虚机预警下面再给一个节点相似度的应用，我们可以在全图或者子图上，利用图算法找到与一个虚机在图上关系的维度上最相似的其他虚机，基于在这种相关性增加新的关系，并在关系上做风险事件预警。 这次的图算法应用中，我们按照一个典型的从[快速子图验证]到[全图生产应用的]工作流。 4.4.1 在子图上快速验证：浏览器内算法首先，我们试着从 server-0 的三度子图上做算法的验证。 GET SUBGRAPH 3 STEPS FROM \"server-0\" YIELD VERTICES AS nodes, EDGES AS relationships; 将结果渲染在画布上，我们可以看到子图中包含了其他几个虚机： 然后，我们利用 explorer 中的浏览器内图算法，可以非常方便地验证我们的想法，这里，我们使用 Jaccard SImilarity 相似性算法，进行 server-0 与 server-1,server-3,server-4,server-6 迭代分别得到相似性： 可以看出，在 3 步子图内，和 server-0 最近接的虚机是 server-4。进一步我们可以简单在子图上看看两者之间的路径作为相似性的解释： 在这个可解释结果中，我们知道 server-0 与 server-4 相似的原因可能是： 坐落在同一个宿主机：node-0 使用同一个镜像：cirros_mod_from_volume-1 如此，我们最终落地的预警机制可能是，当 server-0 出现某一问题、告警时候，给相似的 server-4 也设定预警，预警理由就是它们在同样主机、同样镜像。 4.4.2 落地算法为应用：Workflow+Analytics有了前边的快速实验，我们可以借助 workflow + NebulaGraph Analytics 把它落地为全图上的算法，利用 Analytics 分布式能力去执行。 在生产上，我们利用 Workflow 的 DAG 编排能力创建两个前后相连的任务： 取临近虚机 全图算相似度 第一个任务如下，它实时从给定的虚机（这里写死了 server-0，但是 workflow 可以把这里作为参数化，并封装任务为可以被 API 触发的异步服务）： MATCH (n)-[*1..5]-(m:`nova_instance`) WHERE id(n) == \"server-0\" AND n != m RETURN distinct id(m) 这里 Query job 我们输出待比较的其他虚机的 vid。 接着，JaccardSImilarity job 中，我们选择 ids1 为 server-0（这里如上，上线时是参数化的），ids2 从上游取（前边的 Query job），选择在 openstack 全图扫描所有类型的边。 保存、运行，我们可以看到，结果如下，区别是这次它运算了更多的目标虚机，并且迭代作用范围是全图而非一个子图，可以看到结果是一致的，这是因为子图上关联度大的点和相近的边在 Jaccard 算法里起到了更主要的作用。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:4","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#高相关性虚机预警"},{"categories":["Nebula Graph"],"content":" 4.4 高相关性虚机预警下面再给一个节点相似度的应用，我们可以在全图或者子图上，利用图算法找到与一个虚机在图上关系的维度上最相似的其他虚机，基于在这种相关性增加新的关系，并在关系上做风险事件预警。 这次的图算法应用中，我们按照一个典型的从[快速子图验证]到[全图生产应用的]工作流。 4.4.1 在子图上快速验证：浏览器内算法首先，我们试着从 server-0 的三度子图上做算法的验证。 GET SUBGRAPH 3 STEPS FROM \"server-0\" YIELD VERTICES AS nodes, EDGES AS relationships; 将结果渲染在画布上，我们可以看到子图中包含了其他几个虚机： 然后，我们利用 explorer 中的浏览器内图算法，可以非常方便地验证我们的想法，这里，我们使用 Jaccard SImilarity 相似性算法，进行 server-0 与 server-1,server-3,server-4,server-6 迭代分别得到相似性： 可以看出，在 3 步子图内，和 server-0 最近接的虚机是 server-4。进一步我们可以简单在子图上看看两者之间的路径作为相似性的解释： 在这个可解释结果中，我们知道 server-0 与 server-4 相似的原因可能是： 坐落在同一个宿主机：node-0 使用同一个镜像：cirros_mod_from_volume-1 如此，我们最终落地的预警机制可能是，当 server-0 出现某一问题、告警时候，给相似的 server-4 也设定预警，预警理由就是它们在同样主机、同样镜像。 4.4.2 落地算法为应用：Workflow+Analytics有了前边的快速实验，我们可以借助 workflow + NebulaGraph Analytics 把它落地为全图上的算法，利用 Analytics 分布式能力去执行。 在生产上，我们利用 Workflow 的 DAG 编排能力创建两个前后相连的任务： 取临近虚机 全图算相似度 第一个任务如下，它实时从给定的虚机（这里写死了 server-0，但是 workflow 可以把这里作为参数化，并封装任务为可以被 API 触发的异步服务）： MATCH (n)-[*1..5]-(m:`nova_instance`) WHERE id(n) == \"server-0\" AND n != m RETURN distinct id(m) 这里 Query job 我们输出待比较的其他虚机的 vid。 接着，JaccardSImilarity job 中，我们选择 ids1 为 server-0（这里如上，上线时是参数化的），ids2 从上游取（前边的 Query job），选择在 openstack 全图扫描所有类型的边。 保存、运行，我们可以看到，结果如下，区别是这次它运算了更多的目标虚机，并且迭代作用范围是全图而非一个子图，可以看到结果是一致的，这是因为子图上关联度大的点和相近的边在 Jaccard 算法里起到了更主要的作用。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:4","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#在子图上快速验证浏览器内算法"},{"categories":["Nebula Graph"],"content":" 4.4 高相关性虚机预警下面再给一个节点相似度的应用，我们可以在全图或者子图上，利用图算法找到与一个虚机在图上关系的维度上最相似的其他虚机，基于在这种相关性增加新的关系，并在关系上做风险事件预警。 这次的图算法应用中，我们按照一个典型的从[快速子图验证]到[全图生产应用的]工作流。 4.4.1 在子图上快速验证：浏览器内算法首先，我们试着从 server-0 的三度子图上做算法的验证。 GET SUBGRAPH 3 STEPS FROM \"server-0\" YIELD VERTICES AS nodes, EDGES AS relationships; 将结果渲染在画布上，我们可以看到子图中包含了其他几个虚机： 然后，我们利用 explorer 中的浏览器内图算法，可以非常方便地验证我们的想法，这里，我们使用 Jaccard SImilarity 相似性算法，进行 server-0 与 server-1,server-3,server-4,server-6 迭代分别得到相似性： 可以看出，在 3 步子图内，和 server-0 最近接的虚机是 server-4。进一步我们可以简单在子图上看看两者之间的路径作为相似性的解释： 在这个可解释结果中，我们知道 server-0 与 server-4 相似的原因可能是： 坐落在同一个宿主机：node-0 使用同一个镜像：cirros_mod_from_volume-1 如此，我们最终落地的预警机制可能是，当 server-0 出现某一问题、告警时候，给相似的 server-4 也设定预警，预警理由就是它们在同样主机、同样镜像。 4.4.2 落地算法为应用：Workflow+Analytics有了前边的快速实验，我们可以借助 workflow + NebulaGraph Analytics 把它落地为全图上的算法，利用 Analytics 分布式能力去执行。 在生产上，我们利用 Workflow 的 DAG 编排能力创建两个前后相连的任务： 取临近虚机 全图算相似度 第一个任务如下，它实时从给定的虚机（这里写死了 server-0，但是 workflow 可以把这里作为参数化，并封装任务为可以被 API 触发的异步服务）： MATCH (n)-[*1..5]-(m:`nova_instance`) WHERE id(n) == \"server-0\" AND n != m RETURN distinct id(m) 这里 Query job 我们输出待比较的其他虚机的 vid。 接着，JaccardSImilarity job 中，我们选择 ids1 为 server-0（这里如上，上线时是参数化的），ids2 从上游取（前边的 Query job），选择在 openstack 全图扫描所有类型的边。 保存、运行，我们可以看到，结果如下，区别是这次它运算了更多的目标虚机，并且迭代作用范围是全图而非一个子图，可以看到结果是一致的，这是因为子图上关联度大的点和相近的边在 Jaccard 算法里起到了更主要的作用。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:4","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#落地算法为应用workflowanalytics"},{"categories":["Nebula Graph"],"content":" 4.5 安全相关场景基础设施资源中的关联关系和金融、内容系统、电商领域的风控场景有相似的地方，很多场景本质上利用到了图谱关系中的知识，在图库上实时获取这些复杂多跳天然带有可解释性的安全洞察非常适合。 4.5.1 秘钥泄漏风控分析先看一个秘钥泄漏的场景：假设 key-0 被安全部门确定被泄漏了，我们可以在毫秒时间内获得如下查询： 直接采用了密钥的虚机 与采用秘钥的虚机网络直连的机器 与采用秘钥的虚机跨网络相连的机器 MATCH (key_leaked)-[:`used_by`]-\u003e(involved_server:nova_instance)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:nova_instance) WHERE id(key_leaked) == \"key-0\" OPTIONAL MATCH (server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:nova_instance) WITH involved_server, server_b AS same_subnet_machines, server_c AS cross_net_machines WHERE cross_net_machines != involved_server RETURN involved_server.nova_instance.name AS with_key, same_subnet_machines.nova_instance.name AS l2_vms, cross_net_machines.nova_instance.name AS cross_vpc_vms 贴一下部分结果，我们知道 server-4 采用了这个 keypair，并且 server-6 和它在同一个网络，同时，有一定可能，通过 server-6，server-1,2,0,5 也受到了威胁、影响，相关的机器可以被触发不同级别的告警来降低安全事故的影响。 with_key l2_vms cross_vpc_vms server-4 server-6 server-1 server-4 server-6 server-2 server-4 server-6 server-0 server-4 server-6 server-5 这个查询改造为可视化结果： MATCH p=(key_leaked)-[:`used_by`]-\u003e(involved_server:nova_instance)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:nova_instance) WHERE id(key_leaked) == \"key-0\" OPTIONAL MATCH p1=(server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:nova_instance) RETURN p,p1 在 explorer 里 应用 Dagre-LR 的布局，一关联关系很清晰的被展示出来，也许可以考虑把它引用在安全事故的报告分发给虚机租户。 4.5.2 镜像、云盘漏洞范围分析类似的，一个镜像被扫出漏洞，我们可以瞬间查到涉及到的资源，并做出相应 镜像文件有漏洞 MATCH p=(image_risky)-[:`created_from`]-(step1) WHERE id(image_risky) == \"cirros-0.5.2-x86_64-disk\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 一个云盘有漏洞 MATCH p=(volume_risky)-[:`created_from`]-(step1) WHERE id(volume_risky) == \"volume-1\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 4.5.3 潜在宿主机逃离影响范围分析最后，我们讨论一个比较严重的安全问题：宿主机逃离。 在极端的情况下如果在我们得到消息，server-0 发生了有可能影响宿主机的安全时间的时候，仅仅关闭这个宿主机是不够的，受影响的范围可能已经扩大了，然而，我们不可能因为这样关闭整个机房，所以，利用图谱辅助找出受影响范围会有一些帮助。 下面的查询模式是： 找出可能被影响的子网（VPC），标记最高级别风险子网为后续定位做准备 找到可能被控制了的宿主机 从宿主机触发，找出同主机的其他虚机 从其他虚机触发，找到它们的子网（VPC） 从其他虚机触发，找到可能已经被影响的网盘（防止被挂载到其他机器，扩大影响） MATCH (server_escaping_hypervisor)\u003c-[:`contains`]-(hypervisor_compromised:nova_host) WHERE id(server_escaping_hypervisor) == \"server-0\" OPTIONAL MATCH (server_escaping_hypervisor)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet_high:neutron_network) OPTIONAL MATCH (hypervisor_compromised)-[:`contains`]-\u003e(server_same_host:nova_instance) OPTIONAL MATCH (server_same_host)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet:neutron_network) OPTIONAL MATCH (server_same_host)\u003c-[:attached]-(impacted_volume:cinder_volume) RETURN impacted_subnet_high.neutron_network.name AS impacted_subnet_high, hypervisor_compromised.nova_host.name AS hypervisor_compromised, impacted_subnet.neutron_network.name AS impacted_subnet, [server_same_host.nova_instance.name, server_same_host.nova_instance.instance_name] AS server_same_host, impacted_volume.cinder_volume.name AS impacted_volume 结果中列出了 server-0 被控制之后，考虑宿主机逃离的情况下可能受影响的扩散范围。 impacted_subnet_high hypervisor_compromised impacted_subnet server_same_host impacted_volume shared node0 shared [“server-0”, “instance-00000001”] Empty shared node0 shared [“server-1”, “instance-00000002”] ffaeb199-47f4-4d95-89b2-97fba3c1bcfe shared node0 private [“server-1”, “instance-00000002”] ffaeb199-47f4-4d95-89b2-97fba3c1bcfe shared node0 private [“server-3”, “instance-00000005”] c9db7c2e-c712-49d6-8019-14b82de8542d shared node0 private [“server-3”, “instance-00000005”] volume-2 shared node0 public [“server-4”, “instance-00000006”] volume-2 咱们再看看它的可视化结果。 MATCH p=(server_escaping_hypervisor)\u003c-[:`contains`]-(hypervisor_compromised:nova_host) WHERE id(server_escaping_hypervisor) == \"server-0\" OPTIONAL MATCH p0=(server_escaping_hypervisor)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet_high:neutron_network) OPTIONAL MATCH p1=(hypervisor_compromised)-[:`contains`]-\u003e(server_same_host:nova_instance) OPTIONAL MA","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:5","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#安全相关场景"},{"categories":["Nebula Graph"],"content":" 4.5 安全相关场景基础设施资源中的关联关系和金融、内容系统、电商领域的风控场景有相似的地方，很多场景本质上利用到了图谱关系中的知识，在图库上实时获取这些复杂多跳天然带有可解释性的安全洞察非常适合。 4.5.1 秘钥泄漏风控分析先看一个秘钥泄漏的场景：假设 key-0 被安全部门确定被泄漏了，我们可以在毫秒时间内获得如下查询： 直接采用了密钥的虚机 与采用秘钥的虚机网络直连的机器 与采用秘钥的虚机跨网络相连的机器 MATCH (key_leaked)-[:`used_by`]-\u003e(involved_server:nova_instance)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:nova_instance) WHERE id(key_leaked) == \"key-0\" OPTIONAL MATCH (server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:nova_instance) WITH involved_server, server_b AS same_subnet_machines, server_c AS cross_net_machines WHERE cross_net_machines != involved_server RETURN involved_server.nova_instance.name AS with_key, same_subnet_machines.nova_instance.name AS l2_vms, cross_net_machines.nova_instance.name AS cross_vpc_vms 贴一下部分结果，我们知道 server-4 采用了这个 keypair，并且 server-6 和它在同一个网络，同时，有一定可能，通过 server-6，server-1,2,0,5 也受到了威胁、影响，相关的机器可以被触发不同级别的告警来降低安全事故的影响。 with_key l2_vms cross_vpc_vms server-4 server-6 server-1 server-4 server-6 server-2 server-4 server-6 server-0 server-4 server-6 server-5 这个查询改造为可视化结果： MATCH p=(key_leaked)-[:`used_by`]-\u003e(involved_server:nova_instance)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:nova_instance) WHERE id(key_leaked) == \"key-0\" OPTIONAL MATCH p1=(server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:nova_instance) RETURN p,p1 在 explorer 里 应用 Dagre-LR 的布局，一关联关系很清晰的被展示出来，也许可以考虑把它引用在安全事故的报告分发给虚机租户。 4.5.2 镜像、云盘漏洞范围分析类似的，一个镜像被扫出漏洞，我们可以瞬间查到涉及到的资源，并做出相应 镜像文件有漏洞 MATCH p=(image_risky)-[:`created_from`]-(step1) WHERE id(image_risky) == \"cirros-0.5.2-x86_64-disk\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 一个云盘有漏洞 MATCH p=(volume_risky)-[:`created_from`]-(step1) WHERE id(volume_risky) == \"volume-1\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 4.5.3 潜在宿主机逃离影响范围分析最后，我们讨论一个比较严重的安全问题：宿主机逃离。 在极端的情况下如果在我们得到消息，server-0 发生了有可能影响宿主机的安全时间的时候，仅仅关闭这个宿主机是不够的，受影响的范围可能已经扩大了，然而，我们不可能因为这样关闭整个机房，所以，利用图谱辅助找出受影响范围会有一些帮助。 下面的查询模式是： 找出可能被影响的子网（VPC），标记最高级别风险子网为后续定位做准备 找到可能被控制了的宿主机 从宿主机触发，找出同主机的其他虚机 从其他虚机触发，找到它们的子网（VPC） 从其他虚机触发，找到可能已经被影响的网盘（防止被挂载到其他机器，扩大影响） MATCH (server_escaping_hypervisor)\u003c-[:`contains`]-(hypervisor_compromised:nova_host) WHERE id(server_escaping_hypervisor) == \"server-0\" OPTIONAL MATCH (server_escaping_hypervisor)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet_high:neutron_network) OPTIONAL MATCH (hypervisor_compromised)-[:`contains`]-\u003e(server_same_host:nova_instance) OPTIONAL MATCH (server_same_host)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet:neutron_network) OPTIONAL MATCH (server_same_host)\u003c-[:attached]-(impacted_volume:cinder_volume) RETURN impacted_subnet_high.neutron_network.name AS impacted_subnet_high, hypervisor_compromised.nova_host.name AS hypervisor_compromised, impacted_subnet.neutron_network.name AS impacted_subnet, [server_same_host.nova_instance.name, server_same_host.nova_instance.instance_name] AS server_same_host, impacted_volume.cinder_volume.name AS impacted_volume 结果中列出了 server-0 被控制之后，考虑宿主机逃离的情况下可能受影响的扩散范围。 impacted_subnet_high hypervisor_compromised impacted_subnet server_same_host impacted_volume shared node0 shared [“server-0”, “instance-00000001”] Empty shared node0 shared [“server-1”, “instance-00000002”] ffaeb199-47f4-4d95-89b2-97fba3c1bcfe shared node0 private [“server-1”, “instance-00000002”] ffaeb199-47f4-4d95-89b2-97fba3c1bcfe shared node0 private [“server-3”, “instance-00000005”] c9db7c2e-c712-49d6-8019-14b82de8542d shared node0 private [“server-3”, “instance-00000005”] volume-2 shared node0 public [“server-4”, “instance-00000006”] volume-2 咱们再看看它的可视化结果。 MATCH p=(server_escaping_hypervisor)\u003c-[:`contains`]-(hypervisor_compromised:nova_host) WHERE id(server_escaping_hypervisor) == \"server-0\" OPTIONAL MATCH p0=(server_escaping_hypervisor)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet_high:neutron_network) OPTIONAL MATCH p1=(hypervisor_compromised)-[:`contains`]-\u003e(server_same_host:nova_instance) OPTIONAL MA","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:5","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#秘钥泄漏风控分析"},{"categories":["Nebula Graph"],"content":" 4.5 安全相关场景基础设施资源中的关联关系和金融、内容系统、电商领域的风控场景有相似的地方，很多场景本质上利用到了图谱关系中的知识，在图库上实时获取这些复杂多跳天然带有可解释性的安全洞察非常适合。 4.5.1 秘钥泄漏风控分析先看一个秘钥泄漏的场景：假设 key-0 被安全部门确定被泄漏了，我们可以在毫秒时间内获得如下查询： 直接采用了密钥的虚机 与采用秘钥的虚机网络直连的机器 与采用秘钥的虚机跨网络相连的机器 MATCH (key_leaked)-[:`used_by`]-\u003e(involved_server:nova_instance)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:nova_instance) WHERE id(key_leaked) == \"key-0\" OPTIONAL MATCH (server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:nova_instance) WITH involved_server, server_b AS same_subnet_machines, server_c AS cross_net_machines WHERE cross_net_machines != involved_server RETURN involved_server.nova_instance.name AS with_key, same_subnet_machines.nova_instance.name AS l2_vms, cross_net_machines.nova_instance.name AS cross_vpc_vms 贴一下部分结果，我们知道 server-4 采用了这个 keypair，并且 server-6 和它在同一个网络，同时，有一定可能，通过 server-6，server-1,2,0,5 也受到了威胁、影响，相关的机器可以被触发不同级别的告警来降低安全事故的影响。 with_key l2_vms cross_vpc_vms server-4 server-6 server-1 server-4 server-6 server-2 server-4 server-6 server-0 server-4 server-6 server-5 这个查询改造为可视化结果： MATCH p=(key_leaked)-[:`used_by`]-\u003e(involved_server:nova_instance)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:nova_instance) WHERE id(key_leaked) == \"key-0\" OPTIONAL MATCH p1=(server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:nova_instance) RETURN p,p1 在 explorer 里 应用 Dagre-LR 的布局，一关联关系很清晰的被展示出来，也许可以考虑把它引用在安全事故的报告分发给虚机租户。 4.5.2 镜像、云盘漏洞范围分析类似的，一个镜像被扫出漏洞，我们可以瞬间查到涉及到的资源，并做出相应 镜像文件有漏洞 MATCH p=(image_risky)-[:`created_from`]-(step1) WHERE id(image_risky) == \"cirros-0.5.2-x86_64-disk\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 一个云盘有漏洞 MATCH p=(volume_risky)-[:`created_from`]-(step1) WHERE id(volume_risky) == \"volume-1\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 4.5.3 潜在宿主机逃离影响范围分析最后，我们讨论一个比较严重的安全问题：宿主机逃离。 在极端的情况下如果在我们得到消息，server-0 发生了有可能影响宿主机的安全时间的时候，仅仅关闭这个宿主机是不够的，受影响的范围可能已经扩大了，然而，我们不可能因为这样关闭整个机房，所以，利用图谱辅助找出受影响范围会有一些帮助。 下面的查询模式是： 找出可能被影响的子网（VPC），标记最高级别风险子网为后续定位做准备 找到可能被控制了的宿主机 从宿主机触发，找出同主机的其他虚机 从其他虚机触发，找到它们的子网（VPC） 从其他虚机触发，找到可能已经被影响的网盘（防止被挂载到其他机器，扩大影响） MATCH (server_escaping_hypervisor)\u003c-[:`contains`]-(hypervisor_compromised:nova_host) WHERE id(server_escaping_hypervisor) == \"server-0\" OPTIONAL MATCH (server_escaping_hypervisor)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet_high:neutron_network) OPTIONAL MATCH (hypervisor_compromised)-[:`contains`]-\u003e(server_same_host:nova_instance) OPTIONAL MATCH (server_same_host)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet:neutron_network) OPTIONAL MATCH (server_same_host)\u003c-[:attached]-(impacted_volume:cinder_volume) RETURN impacted_subnet_high.neutron_network.name AS impacted_subnet_high, hypervisor_compromised.nova_host.name AS hypervisor_compromised, impacted_subnet.neutron_network.name AS impacted_subnet, [server_same_host.nova_instance.name, server_same_host.nova_instance.instance_name] AS server_same_host, impacted_volume.cinder_volume.name AS impacted_volume 结果中列出了 server-0 被控制之后，考虑宿主机逃离的情况下可能受影响的扩散范围。 impacted_subnet_high hypervisor_compromised impacted_subnet server_same_host impacted_volume shared node0 shared [“server-0”, “instance-00000001”] Empty shared node0 shared [“server-1”, “instance-00000002”] ffaeb199-47f4-4d95-89b2-97fba3c1bcfe shared node0 private [“server-1”, “instance-00000002”] ffaeb199-47f4-4d95-89b2-97fba3c1bcfe shared node0 private [“server-3”, “instance-00000005”] c9db7c2e-c712-49d6-8019-14b82de8542d shared node0 private [“server-3”, “instance-00000005”] volume-2 shared node0 public [“server-4”, “instance-00000006”] volume-2 咱们再看看它的可视化结果。 MATCH p=(server_escaping_hypervisor)\u003c-[:`contains`]-(hypervisor_compromised:nova_host) WHERE id(server_escaping_hypervisor) == \"server-0\" OPTIONAL MATCH p0=(server_escaping_hypervisor)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet_high:neutron_network) OPTIONAL MATCH p1=(hypervisor_compromised)-[:`contains`]-\u003e(server_same_host:nova_instance) OPTIONAL MA","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:5","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#镜像云盘漏洞范围分析"},{"categories":["Nebula Graph"],"content":" 4.5 安全相关场景基础设施资源中的关联关系和金融、内容系统、电商领域的风控场景有相似的地方，很多场景本质上利用到了图谱关系中的知识，在图库上实时获取这些复杂多跳天然带有可解释性的安全洞察非常适合。 4.5.1 秘钥泄漏风控分析先看一个秘钥泄漏的场景：假设 key-0 被安全部门确定被泄漏了，我们可以在毫秒时间内获得如下查询： 直接采用了密钥的虚机 与采用秘钥的虚机网络直连的机器 与采用秘钥的虚机跨网络相连的机器 MATCH (key_leaked)-[:`used_by`]-\u003e(involved_server:nova_instance)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:nova_instance) WHERE id(key_leaked) == \"key-0\" OPTIONAL MATCH (server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:nova_instance) WITH involved_server, server_b AS same_subnet_machines, server_c AS cross_net_machines WHERE cross_net_machines != involved_server RETURN involved_server.nova_instance.name AS with_key, same_subnet_machines.nova_instance.name AS l2_vms, cross_net_machines.nova_instance.name AS cross_vpc_vms 贴一下部分结果，我们知道 server-4 采用了这个 keypair，并且 server-6 和它在同一个网络，同时，有一定可能，通过 server-6，server-1,2,0,5 也受到了威胁、影响，相关的机器可以被触发不同级别的告警来降低安全事故的影响。 with_key l2_vms cross_vpc_vms server-4 server-6 server-1 server-4 server-6 server-2 server-4 server-6 server-0 server-4 server-6 server-5 这个查询改造为可视化结果： MATCH p=(key_leaked)-[:`used_by`]-\u003e(involved_server:nova_instance)--(:neutron_port)--(net:neutron_network)--(:neutron_port)--(server_b:nova_instance) WHERE id(key_leaked) == \"key-0\" OPTIONAL MATCH p1=(server_b)--()--(other_net:neutron_network)--(:neutron_port)--(server_c:nova_instance) RETURN p,p1 在 explorer 里 应用 Dagre-LR 的布局，一关联关系很清晰的被展示出来，也许可以考虑把它引用在安全事故的报告分发给虚机租户。 4.5.2 镜像、云盘漏洞范围分析类似的，一个镜像被扫出漏洞，我们可以瞬间查到涉及到的资源，并做出相应 镜像文件有漏洞 MATCH p=(image_risky)-[:`created_from`]-(step1) WHERE id(image_risky) == \"cirros-0.5.2-x86_64-disk\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 一个云盘有漏洞 MATCH p=(volume_risky)-[:`created_from`]-(step1) WHERE id(volume_risky) == \"volume-1\" OPTIONAL MATCH p1=(step1)-[:created_from*1..5]-(step2) RETURN p, p1 4.5.3 潜在宿主机逃离影响范围分析最后，我们讨论一个比较严重的安全问题：宿主机逃离。 在极端的情况下如果在我们得到消息，server-0 发生了有可能影响宿主机的安全时间的时候，仅仅关闭这个宿主机是不够的，受影响的范围可能已经扩大了，然而，我们不可能因为这样关闭整个机房，所以，利用图谱辅助找出受影响范围会有一些帮助。 下面的查询模式是： 找出可能被影响的子网（VPC），标记最高级别风险子网为后续定位做准备 找到可能被控制了的宿主机 从宿主机触发，找出同主机的其他虚机 从其他虚机触发，找到它们的子网（VPC） 从其他虚机触发，找到可能已经被影响的网盘（防止被挂载到其他机器，扩大影响） MATCH (server_escaping_hypervisor)\u003c-[:`contains`]-(hypervisor_compromised:nova_host) WHERE id(server_escaping_hypervisor) == \"server-0\" OPTIONAL MATCH (server_escaping_hypervisor)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet_high:neutron_network) OPTIONAL MATCH (hypervisor_compromised)-[:`contains`]-\u003e(server_same_host:nova_instance) OPTIONAL MATCH (server_same_host)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet:neutron_network) OPTIONAL MATCH (server_same_host)\u003c-[:attached]-(impacted_volume:cinder_volume) RETURN impacted_subnet_high.neutron_network.name AS impacted_subnet_high, hypervisor_compromised.nova_host.name AS hypervisor_compromised, impacted_subnet.neutron_network.name AS impacted_subnet, [server_same_host.nova_instance.name, server_same_host.nova_instance.instance_name] AS server_same_host, impacted_volume.cinder_volume.name AS impacted_volume 结果中列出了 server-0 被控制之后，考虑宿主机逃离的情况下可能受影响的扩散范围。 impacted_subnet_high hypervisor_compromised impacted_subnet server_same_host impacted_volume shared node0 shared [“server-0”, “instance-00000001”] Empty shared node0 shared [“server-1”, “instance-00000002”] ffaeb199-47f4-4d95-89b2-97fba3c1bcfe shared node0 private [“server-1”, “instance-00000002”] ffaeb199-47f4-4d95-89b2-97fba3c1bcfe shared node0 private [“server-3”, “instance-00000005”] c9db7c2e-c712-49d6-8019-14b82de8542d shared node0 private [“server-3”, “instance-00000005”] volume-2 shared node0 public [“server-4”, “instance-00000006”] volume-2 咱们再看看它的可视化结果。 MATCH p=(server_escaping_hypervisor)\u003c-[:`contains`]-(hypervisor_compromised:nova_host) WHERE id(server_escaping_hypervisor) == \"server-0\" OPTIONAL MATCH p0=(server_escaping_hypervisor)\u003c-[:attached]-(:neutron_port)\u003c-[:contains]-(impacted_subnet_high:neutron_network) OPTIONAL MATCH p1=(hypervisor_compromised)-[:`contains`]-\u003e(server_same_host:nova_instance) OPTIONAL MA","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:5","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#潜在宿主机逃离影响范围分析"},{"categories":["Nebula Graph"],"content":" 4.6 重点关注资源检测最后，利用 Betweenness Centrality 算法，我们可以得出基础设施中影响面大的那些，”脆弱环节“，这些资源不一定真的处在危险的状态，只是说，它们处在了比较重要的资源之间的交汇处，一旦它们出问题，出问题的代价可能会非常大。 识别出这样的资源之后我们可以考虑： 有针对性采用更激进、昂贵的健康检查策略； 设定更高的支持、关切级别； 主动迁移相关联的资源以降低”脆弱环节“对整体基础设施可用性的影响范围； 这次，我们就只在浏览器内部的子图上做算法流程验证，读者朋友们可以自己试着利用开源的 NebulaGraph Algorithm 或者付费的 NebulaGraph Workflow+Analytics 做全图上的等价操作。 首先，我们在前边用过的方式去扫描图上 1000 个点，并且从其出发，跳一跳，获得一个比较随机的子图，在我们当前的数据集下，这实际上捞取了全图的数据： MATCH (n) WITH n LIMIT 1000 OPTIONAL MATCH p=(n)--() RETURN p, n 在其之上，我们运行 Betweenness Centrality 之后，得到 node0 是分值最大的”脆弱一环“，的确，它是我们当前实验中负载最大的宿主机，可以想象它确实是故障之后全局影响最大的一个资源。 ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:4:6","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#重点关注资源检测"},{"categories":["Nebula Graph"],"content":" 5 总结在海量数据、企业云、混合云的复杂基础设施运维场景下，利用图数据库图算法的能力做高效的辅助运维工作是一个十分值得的尝试与技术投资。 NebulaGraph 作为高性能、开源、分布式的新一代云原生图数据库，是一个很值得考虑的图基础设施选型目标。 欢迎大家在文末留言讨论，本文的可复现环境和示例的 ETL 管道的代码、示例数据全都在 https://github.com/wey-gu/openstack-graph/ 开源，欢迎大家来一起完善。 题图版权：Ivan ","date":"2023-01-13","objectID":"/graph-enabled-infra-ops/:5:0","series":null,"tags":["Nebula Graph","DevOps","OpenStack","智能运维","RCA"],"title":"图数据库驱动的基础设施运维示例","uri":"/graph-enabled-infra-ops/#总结"},{"categories":["open-source"],"content":"NebulaGraph 社区如何构建工具让 Slack、WeChat 中宝贵的群聊讨论同步到公共领域","date":"2022-12-19","objectID":"/build-open-communication-infra/","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/"},{"categories":["open-source"],"content":" NebulaGraph 社区如何构建工具让 Slack、WeChat 中宝贵的群聊讨论同步到公共领域 ","date":"2022-12-19","objectID":"/build-open-communication-infra/:0:0","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#"},{"categories":["open-source"],"content":" 1 要开放，不要封闭在开源社区中，开放的一个重要意义是社区内的沟通、讨论应该是透明、包容并且方便所有成员访问的。这意味着社区中的任何人都应该能够参与讨论和决策过程，并且所有相关信息应该公开和自由地共享。 在公共场合进行沟通在开源理念中是重要的，正式这种方式使得社区的成员可以进行有效地共同工作，分享想法和反馈，为项目或社区做出贡献。 为了更清楚表达，我举几个反面的例子： 要求贡献者使用对他们来说难以访问或难以使用的工具可能会妨碍开源社区中的开放沟通。 这可能是由于多种原因，例如： 工具可能昂贵或需要许可证，而并非所有贡献者都能负担得起。 工具可能难以使用或需要很高的技术经验积累，而并非所有贡献者都具备。 工具可能在某些操作系统或设备上不兼容，这可能使一些贡献者难以访问它们。 在不与社区其他成员分享上下文、过程或结果的情况下，只在线下（例如通过当面沟通、IM 或电话会议）进行决策可能会使很重要的知识只被少数贡献者掌握。 这可能会阻止其他人在这些知识之上做贡献或从中学习，阻碍了开源社区所必需的开放沟通和协作。 没有把系统、功能设计和提案信息以公开方式文档化、归档下来，例如只提供某一个公司内网的链接，从而可能伤害开源社区的透明度和包容性。 因为这样的结果是社区的其他成员很难保持对社区进展的正常了解、就更不用说参与进来做贡献了。为了促进透明度和包容性，开源社区应尽量确保所有重要的信息公开和自由地共享、尽可能保有细节地被公开归档。 ","date":"2022-12-19","objectID":"/build-open-communication-infra/:1:0","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#要开放不要封闭"},{"categories":["open-source"],"content":" 2 挑战为了使社区（或工作环境）的沟通保持透明、高效和健康，其实已经存在一些共识，和通用的做法： 异步优于同步，在分布式和全球协作的情况下，同步通信在大多数情况下成本高且效率低。 因此，推荐使用 GitHub Discussion 和 StackOverflow 进行提问式的沟通。 专题（Thread）讨论优于广播（Fan out)，注意力是宝贵的，向所有人群发最终常常导致重要信息没有人真的读。 因此，我们在 GitHub Discussion 和 Slack 中设有分类、频道。建立 SIG 来讨论一些有趣的主题（并归档沟通的结果），而不是将所有事情带到社区会议广泛讨论。 优先选择可搜索/文本、版本控制、协作的方式与工具，并在可能的情况下鼓励成员们给其他人反馈；在基础设施上跟踪文档、设计流程，并且提供评论、review 的能力。 为此，我们用 etherpad.opendev.org 来记录社区会议文档。 但是，就像我们还是需要同步的沟通、有 IM 和会议的需求一样，还是存在一些特例的情况，我们不能盲目追求异步、绝对的开放的，正如前边提到的，能让更多参与者公平、方便与社区连结本身也是开放的一部分，尽管使用的基础设施是可能是封闭的。事实上，几乎所有的开源社区都在用类似的方式建立他们的开源社区沟通平台： Slack 在 IM 消息中中支持丰富的格式化（支持 markdown！）和 Thread 系统，其现代化设计和开放/软定义接口使我们的工作流程可能非常优美流畅。 与 Slack 相比，微信在技术社区中在许多方面都很不理想（只是因为它不是专为这样场景而设计的！），但在国内，它是社区中所有人都可以访问的唯一平台。每个人都有一个微信账号，而只有很少一部分人会每天查邮件。 于是，我们面临的问题是，在 NebulaGraph 社区中有两个平台承担了沟通的重要部分，但这些信息在几个月后就会消失，它们在短时间内只能被割裂的一部分贡献者看到，而未来没有人或其他平台可以读到、搜到和参考、引用这些有价值的讨论。 ","date":"2022-12-19","objectID":"/build-open-communication-infra/:2:0","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#挑战"},{"categories":["open-source"],"content":" 3 我们摸索的方案曾经有一段时间，我们会自己手动收集 Slack、微信群里的讨论摘要，定期分享、归档在公共领域，这个方法也确实带来了一些价值，然而，我们最后都没坚持下去，原因很简单：1. 这太费事儿了，完全不 scale；2. 这种摘要其实不好平衡能被归档信息的裁剪程度，有时候细节非常重要却不容易被摘要保留。 ","date":"2022-12-19","objectID":"/build-open-communication-infra/:3:0","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#我们摸索的方案"},{"categories":["open-source"],"content":" 3.1 搞定 Slack 的信息孤岛2022 年 10 月，我注意到了 linen.dev 这个开源项目同时也是一个 SaaS 服务，有了它，我们可以把 Discord 和 Slack 中的每个 thread 保留，它整站看起来和 Discord/ Slack 机会样，但是，它完全是可以匿名被访问、引用和被搜索引擎搜索的。 经过几个月的评估，我们最终决定了订阅 linen.dev 服务。为此，我们可以获得： 不用去碰现有的 Slack，所有 Slack 的好处都能得以保留 有了这样一个社区的站点 https://community-chat.nebula-graph.io/，其中，Slack 中的每个公共频道内容都能被匿名访问、能被搜索引擎收录，而访客还可以很容易知道怎么加入我们的 Slack，如图右上角： 这个站会实时同步 Slack 里的消息，重要的是，它是面向搜索引擎优化的，你可以搜搜 Kotlin 社区通过 linen 被收录的网页有多少，搜这个：“site: slack-chats.kotlinlang.org”。 每一个 thread 都有一个无需登录的只读 URL，我们可以方便去分享、引用它，虽然这件事儿本身就是超链接、URL的作用，但是在现在已经变得非常不容易了，比如这个新闻里提到现在新一代的人们更倾向于在抖音里搜索而不是在公共领域里。 有了它，我们可以非常开心地在 GitHub 里引用任意一个 Slack 讨论话题： 解决了 Slack 的问题之后，唯一剩下的痛点就是微信群了，每周都有挺多非常宝贵的讨论在社区群中进行却不能被保留下来，真实太令人心疼了，终于有一天，我们决定把这个问题解决。 ","date":"2022-12-19","objectID":"/build-open-communication-infra/:3:1","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#搞定-slack-的信息孤岛"},{"categories":["open-source"],"content":" 3.2 解决微信群的信息公开化首先，能不能直接用 Linen 一把梭，同步群消息呢？我确实在 Linen 社区和他们的 Kam 讨论直接解决 IM 同步的可能，不过到现在，他们都没有优先考虑😭。 然后，我就在想如果直接把微信同步到 Slack，Linen 不就能把微信的信息也收录了吗？ 在 Twitter 上 求助黑客/开源社区 + 一番调研确定了没有这样的东西存在之后，我决定搞一个，做成开源项目，我花了一点时间实现了最初的版本。 石头汤来了 👉🏻：https://t.co/Fdhm9MkoBb#NebulaGraph 社区微信群现在已经会被同步到 slack 了。 — Wey Gu 古思为 (@wey_gu) December 15, 2022 万万没想到，当我做到把消息从微信同步到 Slack 之后，随之而来的问题是，通过 Slack API 发出的消息 Linen 并不会收录。 为此，我放弃了 linen 一把梭的美好愿望，转而考虑把消息同步到其他公共领域，而我第一个想到的就是 GitHub Discussions 之中，又花了周末的下午加晚上，把它做出来了： 现在，这个机器人程序会把配置好的微信群消息同时同步到 Slack 频道和 GitHub Discussion 中给定的标签下的主题中，每一个群一个礼拜是一个主题，所有的消息都是主题下的评论。 ","date":"2022-12-19","objectID":"/build-open-communication-infra/:3:2","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#解决微信群的信息公开化"},{"categories":["open-source"],"content":" 3.3 小结现在，我们保留了所有 Slack/微信的美好的一面的同时，把它们中的讨论消息历史全都归档、索引并公开到这两个域之下了，是不是很酷呢？ https://community-chat.nebula-graph.io/ https://github.com/vesoft-inc/nebula-community/discussions/categories/wechat-chat-history ","date":"2022-12-19","objectID":"/build-open-communication-infra/:3:3","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#小结"},{"categories":["open-source"],"content":" 3.4 后续工作这个同步微信的项目是 Apache 2.0 协议开源的，并且现在由我和Frost Ming在维护，这里还有很多待增强、实现的新功能、新任务，欢迎大家来试玩、贡献。让我们一起把开源社区的沟通做的多一点开放、少一点封闭吧~ 项目地址 👉🏻 https://github.com/wey-gu/chatroom-syncer. ","date":"2022-12-19","objectID":"/build-open-communication-infra/:3:4","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#后续工作"},{"categories":["open-source"],"content":" 4 结论有效的沟通是成功的开源社区的基石，因为它让协作、分享思想与知识、以及所有成员的参与成为可能。为了确保沟通透明、包容和有效，对于开源社区来说，让所有成员有机会参与讨论和决策以及公开自由地分享相关信息是非常重要的。 我们 NebulaGraph 社区的建设者/贡献者将继续寻找和黑客方法，以开放和良好的方式使人们连接在一起，和大家共建更好的开源、技术社区。 题图版权：Artem Beliaikin ","date":"2022-12-19","objectID":"/build-open-communication-infra/:4:0","series":null,"tags":["community","open-source"],"title":"连接微信群、Slack 和 GitHub：社区开放沟通的基础设施搭建","uri":"/build-open-communication-infra/#结论"},{"categories":["Nebula Graph"],"content":"本文是一个基于 NebulaGraph 上解决社交网络问题的常规方法综述。其中介绍的方法提供都了 Playground 供大家学习、玩耍。","date":"2022-12-08","objectID":"/nebulagraph-sns/","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/"},{"categories":["Nebula Graph"],"content":" 图数据库的社交网络应用 本文是一个基于 NebulaGraph 上解决社交网络问题的常规方法综述。其中介绍的方法提供都了 Playground 供大家学习、玩耍。 社交网络大家都不陌生，无论是微信、微博、B 站还是大众点评、知乎、陌陌等服务，其本质上的用户都形成了社交网络。 在一个社交网络系统中，我们可以用图数据库来表示用户和他们的连接关系。图数据库能允许对用户之间的关系进行有效的查询，使得各种基于连接查找、统计、分析的社交网络上的业务实现变得可行、高效。 例如，图形数据库可以用来识别网络中的“有影响力用户”，或者根据用户之间的共同点对新的连接（好友关系、关心的内容）进行推荐，再或者寻找社群中相聚集的不同人群、社区，进行用户画像。图形数据库因为在能支撑复杂多跳查询的同时也能支持实时写入、更新，使其非常适合应用在用户关系不断变化的社交网络系统之上。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:0:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#图数据库的社交网络应用"},{"categories":["Nebula Graph"],"content":" 1 图建模为了给出一些常见社交场景的应用示例，我会把大多数例子建立在一个典型的小型社交网络上，社交网络天然就是一张网络、图的形态。 为此，我在 NebulaGraph 官方示例数据集：篮球运动员之上，增加了三种点： 地址 地点 文章 五种边： 发文 评论 住在 属于（地点） 它的建模非常自然： ","date":"2022-12-08","objectID":"/nebulagraph-sns/:1:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#图建模"},{"categories":["Nebula Graph"],"content":" 2 数据导入","date":"2022-12-08","objectID":"/nebulagraph-sns/:2:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#数据导入"},{"categories":["Nebula Graph"],"content":" 2.1 加载默认数据集首先，我们加载默认的 basketballplayer 数据集。 在命令行 console 之中，我们只需要执行 :play basketballplayer 就可以。 而在 NebulaGraph Studio/Explorer 之中，我们可以在欢迎页点击下载就部署这份基础数据集。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:2:1","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#加载默认数据集"},{"categories":["Nebula Graph"],"content":" 2.2 加载社交网络 schema其次我们执行下边的语句，首先是 Schema 定义的语句： CREATE TAG IF NOT EXISTS post(title string NOT NULL); CREATE EDGE created_post(post_time timestamp); CREATE EDGE commented_at(post_time timestamp); CREATE TAG address(address string NOT NULL, `geo_point` geography(point)); CREATE TAG place(name string NOT NULL, `geo_point` geography(point)); CREATE EDGE belong_to(); CREATE EDGE lived_in(); ","date":"2022-12-08","objectID":"/nebulagraph-sns/:2:2","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#加载社交网络-schema"},{"categories":["Nebula Graph"],"content":" 2.3 加载数据然后，在等两个心跳时间以上之后（20秒），我们可以执行数据插入： INSERT VERTEX post(title) values \\ \"post1\":(\"a beautify flower\"), \"post2\":(\"my first bike\"), \"post3\":(\"I can swim\"), \\ \"post4\":(\"I love you, Dad\"), \"post5\":(\"I hate coriander\"), \"post6\":(\"my best friend, tom\"), \\ \"post7\":(\"my best friend, jerry\"), \"post8\":(\"Frank, the cat\"), \"post9\":(\"sushi rocks\"), \\ \"post10\":(\"I love you, Mom\"), \"post11\":(\"Let's have a party!\"); INSERT EDGE created_post(post_time) values \\ \"player100\"-\u003e\"post1\":(timestamp(\"2019-01-01 00:30:06\")), \\ \"player111\"-\u003e\"post2\":(timestamp(\"2016-11-23 10:04:50\")), \\ \"player101\"-\u003e\"post3\":(timestamp(\"2019-11-11 10:44:06\")), \\ \"player103\"-\u003e\"post4\":(timestamp(\"2014-12-01 20:45:11\")), \\ \"player102\"-\u003e\"post5\":(timestamp(\"2015-03-01 00:30:06\")), \\ \"player104\"-\u003e\"post6\":(timestamp(\"2017-09-21 23:30:06\")), \\ \"player125\"-\u003e\"post7\":(timestamp(\"2018-01-01 00:44:23\")), \\ \"player106\"-\u003e\"post8\":(timestamp(\"2019-01-01 00:30:06\")), \\ \"player117\"-\u003e\"post9\":(timestamp(\"2022-01-01 22:23:30\")), \\ \"player108\"-\u003e\"post10\":(timestamp(\"2011-01-01 10:00:30\")), \\ \"player100\"-\u003e\"post11\":(timestamp(\"2021-11-01 11:10:30\")); INSERT EDGE commented_at(post_time) values \\ \"player105\"-\u003e\"post1\":(timestamp(\"2019-01-02 00:30:06\")), \\ \"player109\"-\u003e\"post1\":(timestamp(\"2016-11-24 10:04:50\")), \\ \"player113\"-\u003e\"post3\":(timestamp(\"2019-11-13 10:44:06\")), \\ \"player101\"-\u003e\"post4\":(timestamp(\"2014-12-04 20:45:11\")), \\ \"player102\"-\u003e\"post1\":(timestamp(\"2015-03-03 00:30:06\")), \\ \"player103\"-\u003e\"post1\":(timestamp(\"2017-09-23 23:30:06\")), \\ \"player102\"-\u003e\"post7\":(timestamp(\"2018-01-04 00:44:23\")), \\ \"player101\"-\u003e\"post8\":(timestamp(\"2019-01-04 00:30:06\")), \\ \"player106\"-\u003e\"post9\":(timestamp(\"2022-01-02 22:23:30\")), \\ \"player105\"-\u003e\"post10\":(timestamp(\"2011-01-11 10:00:30\")), \\ \"player130\"-\u003e\"post1\":(timestamp(\"2019-01-02 00:30:06\")), \\ \"player131\"-\u003e\"post2\":(timestamp(\"2016-11-24 10:04:50\")), \\ \"player131\"-\u003e\"post3\":(timestamp(\"2019-11-13 10:44:06\")), \\ \"player133\"-\u003e\"post4\":(timestamp(\"2014-12-04 20:45:11\")), \\ \"player132\"-\u003e\"post5\":(timestamp(\"2015-03-03 00:30:06\")), \\ \"player134\"-\u003e\"post6\":(timestamp(\"2017-09-23 23:30:06\")), \\ \"player135\"-\u003e\"post7\":(timestamp(\"2018-01-04 00:44:23\")), \\ \"player136\"-\u003e\"post8\":(timestamp(\"2019-01-04 00:30:06\")), \\ \"player137\"-\u003e\"post9\":(timestamp(\"2022-01-02 22:23:30\")), \\ \"player138\"-\u003e\"post10\":(timestamp(\"2011-01-11 10:00:30\")), \\ \"player141\"-\u003e\"post1\":(timestamp(\"2019-01-03 00:30:06\")), \\ \"player142\"-\u003e\"post2\":(timestamp(\"2016-11-25 10:04:50\")), \\ \"player143\"-\u003e\"post3\":(timestamp(\"2019-11-14 10:44:06\")), \\ \"player144\"-\u003e\"post4\":(timestamp(\"2014-12-05 20:45:11\")), \\ \"player145\"-\u003e\"post5\":(timestamp(\"2015-03-04 00:30:06\")), \\ \"player146\"-\u003e\"post6\":(timestamp(\"2017-09-24 23:30:06\")), \\ \"player147\"-\u003e\"post7\":(timestamp(\"2018-01-05 00:44:23\")), \\ \"player148\"-\u003e\"post8\":(timestamp(\"2019-01-05 00:30:06\")), \\ \"player139\"-\u003e\"post9\":(timestamp(\"2022-01-03 22:23:30\")), \\ \"player140\"-\u003e\"post10\":(timestamp(\"2011-01-12 10:01:30\")), \\ \"player141\"-\u003e\"post1\":(timestamp(\"2019-01-04 00:34:06\")), \\ \"player102\"-\u003e\"post2\":(timestamp(\"2016-11-26 10:06:50\")), \\ \"player103\"-\u003e\"post3\":(timestamp(\"2019-11-15 10:45:06\")), \\ \"player104\"-\u003e\"post4\":(timestamp(\"2014-12-06 20:47:11\")), \\ \"player105\"-\u003e\"post5\":(timestamp(\"2015-03-05 00:32:06\")), \\ \"player106\"-\u003e\"post6\":(timestamp(\"2017-09-25 23:31:06\")), \\ \"player107\"-\u003e\"post7\":(timestamp(\"2018-01-06 00:46:23\")), \\ \"player118\"-\u003e\"post8\":(timestamp(\"2019-01-06 00:35:06\")), \\ \"player119\"-\u003e\"post9\":(timestamp(\"2022-01-04 22:26:30\")), \\ \"player110\"-\u003e\"post10\":(timestamp(\"2011-01-15 10:00:30\")), \\ \"player111\"-\u003e\"post1\":(timestamp(\"2019-01-06 00:30:06\")), \\ \"player104\"-\u003e\"post11\":(timestamp(\"2022-01-15 10:00:30\")), \\ \"player125\"-\u003e\"post11\":(timestamp(\"2022-02-15 10:00:30\")), \\ \"player113\"-\u003e\"post11\":(timestamp(\"2022-03-15 10:00:30\")), \\ \"player102\"-\u003e\"post11\":(timestamp(\"2022-04-15 10:00:30\")), \\ \"player108\"-\u003e\"post11\":(timestamp(\"2022-05-15 10:00:30\")); INSERT VERTEX `address` (`address`, `geo_point`) VALUES \\ \"addr_0\":(\"Brittany Forge Apt. 718 East Eric WV 97881\", ST_Point(1,2)),\\ ","date":"2022-12-08","objectID":"/nebulagraph-sns/:2:3","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#加载数据"},{"categories":["Nebula Graph"],"content":" 2.4 数据初探首先，我们看看数据统计 [basketballplayer]\u003e SUBMIT JOB STATS; +------------+ | New Job Id | +------------+ | 10 | +------------+ [basketballplayer]\u003e SHOW STATS; +---------+----------------+-------+ | Type | Name | Count | +---------+----------------+-------+ | \"Tag\" | \"address\" | 19 | | \"Tag\" | \"place\" | 14 | | \"Tag\" | \"player\" | 51 | | \"Tag\" | \"post\" | 10 | | \"Tag\" | \"team\" | 30 | | \"Edge\" | \"belong_to\" | 19 | | \"Edge\" | \"commented_at\" | 40 | | \"Edge\" | \"created_post\" | 10 | | \"Edge\" | \"follow\" | 81 | | \"Edge\" | \"lived_in\" | 19 | | \"Edge\" | \"serve\" | 152 | | \"Space\" | \"vertices\" | 124 | | \"Space\" | \"edges\" | 321 | +---------+----------------+-------+ Got 13 rows (time spent 1038/51372 us) 查一下所有的数据 MATCH ()-[e]-\u003e() RETURN e LIMIT 10000 因为数据量太小了，所以可以把所有数据在 NebulaGraph Explorer 中渲染出来： ","date":"2022-12-08","objectID":"/nebulagraph-sns/:2:4","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#数据初探"},{"categories":["Nebula Graph"],"content":" 3 找出网络中的关键人物识别社交网络中的有影响的关键人物们（influencers）涉及使用各种指标和方法来识别在特定网络中拥有大量影响力的个人。这对很多业务场景都有帮助都很有用，比如用于营销或研究网络中的信息传播。 识别他们的方法有很多，具体的方法和考量的信息、关系、角度也取决于这些关键人物的类型、和获取他们的目的。 一些常见的方法包括看一个人拥有的粉丝或内容被消费的数量，他们在其帖子、视频上读者的参与度，以及他们的内容的影响力（转发、引用）。这些方法在图上也是可以做的，但是比较平凡，我就不举例了，在这里，我们可以试着用评估、计算节点重要性的图算法，在图上得出这些关键人物。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:3:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#找出网络中的关键人物"},{"categories":["Nebula Graph"],"content":" 3.1 PageRankPageRank 是一个非常“古老的”图算法，它通过考虑图上点之间的关系数量去迭代，得到每一个点的得分（Rank），最初由 Google 的创始人 Larry Page 和 Sergey Brin 提出并应用在早期的 Google 搜索引擎中，用来排序搜索结果，这里的 Page 可以是 Larry Page 的姓和 Web Page 的双关了。 在现代、复杂的搜索引擎中，PageRank 早就因为其过于简单而被弃用，但是在其他图结构网络场景中，PageRank 仍然在发光发热，社交网络中我们可以粗略地认为所有链接的重要程度类似，去运行这个算法找出那些关键的用户。 在 NebulaGraph 中，我们可以利用 NebulaGraph Algorithm、NebulaGraph Analytics 去在大的全图上运行 PageRank，而在日常的分析、验证、设计阶段，我们不需要在全量数据上跑结果，而在很小的子图上（最多上万），我们可以轻松地在浏览器里边运行各种图算法去得出线上业务可以用的方法。 今天，我们就用 NebulaGraph Explorer 内置的浏览器内图算法功能执行一下 PageRank 看看（具体方法这里略去，可以参考文档，不过其实就是点一下鼠标的事儿）： 我们可以从上边看到，PageRank 计算之后所有绿色的 player（人）中，“player.name: Tim Duncan” 是最大的一个点，与之相关联的关系看起来的确不少，我们在图上选择他，再右键反选，选择除了 Tim Duncan 之外的所有点，用退格键删除所有其他的点，然后在他作为起点双向探索出1到5步，可以得到 Tim Duncan 的子图： 从子图中可以看到 Tim Duncan 和非常多其他球员有关注的关系的同时，一些其他很受欢迎的队员和他一起一样服役过非常热门的热刺（Spurs）队，这些都印证了 PageRank 的评估方式。 现在我们再看看其他判定维度下的算法会不会得出一样的结论呢？ ","date":"2022-12-08","objectID":"/nebulagraph-sns/:3:1","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#pagerank"},{"categories":["Nebula Graph"],"content":" 3.2 Betweenness Centrality作为另一个流行的节点重要性算法，通过计算一个节点对于图中的中介、桥梁作用来衡量节点的重要性，这里的桥梁作用是有数学定义的量化算法，这里就不展开说了，不过从感官上可以看出它是另一个角度很符合直觉地去评估重要性的方法。 我们重新在画布上查询所有的点边之后，在浏览器里运行 Betweenness Centrality 算法，这次的结果是： 从它的五跳内子图可以看出，与之前 PageRank 所得的关键人物 Tim Duncan 呈现的星星状态不同，Dejounte Murray 的子图呈现簇状，在感官、直觉上可以想象 Dejounte Murray 真的在很多节点之间的最小路径的必经之路上，而 Tim Duncan 则似乎和更多的重要连接者产生了关联。 在实际的应用场景中，我们通常要通过不同方式的定义的理解、不同执行结果的试验、分析去找到我们关注的关键人物产生影响的结构特征，用来针对不同需求选择不同的算法。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:3:2","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#betweenness-centrality"},{"categories":["Nebula Graph"],"content":" 4 找出社区、聚集群体社交网络中的社区检测是一种通过分析社交关系来发现社区结构的技术。社区结构是指在社交网络、图谱中相互联系密切的一组节点，这些节点通常具有相似的特征或兴趣。例如，社区结构可能表现为用户根据共同的话题或兴趣聚集在一起的一组用户。 社区检测的目的是通过对社交网络进行分析，找出不同社区的边界，并确定每个社区中的节点。这一过程可以通过使用各种算法来完成，例如标签传播算法、弱联通分量算法和 Louvain 算法等。通过发现社区结构，可以更好地了解社交网络的结构和特征，并有助于社交网络服务提供方更好地推断和预测社交网络中的行为，帮助做好社交网络的治理、广告投放、市场营销等。 由于我们的数据集是非真实的，我在不同的算法之下得出的结果并不能展现出真实的意涵，所以本章只是展示一下利用几个图算法进行社区识别之后的结果，在真实世界的案例中，我们还应该在此基础之上利用领域知识或者其他技术手段协同给出不同群体、社区的画像、标签。 标签传播算法效果： Louvain 算法效果： 弱联通分量算法效果： 在后边的章节，我们有机会可以在更小、更简单的子图上再次验证这几个算法，结果会更有可解释性一些。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:4:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#找出社区聚集群体"},{"categories":["Nebula Graph"],"content":" 5 好友亲密度通过社区识别算法，其实是能够在一定程度上，在全局计算获得兴趣相近、关联紧密的好友的。那么如何获得一个给定用户的其他亲密好友呢？我们可以通过计算这个用户的好友中，和他共同好友的个数来排序获得这一信息！ 我们拿 “Tim Duncan” 举例，我们知道，他的两度好友（好友的好友：(:player{name: \"Tim Duncan\"})-[:follow]-(f:player)-[:follow]-(fof:player)）如果同时也是他的好友的话，那么他们这个中间的好友就是他和这个朋友的共同好友（Mutual Friend），那么有理由相信那些和 Tim Duncan 有更多共同好友的人可能跟他有更高亲密度： MATCH (start:`player`{name: \"Tim Duncan\"})-[:`follow`]-(f:`player`)-[:`follow`]-(fof:`player`), (start:`player`)-[:`follow`]-(fof:`player`) RETURN fof.`player`.name, count(DISTINCT f) AS NrOfMutualF ORDER BY NrOfMutualF DESC; 这个计算结果是，“Tony Parker” 和 Tim 有 5 个共同好友，最为亲密。 fof.player.name NrOfMutualF Tony Parker 5 Dejounte Murray 4 Manu Ginobili 3 Marco Belinelli 3 Danny Green 2 Boris Diaw 1 LaMarcus Aldridge 1 Tiago Splitter 1 下面，咱们通过可视化来验证一下这个结果吧！ 先看看每一个好友的共同好友(f:)都是谁？ MATCH (start:player{name: \"Tim Duncan\"})-[:`follow`]-(f:player)-[:`follow`]-(fof:player), (start:player)-[:`follow`]-(fof:player) RETURN fof.player.name, collect(DISTINCT f.player.name); 结果如下： fof.player.name collect(distinct f.player.name) Boris Diaw [“Tony Parker”] Manu Ginobili [“Dejounte Murray”, “Tiago Splitter”, “Tony Parker”] LaMarcus Aldridge [“Tony Parker”] Tiago Splitter [“Manu Ginobili”] Tony Parker [“Dejounte Murray”, “Boris Diaw”, “Manu Ginobili”, “Marco Belinelli”, “LaMarcus Aldridge”] Dejounte Murray [“Danny Green”, “Tony Parker”, “Manu Ginobili”, “Marco Belinelli”] Danny Green [“Dejounte Murray”, “Marco Belinelli”] Marco Belinelli [“Dejounte Murray”, “Danny Green”, “Tony Parker”] 然后我们在 Explorer 上可视化一下这个结果： 首先，我们把 Tim 的量度好友路径全查出来 MATCH p=(start:player{name: \"Tim Duncan\"})-[:`follow`]-(f:player)-[:follow]-(fof:player) RETURN p 然后我们在其中按照度去渲染节点大小，并选中 Tim 和 Tony，并在两者之间查询 follow 类型边、双向、最多 2 跳的全部路径： 可以看出他们之间是最亲密的朋友没跑了，而且他们的共同好友也在路径之中： [\"Dejounte Murray\", \"Boris Diaw\", \"Manu Ginobili\", \"Marco Belinelli\", \"LaMarcus Aldridge\"] ","date":"2022-12-08","objectID":"/nebulagraph-sns/:5:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#好友亲密度"},{"categories":["Nebula Graph"],"content":" 5.1 朋友圈子里的小群体这时候，如前边提到，这份数据集本身的非真实性，使得社区发现算法的结果不能得到其中洞察的内涵，现在我们可以接着这个小的子图，看看 Tim 的好友中可以如何区分群组、社区呢，咱们跑一个 Louvain 、弱联通分量、标签传播看看： 弱联通分量，可以把 Tim 等朋友们大体分割出两三个相互不连通的部分，非常符合连通分量的直观理解和定义。 标签传播，我们可以通过控制迭代次数按需去通过随机的传播划定出不同的划分度，结果可以有一定的区分度： 20 次迭代 1000 次迭代 Louvain，是一个比较高效、稳定的算法，基本上在这个子图下我们可以在很小的迭代次数下得到很符合直觉的划分： ","date":"2022-12-08","objectID":"/nebulagraph-sns/:5:1","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#朋友圈子里的小群体"},{"categories":["Nebula Graph"],"content":" 6 新朋友推荐接着前边二度朋友（朋友的朋友）的思路，我们可以很容易把那些还不是朋友的二度朋友作为推荐添加的好友，而排序规则则是他们之间的共同好友数量： MATCH (start:player{name: \"Tim Duncan\"})-[:`follow`]-(f:player)-[:`follow`]-(fof:player) WHERE NOT (start:player)-[:`follow`]-(fof:player) AND fof != start RETURN fof.player.name, count(DISTINCT f) AS NrOfMutualF ORDER BY NrOfMutualF DESC; fof.player.name NrOfMutualF LeBron James 2 James Harden 1 Chris Paul 1 Yao Ming 1 Damian Lillard 1 JaVale McGee 1 Kevin Durant 1 Kyle Anderson 1 Rudy Gay 1 Russell Westbrook 1 显然，LeBron 最值得推荐！再看看这些共同好友都是谁？ fof.player.name collect(distinct f.player.name) James Harden [“Dejounte Murray”] LeBron James [“Danny Green”, “Dejounte Murray”] Chris Paul [“Dejounte Murray”] Yao Ming [“Shaquille O’Neal”] Damian Lillard [“LaMarcus Aldridge”] JaVale McGee [“Shaquille O’Neal”] Kevin Durant [“Dejounte Murray”] Kyle Anderson [“Dejounte Murray”] Rudy Gay [“LaMarcus Aldridge”] Russell Westbrook [“Dejounte Murray”] 同样，我们在刚才的子图里找找 LeBron James 吧！我们把它俩之间的两步、双向路径找出来，果然只会经过 [\"Danny Green\", \"Dejounte Murray\"] 并且，没有直接的连接： 现在，系统会给两边发提醒：“hey，也许你们应该交个朋友！” ","date":"2022-12-08","objectID":"/nebulagraph-sns/:6:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#新朋友推荐"},{"categories":["Nebula Graph"],"content":" 7 共同邻居查找共同邻居是一个很常见的图库查询，它的场景可能根据不同的邻居关系，节点类型，同构、异构，带来不同的场景，前边两个场景下的共同好友本质上是两点之间的共同邻居，直接查询这样的关系用 OpenCypher 的表达非常简单。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:7:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#共同邻居"},{"categories":["Nebula Graph"],"content":" 7.1 两点之间的共同邻居比如这个表达可以查询两个用户之间的共性、交集，结果可能是共同团队、去过的地方、兴趣爱好、共同参与的帖子回复等等： MATCH p = (`v0`)--()--(`v1`) WHERE id(`v0`) == \"player100\" AND id(`v1`) == \"player104\" RETURN p 而限定了边的类型之后，这个查询就限定在共同好友的查询了。 MATCH p = (v0)--(:`follow`)--(v1) WHERE id(v0) == \"player100\" AND id(v1) == \"player104\" RETURN p ","date":"2022-12-08","objectID":"/nebulagraph-sns/:7:1","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#两点之间的共同邻居"},{"categories":["Nebula Graph"],"content":" 7.2 多点之间的共同邻居：内容推送下面，我们给出一个多点共同邻居的场景，我们从一个文章触发，查出所有在这个文章上有互动的用户，找到这一群体中的共同邻居。 这个共同邻居有什么用处呢？很自然，如果这个共同邻居还没有和这个文章有任何交互，我们可以把这个文章推荐给他。 这个查询的实现很有意思： 第一个 MATCH 是查到所有 post11 文章下留言和作者这些人的总人数 在第二个 MATCH 之后，我们查到所有这群人的一度好友路径中，这些文章过的交互用户的一度好友的参与过文章的朋友数量刚好等于这个参与文章的用户的数量的这些人，他们其实就是这些所有参与用户的共同好友。 MATCH (blog:post)\u003c-[e]-(:player) WHERE id(blog) == \"post11\" WITH blog, count(e) AS invoved_user_count MATCH (blog:post)\u003c-[]-(users:player)-[:`follow`]-(common_neighbor:player) WITH toSet(collect(users)) AS users, common_neighbor, invoved_user_count WHERE size(users) == invoved_user_count RETURN common_neighbor 而这个人就是…Tony！ +-----------------------------------------------------+ | common_neighbor | +-----------------------------------------------------+ | (\"player101\" :player{age: 36, name: \"Tony Parker\"}) | +-----------------------------------------------------+ 而我们可以很容易在可视化中国验证它： MATCH p=(blog:post)\u003c-[]-(users:player)-[:`follow`]-(common_neighbor:player) WHERE id(blog) == \"post11\" RETURN p 渲染这个查询结果，然后再这篇叫做 “Let’s have a party!” 的文章与 Tony 之间查找评论、po文、关注三类边的双向、两跳查询，就可以看到这些参与文章的人们无一例外，都是 Tony 的好友，而只有 Tony 自己还没去文章里留言！ 而 Party 怎么可以少了 Tony 呢？难道是他的惊喜生日 Party，Opps，我们是不是不应该告诉他？ ","date":"2022-12-08","objectID":"/nebulagraph-sns/:7:2","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#多点之间的共同邻居内容推送"},{"categories":["Nebula Graph"],"content":" 8 信息流我在之前写过基于图技术的推荐系统实现方法，其中描述了现代推荐系统中内容过滤、排序方法可以在图谱上进行，社交网络中有一点相似但又不同的场景是信息流（Feed），它的产生类似于推荐系统中的个性化，同时有具有很高的时效性，借助于包含了内容行为知识的社交图谱可以很直观、高效去实现个性化的信息流生成。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:8:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#信息流"},{"categories":["Nebula Graph"],"content":" 8.1 好友参与的内容最简单、直接的信息流定义可能就是在朋友圈、微博 feed 上刷一下关注的人创建、参与的内容列表了，先不考虑排序的问题，这些内容一定是： 一定时间段内好友创建的内容 一定时间端内好友评论的内容 我们可以用 cypher 表达这个查询用户 id 为 player100 的信息流： MATCH (feed_owner:player)-[:`follow`]-(friend:player) WHERE id(feed_owner) == \"player100\" OPTIONAL MATCH (friend:player)-[newly_commented:commented_at]-\u003e(:post)\u003c-[:created_post]-(feed_owner:player) WHERE newly_commented.post_time \u003e timestamp(\"2010-01-01 00:00:00\") OPTIONAL MATCH (friend:player)-[newly_created:created_post]-\u003e(po:post) WHERE newly_created.post_time \u003e timestamp(\"2010-01-01 00:00:00\") WITH DISTINCT friend, collect(DISTINCT po.post.title) + collect(\"comment of \" + dst(newly_commented)) AS feeds WHERE size(feeds) \u003e 0 RETURN friend.player.name, feeds friend.player.name feeds Boris Diaw [“I love you, Mom”, “comment of post11”] Marco Belinelli [“my best friend, tom”, “comment of post11”] Danny Green [“comment of post1”] Tiago Splitter [“comment of post1”] Dejounte Murray [“comment of post11”] Tony Parker [“I can swim”] LaMarcus Aldridge [“I hate coriander”, “comment of post11”, “comment of post1”] Manu Ginobili [“my best friend, jerry”, “comment of post11”, “comment of post11”] 于是，我们可以把这些评论、文章发送到用户的 feed 之上了。 我们也来看看他们在图上的样子吧，我们输出所有查到的路径： MATCH p=(feed_owner:player)-[:`follow`]-(friend:player) WHERE id(feed_owner) == \"player100\" OPTIONAL MATCH p_comment=(friend:player)-[newly_commented:commented_at]-\u003e(:post)\u003c-[:created_post]-(feed_owner:player) WHERE newly_commented.post_time \u003e timestamp(\"2010-01-01 00:00:00\") OPTIONAL MATCH p_post=(friend:player)-[newly_created:created_post]-\u003e(po:post) WHERE newly_created.post_time \u003e timestamp(\"2010-01-01 00:00:00\") RETURN p, p_comment, p_post 渲染在 Explorer 上，选择“神经网络”这个布局，可以很清晰看出这些粉色的文章节点，还有代表评论的边。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:8:1","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#好友参与的内容"},{"categories":["Nebula Graph"],"content":" 8.2 附近好友的内容我们再进一步，把地理信息考虑进来，获取那些住址的经纬度小于一定距离朋友相关的内容。 这里，我们用到了 NebulaGraph 的 GeoSpatial 地理功能，ST_Distance(home.address.geo_point, friend_addr.address.geo_point) AS distance WHERE distance \u003c 1000000 的约束条件帮我们表达了距离的限制。 MATCH (home:address)-[:lived_in]-(feed_owner:player)-[:`follow`]-(friend:player)-[:lived_in]-(friend_addr:address) WHERE id(feed_owner) == \"player100\" WITH feed_owner, friend, ST_Distance(home.address.geo_point, friend_addr.address.geo_point) AS distance WHERE distance \u003c 1000000 OPTIONAL MATCH (friend:player)-[newly_commented:commented_at]-\u003e(:post)\u003c-[:created_post]-(feed_owner:player) WHERE newly_commented.post_time \u003e timestamp(\"2010-01-01 00:00:00\") OPTIONAL MATCH (friend:player)-[newly_created:created_post]-\u003e(po:post) WHERE newly_created.post_time \u003e timestamp(\"2010-01-01 00:00:00\") WITH DISTINCT friend, collect(DISTINCT po.post.title) + collect(\"comment of \" + dst(newly_commented)) AS feeds WHERE size(feeds) \u003e 0 RETURN friend.player.name, feeds friend.player.name feeds Marco Belinelli [“my best friend, tom”, “comment of post11”] Tony Parker [“I can swim”] Danny Green [“comment of post1”] 这时候，从可视化这个结果也可以看到住址这一关系，以及它们的经纬度信息，我手动根据它们的经纬度，把地址的节点在图上排布了一下可以看到这个 feed 的主人 Tim(player100) 的住址（7，8）刚好在其他好友住址的中间位置，这些临近好友的相关的文章和参与评论的内容将被作为信息流推送给 Tim： ","date":"2022-12-08","objectID":"/nebulagraph-sns/:8:2","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#附近好友的内容"},{"categories":["Nebula Graph"],"content":" 9 时空关系追踪时空关系追踪这个图谱应用是在公共安全、物流、疫情防控等场景下，利用图遍历将繁杂、凌乱的信息充分利用起来的典型应用。当我们建立起这样的图谱之后往往只需要简单的图查询就可以获得非常有用的洞察。本章节我给大家距离一下这个应用场景。 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:9:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#时空关系追踪"},{"categories":["Nebula Graph"],"content":" 9.1 数据集为此，我创建了一个虚拟的数据集由来构建一个时空关系图谱。数据集的生成程序和一份可以直接用的文件都放在了 GitHub 上，仓库地址是： https://github.com/wey-gu/covid-track-graph-datagen 。 它的数据建模如下： 在一个全新的环境里，我们可以用下边的 3 行命令就准备好这个图谱： # 安装 NebulaGraph + NebulaGraph Studio curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v3 # 下载数据集 git clone https://github.com/wey-gu/covid-track-graph-datagen \u0026\u0026 cd covid-track-graph-datagen # 导入数据集 docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/:/root \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer-config.yaml 然后我们在 console 里查看一下数据 ~/.nebula-up/console.sh # 进入 console 了，进到 covid_trace 图空间（刚才创建的） USE covid_trace; # 执行数据统计的任务 SHOW JOB STATS 结果： (root@nebula) [covid_trace]\u003e SHOW STATS +---------+------------+--------+ | Type | Name | Count | +---------+------------+--------+ | \"Tag\" | \"人\" | 10000 | | \"Tag\" | \"地址\" | 1000 | | \"Tag\" | \"城市\" | 341 | | \"Tag\" | \"村镇\" | 42950 | | \"Tag\" | \"省份\" | 32 | | \"Tag\" | \"联系方式\" | 0 | | \"Tag\" | \"行政区\" | 3134 | | \"Tag\" | \"街道\" | 667911 | | \"Edge\" | \"住址\" | 0 | | \"Edge\" | \"到访\" | 19986 | | \"Edge\" | \"同住\" | 19998 | | \"Edge\" | \"属于\" | 715336 | | \"Space\" | \"vertices\" | 725368 | | \"Space\" | \"edges\" | 755320 | +---------+------------+--------+ Got 14 rows (time spent 1087/46271 us) ","date":"2022-12-08","objectID":"/nebulagraph-sns/:9:1","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#数据集"},{"categories":["Nebula Graph"],"content":" 9.2 两人之间的关联很自然，利用路径查询就可以了： # 最短 FIND SHORTEST PATH FROM \"p_100\" TO \"p_101\" OVER * BIDIRECT YIELD PATH AS paths # 所有路径 FIND ALL PATH FROM \"p_100\" TO \"p_101\" OVER * BIDIRECT YIELD PATH AS paths | LIMIT 10 最短路径结果： paths \u003c(“p_100”)\u003c-[:同住@0 {}]-(“p_2136”)\u003c-[:同住@0 {}]-(“p_3708”)-[:到访@0 {}]-\u003e(“a_125”)\u003c-[:到访@0 {}]-(“p_101”)\u003e 所有路径结果： paths \u003c(“p_100”)\u003c-[:同住@0 {}]-(“p_2136”)\u003c-[:同住@0 {}]-(“p_3708”)-[:到访@0 {}]-\u003e(“a_125”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)-[:到访@0 {}]-\u003e(“a_328”)\u003c-[:到访@0 {}]-(“p_6976”)\u003c-[:同住@0 {}]-(“p_261”)-[:到访@0 {}]-\u003e(“a_352”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)-[:同住@0 {}]-\u003e(“p_8709”)-[:同住@0 {}]-\u003e(“p_9315”)-[:同住@0 {}]-\u003e(“p_261”)-[:到访@0 {}]-\u003e(“a_352”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)-[:到访@0 {}]-\u003e(“a_328”)\u003c-[:到访@0 {}]-(“p_6311”)-[:同住@0 {}]-\u003e(“p_3941”)-[:到访@0 {}]-\u003e(“a_345”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)-[:到访@0 {}]-\u003e(“a_328”)\u003c-[:到访@0 {}]-(“p_5046”)-[:同住@0 {}]-\u003e(“p_3993”)-[:到访@0 {}]-\u003e(“a_144”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)-[:同住@0 {}]-\u003e(“p_3457”)-[:到访@0 {}]-\u003e(“a_199”)\u003c-[:到访@0 {}]-(“p_6771”)-[:到访@0 {}]-\u003e(“a_458”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)\u003c-[:同住@0 {}]-(“p_1462”)-[:到访@0 {}]-\u003e(“a_922”)\u003c-[:到访@0 {}]-(“p_5869”)-[:到访@0 {}]-\u003e(“a_345”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)\u003c-[:同住@0 {}]-(“p_9489”)-[:到访@0 {}]-\u003e(“a_985”)\u003c-[:到访@0 {}]-(“p_2733”)-[:到访@0 {}]-\u003e(“a_458”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)\u003c-[:同住@0 {}]-(“p_9489”)-[:到访@0 {}]-\u003e(“a_905”)\u003c-[:到访@0 {}]-(“p_2733”)-[:到访@0 {}]-\u003e(“a_458”)\u003c-[:到访@0 {}]-(“p_101”)\u003e \u003c(“p_100”)-[:到访@0 {}]-\u003e(“a_89”)\u003c-[:到访@0 {}]-(“p_1333”)\u003c-[:同住@0 {}]-(“p_1683”)-[:到访@0 {}]-\u003e(“a_345”)\u003c-[:到访@0 {}]-(“p_101”)\u003e 我们把所有路径进行可视化渲染，标记出起点终点的两人，并在其中查到他们的最短路径，他们之间的千丝万缕关系就一目了然了，无论是商业洞察、公共安全还是疫情防控的目的，有了这个信息，相应的工作都可以如虎添翼地向下进展。 当然，在真实的系统上，可能我们只需要关心两个用户之间的关联远近，得出量化的评估： FIND SHORTEST PATH FROM \"p_100\" TO \"p_101\" OVER * BIDIRECT YIELD PATH AS paths | YIELD collect(length($-.paths)) AS len | YIELD coalesce($-.len[0], -1) AS len 结果中我们只关心他们之间最短路径的长度为：4。 len 4 ","date":"2022-12-08","objectID":"/nebulagraph-sns/:9:2","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#两人之间的关联"},{"categories":["Nebula Graph"],"content":" 9.3 时空相交的人进一步我们可以用图语义勾勒出我们想确定的任何带有时间与空间信息的模式，在图谱中实时查询出来，比如对给定的人，他的 id 是 p_101，我们相差在特定时间里所有和他有时空相交的人，这意味着那些人在 p_101 访问某一地方的时间段之内也逗留、访问了这些地方： MATCH (p:人)-[`visit0`:到访]-\u003e(`addr`:地址)\u003c-[`visit1`:到访]-(p1:人) WHERE id(p) == \"p_101\" AND `visit0`.`start_time` \u003c `visit1`.`end_time` AND `visit0`.`end_time` \u003e `visit1`.`start_time` RETURN `addr`.地址.`name`, collect(p1.人.`name`) 我们得到了再每一个到访地点的时空相交人列表如下： addr.地址.name collect(p1.人.name) 闵行仇路q座 255960 [“徐畅”, “王佳”, “曾亮”, “姜桂香”, “邵秀英”, “韦婷婷”, “陶玉”, “马坤”, “黄想”, “张秀芳”, “颜桂芳”, “张洋”] 丰都北京路J座 725701 [“陈春梅”, “施婷婷”, “井成”, “范文”, “王楠”, “尚明”, “薛秀珍”, “宋金凤”, “杨雪”, “邓丽华”, “李杨”, “温佳”, “叶玉”, “周明”, “王桂珍”, “段玉华”, “金成”, “黄鑫”, “邬兵”, “魏柳”, “王兰英”, “杨柳”] 普陀潜江路P座 210730 [“储平”, “洪红霞”, “沈玉英”, “王洁”, “董玉英”, “邓凤英”, “谢海燕”, “梁雷”, “张畅”, “任玉兰”, “贾宇”, “汪成”, “孙琴”, “纪红梅”, “王欣”, “陈兵”, “张成”, “王东”, “谷霞”, “林成”] 普陀武街f座 706352 [“邢成”, “张建军”, “张鑫”, “戴涛”, “蔡洋”, “汪燕”, “尹亮”, “何利”, “何玉”, “周波”, “金秀珍”, “杨波”, “张帅”, “周柳”, “马云”, “张建华”, “王丽丽”, “陈丽”, “万萍”] 城东贵阳街O座 110567 [“李洁”, “陈静”, “王建国”, “方淑华”, “古想”, “漆萍”, “詹桂花”, “王成”, “李慧”, “孙娜”, “马伟”, “谢杰”, “王鹏”, “鞠桂英”, “莫桂英”, “汪雷”, “黄彬”, “李玉梅”, “祝红梅”] 现在，我们在图上可视化这个结果看看： MATCH (p:人)-[`visit0`:到访]-\u003e(`addr`:地址)\u003c-[`visit1`:到访]-(p1:人) WHERE id(p) == \"p_101\" AND `visit0`.`start_time` \u003c `visit1`.`end_time` AND `visit0`.`end_time` \u003e `visit1`.`start_time` RETURN paths; 结果中我们标记了 p_101 为不同的图标，在用标签传播算法识别一下聚集社区，是不是一图胜千言呢？ ","date":"2022-12-08","objectID":"/nebulagraph-sns/:9:3","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#时空相交的人"},{"categories":["Nebula Graph"],"content":" 9.4 最近去过的省份最后，我们再用简单的查询模式表达出一个人在给定时间内，比如从一个时间点开始，到访过的所有省份 MATCH (p:人)-[visit:到访]-\u003e(`addr`:地址)-[:属于*5]-(province:省份) WHERE id(p) == \"p_101\" AND visit.start_time \u003e 1625469000 RETURN province.省份.name, collect(addr.地址.name); 看起来他/她去过不少地方呢： province.省份.name collect(addr.地址.name) 四川省 [“闵行仇路q座 255960”] 山东省 [“城东贵阳街O座 110567”] 云南省 [“丰都北京路J座 725701”] 福建省 [“普陀潜江路P座 210730”] 内蒙古自治区 [“普陀武街f座 706352”] 老轨迹，我们在图上看看这个结果吧，这次，我们选择 Dagre-LR 这个布局渲染，结果是不是非常清晰呢？ ","date":"2022-12-08","objectID":"/nebulagraph-sns/:9:4","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#最近去过的省份"},{"categories":["Nebula Graph"],"content":" 10 总结我们给出了不少社交网络里的应用案例，包括： 查找关键的人 识别聚集的人群、社群 判定两个用户之间的亲密度 推荐新朋友 利用共同邻居精准推送重要内容 根据好友关系、地理位置推送信息流 利用时空关系图谱查询人与人之间关系、获取时空相交的人、访问过的省份 社交网络作为天然的图结构，非常适合用图的技术来存储、查询、计算、分析与可视化去解决其上的各式各样的问题，NebulaGraph 的强大处理能力和可视化能力使得我们已知很多公司在使用它作为社交领域的图存储、计算层，这其中包括：网易游戏、微信、Line、Soul、快手和知乎等等很多行业领先的团队，希望大家通过本章能对社交领域的图技术应有有一个初步的认识。 题图版权：by Ryoji ","date":"2022-12-08","objectID":"/nebulagraph-sns/:10:0","series":null,"tags":["Nebula Graph","SNS","社交网络","图算法"],"title":"图数据库的社交网络应用","uri":"/nebulagraph-sns/#总结"},{"categories":["Nebula Graph"],"content":"一次利用 chatGPT 给出数据抓取代码，借助 NebulaGraph 图数据库与图算法预测体育赛事的尝试。","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/"},{"categories":["Nebula Graph"],"content":" 一次利用 chatGPT 给出数据抓取代码，借助 NebulaGraph 图数据库与图算法预测体育赛事的尝试。 ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:0:0","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#"},{"categories":["Nebula Graph"],"content":" 1 蹭热度最近因为世界杯进行时，被这篇 Cambridge Intelligence 的文章启发（仅仅利用有限的信息量和条件，借助图算法的方法做合理的冠军预测），讨论到也可以试着用 NebulaGraph 玩玩冠军预测，还能顺道科普一波图库技术和图算法。 本来想着几个小时撸出来一个方案，被数据集的收集劝退了，我是是在懒得去 wikepedia 里抓取出来需要的数据，索性就按下放了几天。 同时，另一个热潮是最近 OpenAI 发布了 chatGPT 服务，它可以实现各种语言可是实现的复杂任务设计包括： 随时帮你实现一段什么样的代码 模拟成任意一个 prompt 界面：shell、python、virtual machine、甚至你创造的语言 假设、带入你给定的人设，和你聊天 写诗歌、rap、散文 找出一段代码的 bug 解释一段复杂的正则表达式的含义 chatGPT 的上下文能力、理解力到的前所未有的程度以至于所有人都在讨论新的工作方式：如何掌握让机器帮助我们完成任务。 所以，当我试过让 chatGPT 帮我写复杂的图数据库查询语句、解释复杂图查询语句的含义、解释一大段 Bison 代码含义之后我才意识到：为什么不让 chatGPT 帮我写好抓取数据的代码呢？ ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:1:0","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#蹭热度"},{"categories":["Nebula Graph"],"content":" 2 抓取数据我真试了一下，结果是：完全可以，而且似乎真的很容易。 整个过程基本上我像是一个代码考试的面试官、或者是一个产品经理，提出我的需求，chatGPT 给出代码的实现。我们再试着跑起来代码，找到代码中不合理的地方，指出来、给出建议，chatGPT 就真的能理解我指出的点，并给出相应的修正，像是： 这一全过程我就不在这里列出来了，不过我把生成的代码和整个讨论的过程都分享在这里，感兴趣的同学可以去看看。 最终生成的数据是一个 CSV 文件： 代码生成的文件 world_cup_squads.csv 手动修改、分开了生日和年龄的列 world_cup_squads_v0.csv 它像这样，包含的信息有：球队、小组、编号、位置、球员名字、生日、年龄、参加国际比赛场次、进球数、服役俱乐部。 Team,Group,No.,Pos.,Player,DOB,Age,Caps,Goals,Club Ecuador,A,1,1GK,Hernán Galíndez,(1987-03-30)30 March 1987,35,12,0,Aucas Ecuador,A,2,2DF,Félix Torres,(1997-01-11)11 January 1997,25,17,2,Santos Laguna Ecuador,A,3,2DF,Piero Hincapié,(2002-01-09)9 January 2002,20,21,1,Bayer Leverkusen Ecuador,A,4,2DF,Robert Arboleda,(1991-10-22)22 October 1991,31,33,2,São Paulo Ecuador,A,5,3MF,José Cifuentes,(1999-03-12)12 March 1999,23,11,0,Los Angeles FC 手动删除了 CSV 表头 world_cup_squads_no_headers.csv ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:2:0","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#抓取数据"},{"categories":["Nebula Graph"],"content":" 3 图方法预测2022世界杯","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:0","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#图方法预测2022世界杯"},{"categories":["Nebula Graph"],"content":" 3.1 图建模 前提，本文使用 NebulaGraph 和 NebulaGraph Explorer，你可以在阿里云上免费申请半个月的试用，入口链接是👉🏻 http://c.nxw.so/d52oz ，不要被这个陌生的短链接域名吓到，它只是帮助我们统计有多少同学通过这里访问到 https://market.aliyun.com 而已。 图建模（Graph Modeling）是把真实世界信息以”点–\u003e边“的图形式去抽象与表示。 这里，我们根据公共领域能够容易获得信息、把它映射成如下的点与边： 点： player（球员） team（球队） group（小组） club（俱乐部） 边： groupedin（球队属于哪一小组） belongto（队员属于国家队） serve（队员在俱乐部服役） 而队员的年龄、参加国际场次（caps）、进球数（goals）则很自然作为 player 这一类点的属性。 下图是这个 schema 在 NebulaGraph Studio/Explorer（后边称 Studio/Explorer） 中的截图： 然后，我们可以在右上角把它保存，创建一个新的图空间，应用这个图建模到图空间里。 注：参考文档 https://docs.nebula-graph.com.cn/3.3.0/nebula-explorer/db-management/draft/ ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:1","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#图建模"},{"categories":["Nebula Graph"],"content":" 3.2 导入数据进 NebulaGraph有了图建模，我们可以把之前的 CSV 文件（无表头版本）上传到 Studio 或者 Explorer 里，通过点、选关联不同的列到点边中的 vid 和属性： 之后点击导入，就把整个图导入到 NebulaGraph 了，成功之后，我们还得到了整个csv –\u003e Nebula Importer 的关联配置文件：nebula_importer_config_fifa.yml，你可以直接拖拽整个配置，不用自己去配置它了。 注：参考文档 https://docs.nebula-graph.com.cn/3.3.0/nebula-explorer/db-management/11.import-data/ 导入之后，我们可以在 schema 界面里查看数据统计，我们可以看到有 831 名球员参加了 2022 卡塔尔世界杯，他们服役在 295 个不同的俱乐部： 注：参考文档 https://docs.nebula-graph.com.cn/3.3.0/nebula-explorer/db-management/10.create-schema/#_6 ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:2","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#导入数据进-nebulagraph"},{"categories":["Nebula Graph"],"content":" 3.3 探索数据 3.3.1 查询数据下面，我们试着把所有的数据展示出来看看吧，首先，借助 NebulaGraph Explorer，我用拖拽的方式画出来任意类型的点（TAG）和任意类型点（TAG）之间的边，这里我们知道所有的点都是至少包含在一个边里的，所以不会漏掉任何孤立的点。 让它帮我生成查询的语句，这里，它默认 LIMIT 100 了，我们手动改大一些（ LIMIT 10000），让它在 Console 里执行。 3.3.2 初步观察数据结果渲染出来是这样子，可以看到它天然形成了一簇一簇的模式。 这些外围、形成的簇多是一些由非传统意义上的有全球影响力的俱乐部，和非传统的足球厉害的国家队的球员组成，因为通常这些俱乐部只有一两个球员，而且他们还集中在一个国家队、地区，所以没有和很多其他球员、国家队产生连接。 3.3.3 图算法辅助分析在我点击了 Explorer 中的两个按钮之后（详细参考后边的文档链接），在浏览器里，我们可以看到整个图已经变成： 注：这部分功能可以参考文档 https://docs.nebula-graph.com.cn/3.3.0/nebula-explorer/graph-explorer/graph-algorithm/ 这里，利用到了两个图算法来分析这里的洞察： 利用点的出入度，改变他们的显示大小突出重要程度 利用 Louvain 算法区分点的社区分割 可以看到红色的大点是鼎鼎大名的巴塞罗那，而它的球员们也被红色标记了。 ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:3","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#探索数据"},{"categories":["Nebula Graph"],"content":" 3.3 探索数据 3.3.1 查询数据下面，我们试着把所有的数据展示出来看看吧，首先，借助 NebulaGraph Explorer，我用拖拽的方式画出来任意类型的点（TAG）和任意类型点（TAG）之间的边，这里我们知道所有的点都是至少包含在一个边里的，所以不会漏掉任何孤立的点。 让它帮我生成查询的语句，这里，它默认 LIMIT 100 了，我们手动改大一些（ LIMIT 10000），让它在 Console 里执行。 3.3.2 初步观察数据结果渲染出来是这样子，可以看到它天然形成了一簇一簇的模式。 这些外围、形成的簇多是一些由非传统意义上的有全球影响力的俱乐部，和非传统的足球厉害的国家队的球员组成，因为通常这些俱乐部只有一两个球员，而且他们还集中在一个国家队、地区，所以没有和很多其他球员、国家队产生连接。 3.3.3 图算法辅助分析在我点击了 Explorer 中的两个按钮之后（详细参考后边的文档链接），在浏览器里，我们可以看到整个图已经变成： 注：这部分功能可以参考文档 https://docs.nebula-graph.com.cn/3.3.0/nebula-explorer/graph-explorer/graph-algorithm/ 这里，利用到了两个图算法来分析这里的洞察： 利用点的出入度，改变他们的显示大小突出重要程度 利用 Louvain 算法区分点的社区分割 可以看到红色的大点是鼎鼎大名的巴塞罗那，而它的球员们也被红色标记了。 ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:3","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#查询数据"},{"categories":["Nebula Graph"],"content":" 3.3 探索数据 3.3.1 查询数据下面，我们试着把所有的数据展示出来看看吧，首先，借助 NebulaGraph Explorer，我用拖拽的方式画出来任意类型的点（TAG）和任意类型点（TAG）之间的边，这里我们知道所有的点都是至少包含在一个边里的，所以不会漏掉任何孤立的点。 让它帮我生成查询的语句，这里，它默认 LIMIT 100 了，我们手动改大一些（ LIMIT 10000），让它在 Console 里执行。 3.3.2 初步观察数据结果渲染出来是这样子，可以看到它天然形成了一簇一簇的模式。 这些外围、形成的簇多是一些由非传统意义上的有全球影响力的俱乐部，和非传统的足球厉害的国家队的球员组成，因为通常这些俱乐部只有一两个球员，而且他们还集中在一个国家队、地区，所以没有和很多其他球员、国家队产生连接。 3.3.3 图算法辅助分析在我点击了 Explorer 中的两个按钮之后（详细参考后边的文档链接），在浏览器里，我们可以看到整个图已经变成： 注：这部分功能可以参考文档 https://docs.nebula-graph.com.cn/3.3.0/nebula-explorer/graph-explorer/graph-algorithm/ 这里，利用到了两个图算法来分析这里的洞察： 利用点的出入度，改变他们的显示大小突出重要程度 利用 Louvain 算法区分点的社区分割 可以看到红色的大点是鼎鼎大名的巴塞罗那，而它的球员们也被红色标记了。 ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:3","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#初步观察数据"},{"categories":["Nebula Graph"],"content":" 3.3 探索数据 3.3.1 查询数据下面，我们试着把所有的数据展示出来看看吧，首先，借助 NebulaGraph Explorer，我用拖拽的方式画出来任意类型的点（TAG）和任意类型点（TAG）之间的边，这里我们知道所有的点都是至少包含在一个边里的，所以不会漏掉任何孤立的点。 让它帮我生成查询的语句，这里，它默认 LIMIT 100 了，我们手动改大一些（ LIMIT 10000），让它在 Console 里执行。 3.3.2 初步观察数据结果渲染出来是这样子，可以看到它天然形成了一簇一簇的模式。 这些外围、形成的簇多是一些由非传统意义上的有全球影响力的俱乐部，和非传统的足球厉害的国家队的球员组成，因为通常这些俱乐部只有一两个球员，而且他们还集中在一个国家队、地区，所以没有和很多其他球员、国家队产生连接。 3.3.3 图算法辅助分析在我点击了 Explorer 中的两个按钮之后（详细参考后边的文档链接），在浏览器里，我们可以看到整个图已经变成： 注：这部分功能可以参考文档 https://docs.nebula-graph.com.cn/3.3.0/nebula-explorer/graph-explorer/graph-algorithm/ 这里，利用到了两个图算法来分析这里的洞察： 利用点的出入度，改变他们的显示大小突出重要程度 利用 Louvain 算法区分点的社区分割 可以看到红色的大点是鼎鼎大名的巴塞罗那，而它的球员们也被红色标记了。 ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:3","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#图算法辅助分析"},{"categories":["Nebula Graph"],"content":" 3.4 预测冠军算法为了能充分利用图的魔法（与图上的隐含条件、信息），我的思路是选择一种利用链接进行节点重要程度分析的图算法，找出拥有更高重要性的点，对他们全局迭代、排序，从而获得前几名的国家队排名。 这些方法其实就体现在厉害的球员同时拥有更大的社区、连接度，同时，为了增加传统强队之间的区分度，我准备把出场率、进球数的信息也考虑进来。 最终，我的算法是： 取出所有的 (球员)-服役-\u003e(俱乐部) 的关系，过滤其中进球数过少、单场进球过少的球员（以平衡一些弱队的老球员带来的过大影响） 从所有过滤之后的球员中向外探索，获得国家队 在以上的子图上运行 Betweenness Centrality 算法，计算节点重要度评分 3.4.1 算法过程首先，我们取出所有进球数超过 10，场均进球超过 0.2 的 (球员)-服役-\u003e(俱乐部) 的子图： MATCH ()-[e]-\u003e() WITH e LIMIT 10000 WITH e AS e WHERE e.goals \u003e 10 AND toFloat(e.goals)/e.caps \u003e 0.2 RETURN e 注：为了方便，我把进球数和出场数也作为了 serve 边上的属性了。 然后，我们全选图上的所有点，点击左边的工具栏，选择出方向的 belongto 边，向外进行图拓展（遍历），同时选择将拓展得到的新点标记为旗帜的 icon： 现在，我们获得了最终的子图，我们利用工具栏里的浏览器内的图算法功能，执行 BNC（Betweenness Centrality） 然后，这个子图变成了这样子： ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:4","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#预测冠军算法"},{"categories":["Nebula Graph"],"content":" 3.4 预测冠军算法为了能充分利用图的魔法（与图上的隐含条件、信息），我的思路是选择一种利用链接进行节点重要程度分析的图算法，找出拥有更高重要性的点，对他们全局迭代、排序，从而获得前几名的国家队排名。 这些方法其实就体现在厉害的球员同时拥有更大的社区、连接度，同时，为了增加传统强队之间的区分度，我准备把出场率、进球数的信息也考虑进来。 最终，我的算法是： 取出所有的 (球员)-服役-\u003e(俱乐部) 的关系，过滤其中进球数过少、单场进球过少的球员（以平衡一些弱队的老球员带来的过大影响） 从所有过滤之后的球员中向外探索，获得国家队 在以上的子图上运行 Betweenness Centrality 算法，计算节点重要度评分 3.4.1 算法过程首先，我们取出所有进球数超过 10，场均进球超过 0.2 的 (球员)-服役-\u003e(俱乐部) 的子图： MATCH ()-[e]-\u003e() WITH e LIMIT 10000 WITH e AS e WHERE e.goals \u003e 10 AND toFloat(e.goals)/e.caps \u003e 0.2 RETURN e 注：为了方便，我把进球数和出场数也作为了 serve 边上的属性了。 然后，我们全选图上的所有点，点击左边的工具栏，选择出方向的 belongto 边，向外进行图拓展（遍历），同时选择将拓展得到的新点标记为旗帜的 icon： 现在，我们获得了最终的子图，我们利用工具栏里的浏览器内的图算法功能，执行 BNC（Betweenness Centrality） 然后，这个子图变成了这样子： ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:3:4","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#算法过程"},{"categories":["Nebula Graph"],"content":" 4 预测结果最终，我们根据 Betweenness Centrality 的值，排序，可以得到最终的获胜球队应该是：巴西 🇧🇷！ 其次是比利时、德国、英格兰、法国、阿根廷，让我们等两个礼拜回来看看预测结果是否准确吧 :D。 注：排序数据（其中还有非参赛球队的点） Vertex Betweenness Centrality Brazil🇧🇷 3499 Paris Saint-Germain 3073.3333333333300 Neymar 3000 Tottenham Hotspur 2740 Belgium🇧🇪 2587.833333333330 Richarlison 2541 Kevin De Bruyne 2184 Manchester City 2125 İlkay Gündoğan 2064 Germany🇩🇪 2046 Harry Kane (captain 1869 England🏴󠁧󠁢󠁥󠁮󠁧󠁿 1864 France🇫🇷 1858.6666666666700 Argentina🇦🇷 1834.6666666666700 Bayern Munich 1567 Kylian Mbappé 1535.3333333333300 Lionel Messi (captain 1535.3333333333300 Gabriel Jesus 1344 题图：这个文章的图也是用 OpenAI DALL-E 2 生成，并用 DALL-E 2 Outpainting 扩充的，原图。 ","date":"2022-12-06","objectID":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/:4:0","series":null,"tags":["Nebula Graph","世界杯","图建模","OpenAI","chatGPT","图算法"],"title":"chatGPT 加 NebulaGraph 预测 2022 世界杯冠军球队","uri":"/chatgpt-and-nebulagraph-predict-fifa-world-cup/#预测结果"},{"categories":["Nebula Graph","Amundsen"],"content":"也许我们没有必要从头在 NebulaGraph 上搭建自己的数据血缘项目，本文分享如何用开源、现代的 DataOps、ETL、Dashboard、元数据、数据血缘管理系统构建大数据治理基础设施","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/"},{"categories":["Nebula Graph","Amundsen"],"content":" 也许我们没有必要从头在 NebulaGraph 上搭建自己的数据血缘项目，本文分享如何用开源、现代的 DataOps、ETL、Dashboard、元数据、数据血缘管理系统构建大数据治理基础设施 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:0:0","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#"},{"categories":["Nebula Graph","Amundsen"],"content":" 1 元数据治理系统元数据治理系统是一个提供了所有数据在哪、它们的格式化方式、生成、转换、依赖、呈现和所属的一站式视图。 元数据治理系统是所有数据仓库、数据库、表、仪表板、ETL 作业等的目录接口（catalog），有了它，我们就不用在群里喊“大家好，我可以更改这个表的 schema 吗？”， “请问谁知道我如何找到 table-view-foo-bar 的原始数据？”，一个成熟的数据治理方案中的元数据治理系统，对成规模的数据团队来说非常必要。 对于另一个词：数据血缘则是众多需要管理的元数据之一，例如，某些 Dashboard 是 某一个 Table View 的下游，而这个 Table View 又是从另外两个上游的表 JOIN 而来两。 我们显然应该清晰的掌握、管理这些信息，去构建一个可信、可控的系统和数据质量控制体系。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:1:0","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#元数据治理系统"},{"categories":["Nebula Graph","Amundsen"],"content":" 2 参考解决方案","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:0","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#参考解决方案"},{"categories":["Nebula Graph","Amundsen"],"content":" 2.1 方案的动机元数据和数据血缘本质上非常适合图数据建模、图数据库的场景。这里典型的查询就是面向图关系的查询了，像“查找每个给定组件（即表）的所有 n 深度数据血缘”就是一个 NebulaGraph 中的FIND ALL PATH 查询。 作为 NebulaGraph 社区中的一员，我发现人们在论坛、群里讨论的查询和图建模总能看出来很多人都在 NebulaGraph 上从头搭建自己的数据血缘系统，而这些工作看起来大多数都是重复造轮子（而且轮子并不容易造）。 我们来看看这样的元数据治理系统的轮子里，都需要那些功能组件： 元数据 extractor 这部分需要从数据栈的不同方（如数据库、数仓、Dashboard，甚至从 ETL Pipeline 和应用、服务等等）中以拉或者推的方式获取。 元数据存储 可以存在数据库、图数据库里，或者有时候存成超大的 JSON manifest 文件都行 元数据目录接口系统（Catalog） 提供 API 和/或 GUI 界面以读取/写入元数据和数据血缘的系统 在 NebulaGraph 社区中，我看到不少人因为提问的查询和建模中明显有数据血缘的痕迹，意识到大家都在从头搭建数据血缘系统。考虑到系统中元数据的提取对象都是从各种知名数据库、数仓、最终的需求也大相径庭，这种重复的开发、研究、探索是一种大大的浪费。 所以，我准备搭建一个能够启发大家的参考数据血缘、治理方案，利用到市面上最好的开源项目。希望能让打算在 NebulaGraph 上定义和迭代自己的 Graph Model 并创建内部元数据和 pipeline 的人可以从这个项目中受益，从而拥有一个相对完善、设计精美的开箱即用的元数据治理系统，和相对更完善的图模型。 我尽量把这个方案做的完备、端到端（不只有元数据管理），希望也能为考虑做基于图做数据治理的新手一些启发和参考。 下图是整个方案的简单示意图： 其中上方是元数据的来源与导入、下方是元数据的存储与展示、发现。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:1","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#方案的动机"},{"categories":["Nebula Graph","Amundsen"],"content":" 2.2 技术栈介绍下边介绍一下其中的每一部分。 2.2.1 数据库和数仓为了处理和使用原始和中间数据，这里一定涉及至少一个数据库或者数仓。 它可以是 Hive、Apache Delta、TiDB、Cassandra、MySQL 或 Postgres，在这个参考项目中，我们选一个简单、流行的 Postgres。 ✅ - 数据仓库：Postgres 2.2.2 数据运维 DataOps我们应该有某种 DataOps 的方案，让 Pipeline 和环境具有可重复性、可测试性和版本控制性。 在这里，我们使用了 GitLab 创建的 Meltano。 Meltano 是一个 just-work 的 DataOps 平台，它以一种神奇而优雅的方式将 Singer 作为 EL 和 dbt 作为 T 连接起来，它还连接到其他一些 dataInfra 实用程序，例如 Apache Superset 和 Apache Airflow 等。 至此，我们又纳入了一个成员： ✅ - GitOps：Meltano https://gitlab.com/meltano/meltano 2.2.3 ETL如前边提到，我们还利用 Singer 与 Meltano 一起将来自许多不同数据源的数据 E（提取）和 L（加载）数据目标，并使用 dbt 作为 Transform 的平台。 ✅ - EL：Singer https://singer.io/ ✅ - T: dbt https://getdbt.com/ 2.2.4 数据可视化在数据之上创建 Dashboard、图表和表格来获得洞察是很直接的需求（可以想象为想象大数据之上的 excel 图标功能）。 Apache Superset 是我很喜欢的开源数据可视化项目，我准备用它来作为被治理管理的目标之一，同时，也会利用它的可视化作为元数据洞察功能的一部分。 ✅ - Dashboard：Apache Superset https://superset.apache.org/ 2.2.5 任务编排（DAG Job Orchestration）在大多数情况下，我们的 DataOps 作业、任务会增长到需要一个编排系统的规模，我们可以用 Apache Airflow 来负责这一块。 ✅ - DAG：Apache Airflow https://airflow.apache.org/ 2.2.6 元数据治理随着越来越多的组件和数据被引入数据基础设施，在数据库、表、数据建模(schema)、Dashboard、DAG（编排系统中的有向无环图）、应用与服务的所有生命周期中都将存在海量的元数据，需要对它们的管理员和团队进行协同管理、连接和发现。 Linux Foundation Amundsen 是我认为可以解决这个问题的最佳项目之一。 ✅ - 数据发现：Linux Foundation Amundsen https://www.amundsen.io/amundsen/ Amundsen 用图数据库为事实源（single source of truth）以加速多跳查询，Elastic Search 为全文搜索引擎，它能对所有元数据及其血缘进行了顺滑的处理还提供了优雅的 UI 和 API。 Amundsen 支持多种图数据库为后端，这里咱们用 NebulaGraph。 ✅ - 全文搜索：Elastic Search ✅ - 图数据库：NebulaGraph 现在，所有组件都齐活了，开始组装它们吧。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#技术栈介绍"},{"categories":["Nebula Graph","Amundsen"],"content":" 2.2 技术栈介绍下边介绍一下其中的每一部分。 2.2.1 数据库和数仓为了处理和使用原始和中间数据，这里一定涉及至少一个数据库或者数仓。 它可以是 Hive、Apache Delta、TiDB、Cassandra、MySQL 或 Postgres，在这个参考项目中，我们选一个简单、流行的 Postgres。 ✅ - 数据仓库：Postgres 2.2.2 数据运维 DataOps我们应该有某种 DataOps 的方案，让 Pipeline 和环境具有可重复性、可测试性和版本控制性。 在这里，我们使用了 GitLab 创建的 Meltano。 Meltano 是一个 just-work 的 DataOps 平台，它以一种神奇而优雅的方式将 Singer 作为 EL 和 dbt 作为 T 连接起来，它还连接到其他一些 dataInfra 实用程序，例如 Apache Superset 和 Apache Airflow 等。 至此，我们又纳入了一个成员： ✅ - GitOps：Meltano https://gitlab.com/meltano/meltano 2.2.3 ETL如前边提到，我们还利用 Singer 与 Meltano 一起将来自许多不同数据源的数据 E（提取）和 L（加载）数据目标，并使用 dbt 作为 Transform 的平台。 ✅ - EL：Singer https://singer.io/ ✅ - T: dbt https://getdbt.com/ 2.2.4 数据可视化在数据之上创建 Dashboard、图表和表格来获得洞察是很直接的需求（可以想象为想象大数据之上的 excel 图标功能）。 Apache Superset 是我很喜欢的开源数据可视化项目，我准备用它来作为被治理管理的目标之一，同时，也会利用它的可视化作为元数据洞察功能的一部分。 ✅ - Dashboard：Apache Superset https://superset.apache.org/ 2.2.5 任务编排（DAG Job Orchestration）在大多数情况下，我们的 DataOps 作业、任务会增长到需要一个编排系统的规模，我们可以用 Apache Airflow 来负责这一块。 ✅ - DAG：Apache Airflow https://airflow.apache.org/ 2.2.6 元数据治理随着越来越多的组件和数据被引入数据基础设施，在数据库、表、数据建模(schema)、Dashboard、DAG（编排系统中的有向无环图）、应用与服务的所有生命周期中都将存在海量的元数据，需要对它们的管理员和团队进行协同管理、连接和发现。 Linux Foundation Amundsen 是我认为可以解决这个问题的最佳项目之一。 ✅ - 数据发现：Linux Foundation Amundsen https://www.amundsen.io/amundsen/ Amundsen 用图数据库为事实源（single source of truth）以加速多跳查询，Elastic Search 为全文搜索引擎，它能对所有元数据及其血缘进行了顺滑的处理还提供了优雅的 UI 和 API。 Amundsen 支持多种图数据库为后端，这里咱们用 NebulaGraph。 ✅ - 全文搜索：Elastic Search ✅ - 图数据库：NebulaGraph 现在，所有组件都齐活了，开始组装它们吧。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#数据库和数仓"},{"categories":["Nebula Graph","Amundsen"],"content":" 2.2 技术栈介绍下边介绍一下其中的每一部分。 2.2.1 数据库和数仓为了处理和使用原始和中间数据，这里一定涉及至少一个数据库或者数仓。 它可以是 Hive、Apache Delta、TiDB、Cassandra、MySQL 或 Postgres，在这个参考项目中，我们选一个简单、流行的 Postgres。 ✅ - 数据仓库：Postgres 2.2.2 数据运维 DataOps我们应该有某种 DataOps 的方案，让 Pipeline 和环境具有可重复性、可测试性和版本控制性。 在这里，我们使用了 GitLab 创建的 Meltano。 Meltano 是一个 just-work 的 DataOps 平台，它以一种神奇而优雅的方式将 Singer 作为 EL 和 dbt 作为 T 连接起来，它还连接到其他一些 dataInfra 实用程序，例如 Apache Superset 和 Apache Airflow 等。 至此，我们又纳入了一个成员： ✅ - GitOps：Meltano https://gitlab.com/meltano/meltano 2.2.3 ETL如前边提到，我们还利用 Singer 与 Meltano 一起将来自许多不同数据源的数据 E（提取）和 L（加载）数据目标，并使用 dbt 作为 Transform 的平台。 ✅ - EL：Singer https://singer.io/ ✅ - T: dbt https://getdbt.com/ 2.2.4 数据可视化在数据之上创建 Dashboard、图表和表格来获得洞察是很直接的需求（可以想象为想象大数据之上的 excel 图标功能）。 Apache Superset 是我很喜欢的开源数据可视化项目，我准备用它来作为被治理管理的目标之一，同时，也会利用它的可视化作为元数据洞察功能的一部分。 ✅ - Dashboard：Apache Superset https://superset.apache.org/ 2.2.5 任务编排（DAG Job Orchestration）在大多数情况下，我们的 DataOps 作业、任务会增长到需要一个编排系统的规模，我们可以用 Apache Airflow 来负责这一块。 ✅ - DAG：Apache Airflow https://airflow.apache.org/ 2.2.6 元数据治理随着越来越多的组件和数据被引入数据基础设施，在数据库、表、数据建模(schema)、Dashboard、DAG（编排系统中的有向无环图）、应用与服务的所有生命周期中都将存在海量的元数据，需要对它们的管理员和团队进行协同管理、连接和发现。 Linux Foundation Amundsen 是我认为可以解决这个问题的最佳项目之一。 ✅ - 数据发现：Linux Foundation Amundsen https://www.amundsen.io/amundsen/ Amundsen 用图数据库为事实源（single source of truth）以加速多跳查询，Elastic Search 为全文搜索引擎，它能对所有元数据及其血缘进行了顺滑的处理还提供了优雅的 UI 和 API。 Amundsen 支持多种图数据库为后端，这里咱们用 NebulaGraph。 ✅ - 全文搜索：Elastic Search ✅ - 图数据库：NebulaGraph 现在，所有组件都齐活了，开始组装它们吧。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#数据运维-dataops"},{"categories":["Nebula Graph","Amundsen"],"content":" 2.2 技术栈介绍下边介绍一下其中的每一部分。 2.2.1 数据库和数仓为了处理和使用原始和中间数据，这里一定涉及至少一个数据库或者数仓。 它可以是 Hive、Apache Delta、TiDB、Cassandra、MySQL 或 Postgres，在这个参考项目中，我们选一个简单、流行的 Postgres。 ✅ - 数据仓库：Postgres 2.2.2 数据运维 DataOps我们应该有某种 DataOps 的方案，让 Pipeline 和环境具有可重复性、可测试性和版本控制性。 在这里，我们使用了 GitLab 创建的 Meltano。 Meltano 是一个 just-work 的 DataOps 平台，它以一种神奇而优雅的方式将 Singer 作为 EL 和 dbt 作为 T 连接起来，它还连接到其他一些 dataInfra 实用程序，例如 Apache Superset 和 Apache Airflow 等。 至此，我们又纳入了一个成员： ✅ - GitOps：Meltano https://gitlab.com/meltano/meltano 2.2.3 ETL如前边提到，我们还利用 Singer 与 Meltano 一起将来自许多不同数据源的数据 E（提取）和 L（加载）数据目标，并使用 dbt 作为 Transform 的平台。 ✅ - EL：Singer https://singer.io/ ✅ - T: dbt https://getdbt.com/ 2.2.4 数据可视化在数据之上创建 Dashboard、图表和表格来获得洞察是很直接的需求（可以想象为想象大数据之上的 excel 图标功能）。 Apache Superset 是我很喜欢的开源数据可视化项目，我准备用它来作为被治理管理的目标之一，同时，也会利用它的可视化作为元数据洞察功能的一部分。 ✅ - Dashboard：Apache Superset https://superset.apache.org/ 2.2.5 任务编排（DAG Job Orchestration）在大多数情况下，我们的 DataOps 作业、任务会增长到需要一个编排系统的规模，我们可以用 Apache Airflow 来负责这一块。 ✅ - DAG：Apache Airflow https://airflow.apache.org/ 2.2.6 元数据治理随着越来越多的组件和数据被引入数据基础设施，在数据库、表、数据建模(schema)、Dashboard、DAG（编排系统中的有向无环图）、应用与服务的所有生命周期中都将存在海量的元数据，需要对它们的管理员和团队进行协同管理、连接和发现。 Linux Foundation Amundsen 是我认为可以解决这个问题的最佳项目之一。 ✅ - 数据发现：Linux Foundation Amundsen https://www.amundsen.io/amundsen/ Amundsen 用图数据库为事实源（single source of truth）以加速多跳查询，Elastic Search 为全文搜索引擎，它能对所有元数据及其血缘进行了顺滑的处理还提供了优雅的 UI 和 API。 Amundsen 支持多种图数据库为后端，这里咱们用 NebulaGraph。 ✅ - 全文搜索：Elastic Search ✅ - 图数据库：NebulaGraph 现在，所有组件都齐活了，开始组装它们吧。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#etl"},{"categories":["Nebula Graph","Amundsen"],"content":" 2.2 技术栈介绍下边介绍一下其中的每一部分。 2.2.1 数据库和数仓为了处理和使用原始和中间数据，这里一定涉及至少一个数据库或者数仓。 它可以是 Hive、Apache Delta、TiDB、Cassandra、MySQL 或 Postgres，在这个参考项目中，我们选一个简单、流行的 Postgres。 ✅ - 数据仓库：Postgres 2.2.2 数据运维 DataOps我们应该有某种 DataOps 的方案，让 Pipeline 和环境具有可重复性、可测试性和版本控制性。 在这里，我们使用了 GitLab 创建的 Meltano。 Meltano 是一个 just-work 的 DataOps 平台，它以一种神奇而优雅的方式将 Singer 作为 EL 和 dbt 作为 T 连接起来，它还连接到其他一些 dataInfra 实用程序，例如 Apache Superset 和 Apache Airflow 等。 至此，我们又纳入了一个成员： ✅ - GitOps：Meltano https://gitlab.com/meltano/meltano 2.2.3 ETL如前边提到，我们还利用 Singer 与 Meltano 一起将来自许多不同数据源的数据 E（提取）和 L（加载）数据目标，并使用 dbt 作为 Transform 的平台。 ✅ - EL：Singer https://singer.io/ ✅ - T: dbt https://getdbt.com/ 2.2.4 数据可视化在数据之上创建 Dashboard、图表和表格来获得洞察是很直接的需求（可以想象为想象大数据之上的 excel 图标功能）。 Apache Superset 是我很喜欢的开源数据可视化项目，我准备用它来作为被治理管理的目标之一，同时，也会利用它的可视化作为元数据洞察功能的一部分。 ✅ - Dashboard：Apache Superset https://superset.apache.org/ 2.2.5 任务编排（DAG Job Orchestration）在大多数情况下，我们的 DataOps 作业、任务会增长到需要一个编排系统的规模，我们可以用 Apache Airflow 来负责这一块。 ✅ - DAG：Apache Airflow https://airflow.apache.org/ 2.2.6 元数据治理随着越来越多的组件和数据被引入数据基础设施，在数据库、表、数据建模(schema)、Dashboard、DAG（编排系统中的有向无环图）、应用与服务的所有生命周期中都将存在海量的元数据，需要对它们的管理员和团队进行协同管理、连接和发现。 Linux Foundation Amundsen 是我认为可以解决这个问题的最佳项目之一。 ✅ - 数据发现：Linux Foundation Amundsen https://www.amundsen.io/amundsen/ Amundsen 用图数据库为事实源（single source of truth）以加速多跳查询，Elastic Search 为全文搜索引擎，它能对所有元数据及其血缘进行了顺滑的处理还提供了优雅的 UI 和 API。 Amundsen 支持多种图数据库为后端，这里咱们用 NebulaGraph。 ✅ - 全文搜索：Elastic Search ✅ - 图数据库：NebulaGraph 现在，所有组件都齐活了，开始组装它们吧。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#数据可视化"},{"categories":["Nebula Graph","Amundsen"],"content":" 2.2 技术栈介绍下边介绍一下其中的每一部分。 2.2.1 数据库和数仓为了处理和使用原始和中间数据，这里一定涉及至少一个数据库或者数仓。 它可以是 Hive、Apache Delta、TiDB、Cassandra、MySQL 或 Postgres，在这个参考项目中，我们选一个简单、流行的 Postgres。 ✅ - 数据仓库：Postgres 2.2.2 数据运维 DataOps我们应该有某种 DataOps 的方案，让 Pipeline 和环境具有可重复性、可测试性和版本控制性。 在这里，我们使用了 GitLab 创建的 Meltano。 Meltano 是一个 just-work 的 DataOps 平台，它以一种神奇而优雅的方式将 Singer 作为 EL 和 dbt 作为 T 连接起来，它还连接到其他一些 dataInfra 实用程序，例如 Apache Superset 和 Apache Airflow 等。 至此，我们又纳入了一个成员： ✅ - GitOps：Meltano https://gitlab.com/meltano/meltano 2.2.3 ETL如前边提到，我们还利用 Singer 与 Meltano 一起将来自许多不同数据源的数据 E（提取）和 L（加载）数据目标，并使用 dbt 作为 Transform 的平台。 ✅ - EL：Singer https://singer.io/ ✅ - T: dbt https://getdbt.com/ 2.2.4 数据可视化在数据之上创建 Dashboard、图表和表格来获得洞察是很直接的需求（可以想象为想象大数据之上的 excel 图标功能）。 Apache Superset 是我很喜欢的开源数据可视化项目，我准备用它来作为被治理管理的目标之一，同时，也会利用它的可视化作为元数据洞察功能的一部分。 ✅ - Dashboard：Apache Superset https://superset.apache.org/ 2.2.5 任务编排（DAG Job Orchestration）在大多数情况下，我们的 DataOps 作业、任务会增长到需要一个编排系统的规模，我们可以用 Apache Airflow 来负责这一块。 ✅ - DAG：Apache Airflow https://airflow.apache.org/ 2.2.6 元数据治理随着越来越多的组件和数据被引入数据基础设施，在数据库、表、数据建模(schema)、Dashboard、DAG（编排系统中的有向无环图）、应用与服务的所有生命周期中都将存在海量的元数据，需要对它们的管理员和团队进行协同管理、连接和发现。 Linux Foundation Amundsen 是我认为可以解决这个问题的最佳项目之一。 ✅ - 数据发现：Linux Foundation Amundsen https://www.amundsen.io/amundsen/ Amundsen 用图数据库为事实源（single source of truth）以加速多跳查询，Elastic Search 为全文搜索引擎，它能对所有元数据及其血缘进行了顺滑的处理还提供了优雅的 UI 和 API。 Amundsen 支持多种图数据库为后端，这里咱们用 NebulaGraph。 ✅ - 全文搜索：Elastic Search ✅ - 图数据库：NebulaGraph 现在，所有组件都齐活了，开始组装它们吧。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#任务编排dag-job-orchestration"},{"categories":["Nebula Graph","Amundsen"],"content":" 2.2 技术栈介绍下边介绍一下其中的每一部分。 2.2.1 数据库和数仓为了处理和使用原始和中间数据，这里一定涉及至少一个数据库或者数仓。 它可以是 Hive、Apache Delta、TiDB、Cassandra、MySQL 或 Postgres，在这个参考项目中，我们选一个简单、流行的 Postgres。 ✅ - 数据仓库：Postgres 2.2.2 数据运维 DataOps我们应该有某种 DataOps 的方案，让 Pipeline 和环境具有可重复性、可测试性和版本控制性。 在这里，我们使用了 GitLab 创建的 Meltano。 Meltano 是一个 just-work 的 DataOps 平台，它以一种神奇而优雅的方式将 Singer 作为 EL 和 dbt 作为 T 连接起来，它还连接到其他一些 dataInfra 实用程序，例如 Apache Superset 和 Apache Airflow 等。 至此，我们又纳入了一个成员： ✅ - GitOps：Meltano https://gitlab.com/meltano/meltano 2.2.3 ETL如前边提到，我们还利用 Singer 与 Meltano 一起将来自许多不同数据源的数据 E（提取）和 L（加载）数据目标，并使用 dbt 作为 Transform 的平台。 ✅ - EL：Singer https://singer.io/ ✅ - T: dbt https://getdbt.com/ 2.2.4 数据可视化在数据之上创建 Dashboard、图表和表格来获得洞察是很直接的需求（可以想象为想象大数据之上的 excel 图标功能）。 Apache Superset 是我很喜欢的开源数据可视化项目，我准备用它来作为被治理管理的目标之一，同时，也会利用它的可视化作为元数据洞察功能的一部分。 ✅ - Dashboard：Apache Superset https://superset.apache.org/ 2.2.5 任务编排（DAG Job Orchestration）在大多数情况下，我们的 DataOps 作业、任务会增长到需要一个编排系统的规模，我们可以用 Apache Airflow 来负责这一块。 ✅ - DAG：Apache Airflow https://airflow.apache.org/ 2.2.6 元数据治理随着越来越多的组件和数据被引入数据基础设施，在数据库、表、数据建模(schema)、Dashboard、DAG（编排系统中的有向无环图）、应用与服务的所有生命周期中都将存在海量的元数据，需要对它们的管理员和团队进行协同管理、连接和发现。 Linux Foundation Amundsen 是我认为可以解决这个问题的最佳项目之一。 ✅ - 数据发现：Linux Foundation Amundsen https://www.amundsen.io/amundsen/ Amundsen 用图数据库为事实源（single source of truth）以加速多跳查询，Elastic Search 为全文搜索引擎，它能对所有元数据及其血缘进行了顺滑的处理还提供了优雅的 UI 和 API。 Amundsen 支持多种图数据库为后端，这里咱们用 NebulaGraph。 ✅ - 全文搜索：Elastic Search ✅ - 图数据库：NebulaGraph 现在，所有组件都齐活了，开始组装它们吧。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:2:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#元数据治理"},{"categories":["Nebula Graph","Amundsen"],"content":" 3 环境搭建与各组件初识整个项目方案都是开源的，大家可以在这里找到它的所有细节： https://github.com/wey-gu/data-lineage-ref-solution 整个项目大家的实验中我遵循尽量干净、鼓励的原则，需要假设在一个 unix-like 的系统上运行，有互联网和 Docker-Compose。 注：参考 https://docs.docker.com/compose/install/ 在继续之前安装 Docker 和 Docker Compose。 这里我们在 Ubuntu 20.04 LTS X86_64 上运行它，但在其他发行版或 Linux 版本上应该也没有问题。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:0","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#环境搭建与各组件初识"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.1 运行一个数仓、数据库首先，安装 Postgres 作为我们的数仓。 这个单行命令会创建一个使用 docker 在后台运行的 Postgres，进程关闭之后容器不会残留而是被清理掉（因为参数--rm）。 docker run --rm --name postgres \\ -e POSTGRES_PASSWORD=lineage_ref \\ -e POSTGRES_USER=lineage_ref \\ -e POSTGRES_DB=warehouse -d \\ -p 5432:5432 postgres 然后我们可以使用 Postgres CLI 或 GUI 客户端来验证它。 提示：可以用 VS Code 插件：SQL TOOLS 快速以 GUI 方式连接到数据库（支持 MariaDB、Postgres 、Cassandra 等） https://marketplace.visualstudio.com/items?itemName=mtxr.sqltools ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:1","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#运行一个数仓数据库"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.2 DataOps 工具链部署然后，安装有机结合了 Singler 和 dbt 的 Meltano。 Meltano 帮助我们管理 ETL 工具（作为插件）及其所有配置和 pipeline。 这些元信息位于 meltano 配置及其系统数据库（https://docs.meltano.com/concepts/project#system-database）中，其中配置是基于文件的（可以使用 GitOps 管理），它的默认系统数据库是 SQLite。 3.2.1 安装 Meltano使用 Meltano 的工作流是启动一个“meltano 项目”并开始将 E、L 和 T 添加到配置文件中。 项目的启动只需要一个 CLI 命令调用：meltano init yourprojectname，在那之前，可以先用 Python 的包管理器：pip 或者 Docker 镜像安装 Meltano： 在 python 虚拟环境中使用 pip 安装 Meltano： mkdir .venv # example in a debian flavor Linux distro sudo apt-get install python3-dev python3-pip python3-venv python3-wheel -y python3 -m venv .venv/meltano source .venv/meltano/bin/activate python3 -m pip install wheel python3 -m pip install meltano # init a project mkdir meltano_projects \u0026\u0026 cd meltano_projects # replace \u003cyourprojectname\u003e with your own one touch .env meltano init \u003cyourprojectname\u003e 或者用容器安装 Meltano： docker pull meltano/meltano:latest docker run --rm meltano/meltano --version # init a project mkdir meltano_projects \u0026\u0026 cd meltano_projects # replace \u003cyourprojectname\u003e with your own one touch .env docker run --rm -v \"$(pwd)\":/projects \\ -w /projects --env-file .env \\ meltano/meltano init \u003cyourprojectname\u003e 除了 meltano init，还有一些其他命令，例如 meltano etl 表示 ETL 的执行，还有 meltano invoke \u003cplugin\u003e 来调用插件命令，详细可以参考它的速查表（https://docs.meltano.com/reference/command-line-interface）。 3.2.2 Meltano GUI 界面Meltano 还带有一个基于 Web 的 UI，执行 ui 子命令就是启动它： meltano ui 默认他会跑在 http://localhost:5000 上。 对于 Docker 运行的情况，只需要在暴露 5000 端口的情况下运行容器即可，由于容器的默认命令已经是 meltano ui，所以 run 的命令只需： docker run -v \"$(pwd)\":/project \\ -w /project \\ -p 5000:5000 \\ meltano/meltano 3.2.3 Meltano 项目示例写到这里的时候，我注意到 Pat Nadolny 创建了很好的示例项目在 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/singer_dbt_jaffle，它利用 dbt 的 Meltano 示例数据集，采用 Airflow 编排 ETL 任务（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/dbt_orchestration，还有利用 Superset 的例子（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset）。 这里，我就不重复造轮子了，直接利用他的例子吧。 咱们可以参照 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/singer_dbt_jaffle，运行这样的数据管道（pipeline）： tap-CSV(Singer)，从 CSV 文件中提取数据 target-postgres(Singer)，将数据加载到 Postgres dbt，将数据转换为聚合表或视图 注意，前边我们已经启动了 postgres，那一步可以跳过。 操作过程是： git clone https://github.com/pnadolny13/meltano_example_implementations.git cd meltano_example_implementations/meltano_projects/singer_dbt_jaffle/ meltano install touch .env echo PG_PASSWORD=\"lineage_ref\" \u003e\u003e .env echo PG_USERNAME=\"lineage_ref\" \u003e\u003e .env # Extract and Load(with Singer) meltano run tap-csv target-postgres # Trasnform(with dbt) meltano run dbt:run # Generate dbt docs meltano invoke dbt docs generate # Serve generated dbt docs meltano invoke dbt docs to serve # Then visit http://localhost:8080 现在，我们可以连接到 Postgres 来查看 加载和转换后的数据预览如下，截图来自 VS Code 的 SQLTool： Payments 表里长这样子： ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#dataops-工具链部署"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.2 DataOps 工具链部署然后，安装有机结合了 Singler 和 dbt 的 Meltano。 Meltano 帮助我们管理 ETL 工具（作为插件）及其所有配置和 pipeline。 这些元信息位于 meltano 配置及其系统数据库（https://docs.meltano.com/concepts/project#system-database）中，其中配置是基于文件的（可以使用 GitOps 管理），它的默认系统数据库是 SQLite。 3.2.1 安装 Meltano使用 Meltano 的工作流是启动一个“meltano 项目”并开始将 E、L 和 T 添加到配置文件中。 项目的启动只需要一个 CLI 命令调用：meltano init yourprojectname，在那之前，可以先用 Python 的包管理器：pip 或者 Docker 镜像安装 Meltano： 在 python 虚拟环境中使用 pip 安装 Meltano： mkdir .venv # example in a debian flavor Linux distro sudo apt-get install python3-dev python3-pip python3-venv python3-wheel -y python3 -m venv .venv/meltano source .venv/meltano/bin/activate python3 -m pip install wheel python3 -m pip install meltano # init a project mkdir meltano_projects \u0026\u0026 cd meltano_projects # replace with your own one touch .env meltano init 或者用容器安装 Meltano： docker pull meltano/meltano:latest docker run --rm meltano/meltano --version # init a project mkdir meltano_projects \u0026\u0026 cd meltano_projects # replace with your own one touch .env docker run --rm -v \"$(pwd)\":/projects \\ -w /projects --env-file .env \\ meltano/meltano init 除了 meltano init，还有一些其他命令，例如 meltano etl 表示 ETL 的执行，还有 meltano invoke 来调用插件命令，详细可以参考它的速查表（https://docs.meltano.com/reference/command-line-interface）。 3.2.2 Meltano GUI 界面Meltano 还带有一个基于 Web 的 UI，执行 ui 子命令就是启动它： meltano ui 默认他会跑在 http://localhost:5000 上。 对于 Docker 运行的情况，只需要在暴露 5000 端口的情况下运行容器即可，由于容器的默认命令已经是 meltano ui，所以 run 的命令只需： docker run -v \"$(pwd)\":/project \\ -w /project \\ -p 5000:5000 \\ meltano/meltano 3.2.3 Meltano 项目示例写到这里的时候，我注意到 Pat Nadolny 创建了很好的示例项目在 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/singer_dbt_jaffle，它利用 dbt 的 Meltano 示例数据集，采用 Airflow 编排 ETL 任务（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/dbt_orchestration，还有利用 Superset 的例子（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset）。 这里，我就不重复造轮子了，直接利用他的例子吧。 咱们可以参照 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/singer_dbt_jaffle，运行这样的数据管道（pipeline）： tap-CSV(Singer)，从 CSV 文件中提取数据 target-postgres(Singer)，将数据加载到 Postgres dbt，将数据转换为聚合表或视图 注意，前边我们已经启动了 postgres，那一步可以跳过。 操作过程是： git clone https://github.com/pnadolny13/meltano_example_implementations.git cd meltano_example_implementations/meltano_projects/singer_dbt_jaffle/ meltano install touch .env echo PG_PASSWORD=\"lineage_ref\" \u003e\u003e .env echo PG_USERNAME=\"lineage_ref\" \u003e\u003e .env # Extract and Load(with Singer) meltano run tap-csv target-postgres # Trasnform(with dbt) meltano run dbt:run # Generate dbt docs meltano invoke dbt docs generate # Serve generated dbt docs meltano invoke dbt docs to serve # Then visit http://localhost:8080 现在，我们可以连接到 Postgres 来查看 加载和转换后的数据预览如下，截图来自 VS Code 的 SQLTool： Payments 表里长这样子： ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#安装-meltano"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.2 DataOps 工具链部署然后，安装有机结合了 Singler 和 dbt 的 Meltano。 Meltano 帮助我们管理 ETL 工具（作为插件）及其所有配置和 pipeline。 这些元信息位于 meltano 配置及其系统数据库（https://docs.meltano.com/concepts/project#system-database）中，其中配置是基于文件的（可以使用 GitOps 管理），它的默认系统数据库是 SQLite。 3.2.1 安装 Meltano使用 Meltano 的工作流是启动一个“meltano 项目”并开始将 E、L 和 T 添加到配置文件中。 项目的启动只需要一个 CLI 命令调用：meltano init yourprojectname，在那之前，可以先用 Python 的包管理器：pip 或者 Docker 镜像安装 Meltano： 在 python 虚拟环境中使用 pip 安装 Meltano： mkdir .venv # example in a debian flavor Linux distro sudo apt-get install python3-dev python3-pip python3-venv python3-wheel -y python3 -m venv .venv/meltano source .venv/meltano/bin/activate python3 -m pip install wheel python3 -m pip install meltano # init a project mkdir meltano_projects \u0026\u0026 cd meltano_projects # replace with your own one touch .env meltano init 或者用容器安装 Meltano： docker pull meltano/meltano:latest docker run --rm meltano/meltano --version # init a project mkdir meltano_projects \u0026\u0026 cd meltano_projects # replace with your own one touch .env docker run --rm -v \"$(pwd)\":/projects \\ -w /projects --env-file .env \\ meltano/meltano init 除了 meltano init，还有一些其他命令，例如 meltano etl 表示 ETL 的执行，还有 meltano invoke 来调用插件命令，详细可以参考它的速查表（https://docs.meltano.com/reference/command-line-interface）。 3.2.2 Meltano GUI 界面Meltano 还带有一个基于 Web 的 UI，执行 ui 子命令就是启动它： meltano ui 默认他会跑在 http://localhost:5000 上。 对于 Docker 运行的情况，只需要在暴露 5000 端口的情况下运行容器即可，由于容器的默认命令已经是 meltano ui，所以 run 的命令只需： docker run -v \"$(pwd)\":/project \\ -w /project \\ -p 5000:5000 \\ meltano/meltano 3.2.3 Meltano 项目示例写到这里的时候，我注意到 Pat Nadolny 创建了很好的示例项目在 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/singer_dbt_jaffle，它利用 dbt 的 Meltano 示例数据集，采用 Airflow 编排 ETL 任务（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/dbt_orchestration，还有利用 Superset 的例子（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset）。 这里，我就不重复造轮子了，直接利用他的例子吧。 咱们可以参照 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/singer_dbt_jaffle，运行这样的数据管道（pipeline）： tap-CSV(Singer)，从 CSV 文件中提取数据 target-postgres(Singer)，将数据加载到 Postgres dbt，将数据转换为聚合表或视图 注意，前边我们已经启动了 postgres，那一步可以跳过。 操作过程是： git clone https://github.com/pnadolny13/meltano_example_implementations.git cd meltano_example_implementations/meltano_projects/singer_dbt_jaffle/ meltano install touch .env echo PG_PASSWORD=\"lineage_ref\" \u003e\u003e .env echo PG_USERNAME=\"lineage_ref\" \u003e\u003e .env # Extract and Load(with Singer) meltano run tap-csv target-postgres # Trasnform(with dbt) meltano run dbt:run # Generate dbt docs meltano invoke dbt docs generate # Serve generated dbt docs meltano invoke dbt docs to serve # Then visit http://localhost:8080 现在，我们可以连接到 Postgres 来查看 加载和转换后的数据预览如下，截图来自 VS Code 的 SQLTool： Payments 表里长这样子： ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#meltano-gui-界面"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.2 DataOps 工具链部署然后，安装有机结合了 Singler 和 dbt 的 Meltano。 Meltano 帮助我们管理 ETL 工具（作为插件）及其所有配置和 pipeline。 这些元信息位于 meltano 配置及其系统数据库（https://docs.meltano.com/concepts/project#system-database）中，其中配置是基于文件的（可以使用 GitOps 管理），它的默认系统数据库是 SQLite。 3.2.1 安装 Meltano使用 Meltano 的工作流是启动一个“meltano 项目”并开始将 E、L 和 T 添加到配置文件中。 项目的启动只需要一个 CLI 命令调用：meltano init yourprojectname，在那之前，可以先用 Python 的包管理器：pip 或者 Docker 镜像安装 Meltano： 在 python 虚拟环境中使用 pip 安装 Meltano： mkdir .venv # example in a debian flavor Linux distro sudo apt-get install python3-dev python3-pip python3-venv python3-wheel -y python3 -m venv .venv/meltano source .venv/meltano/bin/activate python3 -m pip install wheel python3 -m pip install meltano # init a project mkdir meltano_projects \u0026\u0026 cd meltano_projects # replace with your own one touch .env meltano init 或者用容器安装 Meltano： docker pull meltano/meltano:latest docker run --rm meltano/meltano --version # init a project mkdir meltano_projects \u0026\u0026 cd meltano_projects # replace with your own one touch .env docker run --rm -v \"$(pwd)\":/projects \\ -w /projects --env-file .env \\ meltano/meltano init 除了 meltano init，还有一些其他命令，例如 meltano etl 表示 ETL 的执行，还有 meltano invoke 来调用插件命令，详细可以参考它的速查表（https://docs.meltano.com/reference/command-line-interface）。 3.2.2 Meltano GUI 界面Meltano 还带有一个基于 Web 的 UI，执行 ui 子命令就是启动它： meltano ui 默认他会跑在 http://localhost:5000 上。 对于 Docker 运行的情况，只需要在暴露 5000 端口的情况下运行容器即可，由于容器的默认命令已经是 meltano ui，所以 run 的命令只需： docker run -v \"$(pwd)\":/project \\ -w /project \\ -p 5000:5000 \\ meltano/meltano 3.2.3 Meltano 项目示例写到这里的时候，我注意到 Pat Nadolny 创建了很好的示例项目在 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/singer_dbt_jaffle，它利用 dbt 的 Meltano 示例数据集，采用 Airflow 编排 ETL 任务（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/dbt_orchestration，还有利用 Superset 的例子（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset）。 这里，我就不重复造轮子了，直接利用他的例子吧。 咱们可以参照 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/singer_dbt_jaffle，运行这样的数据管道（pipeline）： tap-CSV(Singer)，从 CSV 文件中提取数据 target-postgres(Singer)，将数据加载到 Postgres dbt，将数据转换为聚合表或视图 注意，前边我们已经启动了 postgres，那一步可以跳过。 操作过程是： git clone https://github.com/pnadolny13/meltano_example_implementations.git cd meltano_example_implementations/meltano_projects/singer_dbt_jaffle/ meltano install touch .env echo PG_PASSWORD=\"lineage_ref\" \u003e\u003e .env echo PG_USERNAME=\"lineage_ref\" \u003e\u003e .env # Extract and Load(with Singer) meltano run tap-csv target-postgres # Trasnform(with dbt) meltano run dbt:run # Generate dbt docs meltano invoke dbt docs generate # Serve generated dbt docs meltano invoke dbt docs to serve # Then visit http://localhost:8080 现在，我们可以连接到 Postgres 来查看 加载和转换后的数据预览如下，截图来自 VS Code 的 SQLTool： Payments 表里长这样子： ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#meltano-项目示例"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.3 搭一个 BI Dashboard 系统现在，我们有了数据仓库中的一些数据，用 ETL 工具链将不同的数据源导了进去，接下来可以试着用一下这些数据了。 像仪表大盘 Dashbaord 这样的 BI 工具能帮助我们从数据中获得有用的洞察，使用 Apache Superset，可以很容易地创建和管理基于这些数据源的 Dashboard 和各式各样的图表。 本章的重点不在于 Apache Superset 本身，所以，咱们还是复用 Pat Nadolny 在的例子 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset。 3.3.1 Bootstrap Meltano 和 Superset创建一个安装了 Meltano 的 python venv： mkdir .venv python3 -m venv .venv/meltano source .venv/meltano/bin/activate python3 -m pip install wheel python3 -m pip install meltano 参考 Pat 的 Guide（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset），稍微做一些修改： 克隆 repo，进入 jaffle_superset 项目 git clone https://github.com/pnadolny13/meltano_example_implementations.git cd meltano_example_implementations/meltano_projects/jaffle_superset/ 修改meltano配置文件，让 Superset 连接到我们创建的 Postgres： vim meltano_projects/jaffle_superset/meltano.yml 这里，我将主机名更改为“10.1.1.111”，这是我当前主机的 IP，而如果读者在 Windows 或者 macOS 机器的 Docker Desktop 上跑的话，这里不要修改，否则要参考我去改成自己实际的地址： --- a/meltano_projects/jaffle_superset/meltano.yml +++ b/meltano_projects/jaffle_superset/meltano.yml @@ -71,7 +71,7 @@ plugins: A list of database driver dependencies can be found here https://superset.apache.org/docs/databases/installing-database-drivers config: database_name: my_postgres - sqlalchemy_uri: postgresql+psycopg2://${PG_USERNAME}:${PG_PASSWORD}@host.docker.internal:${PG_PORT}/${PG_DATABASE} + sqlalchemy_uri: postgresql+psycopg2://${PG_USERNAME}:${PG_PASSWORD}@10.1.1.168:${PG_PORT}/${PG_DATABASE} tables: - model.my_meltano_project.customers - model.my_meltano_project.orders 添加 Postgres 登录的信息到 .env 文件： echo PG_USERNAME=lineage_ref \u003e\u003e .env echo PG_PASSWORD=lineage_ref \u003e\u003e .env 安装 Meltano 项目，运行 ETL 任务 meltano install meltano run tap-csv target-postgres dbt:run 调用、启动 superset，这里注意 ui 不是 meltano 的内部命令，而是一个配置进去的自定义行为（user-defined action） meltano invoke superset:ui 在另一个命令行终端，执行另一个自定义的命令 load_datasources meltano invoke superset:load_datasources 通过浏览器访问 http://localhost:8088/ 就是Superset 的图形界面了： 3.3.2 创建一个 Dashboard试一下在这个 Meltano 项目中定义的 Postgres 中的 ETL 数据上创建一个 Dashboard 吧 点击 + DASHBOARD，填写仪表盘名称，然后点击 SAVE，然后点击 + CREATE A NEW CHART 在新图表（Create a new chart）视图中，我们应该选择图表类型和数据集。 在这里，我选择了 orders 表作为数据源和 Pie Chart 图表类型： 点击“CREATE NEW CHART”后，我们在图表定义视图中，我选择了“status”的“Query”为“DIMENSIONS”，“COUNT(amount)”为“METRIC”。 至此，咱们就可以看到每个订单状态分布的饼图了。 点击 SAVE ，它会询问应该将此图表添加到哪个 Dashboard，选择后，单击 SAVE \u0026 GO TO DASHBOARD。 然后，在 Dashboard 中，我们可以看到那里的所有图表。 您可以看到我还添加了另一个图表来显示客户订单数量分布： 点 ··· 的话，还能看到刷新率设置、下载渲染图等其他的功能。 目前，我们有一个简单但典型的 homelab 数据技术栈了，并且所有东西都是开源的！ 想象一下，我们在 CSV 中有 100 个数据集，在数据仓库中有 200 个表，并且有几个数据工程师在运行不同的项目，这些项目使用、生成不同的应用与服务、Dashbaord 和数据库。 当有人想要查找、发现或者修改其中的一些表、数据集、Dashbaord 和管道，在沟通和工程方面可能都是非常不好管理的。 如前边提到的，我们需要这个示例项目的主要部分：元数据发现系统。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:3","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#搭一个-bi-dashboard-系统"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.3 搭一个 BI Dashboard 系统现在，我们有了数据仓库中的一些数据，用 ETL 工具链将不同的数据源导了进去，接下来可以试着用一下这些数据了。 像仪表大盘 Dashbaord 这样的 BI 工具能帮助我们从数据中获得有用的洞察，使用 Apache Superset，可以很容易地创建和管理基于这些数据源的 Dashboard 和各式各样的图表。 本章的重点不在于 Apache Superset 本身，所以，咱们还是复用 Pat Nadolny 在的例子 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset。 3.3.1 Bootstrap Meltano 和 Superset创建一个安装了 Meltano 的 python venv： mkdir .venv python3 -m venv .venv/meltano source .venv/meltano/bin/activate python3 -m pip install wheel python3 -m pip install meltano 参考 Pat 的 Guide（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset），稍微做一些修改： 克隆 repo，进入 jaffle_superset 项目 git clone https://github.com/pnadolny13/meltano_example_implementations.git cd meltano_example_implementations/meltano_projects/jaffle_superset/ 修改meltano配置文件，让 Superset 连接到我们创建的 Postgres： vim meltano_projects/jaffle_superset/meltano.yml 这里，我将主机名更改为“10.1.1.111”，这是我当前主机的 IP，而如果读者在 Windows 或者 macOS 机器的 Docker Desktop 上跑的话，这里不要修改，否则要参考我去改成自己实际的地址： --- a/meltano_projects/jaffle_superset/meltano.yml +++ b/meltano_projects/jaffle_superset/meltano.yml @@ -71,7 +71,7 @@ plugins: A list of database driver dependencies can be found here https://superset.apache.org/docs/databases/installing-database-drivers config: database_name: my_postgres - sqlalchemy_uri: postgresql+psycopg2://${PG_USERNAME}:${PG_PASSWORD}@host.docker.internal:${PG_PORT}/${PG_DATABASE} + sqlalchemy_uri: postgresql+psycopg2://${PG_USERNAME}:${PG_PASSWORD}@10.1.1.168:${PG_PORT}/${PG_DATABASE} tables: - model.my_meltano_project.customers - model.my_meltano_project.orders 添加 Postgres 登录的信息到 .env 文件： echo PG_USERNAME=lineage_ref \u003e\u003e .env echo PG_PASSWORD=lineage_ref \u003e\u003e .env 安装 Meltano 项目，运行 ETL 任务 meltano install meltano run tap-csv target-postgres dbt:run 调用、启动 superset，这里注意 ui 不是 meltano 的内部命令，而是一个配置进去的自定义行为（user-defined action） meltano invoke superset:ui 在另一个命令行终端，执行另一个自定义的命令 load_datasources meltano invoke superset:load_datasources 通过浏览器访问 http://localhost:8088/ 就是Superset 的图形界面了： 3.3.2 创建一个 Dashboard试一下在这个 Meltano 项目中定义的 Postgres 中的 ETL 数据上创建一个 Dashboard 吧 点击 + DASHBOARD，填写仪表盘名称，然后点击 SAVE，然后点击 + CREATE A NEW CHART 在新图表（Create a new chart）视图中，我们应该选择图表类型和数据集。 在这里，我选择了 orders 表作为数据源和 Pie Chart 图表类型： 点击“CREATE NEW CHART”后，我们在图表定义视图中，我选择了“status”的“Query”为“DIMENSIONS”，“COUNT(amount)”为“METRIC”。 至此，咱们就可以看到每个订单状态分布的饼图了。 点击 SAVE ，它会询问应该将此图表添加到哪个 Dashboard，选择后，单击 SAVE \u0026 GO TO DASHBOARD。 然后，在 Dashboard 中，我们可以看到那里的所有图表。 您可以看到我还添加了另一个图表来显示客户订单数量分布： 点 ··· 的话，还能看到刷新率设置、下载渲染图等其他的功能。 目前，我们有一个简单但典型的 homelab 数据技术栈了，并且所有东西都是开源的！ 想象一下，我们在 CSV 中有 100 个数据集，在数据仓库中有 200 个表，并且有几个数据工程师在运行不同的项目，这些项目使用、生成不同的应用与服务、Dashbaord 和数据库。 当有人想要查找、发现或者修改其中的一些表、数据集、Dashbaord 和管道，在沟通和工程方面可能都是非常不好管理的。 如前边提到的，我们需要这个示例项目的主要部分：元数据发现系统。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:3","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#bootstrap-meltano-和-superset"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.3 搭一个 BI Dashboard 系统现在，我们有了数据仓库中的一些数据，用 ETL 工具链将不同的数据源导了进去，接下来可以试着用一下这些数据了。 像仪表大盘 Dashbaord 这样的 BI 工具能帮助我们从数据中获得有用的洞察，使用 Apache Superset，可以很容易地创建和管理基于这些数据源的 Dashboard 和各式各样的图表。 本章的重点不在于 Apache Superset 本身，所以，咱们还是复用 Pat Nadolny 在的例子 https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset。 3.3.1 Bootstrap Meltano 和 Superset创建一个安装了 Meltano 的 python venv： mkdir .venv python3 -m venv .venv/meltano source .venv/meltano/bin/activate python3 -m pip install wheel python3 -m pip install meltano 参考 Pat 的 Guide（https://github.com/pnadolny13/meltano_example_implementations/tree/main/meltano_projects/jaffle_superset），稍微做一些修改： 克隆 repo，进入 jaffle_superset 项目 git clone https://github.com/pnadolny13/meltano_example_implementations.git cd meltano_example_implementations/meltano_projects/jaffle_superset/ 修改meltano配置文件，让 Superset 连接到我们创建的 Postgres： vim meltano_projects/jaffle_superset/meltano.yml 这里，我将主机名更改为“10.1.1.111”，这是我当前主机的 IP，而如果读者在 Windows 或者 macOS 机器的 Docker Desktop 上跑的话，这里不要修改，否则要参考我去改成自己实际的地址： --- a/meltano_projects/jaffle_superset/meltano.yml +++ b/meltano_projects/jaffle_superset/meltano.yml @@ -71,7 +71,7 @@ plugins: A list of database driver dependencies can be found here https://superset.apache.org/docs/databases/installing-database-drivers config: database_name: my_postgres - sqlalchemy_uri: postgresql+psycopg2://${PG_USERNAME}:${PG_PASSWORD}@host.docker.internal:${PG_PORT}/${PG_DATABASE} + sqlalchemy_uri: postgresql+psycopg2://${PG_USERNAME}:${PG_PASSWORD}@10.1.1.168:${PG_PORT}/${PG_DATABASE} tables: - model.my_meltano_project.customers - model.my_meltano_project.orders 添加 Postgres 登录的信息到 .env 文件： echo PG_USERNAME=lineage_ref \u003e\u003e .env echo PG_PASSWORD=lineage_ref \u003e\u003e .env 安装 Meltano 项目，运行 ETL 任务 meltano install meltano run tap-csv target-postgres dbt:run 调用、启动 superset，这里注意 ui 不是 meltano 的内部命令，而是一个配置进去的自定义行为（user-defined action） meltano invoke superset:ui 在另一个命令行终端，执行另一个自定义的命令 load_datasources meltano invoke superset:load_datasources 通过浏览器访问 http://localhost:8088/ 就是Superset 的图形界面了： 3.3.2 创建一个 Dashboard试一下在这个 Meltano 项目中定义的 Postgres 中的 ETL 数据上创建一个 Dashboard 吧 点击 + DASHBOARD，填写仪表盘名称，然后点击 SAVE，然后点击 + CREATE A NEW CHART 在新图表（Create a new chart）视图中，我们应该选择图表类型和数据集。 在这里，我选择了 orders 表作为数据源和 Pie Chart 图表类型： 点击“CREATE NEW CHART”后，我们在图表定义视图中，我选择了“status”的“Query”为“DIMENSIONS”，“COUNT(amount)”为“METRIC”。 至此，咱们就可以看到每个订单状态分布的饼图了。 点击 SAVE ，它会询问应该将此图表添加到哪个 Dashboard，选择后，单击 SAVE \u0026 GO TO DASHBOARD。 然后，在 Dashboard 中，我们可以看到那里的所有图表。 您可以看到我还添加了另一个图表来显示客户订单数量分布： 点 ··· 的话，还能看到刷新率设置、下载渲染图等其他的功能。 目前，我们有一个简单但典型的 homelab 数据技术栈了，并且所有东西都是开源的！ 想象一下，我们在 CSV 中有 100 个数据集，在数据仓库中有 200 个表，并且有几个数据工程师在运行不同的项目，这些项目使用、生成不同的应用与服务、Dashbaord 和数据库。 当有人想要查找、发现或者修改其中的一些表、数据集、Dashbaord 和管道，在沟通和工程方面可能都是非常不好管理的。 如前边提到的，我们需要这个示例项目的主要部分：元数据发现系统。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:3","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#创建一个-dashboard"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.4 元数据发现系统然后，我们部署一个带有 NebulaGraph 和 Elasticsearch 的 Amundsen。 注：目前【NebulaGraph 作为 Amundsen 后端的 PR】（https://github.com/amundsen-io/amundsen/pull/1817）尚未合并，我还在与 Amundsen 团队合作（https://github.com/amundsen-io/rfcs/pull/48）来实现它。 有了 Amundsen，我们可以在一个地方发现和管理整个数据栈中的所有元数据。 Amundsen 主要有两个部分组成： 元数据导入 Metadata Ingestion Amundsen Data builder 元数据目录服务 Metadata Catalog Amundsen Frontend service Amundsen Metadata service Amundsen Search service 它的工作原理是：利用 Data builder 从不同来源提取元数据，并将元数据持久化到 Meta service 的后端存储和 Search service 的后端存储中，用户从 Froent service 或通过 Meta Service 的API。 3.4.1 部署 Amundsen 3.4.1.1 元数据服务 Metadata service我们用 docker-compose 文件部署一个 Amundsen 集群。 由于 NebulaGraph 后端支持尚未合并，还不能用官方的代码，先用我自己的分叉版本。 首先，让我们克隆包含所有子模块的 repo： git clone -b amundsen_nebula_graph --recursive git@github.com:wey-gu/amundsen.git cd amundsen 然后，启动所有目录服务（catalog services）及其后端存储： docker-compose -f docker-amundsen-nebula.yml up 注：可以添加 -d 来让容器在后台运行： docker-compose -f docker-amundsen-nebula.yml up -d 关闭后台运行的集群 docker-compose -f docker-amundsen-nebula.yml stop 删除后台运行的集群 docker-compose -f docker-amundsen-nebula.yml down 由于这个 docker-compose 文件是供开发人员试玩、调试 Amundsen 用的，而不是给生产部署准备的，它在启动的时候会从代码库构建镜像，第一次跑的时候启动会慢一些。 部署好了之后，我们使用 Data builder 将一些示例、虚构的数据加载存储里。 3.4.1.2 抓取元数据 Data builderAmundsen Data builder 就像 Meltano 系统一样，只不过是用在元数据的上的 ETL ，它把元数据加载到“Meta service”和“Search service”的后端存储：NebulaGraph 和 Elasticsearch 里。 这里的 Data builder 只是一个 python 模块，所有的元数据 ETL 作业可以作为脚本运行，也可以用 Apache Airflow 等 DAG 平台进行编排。 安装 Amundsen Data builder： cd databuilder python3 -m venv .venv source .venv/bin/activate python3 -m pip install wheel python3 -m pip install -r requirements.txt python3 setup.py install 调用这个示例数据构建器 ETL 脚本来把示例的虚拟数据导进去。 python3 example/scripts/sample_data_loader_nebula.py 3.4.1.3 验证一下 Amundsen在访问 Amundsen 之前，我们需要创建一个测试用户： # run a container with curl attached to amundsenfrontend docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot # Create a user with id test_user_id curl -X PUT -v http://amundsenmetadata:5002/user \\ -H \"Content-Type: application/json\" \\ --data \\ '{\"user_id\":\"test_user_id\",\"first_name\":\"test\",\"last_name\":\"user\", \"email\":\"test_user_id@mail.com\"}' exit 然后我们可以在 http://localhost:5000 查看 UI 并尝试搜索 test，它应该会返回一些结果。 然后，可以单击并浏览在“sample_data_loader_nebula.py”期间加载到 Amundsen 的那些示例元数据。 此外，我们还可以通过 NebulaStudio(http://localhost:7001) 访问 NebulaGraph 里的这些数据。 注意在 Nebula Studio 中，默认登录字段为： 主机：graphd:9669 用户：root 密码：nebula 下图显示了有关 Amundsen 组件的更多详细信息： ┌────────────────────────┐ ┌────────────────────────────────────────┐ │ Frontend:5000 │ │ Metadata Sources │ ├────────────────────────┤ │ ┌────────┐ ┌─────────┐ ┌─────────────┐ │ │ Metaservice:5001 │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ Foo DB │ │ Bar App │ │ X Dashboard │ │ ┌────┼─┤ Nebula Proxy │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │ │ │ │ │ ├────────────────────────┤ │ └────────┘ └─────┬───┘ └─────────────┘ │ ┌─┼────┤ Search searvice:5002 │ │ │ │ │ │ └────────────────────────┘ └──────────────────┼─────────────────────┘ │ │ ┌─────────────────────────────────────────────┼───────────────────────┐ │ │ │ │ │ │ │ │ Databuilder ┌───────────────────────────┘ │ │ │ │ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────────────────────┐ │ │ │ ┌──┼─► Extractor of Sources ├─► nebula_search_data_extractor │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Loader filesystem_csv_nebula │ │ Loader Elastic FS loader │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Publisher nebula_csv_publisher │ │ Publisher Elasticsearch │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ └─────────────────┼─────────────────────────────────┼─────────────────┘ │ │ └────────────────┐ │ │ │ │ ┌─────────────┼───►─────────────────────────┐ ┌─────▼─────┐ │ │ │ Nebula Gra","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:4","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#元数据发现系统"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.4 元数据发现系统然后，我们部署一个带有 NebulaGraph 和 Elasticsearch 的 Amundsen。 注：目前【NebulaGraph 作为 Amundsen 后端的 PR】（https://github.com/amundsen-io/amundsen/pull/1817）尚未合并，我还在与 Amundsen 团队合作（https://github.com/amundsen-io/rfcs/pull/48）来实现它。 有了 Amundsen，我们可以在一个地方发现和管理整个数据栈中的所有元数据。 Amundsen 主要有两个部分组成： 元数据导入 Metadata Ingestion Amundsen Data builder 元数据目录服务 Metadata Catalog Amundsen Frontend service Amundsen Metadata service Amundsen Search service 它的工作原理是：利用 Data builder 从不同来源提取元数据，并将元数据持久化到 Meta service 的后端存储和 Search service 的后端存储中，用户从 Froent service 或通过 Meta Service 的API。 3.4.1 部署 Amundsen 3.4.1.1 元数据服务 Metadata service我们用 docker-compose 文件部署一个 Amundsen 集群。 由于 NebulaGraph 后端支持尚未合并，还不能用官方的代码，先用我自己的分叉版本。 首先，让我们克隆包含所有子模块的 repo： git clone -b amundsen_nebula_graph --recursive git@github.com:wey-gu/amundsen.git cd amundsen 然后，启动所有目录服务（catalog services）及其后端存储： docker-compose -f docker-amundsen-nebula.yml up 注：可以添加 -d 来让容器在后台运行： docker-compose -f docker-amundsen-nebula.yml up -d 关闭后台运行的集群 docker-compose -f docker-amundsen-nebula.yml stop 删除后台运行的集群 docker-compose -f docker-amundsen-nebula.yml down 由于这个 docker-compose 文件是供开发人员试玩、调试 Amundsen 用的，而不是给生产部署准备的，它在启动的时候会从代码库构建镜像，第一次跑的时候启动会慢一些。 部署好了之后，我们使用 Data builder 将一些示例、虚构的数据加载存储里。 3.4.1.2 抓取元数据 Data builderAmundsen Data builder 就像 Meltano 系统一样，只不过是用在元数据的上的 ETL ，它把元数据加载到“Meta service”和“Search service”的后端存储：NebulaGraph 和 Elasticsearch 里。 这里的 Data builder 只是一个 python 模块，所有的元数据 ETL 作业可以作为脚本运行，也可以用 Apache Airflow 等 DAG 平台进行编排。 安装 Amundsen Data builder： cd databuilder python3 -m venv .venv source .venv/bin/activate python3 -m pip install wheel python3 -m pip install -r requirements.txt python3 setup.py install 调用这个示例数据构建器 ETL 脚本来把示例的虚拟数据导进去。 python3 example/scripts/sample_data_loader_nebula.py 3.4.1.3 验证一下 Amundsen在访问 Amundsen 之前，我们需要创建一个测试用户： # run a container with curl attached to amundsenfrontend docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot # Create a user with id test_user_id curl -X PUT -v http://amundsenmetadata:5002/user \\ -H \"Content-Type: application/json\" \\ --data \\ '{\"user_id\":\"test_user_id\",\"first_name\":\"test\",\"last_name\":\"user\", \"email\":\"test_user_id@mail.com\"}' exit 然后我们可以在 http://localhost:5000 查看 UI 并尝试搜索 test，它应该会返回一些结果。 然后，可以单击并浏览在“sample_data_loader_nebula.py”期间加载到 Amundsen 的那些示例元数据。 此外，我们还可以通过 NebulaStudio(http://localhost:7001) 访问 NebulaGraph 里的这些数据。 注意在 Nebula Studio 中，默认登录字段为： 主机：graphd:9669 用户：root 密码：nebula 下图显示了有关 Amundsen 组件的更多详细信息： ┌────────────────────────┐ ┌────────────────────────────────────────┐ │ Frontend:5000 │ │ Metadata Sources │ ├────────────────────────┤ │ ┌────────┐ ┌─────────┐ ┌─────────────┐ │ │ Metaservice:5001 │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ Foo DB │ │ Bar App │ │ X Dashboard │ │ ┌────┼─┤ Nebula Proxy │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │ │ │ │ │ ├────────────────────────┤ │ └────────┘ └─────┬───┘ └─────────────┘ │ ┌─┼────┤ Search searvice:5002 │ │ │ │ │ │ └────────────────────────┘ └──────────────────┼─────────────────────┘ │ │ ┌─────────────────────────────────────────────┼───────────────────────┐ │ │ │ │ │ │ │ │ Databuilder ┌───────────────────────────┘ │ │ │ │ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────────────────────┐ │ │ │ ┌──┼─► Extractor of Sources ├─► nebula_search_data_extractor │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Loader filesystem_csv_nebula │ │ Loader Elastic FS loader │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Publisher nebula_csv_publisher │ │ Publisher Elasticsearch │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ └─────────────────┼─────────────────────────────────┼─────────────────┘ │ │ └────────────────┐ │ │ │ │ ┌─────────────┼───►─────────────────────────┐ ┌─────▼─────┐ │ │ │ Nebula Gra","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:4","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#部署-amundsen"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.4 元数据发现系统然后，我们部署一个带有 NebulaGraph 和 Elasticsearch 的 Amundsen。 注：目前【NebulaGraph 作为 Amundsen 后端的 PR】（https://github.com/amundsen-io/amundsen/pull/1817）尚未合并，我还在与 Amundsen 团队合作（https://github.com/amundsen-io/rfcs/pull/48）来实现它。 有了 Amundsen，我们可以在一个地方发现和管理整个数据栈中的所有元数据。 Amundsen 主要有两个部分组成： 元数据导入 Metadata Ingestion Amundsen Data builder 元数据目录服务 Metadata Catalog Amundsen Frontend service Amundsen Metadata service Amundsen Search service 它的工作原理是：利用 Data builder 从不同来源提取元数据，并将元数据持久化到 Meta service 的后端存储和 Search service 的后端存储中，用户从 Froent service 或通过 Meta Service 的API。 3.4.1 部署 Amundsen 3.4.1.1 元数据服务 Metadata service我们用 docker-compose 文件部署一个 Amundsen 集群。 由于 NebulaGraph 后端支持尚未合并，还不能用官方的代码，先用我自己的分叉版本。 首先，让我们克隆包含所有子模块的 repo： git clone -b amundsen_nebula_graph --recursive git@github.com:wey-gu/amundsen.git cd amundsen 然后，启动所有目录服务（catalog services）及其后端存储： docker-compose -f docker-amundsen-nebula.yml up 注：可以添加 -d 来让容器在后台运行： docker-compose -f docker-amundsen-nebula.yml up -d 关闭后台运行的集群 docker-compose -f docker-amundsen-nebula.yml stop 删除后台运行的集群 docker-compose -f docker-amundsen-nebula.yml down 由于这个 docker-compose 文件是供开发人员试玩、调试 Amundsen 用的，而不是给生产部署准备的，它在启动的时候会从代码库构建镜像，第一次跑的时候启动会慢一些。 部署好了之后，我们使用 Data builder 将一些示例、虚构的数据加载存储里。 3.4.1.2 抓取元数据 Data builderAmundsen Data builder 就像 Meltano 系统一样，只不过是用在元数据的上的 ETL ，它把元数据加载到“Meta service”和“Search service”的后端存储：NebulaGraph 和 Elasticsearch 里。 这里的 Data builder 只是一个 python 模块，所有的元数据 ETL 作业可以作为脚本运行，也可以用 Apache Airflow 等 DAG 平台进行编排。 安装 Amundsen Data builder： cd databuilder python3 -m venv .venv source .venv/bin/activate python3 -m pip install wheel python3 -m pip install -r requirements.txt python3 setup.py install 调用这个示例数据构建器 ETL 脚本来把示例的虚拟数据导进去。 python3 example/scripts/sample_data_loader_nebula.py 3.4.1.3 验证一下 Amundsen在访问 Amundsen 之前，我们需要创建一个测试用户： # run a container with curl attached to amundsenfrontend docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot # Create a user with id test_user_id curl -X PUT -v http://amundsenmetadata:5002/user \\ -H \"Content-Type: application/json\" \\ --data \\ '{\"user_id\":\"test_user_id\",\"first_name\":\"test\",\"last_name\":\"user\", \"email\":\"test_user_id@mail.com\"}' exit 然后我们可以在 http://localhost:5000 查看 UI 并尝试搜索 test，它应该会返回一些结果。 然后，可以单击并浏览在“sample_data_loader_nebula.py”期间加载到 Amundsen 的那些示例元数据。 此外，我们还可以通过 NebulaStudio(http://localhost:7001) 访问 NebulaGraph 里的这些数据。 注意在 Nebula Studio 中，默认登录字段为： 主机：graphd:9669 用户：root 密码：nebula 下图显示了有关 Amundsen 组件的更多详细信息： ┌────────────────────────┐ ┌────────────────────────────────────────┐ │ Frontend:5000 │ │ Metadata Sources │ ├────────────────────────┤ │ ┌────────┐ ┌─────────┐ ┌─────────────┐ │ │ Metaservice:5001 │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ Foo DB │ │ Bar App │ │ X Dashboard │ │ ┌────┼─┤ Nebula Proxy │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │ │ │ │ │ ├────────────────────────┤ │ └────────┘ └─────┬───┘ └─────────────┘ │ ┌─┼────┤ Search searvice:5002 │ │ │ │ │ │ └────────────────────────┘ └──────────────────┼─────────────────────┘ │ │ ┌─────────────────────────────────────────────┼───────────────────────┐ │ │ │ │ │ │ │ │ Databuilder ┌───────────────────────────┘ │ │ │ │ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────────────────────┐ │ │ │ ┌──┼─► Extractor of Sources ├─► nebula_search_data_extractor │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Loader filesystem_csv_nebula │ │ Loader Elastic FS loader │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Publisher nebula_csv_publisher │ │ Publisher Elasticsearch │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ └─────────────────┼─────────────────────────────────┼─────────────────┘ │ │ └────────────────┐ │ │ │ │ ┌─────────────┼───►─────────────────────────┐ ┌─────▼─────┐ │ │ │ Nebula Gra","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:4","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#元数据服务-metadata-service"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.4 元数据发现系统然后，我们部署一个带有 NebulaGraph 和 Elasticsearch 的 Amundsen。 注：目前【NebulaGraph 作为 Amundsen 后端的 PR】（https://github.com/amundsen-io/amundsen/pull/1817）尚未合并，我还在与 Amundsen 团队合作（https://github.com/amundsen-io/rfcs/pull/48）来实现它。 有了 Amundsen，我们可以在一个地方发现和管理整个数据栈中的所有元数据。 Amundsen 主要有两个部分组成： 元数据导入 Metadata Ingestion Amundsen Data builder 元数据目录服务 Metadata Catalog Amundsen Frontend service Amundsen Metadata service Amundsen Search service 它的工作原理是：利用 Data builder 从不同来源提取元数据，并将元数据持久化到 Meta service 的后端存储和 Search service 的后端存储中，用户从 Froent service 或通过 Meta Service 的API。 3.4.1 部署 Amundsen 3.4.1.1 元数据服务 Metadata service我们用 docker-compose 文件部署一个 Amundsen 集群。 由于 NebulaGraph 后端支持尚未合并，还不能用官方的代码，先用我自己的分叉版本。 首先，让我们克隆包含所有子模块的 repo： git clone -b amundsen_nebula_graph --recursive git@github.com:wey-gu/amundsen.git cd amundsen 然后，启动所有目录服务（catalog services）及其后端存储： docker-compose -f docker-amundsen-nebula.yml up 注：可以添加 -d 来让容器在后台运行： docker-compose -f docker-amundsen-nebula.yml up -d 关闭后台运行的集群 docker-compose -f docker-amundsen-nebula.yml stop 删除后台运行的集群 docker-compose -f docker-amundsen-nebula.yml down 由于这个 docker-compose 文件是供开发人员试玩、调试 Amundsen 用的，而不是给生产部署准备的，它在启动的时候会从代码库构建镜像，第一次跑的时候启动会慢一些。 部署好了之后，我们使用 Data builder 将一些示例、虚构的数据加载存储里。 3.4.1.2 抓取元数据 Data builderAmundsen Data builder 就像 Meltano 系统一样，只不过是用在元数据的上的 ETL ，它把元数据加载到“Meta service”和“Search service”的后端存储：NebulaGraph 和 Elasticsearch 里。 这里的 Data builder 只是一个 python 模块，所有的元数据 ETL 作业可以作为脚本运行，也可以用 Apache Airflow 等 DAG 平台进行编排。 安装 Amundsen Data builder： cd databuilder python3 -m venv .venv source .venv/bin/activate python3 -m pip install wheel python3 -m pip install -r requirements.txt python3 setup.py install 调用这个示例数据构建器 ETL 脚本来把示例的虚拟数据导进去。 python3 example/scripts/sample_data_loader_nebula.py 3.4.1.3 验证一下 Amundsen在访问 Amundsen 之前，我们需要创建一个测试用户： # run a container with curl attached to amundsenfrontend docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot # Create a user with id test_user_id curl -X PUT -v http://amundsenmetadata:5002/user \\ -H \"Content-Type: application/json\" \\ --data \\ '{\"user_id\":\"test_user_id\",\"first_name\":\"test\",\"last_name\":\"user\", \"email\":\"test_user_id@mail.com\"}' exit 然后我们可以在 http://localhost:5000 查看 UI 并尝试搜索 test，它应该会返回一些结果。 然后，可以单击并浏览在“sample_data_loader_nebula.py”期间加载到 Amundsen 的那些示例元数据。 此外，我们还可以通过 NebulaStudio(http://localhost:7001) 访问 NebulaGraph 里的这些数据。 注意在 Nebula Studio 中，默认登录字段为： 主机：graphd:9669 用户：root 密码：nebula 下图显示了有关 Amundsen 组件的更多详细信息： ┌────────────────────────┐ ┌────────────────────────────────────────┐ │ Frontend:5000 │ │ Metadata Sources │ ├────────────────────────┤ │ ┌────────┐ ┌─────────┐ ┌─────────────┐ │ │ Metaservice:5001 │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ Foo DB │ │ Bar App │ │ X Dashboard │ │ ┌────┼─┤ Nebula Proxy │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │ │ │ │ │ ├────────────────────────┤ │ └────────┘ └─────┬───┘ └─────────────┘ │ ┌─┼────┤ Search searvice:5002 │ │ │ │ │ │ └────────────────────────┘ └──────────────────┼─────────────────────┘ │ │ ┌─────────────────────────────────────────────┼───────────────────────┐ │ │ │ │ │ │ │ │ Databuilder ┌───────────────────────────┘ │ │ │ │ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────────────────────┐ │ │ │ ┌──┼─► Extractor of Sources ├─► nebula_search_data_extractor │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Loader filesystem_csv_nebula │ │ Loader Elastic FS loader │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Publisher nebula_csv_publisher │ │ Publisher Elasticsearch │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ └─────────────────┼─────────────────────────────────┼─────────────────┘ │ │ └────────────────┐ │ │ │ │ ┌─────────────┼───►─────────────────────────┐ ┌─────▼─────┐ │ │ │ Nebula Gra","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:4","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#抓取元数据-data-builder"},{"categories":["Nebula Graph","Amundsen"],"content":" 3.4 元数据发现系统然后，我们部署一个带有 NebulaGraph 和 Elasticsearch 的 Amundsen。 注：目前【NebulaGraph 作为 Amundsen 后端的 PR】（https://github.com/amundsen-io/amundsen/pull/1817）尚未合并，我还在与 Amundsen 团队合作（https://github.com/amundsen-io/rfcs/pull/48）来实现它。 有了 Amundsen，我们可以在一个地方发现和管理整个数据栈中的所有元数据。 Amundsen 主要有两个部分组成： 元数据导入 Metadata Ingestion Amundsen Data builder 元数据目录服务 Metadata Catalog Amundsen Frontend service Amundsen Metadata service Amundsen Search service 它的工作原理是：利用 Data builder 从不同来源提取元数据，并将元数据持久化到 Meta service 的后端存储和 Search service 的后端存储中，用户从 Froent service 或通过 Meta Service 的API。 3.4.1 部署 Amundsen 3.4.1.1 元数据服务 Metadata service我们用 docker-compose 文件部署一个 Amundsen 集群。 由于 NebulaGraph 后端支持尚未合并，还不能用官方的代码，先用我自己的分叉版本。 首先，让我们克隆包含所有子模块的 repo： git clone -b amundsen_nebula_graph --recursive git@github.com:wey-gu/amundsen.git cd amundsen 然后，启动所有目录服务（catalog services）及其后端存储： docker-compose -f docker-amundsen-nebula.yml up 注：可以添加 -d 来让容器在后台运行： docker-compose -f docker-amundsen-nebula.yml up -d 关闭后台运行的集群 docker-compose -f docker-amundsen-nebula.yml stop 删除后台运行的集群 docker-compose -f docker-amundsen-nebula.yml down 由于这个 docker-compose 文件是供开发人员试玩、调试 Amundsen 用的，而不是给生产部署准备的，它在启动的时候会从代码库构建镜像，第一次跑的时候启动会慢一些。 部署好了之后，我们使用 Data builder 将一些示例、虚构的数据加载存储里。 3.4.1.2 抓取元数据 Data builderAmundsen Data builder 就像 Meltano 系统一样，只不过是用在元数据的上的 ETL ，它把元数据加载到“Meta service”和“Search service”的后端存储：NebulaGraph 和 Elasticsearch 里。 这里的 Data builder 只是一个 python 模块，所有的元数据 ETL 作业可以作为脚本运行，也可以用 Apache Airflow 等 DAG 平台进行编排。 安装 Amundsen Data builder： cd databuilder python3 -m venv .venv source .venv/bin/activate python3 -m pip install wheel python3 -m pip install -r requirements.txt python3 setup.py install 调用这个示例数据构建器 ETL 脚本来把示例的虚拟数据导进去。 python3 example/scripts/sample_data_loader_nebula.py 3.4.1.3 验证一下 Amundsen在访问 Amundsen 之前，我们需要创建一个测试用户： # run a container with curl attached to amundsenfrontend docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot # Create a user with id test_user_id curl -X PUT -v http://amundsenmetadata:5002/user \\ -H \"Content-Type: application/json\" \\ --data \\ '{\"user_id\":\"test_user_id\",\"first_name\":\"test\",\"last_name\":\"user\", \"email\":\"test_user_id@mail.com\"}' exit 然后我们可以在 http://localhost:5000 查看 UI 并尝试搜索 test，它应该会返回一些结果。 然后，可以单击并浏览在“sample_data_loader_nebula.py”期间加载到 Amundsen 的那些示例元数据。 此外，我们还可以通过 NebulaStudio(http://localhost:7001) 访问 NebulaGraph 里的这些数据。 注意在 Nebula Studio 中，默认登录字段为： 主机：graphd:9669 用户：root 密码：nebula 下图显示了有关 Amundsen 组件的更多详细信息： ┌────────────────────────┐ ┌────────────────────────────────────────┐ │ Frontend:5000 │ │ Metadata Sources │ ├────────────────────────┤ │ ┌────────┐ ┌─────────┐ ┌─────────────┐ │ │ Metaservice:5001 │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ Foo DB │ │ Bar App │ │ X Dashboard │ │ ┌────┼─┤ Nebula Proxy │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │ │ │ │ │ ├────────────────────────┤ │ └────────┘ └─────┬───┘ └─────────────┘ │ ┌─┼────┤ Search searvice:5002 │ │ │ │ │ │ └────────────────────────┘ └──────────────────┼─────────────────────┘ │ │ ┌─────────────────────────────────────────────┼───────────────────────┐ │ │ │ │ │ │ │ │ Databuilder ┌───────────────────────────┘ │ │ │ │ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────────────────────┐ │ │ │ ┌──┼─► Extractor of Sources ├─► nebula_search_data_extractor │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Loader filesystem_csv_nebula │ │ Loader Elastic FS loader │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ │ ┌───────────────▼────────────────┐ ┌──────────────▼───────────────┐ │ │ │ │ │ │ Publisher nebula_csv_publisher │ │ Publisher Elasticsearch │ │ │ │ │ │ └───────────────┬────────────────┘ └──────────────┬───────────────┘ │ │ │ │ └─────────────────┼─────────────────────────────────┼─────────────────┘ │ │ └────────────────┐ │ │ │ │ ┌─────────────┼───►─────────────────────────┐ ┌─────▼─────┐ │ │ │ Nebula Gra","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:3:4","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#验证一下-amundsen"},{"categories":["Nebula Graph","Amundsen"],"content":" 4 穿针引线：元数据发现设置好基本环境后，让我们把所有东西穿起来。还记得我们有 ELT 一些数据到 PostgreSQL 吗？ 那么，我们如何让 Amundsen 发现有关这些数据和 ETL 的元数据呢？ ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:0","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#穿针引线元数据发现"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.1 提取 Postgres 元数据我们从数据源开始：首先是 Postgres。 我们为 python3 安装 Postgres 客户端： sudo apt-get install libpq-dev pip3 install Psycopg2 4.1.1 执行 Postgres 元数据 ETL运行一个脚本来解析 Postgres 元数据： export CREDENTIALS_POSTGRES_USER=lineage_ref export CREDENTIALS_POSTGRES_PASSWORD=lineage_ref export CREDENTIALS_POSTGRES_DATABASE=warehouse python3 example/scripts/sample_postgres_loader_nebula.py If you look into the code of the sample script for loading Postgres metadata to Nebula, the main lines are quite straightforward: 我们看看把 Postgres 元数据加载到 NebulaGraph 的示例脚本的代码，非常简单直接： # part 1: PostgressMetadata --\u003e CSV --\u003e Nebula Graph job = DefaultJob( conf=job_config, task=DefaultTask( extractor=PostgresMetadataExtractor(), loader=FsNebulaCSVLoader()), publisher=NebulaCsvPublisher()) ... # part 2: Metadata stored in NebulaGraph --\u003e Elasticsearch extractor = NebulaSearchDataExtractor() task = SearchMetadatatoElasticasearchTask(extractor=extractor) job = DefaultJob(conf=job_config, task=task) 第一个工作路径是：PostgressMetadata --\u003e CSV --\u003e Nebula Graph PostgresMetadataExtractor 用于从 Postgres 中提取/提取元数据，可以参考文档（https://www.amundsen.io/amundsen/databuilder/#postgresmetadataextractor）。 FsNebulaCSVLoader 用于将提取的数据中间放置为 CSV 文件 NebulaCsvPublisher 用于将元数据以 CSV 的形式发布到 NebulaGraph 第二个工作路径是：Metadata stored in NebulaGraph --\u003e Elasticsearch NebulaSearchDataExtractor 用于获取存储在 Nebula Graph 中的元数据 SearchMetadatatoElasticasearchTask 用于使 Elasticsearch 对元数据进行索引。 请注意，在生产环境中，我们可以在脚本中或使用 Apache Airflow 等编排平台触发这些作业。 4.1.2 验证 Postgres 中元数据的获取搜索payments或者直接访问http://localhost:5000/table_detail/warehouse/postgres/public/payments，你可以看到我们 Postgres 的元数据，比如： 然后，像上面的屏幕截图一样，可以轻松完成元数据管理操作，如添加标签、所有者和描述。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:1","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#提取-postgres-元数据"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.1 提取 Postgres 元数据我们从数据源开始：首先是 Postgres。 我们为 python3 安装 Postgres 客户端： sudo apt-get install libpq-dev pip3 install Psycopg2 4.1.1 执行 Postgres 元数据 ETL运行一个脚本来解析 Postgres 元数据： export CREDENTIALS_POSTGRES_USER=lineage_ref export CREDENTIALS_POSTGRES_PASSWORD=lineage_ref export CREDENTIALS_POSTGRES_DATABASE=warehouse python3 example/scripts/sample_postgres_loader_nebula.py If you look into the code of the sample script for loading Postgres metadata to Nebula, the main lines are quite straightforward: 我们看看把 Postgres 元数据加载到 NebulaGraph 的示例脚本的代码，非常简单直接： # part 1: PostgressMetadata --\u003e CSV --\u003e Nebula Graph job = DefaultJob( conf=job_config, task=DefaultTask( extractor=PostgresMetadataExtractor(), loader=FsNebulaCSVLoader()), publisher=NebulaCsvPublisher()) ... # part 2: Metadata stored in NebulaGraph --\u003e Elasticsearch extractor = NebulaSearchDataExtractor() task = SearchMetadatatoElasticasearchTask(extractor=extractor) job = DefaultJob(conf=job_config, task=task) 第一个工作路径是：PostgressMetadata --\u003e CSV --\u003e Nebula Graph PostgresMetadataExtractor 用于从 Postgres 中提取/提取元数据，可以参考文档（https://www.amundsen.io/amundsen/databuilder/#postgresmetadataextractor）。 FsNebulaCSVLoader 用于将提取的数据中间放置为 CSV 文件 NebulaCsvPublisher 用于将元数据以 CSV 的形式发布到 NebulaGraph 第二个工作路径是：Metadata stored in NebulaGraph --\u003e Elasticsearch NebulaSearchDataExtractor 用于获取存储在 Nebula Graph 中的元数据 SearchMetadatatoElasticasearchTask 用于使 Elasticsearch 对元数据进行索引。 请注意，在生产环境中，我们可以在脚本中或使用 Apache Airflow 等编排平台触发这些作业。 4.1.2 验证 Postgres 中元数据的获取搜索payments或者直接访问http://localhost:5000/table_detail/warehouse/postgres/public/payments，你可以看到我们 Postgres 的元数据，比如： 然后，像上面的屏幕截图一样，可以轻松完成元数据管理操作，如添加标签、所有者和描述。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:1","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#执行-postgres-元数据-etl"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.1 提取 Postgres 元数据我们从数据源开始：首先是 Postgres。 我们为 python3 安装 Postgres 客户端： sudo apt-get install libpq-dev pip3 install Psycopg2 4.1.1 执行 Postgres 元数据 ETL运行一个脚本来解析 Postgres 元数据： export CREDENTIALS_POSTGRES_USER=lineage_ref export CREDENTIALS_POSTGRES_PASSWORD=lineage_ref export CREDENTIALS_POSTGRES_DATABASE=warehouse python3 example/scripts/sample_postgres_loader_nebula.py If you look into the code of the sample script for loading Postgres metadata to Nebula, the main lines are quite straightforward: 我们看看把 Postgres 元数据加载到 NebulaGraph 的示例脚本的代码，非常简单直接： # part 1: PostgressMetadata --\u003e CSV --\u003e Nebula Graph job = DefaultJob( conf=job_config, task=DefaultTask( extractor=PostgresMetadataExtractor(), loader=FsNebulaCSVLoader()), publisher=NebulaCsvPublisher()) ... # part 2: Metadata stored in NebulaGraph --\u003e Elasticsearch extractor = NebulaSearchDataExtractor() task = SearchMetadatatoElasticasearchTask(extractor=extractor) job = DefaultJob(conf=job_config, task=task) 第一个工作路径是：PostgressMetadata --\u003e CSV --\u003e Nebula Graph PostgresMetadataExtractor 用于从 Postgres 中提取/提取元数据，可以参考文档（https://www.amundsen.io/amundsen/databuilder/#postgresmetadataextractor）。 FsNebulaCSVLoader 用于将提取的数据中间放置为 CSV 文件 NebulaCsvPublisher 用于将元数据以 CSV 的形式发布到 NebulaGraph 第二个工作路径是：Metadata stored in NebulaGraph --\u003e Elasticsearch NebulaSearchDataExtractor 用于获取存储在 Nebula Graph 中的元数据 SearchMetadatatoElasticasearchTask 用于使 Elasticsearch 对元数据进行索引。 请注意，在生产环境中，我们可以在脚本中或使用 Apache Airflow 等编排平台触发这些作业。 4.1.2 验证 Postgres 中元数据的获取搜索payments或者直接访问http://localhost:5000/table_detail/warehouse/postgres/public/payments，你可以看到我们 Postgres 的元数据，比如： 然后，像上面的屏幕截图一样，可以轻松完成元数据管理操作，如添加标签、所有者和描述。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:1","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#验证-postgres-中元数据的获取"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.2 提取 dbt 元数据实际上，我们也可以从 dbt 本身提取元数据。 Amundsen DbtExtractor 会解析 catalog.json 或 manifest.json 文件以将元数据加载到 Amundsen 存储（NebulaGraph 和 Elasticsearch )。 在上面的 meltano 章节中，我们已经使用 meltano invoke dbt docs generate 生成了这个文件： 14:23:15 Done. 14:23:15 Building catalog 14:23:15 Catalog written to /home/ubuntu/ref-data-lineage/meltano_example_implementations/meltano_projects/singer_dbt_jaffle/.meltano/transformers/dbt/target/catalog.json 4.2.1 dbt 元数据 ETL 的执行我们试着解析示例 dbt 文件中的元数据吧： $ ls -l example/sample_data/dbt/ total 184 -rw-rw-r-- 1 w w 5320 May 15 07:17 catalog.json -rw-rw-r-- 1 w w 177163 May 15 07:17 manifest.json 我写的这个示例的加载例子如下： python3 example/scripts/sample_dbt_loader_nebula.py 其中主要的代码如下： # part 1: Dbt manifest --\u003e CSV --\u003e Nebula Graph job = DefaultJob( conf=job_config, task=DefaultTask( extractor=DbtExtractor(), loader=FsNebulaCSVLoader()), publisher=NebulaCsvPublisher()) ... # part 2: Metadata stored in NebulaGraph --\u003e Elasticsearch extractor = NebulaSearchDataExtractor() task = SearchMetadatatoElasticasearchTask(extractor=extractor) job = DefaultJob(conf=job_config, task=task) 它和 Postgres 元数据 ETL 的唯一区别是 extractor=DbtExtractor()，它带有以下配置以获取有关 dbt 项目的以下信息： 数据库名称 目录_json manifest_json job_config = ConfigFactory.from_dict({ 'extractor.dbt.database_name': database_name, 'extractor.dbt.catalog_json': catalog_file_loc, # File 'extractor.dbt.manifest_json': json.dumps(manifest_data), # JSON Dumped objecy 'extractor.dbt.source_url': source_url}) 4.2.2 验证 dbt 抓取结果搜索 dbt_demo 或者直接访问 http://localhost:5000/table_detail/dbt_demo/snowflake/public/raw_inventory_value，可以看到 小提示：我们可以选择启用 DEBUG log 级别去看已发送到 Elasticsearch 和 NebulaGraph 的内容。 - logging.basicConfig(level=logging.INFO) + logging.basicConfig(level=logging.DEBUG) 或者，在 NebulaStudio 中探索导入的数据： 首先，点击 “Start with Vertices”，填写顶点 vid：snowflake://dbt_demo.public/fact_warehouse_inventory 然后，我们可以看到顶点显示为粉红色的点。 让我们修改 Expand / ”拓展“选项： 方向：双向 步数：单向、三步 并双击顶点（点），它将双向拓展 3 步： 从上边这个截图里我们可以发现，在可视化之后的图数据库中，这些元数据可以很容易被查看、分析，并从中获得洞察。 小贴士，您可以点击 👁 图标选择一些要显示的属性，我在截图之前就是通过它让一些信息显示出来的。 而且，我们在 NebulaStudio 中看到的也与 Amundsen 元数据服务的数据模型相呼应： 最后，请记住我们曾利用 dbt 来转换meltano 中的一些数据，并且清单文件路径是.meltano/transformers/dbt/target/catalog.json，您可以尝试创建一个数据构建器作业来导入它。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#提取-dbt-元数据"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.2 提取 dbt 元数据实际上，我们也可以从 dbt 本身提取元数据。 Amundsen DbtExtractor 会解析 catalog.json 或 manifest.json 文件以将元数据加载到 Amundsen 存储（NebulaGraph 和 Elasticsearch )。 在上面的 meltano 章节中，我们已经使用 meltano invoke dbt docs generate 生成了这个文件： 14:23:15 Done. 14:23:15 Building catalog 14:23:15 Catalog written to /home/ubuntu/ref-data-lineage/meltano_example_implementations/meltano_projects/singer_dbt_jaffle/.meltano/transformers/dbt/target/catalog.json 4.2.1 dbt 元数据 ETL 的执行我们试着解析示例 dbt 文件中的元数据吧： $ ls -l example/sample_data/dbt/ total 184 -rw-rw-r-- 1 w w 5320 May 15 07:17 catalog.json -rw-rw-r-- 1 w w 177163 May 15 07:17 manifest.json 我写的这个示例的加载例子如下： python3 example/scripts/sample_dbt_loader_nebula.py 其中主要的代码如下： # part 1: Dbt manifest --\u003e CSV --\u003e Nebula Graph job = DefaultJob( conf=job_config, task=DefaultTask( extractor=DbtExtractor(), loader=FsNebulaCSVLoader()), publisher=NebulaCsvPublisher()) ... # part 2: Metadata stored in NebulaGraph --\u003e Elasticsearch extractor = NebulaSearchDataExtractor() task = SearchMetadatatoElasticasearchTask(extractor=extractor) job = DefaultJob(conf=job_config, task=task) 它和 Postgres 元数据 ETL 的唯一区别是 extractor=DbtExtractor()，它带有以下配置以获取有关 dbt 项目的以下信息： 数据库名称 目录_json manifest_json job_config = ConfigFactory.from_dict({ 'extractor.dbt.database_name': database_name, 'extractor.dbt.catalog_json': catalog_file_loc, # File 'extractor.dbt.manifest_json': json.dumps(manifest_data), # JSON Dumped objecy 'extractor.dbt.source_url': source_url}) 4.2.2 验证 dbt 抓取结果搜索 dbt_demo 或者直接访问 http://localhost:5000/table_detail/dbt_demo/snowflake/public/raw_inventory_value，可以看到 小提示：我们可以选择启用 DEBUG log 级别去看已发送到 Elasticsearch 和 NebulaGraph 的内容。 - logging.basicConfig(level=logging.INFO) + logging.basicConfig(level=logging.DEBUG) 或者，在 NebulaStudio 中探索导入的数据： 首先，点击 “Start with Vertices”，填写顶点 vid：snowflake://dbt_demo.public/fact_warehouse_inventory 然后，我们可以看到顶点显示为粉红色的点。 让我们修改 Expand / ”拓展“选项： 方向：双向 步数：单向、三步 并双击顶点（点），它将双向拓展 3 步： 从上边这个截图里我们可以发现，在可视化之后的图数据库中，这些元数据可以很容易被查看、分析，并从中获得洞察。 小贴士，您可以点击 👁 图标选择一些要显示的属性，我在截图之前就是通过它让一些信息显示出来的。 而且，我们在 NebulaStudio 中看到的也与 Amundsen 元数据服务的数据模型相呼应： 最后，请记住我们曾利用 dbt 来转换meltano 中的一些数据，并且清单文件路径是.meltano/transformers/dbt/target/catalog.json，您可以尝试创建一个数据构建器作业来导入它。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#dbt-元数据-etl-的执行"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.2 提取 dbt 元数据实际上，我们也可以从 dbt 本身提取元数据。 Amundsen DbtExtractor 会解析 catalog.json 或 manifest.json 文件以将元数据加载到 Amundsen 存储（NebulaGraph 和 Elasticsearch )。 在上面的 meltano 章节中，我们已经使用 meltano invoke dbt docs generate 生成了这个文件： 14:23:15 Done. 14:23:15 Building catalog 14:23:15 Catalog written to /home/ubuntu/ref-data-lineage/meltano_example_implementations/meltano_projects/singer_dbt_jaffle/.meltano/transformers/dbt/target/catalog.json 4.2.1 dbt 元数据 ETL 的执行我们试着解析示例 dbt 文件中的元数据吧： $ ls -l example/sample_data/dbt/ total 184 -rw-rw-r-- 1 w w 5320 May 15 07:17 catalog.json -rw-rw-r-- 1 w w 177163 May 15 07:17 manifest.json 我写的这个示例的加载例子如下： python3 example/scripts/sample_dbt_loader_nebula.py 其中主要的代码如下： # part 1: Dbt manifest --\u003e CSV --\u003e Nebula Graph job = DefaultJob( conf=job_config, task=DefaultTask( extractor=DbtExtractor(), loader=FsNebulaCSVLoader()), publisher=NebulaCsvPublisher()) ... # part 2: Metadata stored in NebulaGraph --\u003e Elasticsearch extractor = NebulaSearchDataExtractor() task = SearchMetadatatoElasticasearchTask(extractor=extractor) job = DefaultJob(conf=job_config, task=task) 它和 Postgres 元数据 ETL 的唯一区别是 extractor=DbtExtractor()，它带有以下配置以获取有关 dbt 项目的以下信息： 数据库名称 目录_json manifest_json job_config = ConfigFactory.from_dict({ 'extractor.dbt.database_name': database_name, 'extractor.dbt.catalog_json': catalog_file_loc, # File 'extractor.dbt.manifest_json': json.dumps(manifest_data), # JSON Dumped objecy 'extractor.dbt.source_url': source_url}) 4.2.2 验证 dbt 抓取结果搜索 dbt_demo 或者直接访问 http://localhost:5000/table_detail/dbt_demo/snowflake/public/raw_inventory_value，可以看到 小提示：我们可以选择启用 DEBUG log 级别去看已发送到 Elasticsearch 和 NebulaGraph 的内容。 - logging.basicConfig(level=logging.INFO) + logging.basicConfig(level=logging.DEBUG) 或者，在 NebulaStudio 中探索导入的数据： 首先，点击 “Start with Vertices”，填写顶点 vid：snowflake://dbt_demo.public/fact_warehouse_inventory 然后，我们可以看到顶点显示为粉红色的点。 让我们修改 Expand / ”拓展“选项： 方向：双向 步数：单向、三步 并双击顶点（点），它将双向拓展 3 步： 从上边这个截图里我们可以发现，在可视化之后的图数据库中，这些元数据可以很容易被查看、分析，并从中获得洞察。 小贴士，您可以点击 👁 图标选择一些要显示的属性，我在截图之前就是通过它让一些信息显示出来的。 而且，我们在 NebulaStudio 中看到的也与 Amundsen 元数据服务的数据模型相呼应： 最后，请记住我们曾利用 dbt 来转换meltano 中的一些数据，并且清单文件路径是.meltano/transformers/dbt/target/catalog.json，您可以尝试创建一个数据构建器作业来导入它。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:2","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#验证-dbt-抓取结果"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.3 提取 Superset 中的元数据Amundsen 的 Superset extractor 可以获取 Dashboard 元数据抽取 https://www.amundsen.io/amundsen/databuilder/databuilder/extractor/dashboard/apache_superset/apache_superset_metadata_extractor.py 图表元数据抽取 https://www.amundsen.io/amundsen/databuilder/databuilder /extractor/dashboard/apache_superset/apache_superset_chart_extractor.py Superset 元素与数据源（表）的关系抽取 https://www.amundsen.io/amundsen/databuilder/databuilder/extractor/dashboard/apache_superset/apache_superset_table_extractor.py 咱们现在就尝试摄取之前创建的 Superset Dashboard 的元数据。 4.3.1 Superset 元数据 ETL 的执行下边执行的示例 Superset 提取脚本可以从中获取数据并将元数据加载到 NebulaGraph 和 Elasticsearch 中。 python3 sample_superset_data_loader_nebula.py 如果我们将日志记录级别设置为“DEBUG”，我们实际上可以看到这些中间的过程日志： # fetching metadata from superset DEBUG:urllib3.connectionpool:http://localhost:8088 \"POST /api/v1/security/login HTTP/1.1\" 200 280 INFO:databuilder.task.task:Running a task DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:8088 DEBUG:urllib3.connectionpool:http://localhost:8088 \"GET /api/v1/dashboard?q=(page_size:20,page:0,order_direction:desc) HTTP/1.1\" 308 374 DEBUG:urllib3.connectionpool:http://localhost:8088 \"GET /api/v1/dashboard/?q=(page_size:20,page:0,order_direction:desc) HTTP/1.1\" 200 1058 ... # insert Dashboard DEBUG:databuilder.publisher.nebula_csv_publisher:Query: INSERT VERTEX `Dashboard` (`dashboard_url`, `name`, published_tag, publisher_last_updated_epoch_ms) VALUES \"superset_dashboard://my_cluster.1/3\":(\"http://localhost:8088/superset/dashboard/3/\",\"my_dashboard\",\"unique_tag\",timestamp()); ... # insert a DASHBOARD_WITH_TABLE relationship/edge INFO:databuilder.publisher.nebula_csv_publisher:Importing data in edge files: ['/tmp/amundsen/dashboard/relationships/Dashboard_Table_DASHBOARD_WITH_TABLE.csv'] DEBUG:databuilder.publisher.nebula_csv_publisher:Query: INSERT edge `DASHBOARD_WITH_TABLE` (`END_LABEL`, `START_LABEL`, published_tag, publisher_last_updated_epoch_ms) VALUES \"superset_dashboard://my_cluster.1/3\"-\u003e\"postgresql+psycopg2://my_cluster.warehouse/orders\":(\"Table\",\"Dashboard\",\"unique_tag\", timestamp()), \"superset_dashboard://my_cluster.1/3\"-\u003e\"postgresql+psycopg2://my_cluster.warehouse/customers\":(\"Table\",\"Dashboard\",\"unique_tag\", timestamp()); 4.3.2 验证 Superset Dashboard 元数据通过在 Amundsen 中搜索它，我们现在可以获得 Dashboard 信息。 我们也可以从 NebulaStudio 进行验证。 注：可以参阅 Dashboard 抓取指南 中的 Amundsen Dashboard 图建模： ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:3","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#提取-superset-中的元数据"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.3 提取 Superset 中的元数据Amundsen 的 Superset extractor 可以获取 Dashboard 元数据抽取 https://www.amundsen.io/amundsen/databuilder/databuilder/extractor/dashboard/apache_superset/apache_superset_metadata_extractor.py 图表元数据抽取 https://www.amundsen.io/amundsen/databuilder/databuilder /extractor/dashboard/apache_superset/apache_superset_chart_extractor.py Superset 元素与数据源（表）的关系抽取 https://www.amundsen.io/amundsen/databuilder/databuilder/extractor/dashboard/apache_superset/apache_superset_table_extractor.py 咱们现在就尝试摄取之前创建的 Superset Dashboard 的元数据。 4.3.1 Superset 元数据 ETL 的执行下边执行的示例 Superset 提取脚本可以从中获取数据并将元数据加载到 NebulaGraph 和 Elasticsearch 中。 python3 sample_superset_data_loader_nebula.py 如果我们将日志记录级别设置为“DEBUG”，我们实际上可以看到这些中间的过程日志： # fetching metadata from superset DEBUG:urllib3.connectionpool:http://localhost:8088 \"POST /api/v1/security/login HTTP/1.1\" 200 280 INFO:databuilder.task.task:Running a task DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:8088 DEBUG:urllib3.connectionpool:http://localhost:8088 \"GET /api/v1/dashboard?q=(page_size:20,page:0,order_direction:desc) HTTP/1.1\" 308 374 DEBUG:urllib3.connectionpool:http://localhost:8088 \"GET /api/v1/dashboard/?q=(page_size:20,page:0,order_direction:desc) HTTP/1.1\" 200 1058 ... # insert Dashboard DEBUG:databuilder.publisher.nebula_csv_publisher:Query: INSERT VERTEX `Dashboard` (`dashboard_url`, `name`, published_tag, publisher_last_updated_epoch_ms) VALUES \"superset_dashboard://my_cluster.1/3\":(\"http://localhost:8088/superset/dashboard/3/\",\"my_dashboard\",\"unique_tag\",timestamp()); ... # insert a DASHBOARD_WITH_TABLE relationship/edge INFO:databuilder.publisher.nebula_csv_publisher:Importing data in edge files: ['/tmp/amundsen/dashboard/relationships/Dashboard_Table_DASHBOARD_WITH_TABLE.csv'] DEBUG:databuilder.publisher.nebula_csv_publisher:Query: INSERT edge `DASHBOARD_WITH_TABLE` (`END_LABEL`, `START_LABEL`, published_tag, publisher_last_updated_epoch_ms) VALUES \"superset_dashboard://my_cluster.1/3\"-\u003e\"postgresql+psycopg2://my_cluster.warehouse/orders\":(\"Table\",\"Dashboard\",\"unique_tag\", timestamp()), \"superset_dashboard://my_cluster.1/3\"-\u003e\"postgresql+psycopg2://my_cluster.warehouse/customers\":(\"Table\",\"Dashboard\",\"unique_tag\", timestamp()); 4.3.2 验证 Superset Dashboard 元数据通过在 Amundsen 中搜索它，我们现在可以获得 Dashboard 信息。 我们也可以从 NebulaStudio 进行验证。 注：可以参阅 Dashboard 抓取指南 中的 Amundsen Dashboard 图建模： ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:3","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#superset-元数据-etl-的执行"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.3 提取 Superset 中的元数据Amundsen 的 Superset extractor 可以获取 Dashboard 元数据抽取 https://www.amundsen.io/amundsen/databuilder/databuilder/extractor/dashboard/apache_superset/apache_superset_metadata_extractor.py 图表元数据抽取 https://www.amundsen.io/amundsen/databuilder/databuilder /extractor/dashboard/apache_superset/apache_superset_chart_extractor.py Superset 元素与数据源（表）的关系抽取 https://www.amundsen.io/amundsen/databuilder/databuilder/extractor/dashboard/apache_superset/apache_superset_table_extractor.py 咱们现在就尝试摄取之前创建的 Superset Dashboard 的元数据。 4.3.1 Superset 元数据 ETL 的执行下边执行的示例 Superset 提取脚本可以从中获取数据并将元数据加载到 NebulaGraph 和 Elasticsearch 中。 python3 sample_superset_data_loader_nebula.py 如果我们将日志记录级别设置为“DEBUG”，我们实际上可以看到这些中间的过程日志： # fetching metadata from superset DEBUG:urllib3.connectionpool:http://localhost:8088 \"POST /api/v1/security/login HTTP/1.1\" 200 280 INFO:databuilder.task.task:Running a task DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:8088 DEBUG:urllib3.connectionpool:http://localhost:8088 \"GET /api/v1/dashboard?q=(page_size:20,page:0,order_direction:desc) HTTP/1.1\" 308 374 DEBUG:urllib3.connectionpool:http://localhost:8088 \"GET /api/v1/dashboard/?q=(page_size:20,page:0,order_direction:desc) HTTP/1.1\" 200 1058 ... # insert Dashboard DEBUG:databuilder.publisher.nebula_csv_publisher:Query: INSERT VERTEX `Dashboard` (`dashboard_url`, `name`, published_tag, publisher_last_updated_epoch_ms) VALUES \"superset_dashboard://my_cluster.1/3\":(\"http://localhost:8088/superset/dashboard/3/\",\"my_dashboard\",\"unique_tag\",timestamp()); ... # insert a DASHBOARD_WITH_TABLE relationship/edge INFO:databuilder.publisher.nebula_csv_publisher:Importing data in edge files: ['/tmp/amundsen/dashboard/relationships/Dashboard_Table_DASHBOARD_WITH_TABLE.csv'] DEBUG:databuilder.publisher.nebula_csv_publisher:Query: INSERT edge `DASHBOARD_WITH_TABLE` (`END_LABEL`, `START_LABEL`, published_tag, publisher_last_updated_epoch_ms) VALUES \"superset_dashboard://my_cluster.1/3\"-\u003e\"postgresql+psycopg2://my_cluster.warehouse/orders\":(\"Table\",\"Dashboard\",\"unique_tag\", timestamp()), \"superset_dashboard://my_cluster.1/3\"-\u003e\"postgresql+psycopg2://my_cluster.warehouse/customers\":(\"Table\",\"Dashboard\",\"unique_tag\", timestamp()); 4.3.2 验证 Superset Dashboard 元数据通过在 Amundsen 中搜索它，我们现在可以获得 Dashboard 信息。 我们也可以从 NebulaStudio 进行验证。 注：可以参阅 Dashboard 抓取指南 中的 Amundsen Dashboard 图建模： ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:3","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#验证-superset-dashboard-元数据"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.4 用 Superset 预览数据Superset可以用来预览这样的表格数据。 相应的文档可以参考 https://www.amundsen.io/amundsen/frontend/docs/configuration/#preview-client ，其中 /superset/sql_json/ 的 API 被 Amundsen Frontend service 调用，取得预览信息。 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:4","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#用-superset-预览数据"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.5 开启数据血缘信息默认情况下，数据血缘是关闭的，我们可以通过以下方式启用它： cd 到 Amundsen 代码仓库下，这也是我们运行 docker-compose -f docker-amundsen-nebula.yml up 命令的地方 cd amundsen 修改 frontend 下的 typescript 配置 --- a/frontend/amundsen_application/static/js/config/config-default.ts +++ b/frontend/amundsen_application/static/js/config/config-default.ts tableLineage: { - inAppListEnabled: false, - inAppPageEnabled: false, + inAppListEnabled: true, + inAppPageEnabled: true, externalEnabled: false, iconPath: 'PATH_TO_ICON', isBeta: false, 重新构建 docker 镜像，其中将重建前端图像。 docker-compose -f docker-amundsen-nebula.yml build 然后，重新运行 up -d 以确保前端用新的配置： docker-compose -f docker-amundsen-nebula.yml up -d 结果大概长这样子： $ docker-compose -f docker-amundsen-nebula.yml up -d ... Recreating amundsenfrontend ... done 之后，我们可以访问 http://localhost:5000/lineage/table/gold/hive/test_schema/test_table1 看到 Lineage （beta） 血缘按钮已经显示出来了： 我们可以点击 Downstream 在存在的时候查看该表的下游资源： 或者点血缘按钮查看血缘的图表式： 也有用于血缘查询的 API。 这个例子中我们用 cURL 调用下这个 API： docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot curl \"http://amundsenmetadata:5002/table/snowflake://dbt_demo.public/raw_inventory_value/lineage?depth=3\u0026direction=both\" 上面的 API 调用是查询上游和下游方向的 linage，表 snowflake://dbt_demo.public/raw_inventory_value 的深度为 3。 结果应该是这样的： { \"depth\": 3, \"downstream_entities\": [ { \"level\": 2, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_daily_expenses\", \"parent\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"badges\": [], \"source\": \"snowflake\" }, { \"level\": 1, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"parent\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"badges\": [], \"source\": \"snowflake\" } ], \"key\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"direction\": \"both\", \"upstream_entities\": [] } 实际上，这个血缘数据就是在我们的 DbtExtractor 执行期间提取和加载的，其中 extractor .dbt.{DbtExtractor.EXTRACT_LINEAGE} 默认为 True，因此创建了血缘元数据并将其加载到了 Amundsen。 4.5.1 在 NebulaGraph 中洞察血缘使用图数据库作为元数据存储的两个优点是： 图查询本身是一个灵活的 DSL for lineage API，例如，这个查询帮助我们执行 Amundsen 元数据 API 的等价的查询： MATCH p=(t:`Table`) -[:`HAS_UPSTREAM`|:`HAS_DOWNSTREAM` *1..3]-\u003e(x) WHERE id(t) == \"snowflake://dbt_demo.public/raw_inventory_value\" RETURN p 我们现在甚至可以在 NebulaGraph Studio 或者 Explorer 的控制台中查询它 ​ 然后渲染这个结果： 4.5.2 提取数据血缘这些血缘信息是需要我们明确指定、获取的，获取的方式可以是自己写的 extractor，也可以是一些已经有的方式。比如 dbt 的 extractor和 Open Lineage 项目的 Amundsen extractor。 4.5.2.1 通过 dbt这个在刚才已经展示过了，Dbt 的 Extractor 会从表级别获取血缘和其他 dbt 中产生的元数据信息一起被拿到。 4.5.2.2 通过 Open LineageAmundsen 中的另一个开箱即用的血缘 Extractor 是 OpenLineageTableLineageExtractor。 Open Lineage 是一个开放的框架，可以将不同来源的血统数据收集到一个地方，它可以将血统信息输出为 JSON 文件：https://www.amundsen.io/amundsen/databuilder/#openlineagetablelineageextractor 下边是它的 Amundsen data builder 例子： dict_config = { # ... f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.CLUSTER_NAME}': 'datalab', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.OL_DATASET_NAMESPACE_OVERRIDE}': 'hive_table', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.TABLE_LINEAGE_FILE_LOCATION}': 'input_dir/openlineage_nd.json', } ... task = DefaultTask( extractor=OpenLineageTableLineageExtractor(), loader=FsNebulaCSVLoader()) ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:5","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#开启数据血缘信息"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.5 开启数据血缘信息默认情况下，数据血缘是关闭的，我们可以通过以下方式启用它： cd 到 Amundsen 代码仓库下，这也是我们运行 docker-compose -f docker-amundsen-nebula.yml up 命令的地方 cd amundsen 修改 frontend 下的 typescript 配置 --- a/frontend/amundsen_application/static/js/config/config-default.ts +++ b/frontend/amundsen_application/static/js/config/config-default.ts tableLineage: { - inAppListEnabled: false, - inAppPageEnabled: false, + inAppListEnabled: true, + inAppPageEnabled: true, externalEnabled: false, iconPath: 'PATH_TO_ICON', isBeta: false, 重新构建 docker 镜像，其中将重建前端图像。 docker-compose -f docker-amundsen-nebula.yml build 然后，重新运行 up -d 以确保前端用新的配置： docker-compose -f docker-amundsen-nebula.yml up -d 结果大概长这样子： $ docker-compose -f docker-amundsen-nebula.yml up -d ... Recreating amundsenfrontend ... done 之后，我们可以访问 http://localhost:5000/lineage/table/gold/hive/test_schema/test_table1 看到 Lineage （beta） 血缘按钮已经显示出来了： 我们可以点击 Downstream 在存在的时候查看该表的下游资源： 或者点血缘按钮查看血缘的图表式： 也有用于血缘查询的 API。 这个例子中我们用 cURL 调用下这个 API： docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot curl \"http://amundsenmetadata:5002/table/snowflake://dbt_demo.public/raw_inventory_value/lineage?depth=3\u0026direction=both\" 上面的 API 调用是查询上游和下游方向的 linage，表 snowflake://dbt_demo.public/raw_inventory_value 的深度为 3。 结果应该是这样的： { \"depth\": 3, \"downstream_entities\": [ { \"level\": 2, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_daily_expenses\", \"parent\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"badges\": [], \"source\": \"snowflake\" }, { \"level\": 1, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"parent\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"badges\": [], \"source\": \"snowflake\" } ], \"key\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"direction\": \"both\", \"upstream_entities\": [] } 实际上，这个血缘数据就是在我们的 DbtExtractor 执行期间提取和加载的，其中 extractor .dbt.{DbtExtractor.EXTRACT_LINEAGE} 默认为 True，因此创建了血缘元数据并将其加载到了 Amundsen。 4.5.1 在 NebulaGraph 中洞察血缘使用图数据库作为元数据存储的两个优点是： 图查询本身是一个灵活的 DSL for lineage API，例如，这个查询帮助我们执行 Amundsen 元数据 API 的等价的查询： MATCH p=(t:`Table`) -[:`HAS_UPSTREAM`|:`HAS_DOWNSTREAM` *1..3]-\u003e(x) WHERE id(t) == \"snowflake://dbt_demo.public/raw_inventory_value\" RETURN p 我们现在甚至可以在 NebulaGraph Studio 或者 Explorer 的控制台中查询它 ​ 然后渲染这个结果： 4.5.2 提取数据血缘这些血缘信息是需要我们明确指定、获取的，获取的方式可以是自己写的 extractor，也可以是一些已经有的方式。比如 dbt 的 extractor和 Open Lineage 项目的 Amundsen extractor。 4.5.2.1 通过 dbt这个在刚才已经展示过了，Dbt 的 Extractor 会从表级别获取血缘和其他 dbt 中产生的元数据信息一起被拿到。 4.5.2.2 通过 Open LineageAmundsen 中的另一个开箱即用的血缘 Extractor 是 OpenLineageTableLineageExtractor。 Open Lineage 是一个开放的框架，可以将不同来源的血统数据收集到一个地方，它可以将血统信息输出为 JSON 文件：https://www.amundsen.io/amundsen/databuilder/#openlineagetablelineageextractor 下边是它的 Amundsen data builder 例子： dict_config = { # ... f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.CLUSTER_NAME}': 'datalab', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.OL_DATASET_NAMESPACE_OVERRIDE}': 'hive_table', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.TABLE_LINEAGE_FILE_LOCATION}': 'input_dir/openlineage_nd.json', } ... task = DefaultTask( extractor=OpenLineageTableLineageExtractor(), loader=FsNebulaCSVLoader()) ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:5","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#在-nebulagraph-中洞察血缘"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.5 开启数据血缘信息默认情况下，数据血缘是关闭的，我们可以通过以下方式启用它： cd 到 Amundsen 代码仓库下，这也是我们运行 docker-compose -f docker-amundsen-nebula.yml up 命令的地方 cd amundsen 修改 frontend 下的 typescript 配置 --- a/frontend/amundsen_application/static/js/config/config-default.ts +++ b/frontend/amundsen_application/static/js/config/config-default.ts tableLineage: { - inAppListEnabled: false, - inAppPageEnabled: false, + inAppListEnabled: true, + inAppPageEnabled: true, externalEnabled: false, iconPath: 'PATH_TO_ICON', isBeta: false, 重新构建 docker 镜像，其中将重建前端图像。 docker-compose -f docker-amundsen-nebula.yml build 然后，重新运行 up -d 以确保前端用新的配置： docker-compose -f docker-amundsen-nebula.yml up -d 结果大概长这样子： $ docker-compose -f docker-amundsen-nebula.yml up -d ... Recreating amundsenfrontend ... done 之后，我们可以访问 http://localhost:5000/lineage/table/gold/hive/test_schema/test_table1 看到 Lineage （beta） 血缘按钮已经显示出来了： 我们可以点击 Downstream 在存在的时候查看该表的下游资源： 或者点血缘按钮查看血缘的图表式： 也有用于血缘查询的 API。 这个例子中我们用 cURL 调用下这个 API： docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot curl \"http://amundsenmetadata:5002/table/snowflake://dbt_demo.public/raw_inventory_value/lineage?depth=3\u0026direction=both\" 上面的 API 调用是查询上游和下游方向的 linage，表 snowflake://dbt_demo.public/raw_inventory_value 的深度为 3。 结果应该是这样的： { \"depth\": 3, \"downstream_entities\": [ { \"level\": 2, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_daily_expenses\", \"parent\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"badges\": [], \"source\": \"snowflake\" }, { \"level\": 1, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"parent\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"badges\": [], \"source\": \"snowflake\" } ], \"key\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"direction\": \"both\", \"upstream_entities\": [] } 实际上，这个血缘数据就是在我们的 DbtExtractor 执行期间提取和加载的，其中 extractor .dbt.{DbtExtractor.EXTRACT_LINEAGE} 默认为 True，因此创建了血缘元数据并将其加载到了 Amundsen。 4.5.1 在 NebulaGraph 中洞察血缘使用图数据库作为元数据存储的两个优点是： 图查询本身是一个灵活的 DSL for lineage API，例如，这个查询帮助我们执行 Amundsen 元数据 API 的等价的查询： MATCH p=(t:`Table`) -[:`HAS_UPSTREAM`|:`HAS_DOWNSTREAM` *1..3]-\u003e(x) WHERE id(t) == \"snowflake://dbt_demo.public/raw_inventory_value\" RETURN p 我们现在甚至可以在 NebulaGraph Studio 或者 Explorer 的控制台中查询它 ​ 然后渲染这个结果： 4.5.2 提取数据血缘这些血缘信息是需要我们明确指定、获取的，获取的方式可以是自己写的 extractor，也可以是一些已经有的方式。比如 dbt 的 extractor和 Open Lineage 项目的 Amundsen extractor。 4.5.2.1 通过 dbt这个在刚才已经展示过了，Dbt 的 Extractor 会从表级别获取血缘和其他 dbt 中产生的元数据信息一起被拿到。 4.5.2.2 通过 Open LineageAmundsen 中的另一个开箱即用的血缘 Extractor 是 OpenLineageTableLineageExtractor。 Open Lineage 是一个开放的框架，可以将不同来源的血统数据收集到一个地方，它可以将血统信息输出为 JSON 文件：https://www.amundsen.io/amundsen/databuilder/#openlineagetablelineageextractor 下边是它的 Amundsen data builder 例子： dict_config = { # ... f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.CLUSTER_NAME}': 'datalab', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.OL_DATASET_NAMESPACE_OVERRIDE}': 'hive_table', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.TABLE_LINEAGE_FILE_LOCATION}': 'input_dir/openlineage_nd.json', } ... task = DefaultTask( extractor=OpenLineageTableLineageExtractor(), loader=FsNebulaCSVLoader()) ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:5","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#提取数据血缘"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.5 开启数据血缘信息默认情况下，数据血缘是关闭的，我们可以通过以下方式启用它： cd 到 Amundsen 代码仓库下，这也是我们运行 docker-compose -f docker-amundsen-nebula.yml up 命令的地方 cd amundsen 修改 frontend 下的 typescript 配置 --- a/frontend/amundsen_application/static/js/config/config-default.ts +++ b/frontend/amundsen_application/static/js/config/config-default.ts tableLineage: { - inAppListEnabled: false, - inAppPageEnabled: false, + inAppListEnabled: true, + inAppPageEnabled: true, externalEnabled: false, iconPath: 'PATH_TO_ICON', isBeta: false, 重新构建 docker 镜像，其中将重建前端图像。 docker-compose -f docker-amundsen-nebula.yml build 然后，重新运行 up -d 以确保前端用新的配置： docker-compose -f docker-amundsen-nebula.yml up -d 结果大概长这样子： $ docker-compose -f docker-amundsen-nebula.yml up -d ... Recreating amundsenfrontend ... done 之后，我们可以访问 http://localhost:5000/lineage/table/gold/hive/test_schema/test_table1 看到 Lineage （beta） 血缘按钮已经显示出来了： 我们可以点击 Downstream 在存在的时候查看该表的下游资源： 或者点血缘按钮查看血缘的图表式： 也有用于血缘查询的 API。 这个例子中我们用 cURL 调用下这个 API： docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot curl \"http://amundsenmetadata:5002/table/snowflake://dbt_demo.public/raw_inventory_value/lineage?depth=3\u0026direction=both\" 上面的 API 调用是查询上游和下游方向的 linage，表 snowflake://dbt_demo.public/raw_inventory_value 的深度为 3。 结果应该是这样的： { \"depth\": 3, \"downstream_entities\": [ { \"level\": 2, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_daily_expenses\", \"parent\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"badges\": [], \"source\": \"snowflake\" }, { \"level\": 1, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"parent\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"badges\": [], \"source\": \"snowflake\" } ], \"key\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"direction\": \"both\", \"upstream_entities\": [] } 实际上，这个血缘数据就是在我们的 DbtExtractor 执行期间提取和加载的，其中 extractor .dbt.{DbtExtractor.EXTRACT_LINEAGE} 默认为 True，因此创建了血缘元数据并将其加载到了 Amundsen。 4.5.1 在 NebulaGraph 中洞察血缘使用图数据库作为元数据存储的两个优点是： 图查询本身是一个灵活的 DSL for lineage API，例如，这个查询帮助我们执行 Amundsen 元数据 API 的等价的查询： MATCH p=(t:`Table`) -[:`HAS_UPSTREAM`|:`HAS_DOWNSTREAM` *1..3]-\u003e(x) WHERE id(t) == \"snowflake://dbt_demo.public/raw_inventory_value\" RETURN p 我们现在甚至可以在 NebulaGraph Studio 或者 Explorer 的控制台中查询它 ​ 然后渲染这个结果： 4.5.2 提取数据血缘这些血缘信息是需要我们明确指定、获取的，获取的方式可以是自己写的 extractor，也可以是一些已经有的方式。比如 dbt 的 extractor和 Open Lineage 项目的 Amundsen extractor。 4.5.2.1 通过 dbt这个在刚才已经展示过了，Dbt 的 Extractor 会从表级别获取血缘和其他 dbt 中产生的元数据信息一起被拿到。 4.5.2.2 通过 Open LineageAmundsen 中的另一个开箱即用的血缘 Extractor 是 OpenLineageTableLineageExtractor。 Open Lineage 是一个开放的框架，可以将不同来源的血统数据收集到一个地方，它可以将血统信息输出为 JSON 文件：https://www.amundsen.io/amundsen/databuilder/#openlineagetablelineageextractor 下边是它的 Amundsen data builder 例子： dict_config = { # ... f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.CLUSTER_NAME}': 'datalab', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.OL_DATASET_NAMESPACE_OVERRIDE}': 'hive_table', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.TABLE_LINEAGE_FILE_LOCATION}': 'input_dir/openlineage_nd.json', } ... task = DefaultTask( extractor=OpenLineageTableLineageExtractor(), loader=FsNebulaCSVLoader()) ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:5","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#通过-dbt"},{"categories":["Nebula Graph","Amundsen"],"content":" 4.5 开启数据血缘信息默认情况下，数据血缘是关闭的，我们可以通过以下方式启用它： cd 到 Amundsen 代码仓库下，这也是我们运行 docker-compose -f docker-amundsen-nebula.yml up 命令的地方 cd amundsen 修改 frontend 下的 typescript 配置 --- a/frontend/amundsen_application/static/js/config/config-default.ts +++ b/frontend/amundsen_application/static/js/config/config-default.ts tableLineage: { - inAppListEnabled: false, - inAppPageEnabled: false, + inAppListEnabled: true, + inAppPageEnabled: true, externalEnabled: false, iconPath: 'PATH_TO_ICON', isBeta: false, 重新构建 docker 镜像，其中将重建前端图像。 docker-compose -f docker-amundsen-nebula.yml build 然后，重新运行 up -d 以确保前端用新的配置： docker-compose -f docker-amundsen-nebula.yml up -d 结果大概长这样子： $ docker-compose -f docker-amundsen-nebula.yml up -d ... Recreating amundsenfrontend ... done 之后，我们可以访问 http://localhost:5000/lineage/table/gold/hive/test_schema/test_table1 看到 Lineage （beta） 血缘按钮已经显示出来了： 我们可以点击 Downstream 在存在的时候查看该表的下游资源： 或者点血缘按钮查看血缘的图表式： 也有用于血缘查询的 API。 这个例子中我们用 cURL 调用下这个 API： docker run -it --rm --net container:amundsenfrontend nicolaka/netshoot curl \"http://amundsenmetadata:5002/table/snowflake://dbt_demo.public/raw_inventory_value/lineage?depth=3\u0026direction=both\" 上面的 API 调用是查询上游和下游方向的 linage，表 snowflake://dbt_demo.public/raw_inventory_value 的深度为 3。 结果应该是这样的： { \"depth\": 3, \"downstream_entities\": [ { \"level\": 2, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_daily_expenses\", \"parent\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"badges\": [], \"source\": \"snowflake\" }, { \"level\": 1, \"usage\": 0, \"key\": \"snowflake://dbt_demo.public/fact_warehouse_inventory\", \"parent\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"badges\": [], \"source\": \"snowflake\" } ], \"key\": \"snowflake://dbt_demo.public/raw_inventory_value\", \"direction\": \"both\", \"upstream_entities\": [] } 实际上，这个血缘数据就是在我们的 DbtExtractor 执行期间提取和加载的，其中 extractor .dbt.{DbtExtractor.EXTRACT_LINEAGE} 默认为 True，因此创建了血缘元数据并将其加载到了 Amundsen。 4.5.1 在 NebulaGraph 中洞察血缘使用图数据库作为元数据存储的两个优点是： 图查询本身是一个灵活的 DSL for lineage API，例如，这个查询帮助我们执行 Amundsen 元数据 API 的等价的查询： MATCH p=(t:`Table`) -[:`HAS_UPSTREAM`|:`HAS_DOWNSTREAM` *1..3]-\u003e(x) WHERE id(t) == \"snowflake://dbt_demo.public/raw_inventory_value\" RETURN p 我们现在甚至可以在 NebulaGraph Studio 或者 Explorer 的控制台中查询它 ​ 然后渲染这个结果： 4.5.2 提取数据血缘这些血缘信息是需要我们明确指定、获取的，获取的方式可以是自己写的 extractor，也可以是一些已经有的方式。比如 dbt 的 extractor和 Open Lineage 项目的 Amundsen extractor。 4.5.2.1 通过 dbt这个在刚才已经展示过了，Dbt 的 Extractor 会从表级别获取血缘和其他 dbt 中产生的元数据信息一起被拿到。 4.5.2.2 通过 Open LineageAmundsen 中的另一个开箱即用的血缘 Extractor 是 OpenLineageTableLineageExtractor。 Open Lineage 是一个开放的框架，可以将不同来源的血统数据收集到一个地方，它可以将血统信息输出为 JSON 文件：https://www.amundsen.io/amundsen/databuilder/#openlineagetablelineageextractor 下边是它的 Amundsen data builder 例子： dict_config = { # ... f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.CLUSTER_NAME}': 'datalab', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.OL_DATASET_NAMESPACE_OVERRIDE}': 'hive_table', f'extractor.openlineage_tablelineage.{OpenLineageTableLineageExtractor.TABLE_LINEAGE_FILE_LOCATION}': 'input_dir/openlineage_nd.json', } ... task = DefaultTask( extractor=OpenLineageTableLineageExtractor(), loader=FsNebulaCSVLoader()) ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:4:5","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#通过-open-lineage"},{"categories":["Nebula Graph","Amundsen"],"content":" 5 回顾整套元数据治理/发现的方案思路如下： 将整个数据技术栈中的组件作为元数据源（从任何数据库、数仓，到 dbt、Airflow、Openlineage、Superset 等各级项目） 使用 Databuilder（作为脚本或 DAG）运行元数据 ETL，以使用 NebulaGraph 和 Elasticsearch 存储和索引 从前端 UI（使用 Superset 预览）或 API 去使用、消费、管理和发现元数据 通过查询和 UI 对 NebulaGraph，我们可以获得更多的可能性、灵活性和数据、血缘的洞察 ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:5:0","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#回顾"},{"categories":["Nebula Graph","Amundsen"],"content":" 5.1 涉及到的开源此参考项目中使用的所有项目都按字典顺序在下面列出。 Amundsen Apache Airflow Apache Superset dbt Elasticsearch meltano Nebula Graph Open Lineage singer 题图版权： Phil Hearing ","date":"2022-11-25","objectID":"/data-lineage-oss-ref-solution/:5:1","series":null,"tags":["Nebula Graph","Amundsen","数据血缘","数据治理"],"title":"基于开源技术栈的数据血缘、治理参考解决方案","uri":"/data-lineage-oss-ref-solution/#涉及到的开源"},{"categories":["Nebula Graph"],"content":"本文介绍了利用开源 API 网关 APISIX 加速 NebulaGraph 多个场景的落地最佳实践：负载均衡、暴露存储接口与 TLS Termination。","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/"},{"categories":["Nebula Graph"],"content":" 本文介绍了利用开源 API 网关 APISIX 加速 NebulaGraph 多个场景的落地最佳实践：负载均衡、暴露接口结构与 TLS Termination。 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:0:0","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#"},{"categories":["Nebula Graph"],"content":" 1 API 网关介绍","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:1:0","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#api-网关介绍"},{"categories":["Nebula Graph"],"content":" 1.1 什么是 API 网关API 网关是它位于客户端和服务器之间的“中间人”，用于管理、监控和保护 API。它可以在 API 之前执行一些操作，例如身份验证、授权、缓存、日志记录、审计、流量控制、安全、防火墙、压缩、解压缩、加密、解密等。 API 网关可以工作在 4 层和 7 层。跑在 7 层的API 网关可以使用多种协议，例如 HTTP、HTTPS、WebSocket、gRPC、MQTT 等，在这些应用层协议中做一些操作，例如请求重写、请求转发、请求合并、请求重试、请求缓存、请求限流、请求熔断、请求降级、请求鉴权、请求监控、请求日志、请求审计、请求转发等等。 这里举例一下借助 API 网关可以做的具体的事儿吧： 我们可以在网关层增加认证层，比如 JWT 认证、OAuth2 认证、OpenID 认证等等，这样则不需要在每个服务中都做具体的认证集成工作，这可以节省非常多的开发成本。 我们可以借助网关给跳板机 SSH 流量增加无需客户端修改的复杂认证，比如跳转任何客户端的 SSH 登录，给出一个网址或者输入框，引导登陆者通过网页的 SSO 认证（包含多因素认证），然后再通过网关转发到 SSH 服务。 我们甚至可以在网关层做 Serverless 数据库！TiDB 社区的同学们就在做这个事儿，他们从普通的 MySQL 客户端的登录请求中解析能推断出转到需要的 TiDB 示例的信息，并且在需要 cold start 唤醒实例的时候把连接保持住，可以参考这篇文章：TiDB Gateway。 如果我们特别惨在维护一些屎山项目，不得不针对旧版本的应用程序对新版本的服务端进行兼容，这时候 API 网关也可以通过一些请求重写，把旧版本的请求转换成新版本的请求。 只要脑洞大，理论上API 的网关可以做很多很多事儿，显然，不是所有的事情都是适合在这一层面去做的，通常那些比较通用的事情才适合在这一层面去做，这里我只是给出一些典型和极端的具体例子。 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:1:1","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#什么是-api-网关"},{"categories":["Nebula Graph"],"content":" 1.2 Apache APISIXAPI 网关是从 LB、Reverse Proxy 项目演进过来的，随着云原生的兴起，API 网关也逐渐成为了云原生的一部分，流行的开源的网关就有很多： Nginx Apache APISIX Kong Lura OpenResty Tyk Traefik Istio Envoy 而且其中很多都是基于 Nginx/OpenResty 的下游项目，这里就以 Apache APISIX 为例，介绍一下 NebulaGraph 借助 API 网关的几个实践。 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:1:2","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#apache-apisix"},{"categories":["Nebula Graph"],"content":" 2 NebulaGraph 介绍NebulaGraph 是一个开源的分布式图数据库，它的特点是： 高性能：NebulaGraph 的性能可以达到每秒百万级的读写，具有极高的扩展性，在千亿点万亿边的规模上支持毫秒级的查询。 易扩展：NebulaGraph 的架构是分布式的，可以在多台机器上扩展，每台机器上可以运行多个服务进程，它的查询层是无状态的计算存储分离架构，我们可以很容易引入不同配置、不通类型的计算层，实现同一集群上 TP、AP、 图计算等不同负载的混合查询。 易使用：NebulaGraph 的原生查询语言是类 SQL 的，易于学习和使用，同时支持 OpenCypher。 丰富生态：NebulaGraph 的生态系统正在不断壮大，目前已经有了多个客户端，包括 Java、Python、Go、C++、JavaScript、Spark、Flink 等，同时也有了多个可视化工具，包括 NebulaGraph Studio、Nebula Dashboard、Nebula Explorer 等。 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:2:0","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#nebulagraph-介绍"},{"categories":["Nebula Graph"],"content":" 3 本文讨论的问题本文给出了基于 NebulaGraph 集群应用中涉及到 API 网关的几个场景。 查询接口的负载均衡 底层存储接口的暴露 传输层的加密 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:3:0","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#本文讨论的问题"},{"categories":["Nebula Graph"],"content":" 3.1 查询接口负载均衡首先是图数据库查询接口（GraphD）的负载均衡与高可用的问题。 NebulaGraph 内核由三种服务组成：GraphD、MetaD 和 StorageD： 所以，在默认情况下，集群只会暴露 GraphD 的接口，提供给客户端连接，执行 nGQL 的查询。 这其中，GraphD 是无状态的，这意味着我们可以在多个 GraphD 之间做负载均衡。这里，我们有两种方法：基于客户端的（Client-Side LB），与基于代理的。 3.1.1 客户端的负载均衡客户端的负载均衡，就是在客户端，也就是应用程序中，实现负载均衡的逻辑，NebulaGraph 的各个语言的客户端里边已经内置了简单的轮询（Round-Robin）负载均衡，我们只需要在客户端配置多个 GraphD 的地址就可以了： 比如我们在创建连接池的时候，指定了两个不同的 GraphD 的地址（对应不同进程实例）： from nebula3.gclient.net import ConnectionPool from nebula3.Config import Config config = Config() config.max_connection_pool_size = 10 connection_pool = ConnectionPool() connection_pool.init([('127.0.0.1', 9669), ('127.0.0.1', 49433)], config) 我们在取得连接的时候，就会从连接池中随机取得一个连接： In [10]: connection0 = connection_pool.get_connection() In [11]: connection1 = connection_pool.get_connection() # 这两个连接的 GraphD 地址是不同的 In [12]: connection0._port, connection1._port Out[12]: (9669, 49433) 这种客户端的负载均衡的问题在于它的配置、实现细节与应用代码耦合在一起，如果我们需要修改负载均衡的策略，就需要修改应用代码，这样就会增加应用的复杂度。 3.1.2 代理的负载均衡基于代理的负载均衡，就是在应用程序之前，增加一个代理层，来实现负载均衡的逻辑，这样应用程序就不需要关心负载均衡的问题了。在 k8s 里的话，我们可以使用 k8s 的 Service 来实现这个代理层。 这是一个在 Minikube 中为 NebulaGraph 集群中 GraphD 创建的 Service： cat \u003c\u003cEOF | kubectl create -f - apiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/cluster: nebula app.kubernetes.io/component: graphd app.kubernetes.io/managed-by: nebula-operator app.kubernetes.io/name: nebula-graph name: nebula-graphd-svc-nodeport namespace: default spec: externalTrafficPolicy: Local ports: - name: thrift port: 9669 protocol: TCP targetPort: 9669 nodePort: 30000 - name: http port: 19669 protocol: TCP targetPort: 19669 nodePort: 30001 selector: app.kubernetes.io/cluster: nebula app.kubernetes.io/component: graphd app.kubernetes.io/managed-by: nebula-operator app.kubernetes.io/name: nebula-graph type: NodePort EOF 创建了它之后，我们就可以通过它暴露的单独端口来访问 NebulaGraph 集群中的 GraphD 了： In [13]: connection_pool = ConnectionPool() ...: connection_pool.init([('192.168.49.2', 9669)], config) Out[13]: True In [14]: connection0 = connection_pool.get_connection() In [15]: connection1 = connection_pool.get_connection() In [16]: connection0._ip, connection1._ip Out[16]: ('192.168.49.2', '192.168.49.2') 可以看到，在连接层面上来看，客户端只知道代理的地址，而不知道 NebulaGraph 集群中的 GraphD 的地址，这样就实现了客户端与 NebulaGraph 集群中的 GraphD 的解耦。 然而，当我们在 connection 之上创建 session 的时候，就能看到实际上客户端的不同请求是落在了不同的 GraphD 上的： In [17]: session = connection_pool.get_session('root', 'nebula') In [18]: session._session_id Out[18]: 1668670607568178 In [19]: session1 = connection_pool.get_session('root', 'nebula') In [20]: session1._session_id Out[20]: 1668670625563307 # 得到每一个 session 的 ID In [21]: session.execute(\"SHOW SESSIONS\") # 它们分别对应了两个不同的 graphd 实例 Out[21]: ResultSet(keys: ['SessionId', 'UserName', 'SpaceName', 'CreateTime', 'UpdateTime', 'GraphAddr', 'Timezone', 'ClientIp'], values: [1668670607568178, \"root\", \"\", utc datetime: 2022-11-17T07:36:47.568178, timezone_offset: 0, utc datetime: 2022-11-17T07:36:47.575303, timezone_offset: 0, \"nebula-graphd-0.nebula-graphd-svc.default.svc.cluster.local:9669\", 0, \"172.17.0.1\"],[1668670625563307, \"root\", \"\", utc datetime: 2022-11-17T07:37:05.563307, timezone_offset: 0, utc datetime: 2022-11-17T07:37:03.638910, timezone_offset: 0, \"nebula-graphd-1.nebula-graphd-svc.default.svc.cluster.local:9669\", 0, \"172.17.0.1\"]) ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:3:1","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#查询接口负载均衡"},{"categories":["Nebula Graph"],"content":" 3.1 查询接口负载均衡首先是图数据库查询接口（GraphD）的负载均衡与高可用的问题。 NebulaGraph 内核由三种服务组成：GraphD、MetaD 和 StorageD： 所以，在默认情况下，集群只会暴露 GraphD 的接口，提供给客户端连接，执行 nGQL 的查询。 这其中，GraphD 是无状态的，这意味着我们可以在多个 GraphD 之间做负载均衡。这里，我们有两种方法：基于客户端的（Client-Side LB），与基于代理的。 3.1.1 客户端的负载均衡客户端的负载均衡，就是在客户端，也就是应用程序中，实现负载均衡的逻辑，NebulaGraph 的各个语言的客户端里边已经内置了简单的轮询（Round-Robin）负载均衡，我们只需要在客户端配置多个 GraphD 的地址就可以了： 比如我们在创建连接池的时候，指定了两个不同的 GraphD 的地址（对应不同进程实例）： from nebula3.gclient.net import ConnectionPool from nebula3.Config import Config config = Config() config.max_connection_pool_size = 10 connection_pool = ConnectionPool() connection_pool.init([('127.0.0.1', 9669), ('127.0.0.1', 49433)], config) 我们在取得连接的时候，就会从连接池中随机取得一个连接： In [10]: connection0 = connection_pool.get_connection() In [11]: connection1 = connection_pool.get_connection() # 这两个连接的 GraphD 地址是不同的 In [12]: connection0._port, connection1._port Out[12]: (9669, 49433) 这种客户端的负载均衡的问题在于它的配置、实现细节与应用代码耦合在一起，如果我们需要修改负载均衡的策略，就需要修改应用代码，这样就会增加应用的复杂度。 3.1.2 代理的负载均衡基于代理的负载均衡，就是在应用程序之前，增加一个代理层，来实现负载均衡的逻辑，这样应用程序就不需要关心负载均衡的问题了。在 k8s 里的话，我们可以使用 k8s 的 Service 来实现这个代理层。 这是一个在 Minikube 中为 NebulaGraph 集群中 GraphD 创建的 Service： cat \u003c","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:3:1","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#客户端的负载均衡"},{"categories":["Nebula Graph"],"content":" 3.1 查询接口负载均衡首先是图数据库查询接口（GraphD）的负载均衡与高可用的问题。 NebulaGraph 内核由三种服务组成：GraphD、MetaD 和 StorageD： 所以，在默认情况下，集群只会暴露 GraphD 的接口，提供给客户端连接，执行 nGQL 的查询。 这其中，GraphD 是无状态的，这意味着我们可以在多个 GraphD 之间做负载均衡。这里，我们有两种方法：基于客户端的（Client-Side LB），与基于代理的。 3.1.1 客户端的负载均衡客户端的负载均衡，就是在客户端，也就是应用程序中，实现负载均衡的逻辑，NebulaGraph 的各个语言的客户端里边已经内置了简单的轮询（Round-Robin）负载均衡，我们只需要在客户端配置多个 GraphD 的地址就可以了： 比如我们在创建连接池的时候，指定了两个不同的 GraphD 的地址（对应不同进程实例）： from nebula3.gclient.net import ConnectionPool from nebula3.Config import Config config = Config() config.max_connection_pool_size = 10 connection_pool = ConnectionPool() connection_pool.init([('127.0.0.1', 9669), ('127.0.0.1', 49433)], config) 我们在取得连接的时候，就会从连接池中随机取得一个连接： In [10]: connection0 = connection_pool.get_connection() In [11]: connection1 = connection_pool.get_connection() # 这两个连接的 GraphD 地址是不同的 In [12]: connection0._port, connection1._port Out[12]: (9669, 49433) 这种客户端的负载均衡的问题在于它的配置、实现细节与应用代码耦合在一起，如果我们需要修改负载均衡的策略，就需要修改应用代码，这样就会增加应用的复杂度。 3.1.2 代理的负载均衡基于代理的负载均衡，就是在应用程序之前，增加一个代理层，来实现负载均衡的逻辑，这样应用程序就不需要关心负载均衡的问题了。在 k8s 里的话，我们可以使用 k8s 的 Service 来实现这个代理层。 这是一个在 Minikube 中为 NebulaGraph 集群中 GraphD 创建的 Service： cat \u003c","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:3:1","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#代理的负载均衡"},{"categories":["Nebula Graph"],"content":" 3.2 底层存储接口的暴露在 NebulaGraph 中，我们可以通过 StorageClient 来访问底层的存储接口，这个接口可以用来做一些分析型、数据全扫描计算的工作。 然而存储层的分布式服务实例不像 GraphD 那样，它们是有状态的，这其实与 K8s 或者 Docker Compose 的部署模型是相违背的，如果访问的应用 StorageD 客户端在集群外部，我们需要在 NebulaGraph 集群中的每一个存储实例上都部署一个代理（Service），这非常不方便，有时候还是一种浪费。 此外，由于 NebulaGraph 内部服务发现机制和 StorageD 客户端的实现机制决定，每一个 storaged 服务实体都是由其内部的 host:port 唯一确定和寻址的，这给我们中间的代理工作也带来了一些麻烦。 总结来看，我们的需求是： 能够从集群外部访问 NebulaGraph 的存储层每一个实例 每一个实例的访问地址（host:port）和内部的地址是完全一致的 为了实现这个需求，我之前的做法是为每一个实例单独部署一个 GraphD 代理（消耗一个地址，保证端口不变），再在外部手动搭一个 nginx 作为代理，配合 DNS 把内部的地址解析 nginx 上，然后通过域名找到上游（每一个单独的 GraphD 代理）。 注：我在这两个 gist 里给出了这个方法的实验步骤： https://gist.github.com/wey-gu/950e4f4c673badae375e59007d80d372 https://gist.github.com/wey-gu/699b9a2ef5dff5f0fb5f288d692ddfd5 最近，我找到了一个相对优雅的可维护的方式： 在 NebulaGraph 集群同一个命名空间下引入一个 APISIX 网关 利用 APISIX 中的 nginx TCP 代理的封装：stream-proxy来暴露 storeaged 的接口 为了最终只利用一个集群的出口（Service，我们利用其支持的 TLSv1.3 中的 extend host name 字段：SNI 来路由上游），做到用不同域名的 TCP over TLS 指向后端的不同 storaged 最终，只需要 Storage 客户端能支持 TLSv1.3（发送 SNI），并且能解析所有 StorageD 的地址到 APISIX 的 Service 上即可 示例图： ┌────────────────────────────────────────────────────────────────────────────────────┐ │ K8s Cluster │ │ ┌──────────────────────────┐ │ │ ┌────────────────────────────────────┐ │ NebulaGraph Cluster │ │ │ │ APISIX API-GATEWAY │ │ ┌──────────────┐ │ │ │ │ │ │ │ Storaged-0 │ │ │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ┌────────────────────────────┐ │ │ │ └──────────────┘ │ │ │ │ │ stream-proxy │ │ │ │ │ │ ┌─────┐ │ .─────. │ │ ┌────┐ │ │ │ │ ┌──────────────┐ │ │ │ │ │╱ ╲ │ │ - addr: 9559 │ │──────┼───┼─┘ │ │ Storaged-1 │ │ │ ━━┫ DNS ┣━━( Service )╋━━━╋▶ tls: true │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │`. ,' │ │ │ │──────┼───┼─┘ │ │ │ │ │ └─────┘ │ `───' │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │SNI │ │ │ │ │ │ │ │ │ │ │──────┼───┼─┐ │ ┌──────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ Storaged-2 │ │ │ │ │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │──────┼───┼─┐ │ │ │ │ │ │ │ │ └────┘ │ │ │ │ └──────────────┘ │ │ │ │ └────────────────────────────┘ │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ │ │ │ │ │ Storaged-3 │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ └────────────────────────────────────┘ └──────────────────────────┘ │ │ │ └────────────────────────────────────────────────────────────────────────────────────┘ 这样做的好处是： 在 APISIX 中比较优雅地维护代理的配置，并且可以用到 APISIX 这些现代化的流量管理能力 不需要为每一个 StorageD 单独创建 Service，只需要一个 Service，出集群地址 就可以了 为流量增加了 TLSv1.3 的加密，提高了安全性同时没有给 NebulaGraph 集群内部的南北流量带来的性能损耗 在本文的结尾，我会给出一个实操的实验过程，这里包含了本文提到的所有要点和细节。 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:3:2","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#底层存储接口的暴露"},{"categories":["Nebula Graph"],"content":" 3.3 传输层的加密我们在前一个问题中提及到了，在 APISIX 网关中 terminate TLSv1.3 的连接，借助 SNI 信息路由 StorageD 的方法，其实，单独将 GraphD 接口的 TLS 交给网关来做，好处也是非常明显的： 证书管理在统一的网关控制面做，更加方便 证书运维无 NebulaGraph 集群配置侵入（NebulaGraph 原生支持 TLS 加密，但是加密之后带来了集群内部通信的开销，而且配置和集群其他层面配置在一起，证书更新涉及进程重启，不够灵活） 具体的方法在后边实操中也是有体现的。 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:3:3","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#传输层的加密"},{"categories":["Nebula Graph"],"content":" 4 实操：利用 APISIX 的 stream-proxy 暴露 StorageD 的接口","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:0","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#实操利用-apisix-的-stream-proxy-暴露-storaged-的接口"},{"categories":["Nebula Graph"],"content":" 4.1 实验环境：minikube我们就在本地的 minikube 上做这个实验吧，首先启动一个 minikube，因为 APISIX 内部的 etcd 需要用到 storageclass，我们带上 穷人版的 storageclass 插件，同时，为了在 k8s 外部访问 storaged 的时候用和内部相同的域名和端口，我们把 node-port 允许的端口扩充到小于 9779 的范围。 minikube start \\ --addons=\"default-storageclass\" \\ --extra-config=apiserver.service-node-port-range=1-65535 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:1","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#实验环境minikube"},{"categories":["Nebula Graph"],"content":" 4.2 实验环境：NebulaGraph on K8s这里，我们使用 Nebula Operator 来部署 NebulaGraph 集群，具体的部署方法可以参考 Nebula Operator 文档。 咱们做实验，就偷个懒，用我写的 Nebula-Operator-KinD 来一键部署： curl -sL nebula-kind.siwei.io/install-on-k8s.sh | bash ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:2","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#实验环境nebulagraph-on-k8s"},{"categories":["Nebula Graph"],"content":" 4.3 实验环境：APISIX on k8s首先是安装，在 Helm 参数中指定打开 stream-proxy 的开关： helm repo add apisix https://charts.apiseven.com helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update helm install apisix apisix/apisix \\ --set gateway.type=NodePort \\ --set gateway.stream.enabled=true \\ --set ingress-controller.enabled=true # dashboard 也装上，方便我们绕过 admin API call 做一些方便的操作。 helm install apisix-dashboard apisix/apisix-dashboard 然后，因为截止到现在，APISIX 的 Helm Chart 之中并没有提供 stream-proxy TCP 的监听端口的 TLS 支持的配置格式，见 https://github.com/apache/apisix-helm-chart/issues/348 ，我们需要手动更改 APISIX 的 configmap，把 stream-proxy 的 TLS 配置加上： kubectl edit ConfigMap apisix 我们编辑把 stream_proxy.tcp 改写成这样： stream_proxy: # TCP/UDP proxy only: false tcp: # TCP proxy port list - addr: 9779 tls: true - addr: 9559 tls: true 这里我们需要重建 APISIX Pod，因为 APISIX 的 stream-proxy 的 TLS 配置是在启动的时候加载的，所以我们需要重建 APISIX Pod： kubectl delete $(kubectl get po -l \"app.kubernetes.io/name=apisix\" -o name) ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:3","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#实验环境apisix-on-k8s"},{"categories":["Nebula Graph"],"content":" 4.4 开始实验我们看看这个实验的目标，就是把 NebulaGraph 的 StorageD 的接口暴露出来，让外部的客户端可以访问到，而暴露的方式如图： ┌────────────────────────────────────────────────────────────────────────────────────┐ │ K8s Cluster │ │ ┌──────────────────────────┐ │ │ ┌────────────────────────────────────┐ │ NebulaGraph Cluster │ │ │ │ APISIX API-GATEWAY │ │ ┌──────────────┐ │ │ │ │ │ │ │ Storaged-0 │ │ │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ┌────────────────────────────┐ │ │ │ └──────────────┘ │ │ │ │ │ stream-proxy │ │ │ │ │ │ ┌─────┐ │ .─────. │ │ ┌────┐ │ │ │ │ ┌──────────────┐ │ │ │ │ │╱ ╲ │ │ - addr: 9559 │ │──────┼───┼─┘ │ │ Storaged-1 │ │ │ ━━┫ DNS ┣━━( Service )╋━━━╋▶ tls: true │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │`. ,' │ │ │ │──────┼───┼─┘ │ │ │ │ │ └─────┘ │ `───' │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │SNI │ │ │ │ │ │ │ │ │ │ │──────┼───┼─┐ │ ┌──────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ Storaged-2 │ │ │ │ │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │──────┼───┼─┐ │ │ │ │ │ │ │ │ └────┘ │ │ │ │ └──────────────┘ │ │ │ │ └────────────────────────────┘ │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ │ │ │ │ │ Storaged-3 │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ └────────────────────────────────────┘ └──────────────────────────┘ │ │ │ └────────────────────────────────────────────────────────────────────────────────────┘ 我们已经有了所有的框架，我们要往里填箭头和圆圈了。 $ kubectl get po NAME READY STATUS RESTARTS AGE apisix-6d89854bc5-5m788 1/1 Running 1 (31h ago) 2d4h apisix-dashboard-b544bd766-nh79j 1/1 Running 8 (31h ago) 2d10h apisix-etcd-0 1/1 Running 2 (31h ago) 2d10h apisix-etcd-1 1/1 Running 2 (31h ago) 2d10h apisix-etcd-2 1/1 Running 2 (31h ago) 2d10h nebula-graphd-0 1/1 Running 2 (31h ago) 3d4h nebula-metad-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-1 1/1 Running 2 (31h ago) 3d4h nebula-storaged-2 1/1 Running 2 (31h ago) 3d4h 4.4.1 配置 APISIX 的 stream-proxy参考 APISIX 文档：https://apisix.apache.org/docs/apisix/stream-proxy/#accept-tls-over-tcp-connection 我们用 APISIX 的 API 来配置 stream-proxy： apisix_api_key=\"edd1c9f034335f136f87ad84b625c8f1\" apisix_pod=$(kubectl get po -l \\ \"app.kubernetes.io/name=apisix\" -o name) kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.13:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/2 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-1.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.18:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/3 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-2.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.5:9779\": 1 }, \"type\": \"roundrobin\" } }' 注意，当下，APISIX 的 stream-proxy 上游节点不支持域名解析，是受限于上游的 lua 库，详见我报的 issue：https://github.com/apache/apisix/issues/8334 ，理想情况下，我们这里应该给出每一个 storaged 的 SNI 相同的地址作为 upstream.nodes，好像： kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\": 1 }, \"type\": \"roundrobin\" } }' 4.4.2 配置 APISIX 中 storaged 地址的 TLS 证书在生产环境下，我们应该云原生的方式去管理自签或者公共信任的证书，这里，我们就手动利用 mkcert 工具来做这件事儿。 安装 mkcert # 首次运行，需要安装 mkcert，并且生成根证书 # macOS 的话 brew install mkcert # ubuntu 的话 apt-get install wget libnss3-tools # 然后再去 https://github.com/FiloSottile/mkcert/releases/ 下载 mkcert 签发证书： mkcert '*.nebula-storaged-headless.default.svc.cluster.local' 利用 APISIX-dashboard 将证书导入到 APISIX 之中 单独开一个终端，运行： export POD_NAME=$(\\ kubectl get pods","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:4","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#开始实验"},{"categories":["Nebula Graph"],"content":" 4.4 开始实验我们看看这个实验的目标，就是把 NebulaGraph 的 StorageD 的接口暴露出来，让外部的客户端可以访问到，而暴露的方式如图： ┌────────────────────────────────────────────────────────────────────────────────────┐ │ K8s Cluster │ │ ┌──────────────────────────┐ │ │ ┌────────────────────────────────────┐ │ NebulaGraph Cluster │ │ │ │ APISIX API-GATEWAY │ │ ┌──────────────┐ │ │ │ │ │ │ │ Storaged-0 │ │ │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ┌────────────────────────────┐ │ │ │ └──────────────┘ │ │ │ │ │ stream-proxy │ │ │ │ │ │ ┌─────┐ │ .─────. │ │ ┌────┐ │ │ │ │ ┌──────────────┐ │ │ │ │ │╱ ╲ │ │ - addr: 9559 │ │──────┼───┼─┘ │ │ Storaged-1 │ │ │ ━━┫ DNS ┣━━( Service )╋━━━╋▶ tls: true │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │`. ,' │ │ │ │──────┼───┼─┘ │ │ │ │ │ └─────┘ │ `───' │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │SNI │ │ │ │ │ │ │ │ │ │ │──────┼───┼─┐ │ ┌──────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ Storaged-2 │ │ │ │ │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │──────┼───┼─┐ │ │ │ │ │ │ │ │ └────┘ │ │ │ │ └──────────────┘ │ │ │ │ └────────────────────────────┘ │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ │ │ │ │ │ Storaged-3 │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ └────────────────────────────────────┘ └──────────────────────────┘ │ │ │ └────────────────────────────────────────────────────────────────────────────────────┘ 我们已经有了所有的框架，我们要往里填箭头和圆圈了。 $ kubectl get po NAME READY STATUS RESTARTS AGE apisix-6d89854bc5-5m788 1/1 Running 1 (31h ago) 2d4h apisix-dashboard-b544bd766-nh79j 1/1 Running 8 (31h ago) 2d10h apisix-etcd-0 1/1 Running 2 (31h ago) 2d10h apisix-etcd-1 1/1 Running 2 (31h ago) 2d10h apisix-etcd-2 1/1 Running 2 (31h ago) 2d10h nebula-graphd-0 1/1 Running 2 (31h ago) 3d4h nebula-metad-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-1 1/1 Running 2 (31h ago) 3d4h nebula-storaged-2 1/1 Running 2 (31h ago) 3d4h 4.4.1 配置 APISIX 的 stream-proxy参考 APISIX 文档：https://apisix.apache.org/docs/apisix/stream-proxy/#accept-tls-over-tcp-connection 我们用 APISIX 的 API 来配置 stream-proxy： apisix_api_key=\"edd1c9f034335f136f87ad84b625c8f1\" apisix_pod=$(kubectl get po -l \\ \"app.kubernetes.io/name=apisix\" -o name) kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.13:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/2 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-1.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.18:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/3 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-2.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.5:9779\": 1 }, \"type\": \"roundrobin\" } }' 注意，当下，APISIX 的 stream-proxy 上游节点不支持域名解析，是受限于上游的 lua 库，详见我报的 issue：https://github.com/apache/apisix/issues/8334 ，理想情况下，我们这里应该给出每一个 storaged 的 SNI 相同的地址作为 upstream.nodes，好像： kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\": 1 }, \"type\": \"roundrobin\" } }' 4.4.2 配置 APISIX 中 storaged 地址的 TLS 证书在生产环境下，我们应该云原生的方式去管理自签或者公共信任的证书，这里，我们就手动利用 mkcert 工具来做这件事儿。 安装 mkcert # 首次运行，需要安装 mkcert，并且生成根证书 # macOS 的话 brew install mkcert # ubuntu 的话 apt-get install wget libnss3-tools # 然后再去 https://github.com/FiloSottile/mkcert/releases/ 下载 mkcert 签发证书： mkcert '*.nebula-storaged-headless.default.svc.cluster.local' 利用 APISIX-dashboard 将证书导入到 APISIX 之中 单独开一个终端，运行： export POD_NAME=$(\\ kubectl get pods","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:4","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#配置-apisix-的-stream-proxy"},{"categories":["Nebula Graph"],"content":" 4.4 开始实验我们看看这个实验的目标，就是把 NebulaGraph 的 StorageD 的接口暴露出来，让外部的客户端可以访问到，而暴露的方式如图： ┌────────────────────────────────────────────────────────────────────────────────────┐ │ K8s Cluster │ │ ┌──────────────────────────┐ │ │ ┌────────────────────────────────────┐ │ NebulaGraph Cluster │ │ │ │ APISIX API-GATEWAY │ │ ┌──────────────┐ │ │ │ │ │ │ │ Storaged-0 │ │ │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ┌────────────────────────────┐ │ │ │ └──────────────┘ │ │ │ │ │ stream-proxy │ │ │ │ │ │ ┌─────┐ │ .─────. │ │ ┌────┐ │ │ │ │ ┌──────────────┐ │ │ │ │ │╱ ╲ │ │ - addr: 9559 │ │──────┼───┼─┘ │ │ Storaged-1 │ │ │ ━━┫ DNS ┣━━( Service )╋━━━╋▶ tls: true │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │`. ,' │ │ │ │──────┼───┼─┘ │ │ │ │ │ └─────┘ │ `───' │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │SNI │ │ │ │ │ │ │ │ │ │ │──────┼───┼─┐ │ ┌──────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ Storaged-2 │ │ │ │ │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │──────┼───┼─┐ │ │ │ │ │ │ │ │ └────┘ │ │ │ │ └──────────────┘ │ │ │ │ └────────────────────────────┘ │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ │ │ │ │ │ Storaged-3 │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ └────────────────────────────────────┘ └──────────────────────────┘ │ │ │ └────────────────────────────────────────────────────────────────────────────────────┘ 我们已经有了所有的框架，我们要往里填箭头和圆圈了。 $ kubectl get po NAME READY STATUS RESTARTS AGE apisix-6d89854bc5-5m788 1/1 Running 1 (31h ago) 2d4h apisix-dashboard-b544bd766-nh79j 1/1 Running 8 (31h ago) 2d10h apisix-etcd-0 1/1 Running 2 (31h ago) 2d10h apisix-etcd-1 1/1 Running 2 (31h ago) 2d10h apisix-etcd-2 1/1 Running 2 (31h ago) 2d10h nebula-graphd-0 1/1 Running 2 (31h ago) 3d4h nebula-metad-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-1 1/1 Running 2 (31h ago) 3d4h nebula-storaged-2 1/1 Running 2 (31h ago) 3d4h 4.4.1 配置 APISIX 的 stream-proxy参考 APISIX 文档：https://apisix.apache.org/docs/apisix/stream-proxy/#accept-tls-over-tcp-connection 我们用 APISIX 的 API 来配置 stream-proxy： apisix_api_key=\"edd1c9f034335f136f87ad84b625c8f1\" apisix_pod=$(kubectl get po -l \\ \"app.kubernetes.io/name=apisix\" -o name) kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.13:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/2 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-1.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.18:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/3 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-2.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.5:9779\": 1 }, \"type\": \"roundrobin\" } }' 注意，当下，APISIX 的 stream-proxy 上游节点不支持域名解析，是受限于上游的 lua 库，详见我报的 issue：https://github.com/apache/apisix/issues/8334 ，理想情况下，我们这里应该给出每一个 storaged 的 SNI 相同的地址作为 upstream.nodes，好像： kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\": 1 }, \"type\": \"roundrobin\" } }' 4.4.2 配置 APISIX 中 storaged 地址的 TLS 证书在生产环境下，我们应该云原生的方式去管理自签或者公共信任的证书，这里，我们就手动利用 mkcert 工具来做这件事儿。 安装 mkcert # 首次运行，需要安装 mkcert，并且生成根证书 # macOS 的话 brew install mkcert # ubuntu 的话 apt-get install wget libnss3-tools # 然后再去 https://github.com/FiloSottile/mkcert/releases/ 下载 mkcert 签发证书： mkcert '*.nebula-storaged-headless.default.svc.cluster.local' 利用 APISIX-dashboard 将证书导入到 APISIX 之中 单独开一个终端，运行： export POD_NAME=$(\\ kubectl get pods","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:4","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#配置-apisix-中-storaged-地址的-tls-证书"},{"categories":["Nebula Graph"],"content":" 4.4 开始实验我们看看这个实验的目标，就是把 NebulaGraph 的 StorageD 的接口暴露出来，让外部的客户端可以访问到，而暴露的方式如图： ┌────────────────────────────────────────────────────────────────────────────────────┐ │ K8s Cluster │ │ ┌──────────────────────────┐ │ │ ┌────────────────────────────────────┐ │ NebulaGraph Cluster │ │ │ │ APISIX API-GATEWAY │ │ ┌──────────────┐ │ │ │ │ │ │ │ Storaged-0 │ │ │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ┌────────────────────────────┐ │ │ │ └──────────────┘ │ │ │ │ │ stream-proxy │ │ │ │ │ │ ┌─────┐ │ .─────. │ │ ┌────┐ │ │ │ │ ┌──────────────┐ │ │ │ │ │╱ ╲ │ │ - addr: 9559 │ │──────┼───┼─┘ │ │ Storaged-1 │ │ │ ━━┫ DNS ┣━━( Service )╋━━━╋▶ tls: true │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │`. ,' │ │ │ │──────┼───┼─┘ │ │ │ │ │ └─────┘ │ `───' │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │SNI │ │ │ │ │ │ │ │ │ │ │──────┼───┼─┐ │ ┌──────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ Storaged-2 │ │ │ │ │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │──────┼───┼─┐ │ │ │ │ │ │ │ │ └────┘ │ │ │ │ └──────────────┘ │ │ │ │ └────────────────────────────┘ │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ │ │ │ │ │ Storaged-3 │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ └────────────────────────────────────┘ └──────────────────────────┘ │ │ │ └────────────────────────────────────────────────────────────────────────────────────┘ 我们已经有了所有的框架，我们要往里填箭头和圆圈了。 $ kubectl get po NAME READY STATUS RESTARTS AGE apisix-6d89854bc5-5m788 1/1 Running 1 (31h ago) 2d4h apisix-dashboard-b544bd766-nh79j 1/1 Running 8 (31h ago) 2d10h apisix-etcd-0 1/1 Running 2 (31h ago) 2d10h apisix-etcd-1 1/1 Running 2 (31h ago) 2d10h apisix-etcd-2 1/1 Running 2 (31h ago) 2d10h nebula-graphd-0 1/1 Running 2 (31h ago) 3d4h nebula-metad-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-1 1/1 Running 2 (31h ago) 3d4h nebula-storaged-2 1/1 Running 2 (31h ago) 3d4h 4.4.1 配置 APISIX 的 stream-proxy参考 APISIX 文档：https://apisix.apache.org/docs/apisix/stream-proxy/#accept-tls-over-tcp-connection 我们用 APISIX 的 API 来配置 stream-proxy： apisix_api_key=\"edd1c9f034335f136f87ad84b625c8f1\" apisix_pod=$(kubectl get po -l \\ \"app.kubernetes.io/name=apisix\" -o name) kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.13:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/2 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-1.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.18:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/3 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-2.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.5:9779\": 1 }, \"type\": \"roundrobin\" } }' 注意，当下，APISIX 的 stream-proxy 上游节点不支持域名解析，是受限于上游的 lua 库，详见我报的 issue：https://github.com/apache/apisix/issues/8334 ，理想情况下，我们这里应该给出每一个 storaged 的 SNI 相同的地址作为 upstream.nodes，好像： kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\": 1 }, \"type\": \"roundrobin\" } }' 4.4.2 配置 APISIX 中 storaged 地址的 TLS 证书在生产环境下，我们应该云原生的方式去管理自签或者公共信任的证书，这里，我们就手动利用 mkcert 工具来做这件事儿。 安装 mkcert # 首次运行，需要安装 mkcert，并且生成根证书 # macOS 的话 brew install mkcert # ubuntu 的话 apt-get install wget libnss3-tools # 然后再去 https://github.com/FiloSottile/mkcert/releases/ 下载 mkcert 签发证书： mkcert '*.nebula-storaged-headless.default.svc.cluster.local' 利用 APISIX-dashboard 将证书导入到 APISIX 之中 单独开一个终端，运行： export POD_NAME=$(\\ kubectl get pods","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:4","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#增加-apisix-的-nodeport-service"},{"categories":["Nebula Graph"],"content":" 4.4 开始实验我们看看这个实验的目标，就是把 NebulaGraph 的 StorageD 的接口暴露出来，让外部的客户端可以访问到，而暴露的方式如图： ┌────────────────────────────────────────────────────────────────────────────────────┐ │ K8s Cluster │ │ ┌──────────────────────────┐ │ │ ┌────────────────────────────────────┐ │ NebulaGraph Cluster │ │ │ │ APISIX API-GATEWAY │ │ ┌──────────────┐ │ │ │ │ │ │ │ Storaged-0 │ │ │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ┌────────────────────────────┐ │ │ │ └──────────────┘ │ │ │ │ │ stream-proxy │ │ │ │ │ │ ┌─────┐ │ .─────. │ │ ┌────┐ │ │ │ │ ┌──────────────┐ │ │ │ │ │╱ ╲ │ │ - addr: 9559 │ │──────┼───┼─┘ │ │ Storaged-1 │ │ │ ━━┫ DNS ┣━━( Service )╋━━━╋▶ tls: true │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │`. ,' │ │ │ │──────┼───┼─┘ │ │ │ │ │ └─────┘ │ `───' │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │SNI │ │ │ │ │ │ │ │ │ │ │──────┼───┼─┐ │ ┌──────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ Storaged-2 │ │ │ │ │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │──────┼───┼─┐ │ │ │ │ │ │ │ │ └────┘ │ │ │ │ └──────────────┘ │ │ │ │ └────────────────────────────┘ │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ │ │ │ │ │ Storaged-3 │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ └────────────────────────────────────┘ └──────────────────────────┘ │ │ │ └────────────────────────────────────────────────────────────────────────────────────┘ 我们已经有了所有的框架，我们要往里填箭头和圆圈了。 $ kubectl get po NAME READY STATUS RESTARTS AGE apisix-6d89854bc5-5m788 1/1 Running 1 (31h ago) 2d4h apisix-dashboard-b544bd766-nh79j 1/1 Running 8 (31h ago) 2d10h apisix-etcd-0 1/1 Running 2 (31h ago) 2d10h apisix-etcd-1 1/1 Running 2 (31h ago) 2d10h apisix-etcd-2 1/1 Running 2 (31h ago) 2d10h nebula-graphd-0 1/1 Running 2 (31h ago) 3d4h nebula-metad-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-1 1/1 Running 2 (31h ago) 3d4h nebula-storaged-2 1/1 Running 2 (31h ago) 3d4h 4.4.1 配置 APISIX 的 stream-proxy参考 APISIX 文档：https://apisix.apache.org/docs/apisix/stream-proxy/#accept-tls-over-tcp-connection 我们用 APISIX 的 API 来配置 stream-proxy： apisix_api_key=\"edd1c9f034335f136f87ad84b625c8f1\" apisix_pod=$(kubectl get po -l \\ \"app.kubernetes.io/name=apisix\" -o name) kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.13:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/2 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-1.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.18:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/3 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-2.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.5:9779\": 1 }, \"type\": \"roundrobin\" } }' 注意，当下，APISIX 的 stream-proxy 上游节点不支持域名解析，是受限于上游的 lua 库，详见我报的 issue：https://github.com/apache/apisix/issues/8334 ，理想情况下，我们这里应该给出每一个 storaged 的 SNI 相同的地址作为 upstream.nodes，好像： kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\": 1 }, \"type\": \"roundrobin\" } }' 4.4.2 配置 APISIX 中 storaged 地址的 TLS 证书在生产环境下，我们应该云原生的方式去管理自签或者公共信任的证书，这里，我们就手动利用 mkcert 工具来做这件事儿。 安装 mkcert # 首次运行，需要安装 mkcert，并且生成根证书 # macOS 的话 brew install mkcert # ubuntu 的话 apt-get install wget libnss3-tools # 然后再去 https://github.com/FiloSottile/mkcert/releases/ 下载 mkcert 签发证书： mkcert '*.nebula-storaged-headless.default.svc.cluster.local' 利用 APISIX-dashboard 将证书导入到 APISIX 之中 单独开一个终端，运行： export POD_NAME=$(\\ kubectl get pods","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:4","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#配置-k8s-外部-dns"},{"categories":["Nebula Graph"],"content":" 4.4 开始实验我们看看这个实验的目标，就是把 NebulaGraph 的 StorageD 的接口暴露出来，让外部的客户端可以访问到，而暴露的方式如图： ┌────────────────────────────────────────────────────────────────────────────────────┐ │ K8s Cluster │ │ ┌──────────────────────────┐ │ │ ┌────────────────────────────────────┐ │ NebulaGraph Cluster │ │ │ │ APISIX API-GATEWAY │ │ ┌──────────────┐ │ │ │ │ │ │ │ Storaged-0 │ │ │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ┌────────────────────────────┐ │ │ │ └──────────────┘ │ │ │ │ │ stream-proxy │ │ │ │ │ │ ┌─────┐ │ .─────. │ │ ┌────┐ │ │ │ │ ┌──────────────┐ │ │ │ │ │╱ ╲ │ │ - addr: 9559 │ │──────┼───┼─┘ │ │ Storaged-1 │ │ │ ━━┫ DNS ┣━━( Service )╋━━━╋▶ tls: true │ │ │ │ ┌────┼──────▶│ │ │ │ │ │ │`. ,' │ │ │ │──────┼───┼─┘ │ │ │ │ │ └─────┘ │ `───' │ │ │ │ │ │ │ └──────────────┘ │ │ │ │ │ │SNI │ │ │ │ │ │ │ │ │ │ │──────┼───┼─┐ │ ┌──────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ Storaged-2 │ │ │ │ │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │──────┼───┼─┐ │ │ │ │ │ │ │ │ └────┘ │ │ │ │ └──────────────┘ │ │ │ │ └────────────────────────────┘ │ │ │ │ │ │ │ │ │ │ ┌──────────────┐ │ │ │ │ │ │ │ │ Storaged-3 │ │ │ │ │ │ └────┼──────▶│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──────────────┘ │ │ │ └────────────────────────────────────┘ └──────────────────────────┘ │ │ │ └────────────────────────────────────────────────────────────────────────────────────┘ 我们已经有了所有的框架，我们要往里填箭头和圆圈了。 $ kubectl get po NAME READY STATUS RESTARTS AGE apisix-6d89854bc5-5m788 1/1 Running 1 (31h ago) 2d4h apisix-dashboard-b544bd766-nh79j 1/1 Running 8 (31h ago) 2d10h apisix-etcd-0 1/1 Running 2 (31h ago) 2d10h apisix-etcd-1 1/1 Running 2 (31h ago) 2d10h apisix-etcd-2 1/1 Running 2 (31h ago) 2d10h nebula-graphd-0 1/1 Running 2 (31h ago) 3d4h nebula-metad-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-0 1/1 Running 2 (31h ago) 3d4h nebula-storaged-1 1/1 Running 2 (31h ago) 3d4h nebula-storaged-2 1/1 Running 2 (31h ago) 3d4h 4.4.1 配置 APISIX 的 stream-proxy参考 APISIX 文档：https://apisix.apache.org/docs/apisix/stream-proxy/#accept-tls-over-tcp-connection 我们用 APISIX 的 API 来配置 stream-proxy： apisix_api_key=\"edd1c9f034335f136f87ad84b625c8f1\" apisix_pod=$(kubectl get po -l \\ \"app.kubernetes.io/name=apisix\" -o name) kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.13:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/2 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-1.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.18:9779\": 1 }, \"type\": \"roundrobin\" } }' kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/3 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-2.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"172.17.0.5:9779\": 1 }, \"type\": \"roundrobin\" } }' 注意，当下，APISIX 的 stream-proxy 上游节点不支持域名解析，是受限于上游的 lua 库，详见我报的 issue：https://github.com/apache/apisix/issues/8334 ，理想情况下，我们这里应该给出每一个 storaged 的 SNI 相同的地址作为 upstream.nodes，好像： kubectl exec -it $apisix_pod -- \\ curl http://127.0.0.1:9180/apisix/admin/stream_routes/1 \\ -H \"X-API-KEY: $apisix_api_key\" -X PUT -d \\ '{ \"sni\": \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\", \"upstream\": { \"nodes\": { \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\": 1 }, \"type\": \"roundrobin\" } }' 4.4.2 配置 APISIX 中 storaged 地址的 TLS 证书在生产环境下，我们应该云原生的方式去管理自签或者公共信任的证书，这里，我们就手动利用 mkcert 工具来做这件事儿。 安装 mkcert # 首次运行，需要安装 mkcert，并且生成根证书 # macOS 的话 brew install mkcert # ubuntu 的话 apt-get install wget libnss3-tools # 然后再去 https://github.com/FiloSottile/mkcert/releases/ 下载 mkcert 签发证书： mkcert '*.nebula-storaged-headless.default.svc.cluster.local' 利用 APISIX-dashboard 将证书导入到 APISIX 之中 单独开一个终端，运行： export POD_NAME=$(\\ kubectl get pods","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:4:4","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#验证-nebulagraph-storage-client-可以从所有的节点中获取到数据"},{"categories":["Nebula Graph"],"content":" 5 总结 NebulaGraph 查询接口的负载均衡可以借助 K8s Service来做； NebulaGraph 底层存储接口的暴露在 K8s 中可以利用 APISIX Stream Proxy 和 SNI 来优雅实现； 利用 API 网关对出口传输层的加密是一个很好的选择，相较于用 NebulaGraph 原生的 TLS 的方式。 ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:5:0","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#总结"},{"categories":["Nebula Graph"],"content":" 6 一些坑 发现 fbthrift python 并不支持 发送 extend host name（SNI），https://github.com/vesoft-inc/nebula-python/pull/238 ，写了 PR 去做支持，这时候 APISIX 中的报错是 failed to find SNI: 2022/11/15 10:18:26 [error] 78#78: *1744270 stream [lua] init.lua:842: stream_ssl_phase(): failed to fetch ssl config: failed to find SNI: please check if the client requests via IP or uses an outdated protocol. If you need to report an issue, provide a packet capture file of the TLS handshake., context: ssl_certificate_by_lua*, client: 172.17.0.1, server: 0.0.0.0:9779 参考： https://docs.python.org/3/library/ssl.html#ssl.SSLContext.sslsocket_class https://github.com/apache/thrift/commit/937228e030569bf25ceb379c9491426709792701 https://github.com/apache/thrift/pull/894 https://github.com/apache/thrift/blob/e8353cb46e9f5e71f9b76f55d6bf59530b7f98ef/lib/py/src/transport/TSSLSocket.py#L184 发现 APISIX stream 里边不解析上游 node 域名，我查了所有一溜的 dns 都没有问题，去提了 issue 才知道是已知问题：https://github.com/apache/apisix/issues/8334，只好先手配 IP:Port 作罢。 2022/11/15 12:26:59 [error] 44#44: *9538531 stream [lua] resolver.lua:47: parse_domain(): failed to parse domain: nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local, error: failed to query the DNS server: dns client error: 101 empty record received while prereading client data, client: 172.17.0.1, server: 0.0.0.0:9779 2022/11/15 12:26:59 [error] 44#44: *9538531 stream [lua] upstream.lua:79: parse_domain_for_nodes(): dns resolver domain: nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local error: failed to query the DNS server: dns client error: 101 empty record received while prereading client data, client: 172.17.0.1, server: 0.0.0.0:9779 2022/11/15 12:26:59 [error] 44#44: *9538531 stream [lua] init.lua:965: stream_preread_phase(): failed to set upstream: no valid upstream node while prereading client data, client: 172.17.0.1, server: 0.0.0.0:9779 题图版权 Lars ","date":"2022-11-16","objectID":"/apisix-and-nebulagraph/:6:0","series":null,"tags":["Nebula Graph","API Gateway","云原生","k8s"],"title":"NebulaGraph 的云原生 API 网关最佳实践","uri":"/apisix-and-nebulagraph/#一些坑"},{"categories":["Nebula Graph"],"content":"如何把相对原始的数据处理、建模并导入 NebulaGraph？本文用一个端到端的示例演示，从多数据源聚合数据，清理、利用 dbt 转换成 NebulaGraph 建模的属性图点边记录，最后导入成图谱的全流程。","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/"},{"categories":["Nebula Graph"],"content":" 如何把相对原始的数据处理、建模并导入 NebulaGraph？本文用一个端到端的示例演示，从多数据源聚合数据，清理、利用 dbt 转换成 NebulaGraph 建模的属性图点边记录，最后导入成图谱的全流程。 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:0:0","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#"},{"categories":["Nebula Graph"],"content":" 1 任务假设作为一个类似于 Netflix、爱奇艺的服务提供商，我们需要利用 NebulaGraph 搭建一个用户-电影知识图谱，来辅助支撑推荐、问答和推荐理由等常见由图谱支撑的场景。 知识图谱需要的数据存在在不同的数据源，比如一些公开的 API、数仓中的不同数据库、静态的文件等。这时候，我们需要以下几个步骤来从数据构建图谱： 分析可能获取的数据 选取关心的关联关系，图建模 抽取关联关系，导入图数据库 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:1:0","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#任务"},{"categories":["Nebula Graph"],"content":" 2 数据来源假设我们的数据来源是 OMDB 和 MovieLens。 OMDB 是一个开放的电影数据库，本例中我们模拟公司内部的业务系统，我们可以获得的信息有： 电影 电影的分类 电影中的工作人员（导演、动作指导、演员、后期制作等） 电影封面、宣传片等 MovieLens 是一个开放的数据集，本例中我们模拟公司内部的用户数据，我们可以获得的信息有： 用户 电影 用户对电影的评分交互 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:2:0","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#数据来源"},{"categories":["Nebula Graph"],"content":" 3 图建模在前边我们推荐系统的文章中我们介绍了推荐系统在图上的一些基本的方法（文章的链接是 www.siwei.io/recommendation-system-with-graphdb/）。其中的基于内容过滤关注了用户–\u003e电影、电影–\u003e分类、电影–\u003e演员、电影–\u003e导演的关系，协同过滤的方法则关注用户–\u003e电影的关系，推荐理由服务则关注以上所有的关系，所以总结起来，我们需要的边有： watched(rate(double)) with_genre directed_by acted_by 相应的，其中的顶点类型，我们先根据已有的信息中，顶点中可能需要被关注的信息作为属性，给出初始的规划： user(user_id) movie(name) person(name, birthdate) genre(name) ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:3:0","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#图建模"},{"categories":["Nebula Graph"],"content":" 4 数据转换有了目标的图谱结构定义，我们来看看手上的数据如何映射到它。 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:4:0","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#数据转换"},{"categories":["Nebula Graph"],"content":" 4.1 OMDB 数据首先是 OMDB 中的数据，它由很多表组成，比如 all_movies 这张表，存储了所有的电影、以及它们在不同语言下的名字： movie_id name language_iso_639_1 official_translation 1 Cowboy Bebop de 1 1 Cowboy Bebop en 1 2 Ariel - Abgebrannt in Helsinki de 0 3 Shadows in Paradise en 0 3 Im Schatten des Paradieses de 0 3 Schatten im Paradies de 1 而 all_casts 表格中保有所有电影相关的工作人员： movie_id person_id job_id role position 11 1 21 1 11 1 13 1 11 2 15 Luke Skywalker 1 11 3 15 Han Solo 3 11 4 15 Leia Organa 2 但是这里的每一个人的姓名等信息、以及他/她在电影中任职的职位，则分别在另外的表中： job_names 比如 1 代表编剧、2 代表制作人，有意思的是，和电影 id 与姓名一样，job_id 到 name 是一对多的关系，因为 OMDB 中的数据都是多语言的。 job_id name language_iso_639_1 1 Autoren de 1 Writing Department en 1 Departamento de redacción es 1 Département écriture fr 1 Scenariusz pl 2 Produzenten de 2 Production Department en all_people id name birthday deathday gender 1 George Lucas 1944-05-14 \\N 0 2 Mark Hamill 1951-09-25 \\N 0 3 Harrison Ford 1942-07-13 \\N 0 4 Carrie Fisher 1956-10-21 2016-12-27 1 5 Peter Cushing 1913-05-26 1994-08-11 0 6 Anthony Daniels 1946-02-21 \\N 0 这是在数据来源是表结构、RDBMS 中，是一个很典型的情况，所以对于 movie \u003c-[directed_by]-(person) 这个关系，就涉及了 all_movies，all_casts，all_people，job_names 四个表格 directed_by 起点 person_id 在 all_casts 之中 终点 movie_id 在 all_casts 之中 条件是 job_id 为 job_names 之中的 “director” movie person_id 在 all_casts 之中 名字来自 all_movies 中按 id 查找，language 为 “en” person movie_id 在 all_casts 之中 名字、生日在 all_people 之中 所有 OMDB 中我们关心的表的关联如图： ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:4:1","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#omdb-数据"},{"categories":["Nebula Graph"],"content":" 4.2 MovieLens 数据集而上边只是一个数据源、数据表或者数仓的数据，在真实场景中，我们还需要从其他源头收取数据，并聚合起来，在本例中，我们还需要从 MovieLens 的数据集中抽取需要的知识。 这里，涉及到 MovieLens 数据集，我们利用的只有：用户–\u003e电影，这一条关系。 movies.csv movieId title genres 1 Toy Story (1995) Adventure 2 Jumanji (1995) Adventure 3 Grumpier Old Men (1995) Comedy 4 Waiting to Exhale (1995) Comedy ratings.csv userId movieId rating timestamp 1 1 4 964982703 1 3 4 964981247 1 6 4 964982224 从两个表的数据预览似乎可以得出： watched 起点来自于 ratings.csv 中的 userId 终点来自于 ratings.csv 中的 movieId 评分来自于 ratings.csv 中的 rating user 来自于 ratings.csv 中的 userId 然而，细心的你们一定发现 MovieLens 数据集中的 movieId 和来自于 OMDB 中的电影 id 完全是不同的两套体系，如果我们需要让他们关联起来，需要将 MovieLens 里的 movieId 转换成为 OMDB 中的电影 id。而他们之间的关联条件则是电影的标题。 然而，通观察，我们知道： OMDB 电影中标题是多语言的 MovieLens 中的标题结尾带有(1995)这样的年份信息 所以我们最终的结论为 watched 起点来自于 ratings.csv 中的 userId 终点来自于 ratings.csv 中的 movieId 终点要从 movies.csv 中的 title ，在 OMDB 之中查找，得到 OMDB 的 movie_id 查找条件为去掉年份，从 OMDB 的英文标题中进行匹配 评分来自于 ratings.csv 中的 rating user 来自于 ratings.csv 中的 userId 现在，这个表格之间的关系如下 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:4:2","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#movielens-数据集"},{"categories":["Nebula Graph"],"content":" 4.3 映射数据到图谱（属性图）总结起来，我们需要对多个数据源中的不同表格（或者表格形式的 CSV 文件）进行聚合，这样的对应关系如图所示：其中蓝色虚线表示图中顶点的数据信息来源，粉色虚线表示边信息的来源。 最后，我们还要对不同表中个体的 id 进行格式化，比如 user_id，是自增的数字，我们要转换成全局唯一的 vertex_id，一个方便的方式是在现有 id 的基础上增加字符串前缀，比如 u_。 最终，拿对于 user -[watched]-\u003e movie 这一个关系来说，我们可以处理得到这样的表结构数据： user_id rating title omdb_movie_id u_1 5 Seven (a.k.a. Se7en) 807 u_1 5 Star Wars: Episode IV - A New Hope 11 u_1 5 Star Wars: Episode IV - A New Hope 10 u_1 4 Mask, The 832 u_1 3 Mrs. Doubtfire 832 其中每一行记录中存在三个图上的结构信息： user 顶点 id movie 顶点 id watched 边的 rating 值 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:4:3","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#映射数据到图谱属性图"},{"categories":["Nebula Graph"],"content":" 5 工具到此，我们已经完成了数据的分析与建模设计，在进入”抽取关联关系，导入图数据库“环节之前，先介绍一下我们要用到的工具。 ”抽取关联关系“可以简单认为是 ETL 中的 Extract 和 Transform。本质上就是工程上执行数据映射与转换的工作，市面上有很多不同风格的工具、开源项目可以做。这里我们用到我个人比较喜欢的工具：dbt。 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:5:0","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#工具"},{"categories":["Nebula Graph"],"content":" 5.1 数据转换利器 dbtdbt 是一个开源的数据转换工具，他有非常成熟的社区和生态，可以在大多数主流数仓之中进行高效、可控、高质量的数据转换工作，无论是临时的转换工作（ad-hoc），还是在给定的定时 pipeline 中进行复杂编排，dbt 都可以很好胜任，他的一大特色就是使用 SQL-like 语言去描述数据转换的规则，基于 GitOps，可以非常优雅地去多人协作、维护超大规模数据团队里复杂的数据处理作业。而且内置的数据测试能力可以很好的控制数据的质量，做到可复现、可控制。 dbt 不仅有很多集成的子项目，还能和很多其他优秀的开源项目有机结合（meltano、AirFlow、Amundsen 、Superset 等等），形成一整套现代的数据基础设施体系，感兴趣的同学可以参考我之前搭建的数据血缘与元数据治理参考架构文章：www.siwei.io/en/data-lineage-oss-ref-solution。 简单来说，dbt 是一个 python 写的命令行工具，当我们使用它的时候，针对每一个项目，我们可以创建特定格式的项目文件夹，其中包涵一个 YAML 格式的配置文件，在配置文件里指定数据转换的来源信息在哪里，目标在哪里（处理之后的数据存储的地方，可能是 Postgres，Big Query，Spark 等）。在数据源中，我们用 YAML 文件和 .SQL 文件一起描述了”从哪里取哪些数据，如何做变换，输出什么“的信息。 这个截图就是 dbt 官方文档中的示例项目中的文件和配置，可以看到 models/example 里的信息就是最核心的数据转换（transform）的规则，而所有的其他数据都是和这个数据转换相关的元数据，这些 dbt 项目文件非常适合用 git 来进行维护，进行现代、自动化的 DataOps。 注： 可以参考 dbt 文档上手理解它：https://docs.getdbt.com/docs/get-started/getting-started-dbt-core ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:5:1","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#数据转换利器-dbt"},{"categories":["Nebula Graph"],"content":" 5.2 NebulaGraph 数据导入经过 dbt 对数据进行处理之后，我们可以得到直接映射到不同类型的顶点、边、及其属性的表结构的中间数据，它们可以是 CSV 的文件形式，也可以是数仓中的表，甚至可能是 Spark 中的 dataframe。而将它们导入 NebulaGraph 有不同的选择，其中 NebulaGraph Exchange，Nebula-Importer，还有 Nebula-Spark-Connector 都可以作为导入数据。 注： 大家可以在 www.siwei.io/sketches/nebula-data-import-options 了解更多 NebulaGraph 数据导入不同工具的介绍，知道如何选择。 在这里，我就用最简单的 Nebula-Importer 作为例子。 Nebula-Importer 是一个用 Golang 写的开源工具，它可以编译成一个单文件的二进制，通过预配置的 YAML 格式的文件，获得给定的 CSV 文件到 NebulaGraph 中点、边的对应关系，进行读取和导入。 注： Nebula-Importer 代码：https://github.com/vesoft-inc/nebula-importer/ Nebula-Importer 文档：https://docs.nebula-graph.com.cn/master/nebula-importer/use-importer/ ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:5:2","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#nebulagraph-数据导入"},{"categories":["Nebula Graph"],"content":" 6 实操现在我们就实操一下如何利用 dbt + Nebula-Importer 进行多数据源聚合、转换、再导入 NebulaGraph 的过程，整个项目的代码已经开源，仓库在 https://github.com/wey-gu/movie-recommendation-dataset 上，欢迎大家参考、共建。 整个过程如下： 将源数据简单清洗、导入数仓（Postgres）（EL） 用 dbt 对数据进行转换（Transform）、导出为 CSV 文件 用 Nebula Importer 将 CSV 导入 NebulaGraph（L） ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:0","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#实操"},{"categories":["Nebula Graph"],"content":" 6.1 准备 dbt 环境dbt 是一个 python 项目，我们在一个虚拟的 python3 环境里安装好 dbt 和 dbt-postgres。 python3 -m venv .venv source .venv/bin/activate pip install dbt-postgres 创建一个 dbt 项目，并进入到空的项目里： dbt init dbt_project cd dbt_project 看看里边的文件吧： $ tree . . |-- README.md # 项目说明 README |-- analyses |-- dbt_project.yml # 项目配置文件 |-- macros |-- models # transform 来源 | \\-- example | |-- my_first_dbt_model.sql # 一个描述了如何从元数据中 SELECT 并处理的规则 | |-- my_second_dbt_model.sql | \\-- schema.yml # 规则文件的元数据配置，描述了 sql 规则的属性 |-- seeds # 源数据如果是 CSV 文件，可以放到 seeds 里 |-- snapshots \\-- tests 7 directories, 5 files 最后，咱们拉一个容器里的 Postgres 当做我们这个项目的数仓，如果你已经有各种其他数仓，就不需要这一步了，不过要把项目中的配置文件作相应的修改，并安装相应的 dbt 插件。 docker run --rm --name postgres \\ -e POSTGRES_PASSWORD=nebula \\ -e POSTGRES_USER=nebula \\ -e POSTGRES_DB=warehouse -d \\ -p 5432:5432 postgres ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:1","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#准备-dbt-环境"},{"categories":["Nebula Graph"],"content":" 6.2 数据下载与预处理我们把数据放到项目的 raw_data 下吧 mkdir -p raw_data cd raw_data 注意，假设 raw_data 在 dbt_proeject 之下： tree .. .. |-- README.md |-- analyses |-- dbt_project.yml |-- macros |-- models | \\-- example | |-- my_first_dbt_model.sql | |-- my_second_dbt_model.sql | \\-- schema.yml |-- raw_data # 新建的目录 |-- seeds |-- snapshots \\-- tests 8 directories, 5 files 我们把 omdb 数据下载之后，再解压： wget www.omdb.org/data/all_people.csv.bz2 wget www.omdb.org/data/all_people_aliases.csv.bz2 wget www.omdb.org/data/people_links.csv.bz2 wget www.omdb.org/data/all_casts.csv.bz2 wget www.omdb.org/data/job_names.csv.bz2 wget www.omdb.org/data/all_characters.csv.bz2 wget www.omdb.org/data/movie_categories.csv.bz2 wget www.omdb.org/data/movie_keywords.csv.bz2 wget www.omdb.org/data/category_names.csv.bz2 wget www.omdb.org/data/all_categories.csv.bz2 wget www.omdb.org/data/all_movie_aliases_iso.csv.bz2 bunzip2 *.bz2 然后是 MovieLens 数据集的下载、解压： wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip unzip ml-latest-small.zip rm *.zip 在导入数仓进行转换（Transform）之前我们做一些数据的预处理，然后把他们放到 seeds 之下。 # 因为是实验项目，我们简单粗暴地去掉带有转义的引号的数据，因为它们会被认为是无效字符，处理之后的结果放到 seeds 下边。 grep -v '\\\\\"' raw_data/all_movie_aliases_iso.csv \u003e seeds/all_movie_aliases_iso.csv grep -v '\\\\\"' raw_data/all_casts.csv \u003e seeds/all_casts.csv grep -v '\\\\\"' raw_data/all_characters.csv \u003e seeds/all_characters.csv grep -v '\\\\\"' raw_data/all_people.csv \u003e seeds/all_people.csv grep -v '\\\\\"' raw_data/category_names.csv \u003e seeds/category_names.csv grep -v '\\\\\"' raw_data/job_names.csv \u003e seeds/job_names.csv # 下边的文件无需处理，直接放到 seeds 下边。 cp raw_data/movie_categories.csv seeds/movie_categories.csv cp raw_data/movie_keywords.csv seeds/movie_keywords.csv cp raw_data/all_categories.csv seeds/all_categories.csv cp raw_data/ml-latest-small/ratings.csv seeds/movielens_ratings.csv cp raw_data/ml-latest-small/movies.csv seeds/movielens_movies.csv 有了 seeds 下边的文件之后，可以用一个命令把他们导入到数仓里： 参考文档：https://docs.getdbt.com/docs/build/seeds dbt seed 执行过程因数仓而异，用本地的 postgres 可能要等一会儿才能完成，执行结果大概是这样的： $ dbt seed 05:58:27 Running with dbt=1.3.0 05:58:27 Found 2 models, 4 tests, 0 snapshots, 0 analyses, 289 macros, 0 operations, 11 seed files, 0 sources, 0 exposures, 0 metrics 05:58:28 05:58:28 Concurrency: 8 threads (target='dev') 05:58:28 05:58:28 1 of 11 START seed file public.all_casts ....................................... [RUN] ... 07:10:11 1 of 11 OK loaded seed file public.all_casts ................................... [INSERT 1082228 in 4303.78s] 07:10:11 07:10:11 Finished running 11 seeds in 1 hours 11 minutes and 43.93 seconds (4303.93s). 07:10:11 07:10:11 Completed successfully 07:10:11 07:10:11 Done. PASS=11 WARN=0 ERROR=0 SKIP=0 TOTAL=11 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:2","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#数据下载与预处理"},{"categories":["Nebula Graph"],"content":" 6.3 撰写 Transform model我们创建 model 如下： mkdir models/movie_recommedation touch models/movie_recommedation/user_watched_movies.sql touch models/movie_recommedation/schema.yml 这时候 models 中的文件结构大概是这样的： $ tree models models \\-- movie_recommedation |-- user_watched_movies.sql \\-- schema.yml 这个 model 下边目前只有一个规则，就是负责处理用户观看电影这一个边上数据的 SQL 语句。 我们希望输出三列，所以 schema.yml 中的内容是： version: 2 models: - name: user_watched_movies description: \"The edges between users and movies they have watched\" columns: - name: user_id description: \"user id\" tests: - not_null - name: movie_id description: \"movie id\" tests: - not_null - name: rating description: \"rating given by user to movie\" tests: - not_null 注意，这里的 tests 的表达是对数据验证、测试的约束，有了它，我可以用 dbt 轻松对数据质量进行测试、验收，比如我们要求这里的三个字段都是 not_null。 然后，我们来写 SQL 吧，user_watched_movies.sql： {{ config(materialized='table') }} /* JOIN the movieielens_ratings table with the movieielens_movies table, and removing the movie title tailing the year of release */ WITH user_watched_movies AS( SELECT moveielens_ratings.\"userId\", moveielens_ratings.\"movieId\", moveielens_ratings.rating, REGEXP_REPLACE(moveielens_movies.title, ' \\(\\d{4}\\)$', '') AS title, moveielens_movies.genres AS movielens_genres FROM moveielens_ratings JOIN moveielens_movies ON moveielens_movies.\"movieId\" = moveielens_ratings.\"movieId\" ) /* JOIN user_watched_movies table with all_movie_aliase_iso table where language is English the join condition is the movie title */ SELECT concat('u_',user_watched_movies.\"userId\") AS user_id, user_watched_movies.rating, user_watched_movies.title, all_movie_aliases_iso.\"movie_id\" AS OMDB_movie_id, user_watched_movies.movielens_genres FROM user_watched_movies JOIN all_movie_aliases_iso ON user_watched_movies.title LIKE CONCAT(all_movie_aliases_iso.name, '%') AND all_movie_aliases_iso.language_iso_639_1 = 'en' 而这个 SQL 做的事情就是绿色圆圈标注的部分： 从 moveielens_ratings 中选 user id、movie id、rating、movie title（去掉年份），存成 user_watched_movies 的中间表格 movie title 从 moveielens_movies 中 JOIN ，通过 movie_id 相同的匹配条件取得 从 user_watched_movies 中选 user id（增加前缀 u_）、rating、title、OMDB_movie_id OMDB_movie_id 从 all_movie_aliases_iso 中 JOIN，通过相似的电影姓名匹配 OMDB 电影中英文标题取得 最终的字段作为输出 小贴士：我们可以在 Postgres 的连接器中通过增加 LIMIT 快速调试自己的 SQL 语句。 然后我们可以通过 dbt 来执行、测试刚刚的规则： dbt run -m user_watched_movies 之后，我们应该就可以在 Postgres（数仓）中看到我们转换之后的一个表了。 类似的，如法炮制所有其他部分的 Transform 规则，我们就有这么多 model 了： $ tree models models \\-- movie_recommedation |-- acted_by.sql |-- directed_by.sql |-- genres.sql |-- movies.sql |-- people.sql |-- schema.yml |-- user_watched_movies.sql \\-- with_genre.sql 再对他们分别执行 transform： dbt run -m acted_by dbt run -m directed_by dbt run -m with_genre dbt run -m people dbt run -m genres dbt run -m movies ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:3","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#撰写-transform-model"},{"categories":["Nebula Graph"],"content":" 6.4 导出数据为 CSV实际上，NebulaGraph Exchange 本身就支持把很多数据源（Postgres，Clickhouse，MySQL，Hive 等等）导入 NebulaGraph，只是在这个例子中，我们处理的数据量对于 NebulaGraph 来说非常非常小（只有百万级别的边而已），使用最轻量级的 Nebula-Importer 就足够了。而 Nebula-Importer 能消费的数据只有 CSV 文件，所以我们把刚才的表都输出为文件。 首先，我们进入 postgres 的 console，执行 COPY 命令 参考 Postgres 文档：https://www.postgresql.org/docs/current/sql-copy.html COPY acted_by TO '/tmp/acted_by.csv' WITH DELIMITER ',' CSV HEADER; COPY directed_by TO '/tmp/directed_by.csv' WITH DELIMITER ',' CSV HEADER; COPY with_genre TO '/tmp/with_genre.csv' WITH DELIMITER ',' CSV HEADER; COPY people TO '/tmp/people.csv' WITH DELIMITER ',' CSV HEADER; COPY movies TO '/tmp/movies.csv' WITH DELIMITER ',' CSV HEADER; COPY genres TO '/tmp/genres.csv' WITH DELIMITER ',' CSV HEADER; -- 对于 user_watched_movies 我们不输出表头，因为这个文件中记录了两种点、一种边，没法让 importer 通过约定好的表头自动导入，只能通过无表头的情况下指定第几列对应什么字段 COPY user_watched_movies TO '/tmp/user_watched_movies.csv' WITH DELIMITER ',' CSV; 然后把 postgres 容器里的文件导入到 to_nebulagraph 这个文件夹里： mkdir -p to_nebulagraph docker cp postgres:/tmp/. to_nebulagraph/ ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:4","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#导出数据为-csv"},{"categories":["Nebula Graph"],"content":" 6.5 导入 NebulaGraph 6.5.1 创建 NebulaGraph 集群我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset curl -fsSL nebula-up.siwei.io/install.sh | bash 6.5.2 创建 Schema首先，我们创建一个叫做 moviegraph 的图空间，针对前边的建模，创建点边类型的结构（Schema）： 先进入 NebulaGraph 的 console： ~/.nebula-up/console.sh 然后执行如下 DDL（Data Definiation Language）： CREATE SPACE moviegraph(partition_num=10,replica_factor=1,vid_type=fixed_string(32)); :sleep 20 USE moviegraph; CREATE TAG person(name string, birthdate string); CREATE TAG movie(name string); CREATE TAG genre(name string); CREATE TAG user(user_id string); CREATE EDGE acted_by(); CREATE EDGE directed_by(); CREATE EDGE with_genre(); CREATE EDGE watched(rate float); exit 6.5.3 创建 Nebula-Importer 配置文件这个文件是一个描述 CSV 文件和集群中点边数据对应关系的 YAML 文件。详细的格式可以参考文档：https://docs.nebula-graph.com.cn/master/nebula-importer/use-importer/，或者视频教程：https://www.bilibili.com/video/BV1ny4y1u7i4 。 最终的配置文件我已经问大家写好了，在 https://github.com/wey-gu/movie-recommendation-dataset/blob/main/nebula-importer.yaml 可以下载得到。 这里，我们就直接下载我写好了的配置文件，注意，这个文件不应该是 dbt 项目文件的一部分，所以我们退出目录，向上一层，把它放到 dbt_proeject 外边： cd .. wget https://raw.githubusercontent.com/wey-gu/movie-recommendation-dataset/main/nebula-importer.yaml 6.5.4 开始导入这一步，我们用容器化的 nebula-importer，避免了安装的步骤： docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 很快，所有的数据就导入到 NebulaGraph 之中了，然后我们可以通过 Nebula-Console，执行一些查询看看结果： 进入 console ~/.nebula-up/console.sh 进入图空间、执行 SHOW STATS USE moviegraph; SHOW STATS; 结果： (root@nebula) [moviegraph]\u003e SHOW STATS; +---------+---------------+---------+ | Type | Name | Count | +---------+---------------+---------+ | \"Tag\" | \"genre\" | 14397 | | \"Tag\" | \"movie\" | 20701 | | \"Tag\" | \"person\" | 263907 | | \"Tag\" | \"user\" | 610 | | \"Edge\" | \"acted_by\" | 673763 | | \"Edge\" | \"directed_by\" | 101949 | | \"Edge\" | \"watched\" | 31781 | | \"Edge\" | \"with_genre\" | 194009 | | \"Space\" | \"vertices\" | 299615 | | \"Space\" | \"edges\" | 1001502 | +---------+---------------+---------+ Got 10 rows (time spent 1693/15136 us) 通过 Nebula-Studio，我们也可以在可视化界面探索这个图谱，比如在其中执行这个查询，看一下给用户 u_124 推荐电影 1891 的理由可能是什么？ FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 他的结果是：曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 我在另一篇文章中给大家用同一个图谱展示了更多图数据库、图算法在推荐系统上的应用，如果大家感兴趣，欢迎阅读：https://www.siwei.io/recommendation-system-with-graphdb/ 。 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:5","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#导入-nebulagraph"},{"categories":["Nebula Graph"],"content":" 6.5 导入 NebulaGraph 6.5.1 创建 NebulaGraph 集群我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset curl -fsSL nebula-up.siwei.io/install.sh | bash 6.5.2 创建 Schema首先，我们创建一个叫做 moviegraph 的图空间，针对前边的建模，创建点边类型的结构（Schema）： 先进入 NebulaGraph 的 console： ~/.nebula-up/console.sh 然后执行如下 DDL（Data Definiation Language）： CREATE SPACE moviegraph(partition_num=10,replica_factor=1,vid_type=fixed_string(32)); :sleep 20 USE moviegraph; CREATE TAG person(name string, birthdate string); CREATE TAG movie(name string); CREATE TAG genre(name string); CREATE TAG user(user_id string); CREATE EDGE acted_by(); CREATE EDGE directed_by(); CREATE EDGE with_genre(); CREATE EDGE watched(rate float); exit 6.5.3 创建 Nebula-Importer 配置文件这个文件是一个描述 CSV 文件和集群中点边数据对应关系的 YAML 文件。详细的格式可以参考文档：https://docs.nebula-graph.com.cn/master/nebula-importer/use-importer/，或者视频教程：https://www.bilibili.com/video/BV1ny4y1u7i4 。 最终的配置文件我已经问大家写好了，在 https://github.com/wey-gu/movie-recommendation-dataset/blob/main/nebula-importer.yaml 可以下载得到。 这里，我们就直接下载我写好了的配置文件，注意，这个文件不应该是 dbt 项目文件的一部分，所以我们退出目录，向上一层，把它放到 dbt_proeject 外边： cd .. wget https://raw.githubusercontent.com/wey-gu/movie-recommendation-dataset/main/nebula-importer.yaml 6.5.4 开始导入这一步，我们用容器化的 nebula-importer，避免了安装的步骤： docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 很快，所有的数据就导入到 NebulaGraph 之中了，然后我们可以通过 Nebula-Console，执行一些查询看看结果： 进入 console ~/.nebula-up/console.sh 进入图空间、执行 SHOW STATS USE moviegraph; SHOW STATS; 结果： (root@nebula) [moviegraph]\u003e SHOW STATS; +---------+---------------+---------+ | Type | Name | Count | +---------+---------------+---------+ | \"Tag\" | \"genre\" | 14397 | | \"Tag\" | \"movie\" | 20701 | | \"Tag\" | \"person\" | 263907 | | \"Tag\" | \"user\" | 610 | | \"Edge\" | \"acted_by\" | 673763 | | \"Edge\" | \"directed_by\" | 101949 | | \"Edge\" | \"watched\" | 31781 | | \"Edge\" | \"with_genre\" | 194009 | | \"Space\" | \"vertices\" | 299615 | | \"Space\" | \"edges\" | 1001502 | +---------+---------------+---------+ Got 10 rows (time spent 1693/15136 us) 通过 Nebula-Studio，我们也可以在可视化界面探索这个图谱，比如在其中执行这个查询，看一下给用户 u_124 推荐电影 1891 的理由可能是什么？ FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 他的结果是：曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 我在另一篇文章中给大家用同一个图谱展示了更多图数据库、图算法在推荐系统上的应用，如果大家感兴趣，欢迎阅读：https://www.siwei.io/recommendation-system-with-graphdb/ 。 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:5","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#创建-nebulagraph-集群"},{"categories":["Nebula Graph"],"content":" 6.5 导入 NebulaGraph 6.5.1 创建 NebulaGraph 集群我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset curl -fsSL nebula-up.siwei.io/install.sh | bash 6.5.2 创建 Schema首先，我们创建一个叫做 moviegraph 的图空间，针对前边的建模，创建点边类型的结构（Schema）： 先进入 NebulaGraph 的 console： ~/.nebula-up/console.sh 然后执行如下 DDL（Data Definiation Language）： CREATE SPACE moviegraph(partition_num=10,replica_factor=1,vid_type=fixed_string(32)); :sleep 20 USE moviegraph; CREATE TAG person(name string, birthdate string); CREATE TAG movie(name string); CREATE TAG genre(name string); CREATE TAG user(user_id string); CREATE EDGE acted_by(); CREATE EDGE directed_by(); CREATE EDGE with_genre(); CREATE EDGE watched(rate float); exit 6.5.3 创建 Nebula-Importer 配置文件这个文件是一个描述 CSV 文件和集群中点边数据对应关系的 YAML 文件。详细的格式可以参考文档：https://docs.nebula-graph.com.cn/master/nebula-importer/use-importer/，或者视频教程：https://www.bilibili.com/video/BV1ny4y1u7i4 。 最终的配置文件我已经问大家写好了，在 https://github.com/wey-gu/movie-recommendation-dataset/blob/main/nebula-importer.yaml 可以下载得到。 这里，我们就直接下载我写好了的配置文件，注意，这个文件不应该是 dbt 项目文件的一部分，所以我们退出目录，向上一层，把它放到 dbt_proeject 外边： cd .. wget https://raw.githubusercontent.com/wey-gu/movie-recommendation-dataset/main/nebula-importer.yaml 6.5.4 开始导入这一步，我们用容器化的 nebula-importer，避免了安装的步骤： docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 很快，所有的数据就导入到 NebulaGraph 之中了，然后我们可以通过 Nebula-Console，执行一些查询看看结果： 进入 console ~/.nebula-up/console.sh 进入图空间、执行 SHOW STATS USE moviegraph; SHOW STATS; 结果： (root@nebula) [moviegraph]\u003e SHOW STATS; +---------+---------------+---------+ | Type | Name | Count | +---------+---------------+---------+ | \"Tag\" | \"genre\" | 14397 | | \"Tag\" | \"movie\" | 20701 | | \"Tag\" | \"person\" | 263907 | | \"Tag\" | \"user\" | 610 | | \"Edge\" | \"acted_by\" | 673763 | | \"Edge\" | \"directed_by\" | 101949 | | \"Edge\" | \"watched\" | 31781 | | \"Edge\" | \"with_genre\" | 194009 | | \"Space\" | \"vertices\" | 299615 | | \"Space\" | \"edges\" | 1001502 | +---------+---------------+---------+ Got 10 rows (time spent 1693/15136 us) 通过 Nebula-Studio，我们也可以在可视化界面探索这个图谱，比如在其中执行这个查询，看一下给用户 u_124 推荐电影 1891 的理由可能是什么？ FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 他的结果是：曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 我在另一篇文章中给大家用同一个图谱展示了更多图数据库、图算法在推荐系统上的应用，如果大家感兴趣，欢迎阅读：https://www.siwei.io/recommendation-system-with-graphdb/ 。 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:5","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#创建-schema"},{"categories":["Nebula Graph"],"content":" 6.5 导入 NebulaGraph 6.5.1 创建 NebulaGraph 集群我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset curl -fsSL nebula-up.siwei.io/install.sh | bash 6.5.2 创建 Schema首先，我们创建一个叫做 moviegraph 的图空间，针对前边的建模，创建点边类型的结构（Schema）： 先进入 NebulaGraph 的 console： ~/.nebula-up/console.sh 然后执行如下 DDL（Data Definiation Language）： CREATE SPACE moviegraph(partition_num=10,replica_factor=1,vid_type=fixed_string(32)); :sleep 20 USE moviegraph; CREATE TAG person(name string, birthdate string); CREATE TAG movie(name string); CREATE TAG genre(name string); CREATE TAG user(user_id string); CREATE EDGE acted_by(); CREATE EDGE directed_by(); CREATE EDGE with_genre(); CREATE EDGE watched(rate float); exit 6.5.3 创建 Nebula-Importer 配置文件这个文件是一个描述 CSV 文件和集群中点边数据对应关系的 YAML 文件。详细的格式可以参考文档：https://docs.nebula-graph.com.cn/master/nebula-importer/use-importer/，或者视频教程：https://www.bilibili.com/video/BV1ny4y1u7i4 。 最终的配置文件我已经问大家写好了，在 https://github.com/wey-gu/movie-recommendation-dataset/blob/main/nebula-importer.yaml 可以下载得到。 这里，我们就直接下载我写好了的配置文件，注意，这个文件不应该是 dbt 项目文件的一部分，所以我们退出目录，向上一层，把它放到 dbt_proeject 外边： cd .. wget https://raw.githubusercontent.com/wey-gu/movie-recommendation-dataset/main/nebula-importer.yaml 6.5.4 开始导入这一步，我们用容器化的 nebula-importer，避免了安装的步骤： docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 很快，所有的数据就导入到 NebulaGraph 之中了，然后我们可以通过 Nebula-Console，执行一些查询看看结果： 进入 console ~/.nebula-up/console.sh 进入图空间、执行 SHOW STATS USE moviegraph; SHOW STATS; 结果： (root@nebula) [moviegraph]\u003e SHOW STATS; +---------+---------------+---------+ | Type | Name | Count | +---------+---------------+---------+ | \"Tag\" | \"genre\" | 14397 | | \"Tag\" | \"movie\" | 20701 | | \"Tag\" | \"person\" | 263907 | | \"Tag\" | \"user\" | 610 | | \"Edge\" | \"acted_by\" | 673763 | | \"Edge\" | \"directed_by\" | 101949 | | \"Edge\" | \"watched\" | 31781 | | \"Edge\" | \"with_genre\" | 194009 | | \"Space\" | \"vertices\" | 299615 | | \"Space\" | \"edges\" | 1001502 | +---------+---------------+---------+ Got 10 rows (time spent 1693/15136 us) 通过 Nebula-Studio，我们也可以在可视化界面探索这个图谱，比如在其中执行这个查询，看一下给用户 u_124 推荐电影 1891 的理由可能是什么？ FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 他的结果是：曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 我在另一篇文章中给大家用同一个图谱展示了更多图数据库、图算法在推荐系统上的应用，如果大家感兴趣，欢迎阅读：https://www.siwei.io/recommendation-system-with-graphdb/ 。 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:5","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#创建-nebula-importer-配置文件"},{"categories":["Nebula Graph"],"content":" 6.5 导入 NebulaGraph 6.5.1 创建 NebulaGraph 集群我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset curl -fsSL nebula-up.siwei.io/install.sh | bash 6.5.2 创建 Schema首先，我们创建一个叫做 moviegraph 的图空间，针对前边的建模，创建点边类型的结构（Schema）： 先进入 NebulaGraph 的 console： ~/.nebula-up/console.sh 然后执行如下 DDL（Data Definiation Language）： CREATE SPACE moviegraph(partition_num=10,replica_factor=1,vid_type=fixed_string(32)); :sleep 20 USE moviegraph; CREATE TAG person(name string, birthdate string); CREATE TAG movie(name string); CREATE TAG genre(name string); CREATE TAG user(user_id string); CREATE EDGE acted_by(); CREATE EDGE directed_by(); CREATE EDGE with_genre(); CREATE EDGE watched(rate float); exit 6.5.3 创建 Nebula-Importer 配置文件这个文件是一个描述 CSV 文件和集群中点边数据对应关系的 YAML 文件。详细的格式可以参考文档：https://docs.nebula-graph.com.cn/master/nebula-importer/use-importer/，或者视频教程：https://www.bilibili.com/video/BV1ny4y1u7i4 。 最终的配置文件我已经问大家写好了，在 https://github.com/wey-gu/movie-recommendation-dataset/blob/main/nebula-importer.yaml 可以下载得到。 这里，我们就直接下载我写好了的配置文件，注意，这个文件不应该是 dbt 项目文件的一部分，所以我们退出目录，向上一层，把它放到 dbt_proeject 外边： cd .. wget https://raw.githubusercontent.com/wey-gu/movie-recommendation-dataset/main/nebula-importer.yaml 6.5.4 开始导入这一步，我们用容器化的 nebula-importer，避免了安装的步骤： docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 很快，所有的数据就导入到 NebulaGraph 之中了，然后我们可以通过 Nebula-Console，执行一些查询看看结果： 进入 console ~/.nebula-up/console.sh 进入图空间、执行 SHOW STATS USE moviegraph; SHOW STATS; 结果： (root@nebula) [moviegraph]\u003e SHOW STATS; +---------+---------------+---------+ | Type | Name | Count | +---------+---------------+---------+ | \"Tag\" | \"genre\" | 14397 | | \"Tag\" | \"movie\" | 20701 | | \"Tag\" | \"person\" | 263907 | | \"Tag\" | \"user\" | 610 | | \"Edge\" | \"acted_by\" | 673763 | | \"Edge\" | \"directed_by\" | 101949 | | \"Edge\" | \"watched\" | 31781 | | \"Edge\" | \"with_genre\" | 194009 | | \"Space\" | \"vertices\" | 299615 | | \"Space\" | \"edges\" | 1001502 | +---------+---------------+---------+ Got 10 rows (time spent 1693/15136 us) 通过 Nebula-Studio，我们也可以在可视化界面探索这个图谱，比如在其中执行这个查询，看一下给用户 u_124 推荐电影 1891 的理由可能是什么？ FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 他的结果是：曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 我在另一篇文章中给大家用同一个图谱展示了更多图数据库、图算法在推荐系统上的应用，如果大家感兴趣，欢迎阅读：https://www.siwei.io/recommendation-system-with-graphdb/ 。 ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:6:5","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#开始导入"},{"categories":["Nebula Graph"],"content":" 7 总结当我们打算把海量数据利用图数据库的能力进行知识转化、洞察分析的时候，往往第一步就是要做多数据源到图数据的转换、处理、建模。对于在无从下手的新手们来说，一个可行的思路是从所有的相关信息出发，去设想最关注的关联关系，把边写出来，然后再罗列可以取得的点、以及需要的点、边上的属性。确定了初始的建模之后，就可以利用 ETL 工具把原始的数据清洗、ETL 成点、边类型的表结构，最后，利用导入工具导入 NebulaGraph。 借助于 dbt，我们可以版本控制、测试、迭代我们的建模与数据转换，一点点进化、丰富构建的知识图谱。 题图版权：Claudio ","date":"2022-11-10","objectID":"/nebulagraph-etl-dbt/:7:0","series":null,"tags":["Nebula Graph","etl","dbt","图建模","MovieLens","OMDB"],"title":"利用 dbt，基于表结构的 Nebulagraph 图建模与 ETL","uri":"/nebulagraph-etl-dbt/#总结"},{"categories":["Nebula Graph"],"content":"本文是一个基于 NebulaGraph 上图算法、图数据库、机器学习、GNN 的推荐系统方法综述，大部分介绍的方法提供了 Playground 供大家学习。","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/"},{"categories":["Nebula Graph"],"content":" 1 基于图数据库的推荐系统 本文是一个基于 NebulaGraph 上图算法、图数据库、机器学习、GNN 的推荐系统方法综述，大部分介绍的方法提供了 Playground 供大家学习。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:0","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于图数据库的推荐系统"},{"categories":["Nebula Graph"],"content":" 1.1 基本概念推荐系统诞生的初衷是解决互联网时代才面临的信息量过载问题，从最初的 Amazon 图书推荐、商品推荐，到电影、音乐、视频、新闻推荐，如今大多数网站、App 中都有至少一个基于推荐系统生成的供用户选择的物品列表界面。而这些物品的推荐基本都是基于用户喜好、物品的特征、用户与物品交互历史和其他相关上下文去做的。 一个推荐系统会包含以下几个部分： 数据、特征的处理 从特征出发，生成推荐列表 过滤、排序推荐列表 这其中，过滤的核心方法主要有两种：基于内容的过滤（Content-Based Filtering）、与协同过滤（Collaborative Filtering）。 1.1.1 基于内容的过滤内容过滤方法的本质是给用户的偏好做画像，同时对所有待推荐的物品计算特征，做用户的画像与待推荐物品特征之间的距离运算，过滤得到相近的物品。 ref: https://www.ise.bgu.ac.il/faculty/liorr/recsyshb/chContent.pdf 内容过滤的方法的好处有： 清晰的可解释性，无论是对用户的画像分析，还是对物品的运算本身天然带来了排序、过滤的可解释性 用户数据输入的独立性，对给定的待推荐用户来说，只需要单独分析他们的画像和历史评分就足够了 规避新物品冷启动问题，对于新的添加的物品，即使没有任何历史的用户评价，也可以做出推荐 同时，基于内容过滤的挑战与劣势也有： 特征提取，提取待推荐物品的特征并非总是很容易地，比如照片、视频等非纯文本的物品，而且往往这些物品的特征提取依赖领域专家知识，比如电影推荐系统中需要抽离出导演、电影分类等领域知识作为特征 不擅长突破舒适圈，发掘用户的潜在新兴趣点 存在新用户冷启动问题，对少有信息作为用户画像的用户来说，缺少做进一步物品画像、特种距离运算的输入 1.1.2 基于协同过滤协同过滤方法本质是协同用户与系统之间的交互行为去给出推荐物品。 协同过滤的方法又分为基于记忆（memory-based）的与基于模型（model-based）的。 前者主要有物品与物品之间的协同过滤（ItemCF）和用户与用户之间的协同过滤（UserCF），ItemCF 简单来说是推荐和用户之前选择过的物品类似的物品：根据行为找物品之间的相似性，UserCF 则推荐与之有共同爱好的用户喜欢的物品：根据行为找用户之间的相似性； 而后者基于展现用户喜好的历史实践信息、利用统计与机器学习方法训练模型，对新的用户偏好进行推理。 协同过滤的方法的好处有： 无需对非结构化物品进行特征分析，因为协同过滤关注的是用户和物品之间的协同交互，这绕过了对物品领域知识处理的需求 对用户的个性化更强，更细，基于行为的分析使得对用户偏好的划分本质上是连续的（相比来说，对用户做画像的方法则是离散的），这样的推荐结果会更加“千人千面”，同时，也会蕴含内容过滤、有限的画像角度之下的“惊喜”推荐 而它的缺点有： 有新用户和新物件上的冷启动问题，因为它们身上都缺少历史喜好行为的信息 ref: https://coek.info/pdf-a-dynamic-collaborative-filtering-system-via-a-weighted-clustering-approach-.html 从以上两种主要的过滤方式的优劣中我们可以看到，它们之中存在互补的地方，比如新物件的冷启动上，基于内容的过滤有优势，对于个性化、惊喜推荐角度，协同过滤有优势。所以，在真实世界中，推荐系统在大多演化地比上边的归类复杂得多，而且常常是多种方法的融合。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:1","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基本概念"},{"categories":["Nebula Graph"],"content":" 1.1 基本概念推荐系统诞生的初衷是解决互联网时代才面临的信息量过载问题，从最初的 Amazon 图书推荐、商品推荐，到电影、音乐、视频、新闻推荐，如今大多数网站、App 中都有至少一个基于推荐系统生成的供用户选择的物品列表界面。而这些物品的推荐基本都是基于用户喜好、物品的特征、用户与物品交互历史和其他相关上下文去做的。 一个推荐系统会包含以下几个部分： 数据、特征的处理 从特征出发，生成推荐列表 过滤、排序推荐列表 这其中，过滤的核心方法主要有两种：基于内容的过滤（Content-Based Filtering）、与协同过滤（Collaborative Filtering）。 1.1.1 基于内容的过滤内容过滤方法的本质是给用户的偏好做画像，同时对所有待推荐的物品计算特征，做用户的画像与待推荐物品特征之间的距离运算，过滤得到相近的物品。 ref: https://www.ise.bgu.ac.il/faculty/liorr/recsyshb/chContent.pdf 内容过滤的方法的好处有： 清晰的可解释性，无论是对用户的画像分析，还是对物品的运算本身天然带来了排序、过滤的可解释性 用户数据输入的独立性，对给定的待推荐用户来说，只需要单独分析他们的画像和历史评分就足够了 规避新物品冷启动问题，对于新的添加的物品，即使没有任何历史的用户评价，也可以做出推荐 同时，基于内容过滤的挑战与劣势也有： 特征提取，提取待推荐物品的特征并非总是很容易地，比如照片、视频等非纯文本的物品，而且往往这些物品的特征提取依赖领域专家知识，比如电影推荐系统中需要抽离出导演、电影分类等领域知识作为特征 不擅长突破舒适圈，发掘用户的潜在新兴趣点 存在新用户冷启动问题，对少有信息作为用户画像的用户来说，缺少做进一步物品画像、特种距离运算的输入 1.1.2 基于协同过滤协同过滤方法本质是协同用户与系统之间的交互行为去给出推荐物品。 协同过滤的方法又分为基于记忆（memory-based）的与基于模型（model-based）的。 前者主要有物品与物品之间的协同过滤（ItemCF）和用户与用户之间的协同过滤（UserCF），ItemCF 简单来说是推荐和用户之前选择过的物品类似的物品：根据行为找物品之间的相似性，UserCF 则推荐与之有共同爱好的用户喜欢的物品：根据行为找用户之间的相似性； 而后者基于展现用户喜好的历史实践信息、利用统计与机器学习方法训练模型，对新的用户偏好进行推理。 协同过滤的方法的好处有： 无需对非结构化物品进行特征分析，因为协同过滤关注的是用户和物品之间的协同交互，这绕过了对物品领域知识处理的需求 对用户的个性化更强，更细，基于行为的分析使得对用户偏好的划分本质上是连续的（相比来说，对用户做画像的方法则是离散的），这样的推荐结果会更加“千人千面”，同时，也会蕴含内容过滤、有限的画像角度之下的“惊喜”推荐 而它的缺点有： 有新用户和新物件上的冷启动问题，因为它们身上都缺少历史喜好行为的信息 ref: https://coek.info/pdf-a-dynamic-collaborative-filtering-system-via-a-weighted-clustering-approach-.html 从以上两种主要的过滤方式的优劣中我们可以看到，它们之中存在互补的地方，比如新物件的冷启动上，基于内容的过滤有优势，对于个性化、惊喜推荐角度，协同过滤有优势。所以，在真实世界中，推荐系统在大多演化地比上边的归类复杂得多，而且常常是多种方法的融合。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:1","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于内容的过滤"},{"categories":["Nebula Graph"],"content":" 1.1 基本概念推荐系统诞生的初衷是解决互联网时代才面临的信息量过载问题，从最初的 Amazon 图书推荐、商品推荐，到电影、音乐、视频、新闻推荐，如今大多数网站、App 中都有至少一个基于推荐系统生成的供用户选择的物品列表界面。而这些物品的推荐基本都是基于用户喜好、物品的特征、用户与物品交互历史和其他相关上下文去做的。 一个推荐系统会包含以下几个部分： 数据、特征的处理 从特征出发，生成推荐列表 过滤、排序推荐列表 这其中，过滤的核心方法主要有两种：基于内容的过滤（Content-Based Filtering）、与协同过滤（Collaborative Filtering）。 1.1.1 基于内容的过滤内容过滤方法的本质是给用户的偏好做画像，同时对所有待推荐的物品计算特征，做用户的画像与待推荐物品特征之间的距离运算，过滤得到相近的物品。 ref: https://www.ise.bgu.ac.il/faculty/liorr/recsyshb/chContent.pdf 内容过滤的方法的好处有： 清晰的可解释性，无论是对用户的画像分析，还是对物品的运算本身天然带来了排序、过滤的可解释性 用户数据输入的独立性，对给定的待推荐用户来说，只需要单独分析他们的画像和历史评分就足够了 规避新物品冷启动问题，对于新的添加的物品，即使没有任何历史的用户评价，也可以做出推荐 同时，基于内容过滤的挑战与劣势也有： 特征提取，提取待推荐物品的特征并非总是很容易地，比如照片、视频等非纯文本的物品，而且往往这些物品的特征提取依赖领域专家知识，比如电影推荐系统中需要抽离出导演、电影分类等领域知识作为特征 不擅长突破舒适圈，发掘用户的潜在新兴趣点 存在新用户冷启动问题，对少有信息作为用户画像的用户来说，缺少做进一步物品画像、特种距离运算的输入 1.1.2 基于协同过滤协同过滤方法本质是协同用户与系统之间的交互行为去给出推荐物品。 协同过滤的方法又分为基于记忆（memory-based）的与基于模型（model-based）的。 前者主要有物品与物品之间的协同过滤（ItemCF）和用户与用户之间的协同过滤（UserCF），ItemCF 简单来说是推荐和用户之前选择过的物品类似的物品：根据行为找物品之间的相似性，UserCF 则推荐与之有共同爱好的用户喜欢的物品：根据行为找用户之间的相似性； 而后者基于展现用户喜好的历史实践信息、利用统计与机器学习方法训练模型，对新的用户偏好进行推理。 协同过滤的方法的好处有： 无需对非结构化物品进行特征分析，因为协同过滤关注的是用户和物品之间的协同交互，这绕过了对物品领域知识处理的需求 对用户的个性化更强，更细，基于行为的分析使得对用户偏好的划分本质上是连续的（相比来说，对用户做画像的方法则是离散的），这样的推荐结果会更加“千人千面”，同时，也会蕴含内容过滤、有限的画像角度之下的“惊喜”推荐 而它的缺点有： 有新用户和新物件上的冷启动问题，因为它们身上都缺少历史喜好行为的信息 ref: https://coek.info/pdf-a-dynamic-collaborative-filtering-system-via-a-weighted-clustering-approach-.html 从以上两种主要的过滤方式的优劣中我们可以看到，它们之中存在互补的地方，比如新物件的冷启动上，基于内容的过滤有优势，对于个性化、惊喜推荐角度，协同过滤有优势。所以，在真实世界中，推荐系统在大多演化地比上边的归类复杂得多，而且常常是多种方法的融合。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:1","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于协同过滤"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于图的个性推荐"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#建立图谱"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于内容的过滤-1"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#jaccard-index"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#cbf-方法在-nebulagraph-中的实现"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#可视化分析"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于记忆的协同过滤"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#itemcf"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#可视化分析-itemcf"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#关于高评分"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#pearson-correlation-coefficient"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#usercf"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#可视化分析-usercf"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#混合的方法"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于模型的方法"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#gnn--图数据库的推荐系统"},{"categories":["Nebula Graph"],"content":" 1.3 推荐系统可解释性在结束本章之前，再举一个图数据库在推荐系统中的典型应用：推荐理由。 下图是美团、大众点评中的一个常见的搜索、推荐结果，现代推荐系统的复杂度是非常大的，一方面由很多方法自身的特性决定，另一方面最终的推荐可能是多个系统协同获得最终结果排名，这使得我们很难对推荐结果进行解释。 得益于被推荐用户和物件、以及他们的各种各样画像最终形成的知识图谱，我们只需要在图谱中对推荐结果进行“路径查找”就可以获得很有意义的解释，像是如下截图的“在北京喜欢北京菜的山东老乡都说这家店很赞”就是这样获得的解释。 图片来源：https://tech.meituan.com/2021/04/01/nebula-graph-practice-in-meituan.html 1.3.1 可解释性的例子咱们回到电影推荐的图谱上，我们在前边的算法中曾经获得过用户 u_124 的推荐电影 1891（星球大战：），那么我们可以通过这一个查询获得它的推荐解释： FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 我们可以很快获得 20 条路径： (root@nebula) [moviegraph]\u003e FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 +-----------------------------------------------------------------------------------------------------+ | p | +-----------------------------------------------------------------------------------------------------+ | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_49\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_17\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_10281\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_4\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_3\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_24342\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_2\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"832\")-[:with_genre@0 {}]-\u003e(\"g_1110\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_1110\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_13463\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_12248\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"47981\")-[:with_genre@0 {}]-\u003e(\"g_10219\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_6\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"497\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"120880\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_130\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"497\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11635\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | +-----------------------------------------------------------------------------------------------------+ Got 20 rows (time spent 267151/278139 us) Wed, 09 Nov 2022 19:05:56 CST 我们在结果可视化中可以很容易看出这个推荐的结果可以是： 曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:3","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#推荐系统可解释性"},{"categories":["Nebula Graph"],"content":" 1.3 推荐系统可解释性在结束本章之前，再举一个图数据库在推荐系统中的典型应用：推荐理由。 下图是美团、大众点评中的一个常见的搜索、推荐结果，现代推荐系统的复杂度是非常大的，一方面由很多方法自身的特性决定，另一方面最终的推荐可能是多个系统协同获得最终结果排名，这使得我们很难对推荐结果进行解释。 得益于被推荐用户和物件、以及他们的各种各样画像最终形成的知识图谱，我们只需要在图谱中对推荐结果进行“路径查找”就可以获得很有意义的解释，像是如下截图的“在北京喜欢北京菜的山东老乡都说这家店很赞”就是这样获得的解释。 图片来源：https://tech.meituan.com/2021/04/01/nebula-graph-practice-in-meituan.html 1.3.1 可解释性的例子咱们回到电影推荐的图谱上，我们在前边的算法中曾经获得过用户 u_124 的推荐电影 1891（星球大战：），那么我们可以通过这一个查询获得它的推荐解释： FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 我们可以很快获得 20 条路径： (root@nebula) [moviegraph]\u003e FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 +-----------------------------------------------------------------------------------------------------+ | p | +-----------------------------------------------------------------------------------------------------+ | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_49\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_17\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_10281\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_4\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_3\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_24342\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_2\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"832\")-[:with_genre@0 {}]-\u003e(\"g_1110\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_1110\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_13463\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_12248\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"47981\")-[:with_genre@0 {}]-\u003e(\"g_10219\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_6\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"497\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"120880\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_130\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"497\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11635\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | +-----------------------------------------------------------------------------------------------------+ Got 20 rows (time spent 267151/278139 us) Wed, 09 Nov 2022 19:05:56 CST 我们在结果可视化中可以很容易看出这个推荐的结果可以是： 曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:3","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#可解释性的例子"},{"categories":["Nebula Graph"],"content":" 1.4 总结现在，我们知道图数据库作为推荐系统中信息的最终形式：知识存在，可以适用在不同类型方法上，尽管很多方法中，图库不一定是最终落地系统方案的最流行选择，图数据库所带来的可视化洞察的潜力还是非常大的。 同时，构建的综合知识图谱上的解释、推理能力与一些实时要求高的图方法中（比如 GNN的基于模型方法），能起到带来独一无二的作用。 题图版权：charlesdeluvio ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:4","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#总结"},{"categories":["Nebula Graph"],"content":"本文是一个快速了解为 NebulaGraph 内核贡献代码、构建、Debug 的一站式指南。","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/"},{"categories":["Nebula Graph"],"content":" 如何 build NebulaGraph？如何为 NebulaGraph 内核做贡献？从本章作为切入点就够了。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:0:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#"},{"categories":["Nebula Graph"],"content":" 1 NebulaGraph 的架构简介为了方便对 NebulaGraph 尚未了解的读者也能快速直接从贡献代码为起点了解它，我把开发、贡献内核代码入手所需要的基本架构知识也在这里以最小信息量的形式总结一下，作为前导知识，请资深的 NebulaGraph 玩家直接跳过这一章节。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#nebulagraph-的架构简介"},{"categories":["Nebula Graph"],"content":" 1.1 服务、进程NebulaGraph 的架构和 Google Spanner，TiDB 很相似，核心部分只有三种服务、进程：Graph 服务、Meta 服务和 Storage 服务。它们之间彼此通过 TCP 之上的 Thrift RPC 协议进行通信。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#服务进程"},{"categories":["Nebula Graph"],"content":" 1.2 计算层与存储层NebulaGraph 是存储与计算分离的架构，它的 Meta 服务和 Storage 服务共同组成了存储层，Graph 服务是内核提供的计算层。 这样的设计使得 NebulaGraph 的集群部署可以灵活按需分配计算、存储的资源，比如我们可以为同一个集群中创建不同配置的两组 Graph 服务实例、用来面向不同类型的业务。 同时，计算层解耦于存储层使得在 NebulaGraph 之上的构建不同的特定计算层成为可能，比如 NebulaGraph Algorithm、NebulaGraph Analytics 就是在 NebulaGraph 之上构建了异构的另一个计算层，如果需要，任何人也可以定制自己的专属计算层，从而满足统一图基础存储之上的复合、多样的计算需求。 1.2.1 Graph Service: nebula-graphdGraph 服务是对外接受图库登录、图查询请求、集群管理操作、schema 定义所直接连接的服务，他的进程名字叫 graphd，表示 nebula graph daemon。 Graph 服务的每一个进程是无状态的，这使得横向扩缩 Graph 服务的实例非常灵活、简单。 Graph 服务也叫 Query Engine，其内部和传统的数据库系统的设计非常相似，分为：解析、校验、计划、执行几部分。 1.2.2 Meta Service: nebula-metadMeta 服务顾名思义负责元数据管理，进程名字叫 metad。这些元数据包括： 所有的图空间、Schema 定义 用户鉴权、授权信息 集群服务的发现与服务的分布 图空间中的数据分布 Meta 服务的进程可以单实例部署，在非单机部署的场景下，为了数据、服务的高 SLA ，我们可以奇数多个实例的部署，通常来说 3 个 nebula-metad 就足够了，三个 nebula-metad 通过 RAFT 共识协议构成一个集群提供服务。 1.2.3 Storage Service: nebula-storagedStorage 服务存储所有的图数据，进程名字叫 storaged。storaged 分布式地存储图数据，为 Graph 内部的图查询执行期提供底层的图语义存储接口，方便 Storage 客户端通过 Thrift RPC 协议面向涉及的 storaged 示例进行图语义的读写。 当 NebulaGraph 中图空间的副本数大于 1 的时候，每一个分区都会在不同 storaged 示例上有副本，副本之间则通过 RAFT 协议协调同步与读写。 参考 文档：架构介绍，了解更多详情； 推荐阅读社区官方播客的架构系列文章：nebula-graph.com.cn/tags/架构系列。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#计算层与存储层"},{"categories":["Nebula Graph"],"content":" 1.2 计算层与存储层NebulaGraph 是存储与计算分离的架构，它的 Meta 服务和 Storage 服务共同组成了存储层，Graph 服务是内核提供的计算层。 这样的设计使得 NebulaGraph 的集群部署可以灵活按需分配计算、存储的资源，比如我们可以为同一个集群中创建不同配置的两组 Graph 服务实例、用来面向不同类型的业务。 同时，计算层解耦于存储层使得在 NebulaGraph 之上的构建不同的特定计算层成为可能，比如 NebulaGraph Algorithm、NebulaGraph Analytics 就是在 NebulaGraph 之上构建了异构的另一个计算层，如果需要，任何人也可以定制自己的专属计算层，从而满足统一图基础存储之上的复合、多样的计算需求。 1.2.1 Graph Service: nebula-graphdGraph 服务是对外接受图库登录、图查询请求、集群管理操作、schema 定义所直接连接的服务，他的进程名字叫 graphd，表示 nebula graph daemon。 Graph 服务的每一个进程是无状态的，这使得横向扩缩 Graph 服务的实例非常灵活、简单。 Graph 服务也叫 Query Engine，其内部和传统的数据库系统的设计非常相似，分为：解析、校验、计划、执行几部分。 1.2.2 Meta Service: nebula-metadMeta 服务顾名思义负责元数据管理，进程名字叫 metad。这些元数据包括： 所有的图空间、Schema 定义 用户鉴权、授权信息 集群服务的发现与服务的分布 图空间中的数据分布 Meta 服务的进程可以单实例部署，在非单机部署的场景下，为了数据、服务的高 SLA ，我们可以奇数多个实例的部署，通常来说 3 个 nebula-metad 就足够了，三个 nebula-metad 通过 RAFT 共识协议构成一个集群提供服务。 1.2.3 Storage Service: nebula-storagedStorage 服务存储所有的图数据，进程名字叫 storaged。storaged 分布式地存储图数据，为 Graph 内部的图查询执行期提供底层的图语义存储接口，方便 Storage 客户端通过 Thrift RPC 协议面向涉及的 storaged 示例进行图语义的读写。 当 NebulaGraph 中图空间的副本数大于 1 的时候，每一个分区都会在不同 storaged 示例上有副本，副本之间则通过 RAFT 协议协调同步与读写。 参考 文档：架构介绍，了解更多详情； 推荐阅读社区官方播客的架构系列文章：nebula-graph.com.cn/tags/架构系列。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#graph-service-nebula-graphd"},{"categories":["Nebula Graph"],"content":" 1.2 计算层与存储层NebulaGraph 是存储与计算分离的架构，它的 Meta 服务和 Storage 服务共同组成了存储层，Graph 服务是内核提供的计算层。 这样的设计使得 NebulaGraph 的集群部署可以灵活按需分配计算、存储的资源，比如我们可以为同一个集群中创建不同配置的两组 Graph 服务实例、用来面向不同类型的业务。 同时，计算层解耦于存储层使得在 NebulaGraph 之上的构建不同的特定计算层成为可能，比如 NebulaGraph Algorithm、NebulaGraph Analytics 就是在 NebulaGraph 之上构建了异构的另一个计算层，如果需要，任何人也可以定制自己的专属计算层，从而满足统一图基础存储之上的复合、多样的计算需求。 1.2.1 Graph Service: nebula-graphdGraph 服务是对外接受图库登录、图查询请求、集群管理操作、schema 定义所直接连接的服务，他的进程名字叫 graphd，表示 nebula graph daemon。 Graph 服务的每一个进程是无状态的，这使得横向扩缩 Graph 服务的实例非常灵活、简单。 Graph 服务也叫 Query Engine，其内部和传统的数据库系统的设计非常相似，分为：解析、校验、计划、执行几部分。 1.2.2 Meta Service: nebula-metadMeta 服务顾名思义负责元数据管理，进程名字叫 metad。这些元数据包括： 所有的图空间、Schema 定义 用户鉴权、授权信息 集群服务的发现与服务的分布 图空间中的数据分布 Meta 服务的进程可以单实例部署，在非单机部署的场景下，为了数据、服务的高 SLA ，我们可以奇数多个实例的部署，通常来说 3 个 nebula-metad 就足够了，三个 nebula-metad 通过 RAFT 共识协议构成一个集群提供服务。 1.2.3 Storage Service: nebula-storagedStorage 服务存储所有的图数据，进程名字叫 storaged。storaged 分布式地存储图数据，为 Graph 内部的图查询执行期提供底层的图语义存储接口，方便 Storage 客户端通过 Thrift RPC 协议面向涉及的 storaged 示例进行图语义的读写。 当 NebulaGraph 中图空间的副本数大于 1 的时候，每一个分区都会在不同 storaged 示例上有副本，副本之间则通过 RAFT 协议协调同步与读写。 参考 文档：架构介绍，了解更多详情； 推荐阅读社区官方播客的架构系列文章：nebula-graph.com.cn/tags/架构系列。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#meta-service-nebula-metad"},{"categories":["Nebula Graph"],"content":" 1.2 计算层与存储层NebulaGraph 是存储与计算分离的架构，它的 Meta 服务和 Storage 服务共同组成了存储层，Graph 服务是内核提供的计算层。 这样的设计使得 NebulaGraph 的集群部署可以灵活按需分配计算、存储的资源，比如我们可以为同一个集群中创建不同配置的两组 Graph 服务实例、用来面向不同类型的业务。 同时，计算层解耦于存储层使得在 NebulaGraph 之上的构建不同的特定计算层成为可能，比如 NebulaGraph Algorithm、NebulaGraph Analytics 就是在 NebulaGraph 之上构建了异构的另一个计算层，如果需要，任何人也可以定制自己的专属计算层，从而满足统一图基础存储之上的复合、多样的计算需求。 1.2.1 Graph Service: nebula-graphdGraph 服务是对外接受图库登录、图查询请求、集群管理操作、schema 定义所直接连接的服务，他的进程名字叫 graphd，表示 nebula graph daemon。 Graph 服务的每一个进程是无状态的，这使得横向扩缩 Graph 服务的实例非常灵活、简单。 Graph 服务也叫 Query Engine，其内部和传统的数据库系统的设计非常相似，分为：解析、校验、计划、执行几部分。 1.2.2 Meta Service: nebula-metadMeta 服务顾名思义负责元数据管理，进程名字叫 metad。这些元数据包括： 所有的图空间、Schema 定义 用户鉴权、授权信息 集群服务的发现与服务的分布 图空间中的数据分布 Meta 服务的进程可以单实例部署，在非单机部署的场景下，为了数据、服务的高 SLA ，我们可以奇数多个实例的部署，通常来说 3 个 nebula-metad 就足够了，三个 nebula-metad 通过 RAFT 共识协议构成一个集群提供服务。 1.2.3 Storage Service: nebula-storagedStorage 服务存储所有的图数据，进程名字叫 storaged。storaged 分布式地存储图数据，为 Graph 内部的图查询执行期提供底层的图语义存储接口，方便 Storage 客户端通过 Thrift RPC 协议面向涉及的 storaged 示例进行图语义的读写。 当 NebulaGraph 中图空间的副本数大于 1 的时候，每一个分区都会在不同 storaged 示例上有副本，副本之间则通过 RAFT 协议协调同步与读写。 参考 文档：架构介绍，了解更多详情； 推荐阅读社区官方播客的架构系列文章：nebula-graph.com.cn/tags/架构系列。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#storage-service-nebula-storaged"},{"categories":["Nebula Graph"],"content":" 1.3 进程间通信、服务发现机制graphd、metad、storaged 之间通过 Thrift 协议进行远程调用（RPC），下边给一些例子： graphd 会通过 metaclient 调用 metad 将自己报告为一个正在运行的服务，以便被发现 为用户（使用 graphclient ）登录进行 RPC 调用 当它处理 nGQL 查询时，获取图形存储分布情况 graphd 会通过 storageclient 调用 storaged 在处理 nGQL 时，在它从 metad 获得所需的元信息后，进行图形数据的读/写 storaged 会通过 metaclient调用 metad 将自己报告为一个正在运行的服务，以便被发现 当然有状态的存储引擎内部也有集群同步的流量与通信 storaged 与其他 storaged 有 RAFT 连接 metad 与其他 metad 实例有 RAFT 连接 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#进程间通信服务发现机制"},{"categories":["Nebula Graph"],"content":" 2 开发环境搭建接下来我们开始 NebulaGraph 的构建、开发环境的部分。 NebulaGraph 只支持在 GNU/Linux 分支中构建，目前来说，最方便的方式是在社区预先提供好了依赖的容器镜像的基础上在容器内部构建、调试 NebulaGraph 代码的更改和 Debug。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#开发环境搭建"},{"categories":["Nebula Graph"],"content":" 2.1 创建一个容器化的 NebulaGraph 集群为了更方便地调试代码，我习惯提前创建一个 NebulaGraph Docker 环境，我们可以使用官方的 Docker-Compose 方式部署，也可以使用我在官方 Docker-Compose 基础之上弄的一键部署工具：nebula-up.siwei.io。 以 nebula-up 为例： 在我们的 Linux 开发服务器中执行 curl -fsSL nebula-up.siwei.io/install.sh | bash 就可以了。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#创建一个容器化的-nebulagraph-集群"},{"categories":["Nebula Graph"],"content":" 2.2 代码获取NebulaGraph 的代码仓库托管在 GitHub 之上，我们可以在有互联网的地方直接克隆下来： git clone git@github.com:vesoft-inc/nebula.git cd nebula ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#代码获取"},{"categories":["Nebula Graph"],"content":" 2.3 创建开发容器有了 NebulaGraph 集群，我们可以借助 https://github.com/vesoft-inc/nebula-dev-docker/ 提供的开箱即用开发容器镜像，搭建开发环境： export TAG=ubuntu2004 docker run -ti \\ --network nebula-net \\ --security-opt seccomp=unconfined \\ -v \"$PWD\":/home/nebula \\ -w /home/nebula \\ --name nebula_dev \\ vesoft/nebula-dev:$TAG \\ bash 这其中，-v \"$PWD\" 表示当前的 NebulaGraph 代码本地的路径会被映射到开发容器内部的 /home/nebula，而启动的容器名字是 nebula_dev。 待这个容器启动之后，我们会自动进入到这个容器的 bash shell 之中，如果我们输入 exit 退出容器，它会被关闭，如果我们想再次启动容器，只需要执行： docker start nebula_dev 之后，我们的编译、Debug、测试工作都在 nebula_dev 容器内部进行，在容器是运行状态的情况下，可以随时新建一个容器内部的 bash shell 进程： docker exec -ti nebula_dev bash 注，为了保持编译环境是最新的，我们可以定期删除、拉取、重建这个开发容器，以保持环境与代码相匹配。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#创建开发容器"},{"categories":["Nebula Graph"],"content":" 2.4 编译环境在 nebula_dev 这个容器内部，我们可以进行代码编译： 进入编译容器 docker exec -ti nebula_dev bash 用 CMake 准备 makefile，第一次构建的时候，为了节省时间、内存，我关闭了测试（-DENABLE_TESTING=OFF）： mkdir build \u0026\u0026 cd build cmake -DCMAKE_CXX_COMPILER=$TOOLSET_CLANG_DIR/bin/g++ -DCMAKE_C_COMPILER=$TOOLSET_CLANG_DIR/bin/gcc -DENABLE_WERROR=OFF -DCMAKE_BUILD_TYPE=Debug -DENABLE_TESTING=OFF .. 开始编译，根据服务器的空闲 CPU 个数和内存量力而行，比如我在自己 72 核心的服务器上准备允许同时运行 64 个 job，则运行： make -j64 第一次构建的时间会慢一些，在 make 成功之后，我们也可以执行 make install 把二进制安装到像生产安装时候一样的路径： root@1827b82e88bf:/home/nebula/build# make install root@1827b82e88bf:/home/nebula/build# ls /usr/local/nebula/bin db_dump db_upgrader meta_dump nebula-graphd nebula-metad nebula-storaged root@1827b82e88bf:/home/nebula/build# ls /usr/local/nebula/ bin etc pids scripts share ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:4","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#编译环境"},{"categories":["Nebula Graph"],"content":" 3 调试 NebulaGraph以 GraphD 调试为例。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:3:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#调试-nebulagraph"},{"categories":["Nebula Graph"],"content":" 3.1 安装依赖安装一些后边会方便 Debug 额外用到的依赖 # 装一个 ping，测试一下 nebula-up 安装的集群可以访问 apt update \u0026\u0026 apt install iputils-ping -y # ping graphd 试试看 ping graphd -c 4 # 安装 gdb gdb-dashboard apt install gdb -y wget -P ~ https://git.io/.gdbinit pip install pygments ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:3:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#安装依赖"},{"categories":["Nebula Graph"],"content":" 3.2 准备客户端准备一个 NebulaGraph 的命令行客户端： # 新开一个 nebula_dev 的 shell docker exec -ti nebula_dev bash # 下载 nebula-console 二进制文件，并赋予可执行权限，命名为 nebula-console 并安装到 /usr/bin/ 下 wget https://github.com/vesoft-inc/nebula-console/releases/download/v3.2.0/nebula-console-linux-amd64-v3.2.0 chmod +x nebula-console* mv nebula-console* /usr/bin/nebula-console 连接到前边我们 nebula-up 准备的集群之上，加载 basketballplayer 这个测试数据： nebula-console -u root -p nebula --address=graphd --port=9669 :play basketballplayer; exit ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:3:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#准备客户端"},{"categories":["Nebula Graph"],"content":" 3.3 gdb 运行 graphd我们用 gdb 执行刚刚编译的 nebula-graphd 二进制，让他成为一个新的 graphd 服务，名字就叫 nebula_dev。 首先启动 gdb # 新开一个 nebula_dev 的 shell docker exec -ti nebula_dev bash cd /usr/local/nebula/ mkdir -p /home/nebula/build/log gdb bin/nebula-graphd 在 gdb 内部执行设置必要的参数 跟随 fork 的子进程 set follow-fork-mode child 设置待调试 graphd 的启动参数（配置）： meta_server_addrs 填已经启动的集群的所有 metad 的地址 local_ip 和 ws_ip 填本容器的域名，port 是 graphd 监听端口 log_dir 是输出日志的目录，v 和 minloglevel 是日志的输出等级 set args --flagfile=/usr/local/nebula/etc/nebula-graphd.conf.default \\ --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 \\ --port=9669 \\ --local_ip=nebula_dev \\ --ws_ip=nebula_dev \\ --ws_http_port=19669 \\ --log_dir=/home/nebula/build/log \\ --v=4 \\ --minloglevel=0 如果我们想加断点在 src/common/function/FunctionManager.cpp 2783 行，可以再执行： b /home/nebula/src/common/function/FunctionManager.cpp:2783 配置前边安装的 gdb-dashboard，一个开源的 gdb 界面插件。 # 设定在 gdb 界面上展示 代码、历史、回调栈、变量、表达几个部分，详细参考 https://github.com/cyrus-and/gdb-dashboard dashboard -layout source history stack variables expressions 最后我们让进程通过 gdb 跑起来吧： run 之后，我们就可以在这个窗口/shell 会话下调试 graphd 程序了。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:3:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#gdb-运行-graphd"},{"categories":["Nebula Graph"],"content":" 4 修改 NebulaGraph 代码这里，我以 #3513 这个 issue 为例子，快速介绍一下代码修改的过程。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#修改-nebulagraph-代码"},{"categories":["Nebula Graph"],"content":" 4.1 读代码这个 issue 表达的内容是在有一小部分用户决定把 JSON 以 String 的形式存储在 NebulaGraph 中的属性里，因为这种方式比较罕见且不被推崇，NebulaGraph 没有直接支持对 JSON String 直接解析的方法。 本来这个功能是等到很希望得到支持的同学过来亲自去实现的，而在 Issue 中，刚好有一位新手贡献者在里边回复求助如何能开始参与这个贡献。接着这个契机，我去参与讨论看了一下这个功能可以实现成什么样子，最终讨论的结果是可以做成和 MySQL 中的 JSON_EXTRACT 函数那样，但是改为只接受 JSON String，无需处理输出路径参数。 这个任务一句话来说就是为 NebulaGraph 引入一个解析 JSON String 为 Map 的函数。那么，应该大概如何实现这个功能呢？ 4.1.1 在哪里修改很自然，引入新的函数的更改肯定有很多，所以我们只需要找到之前增加新函数的 PR 就可以快速知道在哪些地方修改了。 当然我们可以自底向上去了解 NebulaGraph 整体的代码结构，然后一点点找到函数处理的位置，事实上有的时候我们也不得不这么做，这时候除了代码本身，一些面向贡献者的文章可能会帮助我们事半功倍对整体有一个了解，NebulaGraph 官方博客里就有这样的一个系列文章，推荐大家在贡献的时候也去通读一下：nebula-graph.com.cn/posts/nebula-graph-source-code-reading-00。 于是，我从 #4526 这个 PR 里了解到所有函数入口都被统一管理在 src/common/function/FunctionManager.cpp 之中，通过搜索、理解其中其他某一个函数的关键词之后可以很容易理解一个函数实体的关键词、输入输出数据类型、以及它的处理逻辑的代码在哪里实现。 同时，我注意到在同一个目录下，src/common/function/test/FunctionManagerTest.cpp 之中则是所有这些函数的单元测试代码，用同样的方式也可以知道新加的一个函数需要如何在里边实现基于 gtest 的单元测试。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#读代码"},{"categories":["Nebula Graph"],"content":" 4.1 读代码这个 issue 表达的内容是在有一小部分用户决定把 JSON 以 String 的形式存储在 NebulaGraph 中的属性里，因为这种方式比较罕见且不被推崇，NebulaGraph 没有直接支持对 JSON String 直接解析的方法。 本来这个功能是等到很希望得到支持的同学过来亲自去实现的，而在 Issue 中，刚好有一位新手贡献者在里边回复求助如何能开始参与这个贡献。接着这个契机，我去参与讨论看了一下这个功能可以实现成什么样子，最终讨论的结果是可以做成和 MySQL 中的 JSON_EXTRACT 函数那样，但是改为只接受 JSON String，无需处理输出路径参数。 这个任务一句话来说就是为 NebulaGraph 引入一个解析 JSON String 为 Map 的函数。那么，应该大概如何实现这个功能呢？ 4.1.1 在哪里修改很自然，引入新的函数的更改肯定有很多，所以我们只需要找到之前增加新函数的 PR 就可以快速知道在哪些地方修改了。 当然我们可以自底向上去了解 NebulaGraph 整体的代码结构，然后一点点找到函数处理的位置，事实上有的时候我们也不得不这么做，这时候除了代码本身，一些面向贡献者的文章可能会帮助我们事半功倍对整体有一个了解，NebulaGraph 官方博客里就有这样的一个系列文章，推荐大家在贡献的时候也去通读一下：nebula-graph.com.cn/posts/nebula-graph-source-code-reading-00。 于是，我从 #4526 这个 PR 里了解到所有函数入口都被统一管理在 src/common/function/FunctionManager.cpp 之中，通过搜索、理解其中其他某一个函数的关键词之后可以很容易理解一个函数实体的关键词、输入输出数据类型、以及它的处理逻辑的代码在哪里实现。 同时，我注意到在同一个目录下，src/common/function/test/FunctionManagerTest.cpp 之中则是所有这些函数的单元测试代码，用同样的方式也可以知道新加的一个函数需要如何在里边实现基于 gtest 的单元测试。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#在哪里修改"},{"categories":["Nebula Graph"],"content":" 4.2 开始改代码 注：在修改代码之前，请确保自己在最新的 master 分支之上创建一个单独的分支，这里的例子中，我把分支名字叫 fn_JSON_EXTRACT： git checkout master git pull git checkout -b fn_JSON_EXTRACT 通过 Google 了解与交叉验证 NebulaGraph 内部使用的 utils 库，我知道我应该用 folly::parseJson 把字符串读成 folly::dynamic 然后再 cast 成 NebulaGraph 内置的 Map() 类型，然后，借助于 StackOverflow/GitHub Copilot，我终于完成了第一个版本的代码修改。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#开始改代码"},{"categories":["Nebula Graph"],"content":" 4.3 调试代码接下来，我兴冲冲地改好了第一版的代码，信心满满地开始编译！实际上因为是 CPP 新手，即使在 Copilot 的加持下，我的代码还是花了好几次修改才通过编译。 然后，我开始用 GDB 把修改了的 GraphD 启动起来，用 console 发起 JSON_EXTRACT 的函数调用，先调通了期待中的效果，并试着跑几种异常的输入，在发现新问题、修改、编译、调试的几轮循环下让代码达到了期望的状态，这时候，我知道我要把代码提交到 GitHub 请项目的资深贡献者帮忙 review 啦！ ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#调试代码"},{"categories":["Nebula Graph"],"content":" 5 提交 PRPR（Pull Request）是 GitHub 中方便多人代码协作、代码审查中的一种方式，它通过把一个 repo 下的分支与这个审查协作的实例（PR）做映射，得到一个项目下唯一的 PR 号码之后，生成单独的网页，在这个网页下，我们可以做不同贡献者之间的交流和后续的代码更新，这个过程中代码提交者们可以一直在这个分支上不断提交代码直到代码的状态被各方同意之后，就可以合并（merge）到目的分支中。 这个过程可以分为： 创建 GitHub 上远程的个人开发分支 基于分支创建目标项目仓库中的 PR 在 PR 中协作、讨论、不断再次提交到开发分支直到多方达到合并、或者关闭的共识 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#提交-pr"},{"categories":["Nebula Graph"],"content":" 5.1 提交到个人远程分支这一步骤里，我们要把当前的本地提交的 commit，提交到自己的 GitHub 分叉之中。 5.1.1 commit 本地修改首先，我们确认一下本地的修改是否都是期待中的： # 先确定修改的文件 $ git status # 再看看修改的内容 $ git diff 然后，把它们 commit（提交在本地仓库） # 添加所有当前目录（. 这个点表示当前目录）修改过的文件为待 commit $ git add . # 然后我们可以看一下状态，这些修改的文件状态已经不同了 $ git status # 最后，提交在本地仓库，并用 -m 参数指定单行的 commit message $ git commit -m \"feat: introduce function JSON_EXTRACT\" 5.1.2 提交到自己远程的分支在提交之前，要确保自己的 GitHub 账号之下确实存在 NebulaGraph 代码仓库的分叉（fork），比如我的 GitHub 账号是 wey-gu，我访问，那么我对 https://github.com/vesoft-inc/nebula 的分叉应该就是 https://github.com/wey-gu/nebula 。 如果还没有自己的分叉，可以直接在 https://github.com/vesoft-inc/nebula 上点击右上角的 Fork，创建自己的分叉仓库。 当远程的个人分叉存在之后，我们可以把代码提交上去了 # 添加一个新的远程仓库叫 wey git remote add wey git@github.com:wey-gu/nebula.git # 提交 JSON_EXTRACT 分支到 wey 这个 remote 仓库 git push wey JSON_EXTRACT 5.1.3 在个人远程分叉分支上创建 PR这时候，我们访问这个远程分支：https://github.com/wey-gu/nebula/tree/fn_JSON_EXTRACT ，就能找到 Open PR 的入口： 然后点击 Open pull request 按钮，就进入到创建 PR 的界面了，这和在一般的论坛里提交一个帖子是很类似的： 提交之后，我们可以等待、或者邀请其他人来做代码的审查（review），往往其他的贡献者都能从他们的角度给出一些代码修改的建议和提示，我们需要经过几轮的代码修改、讨论之后使得代码达到最佳的状态。 而这些审查者中除了社区的贡献者（人类）之外，还有一些自动化的机器人，他们会在代码库中自动化的通过持续集成（CI）的方式运行一些自动化的审查工作，可能包括以下几种： CLA：Contributor License Agreement（贡献者许可协议），这是一个要 PR 作者在首次提交代码到项目时签署的协议，因为代码将被提交到公共空间，这份协议的签署意味着作者同意代码被分享、复用、修改这件事情。 lint：代码风格检查，这也是最常见的 CI 任务 test：各种层面的测试检查任务 通常来说，这些所有的自动化审查机器人所代表的任务也需要全都通过，代码的状态才能被认为是可以合并的，而不出意外，我首次提交的代码果然有测试的失败。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#提交到个人远程分支"},{"categories":["Nebula Graph"],"content":" 5.1 提交到个人远程分支这一步骤里，我们要把当前的本地提交的 commit，提交到自己的 GitHub 分叉之中。 5.1.1 commit 本地修改首先，我们确认一下本地的修改是否都是期待中的： # 先确定修改的文件 $ git status # 再看看修改的内容 $ git diff 然后，把它们 commit（提交在本地仓库） # 添加所有当前目录（. 这个点表示当前目录）修改过的文件为待 commit $ git add . # 然后我们可以看一下状态，这些修改的文件状态已经不同了 $ git status # 最后，提交在本地仓库，并用 -m 参数指定单行的 commit message $ git commit -m \"feat: introduce function JSON_EXTRACT\" 5.1.2 提交到自己远程的分支在提交之前，要确保自己的 GitHub 账号之下确实存在 NebulaGraph 代码仓库的分叉（fork），比如我的 GitHub 账号是 wey-gu，我访问，那么我对 https://github.com/vesoft-inc/nebula 的分叉应该就是 https://github.com/wey-gu/nebula 。 如果还没有自己的分叉，可以直接在 https://github.com/vesoft-inc/nebula 上点击右上角的 Fork，创建自己的分叉仓库。 当远程的个人分叉存在之后，我们可以把代码提交上去了 # 添加一个新的远程仓库叫 wey git remote add wey git@github.com:wey-gu/nebula.git # 提交 JSON_EXTRACT 分支到 wey 这个 remote 仓库 git push wey JSON_EXTRACT 5.1.3 在个人远程分叉分支上创建 PR这时候，我们访问这个远程分支：https://github.com/wey-gu/nebula/tree/fn_JSON_EXTRACT ，就能找到 Open PR 的入口： 然后点击 Open pull request 按钮，就进入到创建 PR 的界面了，这和在一般的论坛里提交一个帖子是很类似的： 提交之后，我们可以等待、或者邀请其他人来做代码的审查（review），往往其他的贡献者都能从他们的角度给出一些代码修改的建议和提示，我们需要经过几轮的代码修改、讨论之后使得代码达到最佳的状态。 而这些审查者中除了社区的贡献者（人类）之外，还有一些自动化的机器人，他们会在代码库中自动化的通过持续集成（CI）的方式运行一些自动化的审查工作，可能包括以下几种： CLA：Contributor License Agreement（贡献者许可协议），这是一个要 PR 作者在首次提交代码到项目时签署的协议，因为代码将被提交到公共空间，这份协议的签署意味着作者同意代码被分享、复用、修改这件事情。 lint：代码风格检查，这也是最常见的 CI 任务 test：各种层面的测试检查任务 通常来说，这些所有的自动化审查机器人所代表的任务也需要全都通过，代码的状态才能被认为是可以合并的，而不出意外，我首次提交的代码果然有测试的失败。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#commit-本地修改"},{"categories":["Nebula Graph"],"content":" 5.1 提交到个人远程分支这一步骤里，我们要把当前的本地提交的 commit，提交到自己的 GitHub 分叉之中。 5.1.1 commit 本地修改首先，我们确认一下本地的修改是否都是期待中的： # 先确定修改的文件 $ git status # 再看看修改的内容 $ git diff 然后，把它们 commit（提交在本地仓库） # 添加所有当前目录（. 这个点表示当前目录）修改过的文件为待 commit $ git add . # 然后我们可以看一下状态，这些修改的文件状态已经不同了 $ git status # 最后，提交在本地仓库，并用 -m 参数指定单行的 commit message $ git commit -m \"feat: introduce function JSON_EXTRACT\" 5.1.2 提交到自己远程的分支在提交之前，要确保自己的 GitHub 账号之下确实存在 NebulaGraph 代码仓库的分叉（fork），比如我的 GitHub 账号是 wey-gu，我访问，那么我对 https://github.com/vesoft-inc/nebula 的分叉应该就是 https://github.com/wey-gu/nebula 。 如果还没有自己的分叉，可以直接在 https://github.com/vesoft-inc/nebula 上点击右上角的 Fork，创建自己的分叉仓库。 当远程的个人分叉存在之后，我们可以把代码提交上去了 # 添加一个新的远程仓库叫 wey git remote add wey git@github.com:wey-gu/nebula.git # 提交 JSON_EXTRACT 分支到 wey 这个 remote 仓库 git push wey JSON_EXTRACT 5.1.3 在个人远程分叉分支上创建 PR这时候，我们访问这个远程分支：https://github.com/wey-gu/nebula/tree/fn_JSON_EXTRACT ，就能找到 Open PR 的入口： 然后点击 Open pull request 按钮，就进入到创建 PR 的界面了，这和在一般的论坛里提交一个帖子是很类似的： 提交之后，我们可以等待、或者邀请其他人来做代码的审查（review），往往其他的贡献者都能从他们的角度给出一些代码修改的建议和提示，我们需要经过几轮的代码修改、讨论之后使得代码达到最佳的状态。 而这些审查者中除了社区的贡献者（人类）之外，还有一些自动化的机器人，他们会在代码库中自动化的通过持续集成（CI）的方式运行一些自动化的审查工作，可能包括以下几种： CLA：Contributor License Agreement（贡献者许可协议），这是一个要 PR 作者在首次提交代码到项目时签署的协议，因为代码将被提交到公共空间，这份协议的签署意味着作者同意代码被分享、复用、修改这件事情。 lint：代码风格检查，这也是最常见的 CI 任务 test：各种层面的测试检查任务 通常来说，这些所有的自动化审查机器人所代表的任务也需要全都通过，代码的状态才能被认为是可以合并的，而不出意外，我首次提交的代码果然有测试的失败。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#提交到自己远程的分支"},{"categories":["Nebula Graph"],"content":" 5.1 提交到个人远程分支这一步骤里，我们要把当前的本地提交的 commit，提交到自己的 GitHub 分叉之中。 5.1.1 commit 本地修改首先，我们确认一下本地的修改是否都是期待中的： # 先确定修改的文件 $ git status # 再看看修改的内容 $ git diff 然后，把它们 commit（提交在本地仓库） # 添加所有当前目录（. 这个点表示当前目录）修改过的文件为待 commit $ git add . # 然后我们可以看一下状态，这些修改的文件状态已经不同了 $ git status # 最后，提交在本地仓库，并用 -m 参数指定单行的 commit message $ git commit -m \"feat: introduce function JSON_EXTRACT\" 5.1.2 提交到自己远程的分支在提交之前，要确保自己的 GitHub 账号之下确实存在 NebulaGraph 代码仓库的分叉（fork），比如我的 GitHub 账号是 wey-gu，我访问，那么我对 https://github.com/vesoft-inc/nebula 的分叉应该就是 https://github.com/wey-gu/nebula 。 如果还没有自己的分叉，可以直接在 https://github.com/vesoft-inc/nebula 上点击右上角的 Fork，创建自己的分叉仓库。 当远程的个人分叉存在之后，我们可以把代码提交上去了 # 添加一个新的远程仓库叫 wey git remote add wey git@github.com:wey-gu/nebula.git # 提交 JSON_EXTRACT 分支到 wey 这个 remote 仓库 git push wey JSON_EXTRACT 5.1.3 在个人远程分叉分支上创建 PR这时候，我们访问这个远程分支：https://github.com/wey-gu/nebula/tree/fn_JSON_EXTRACT ，就能找到 Open PR 的入口： 然后点击 Open pull request 按钮，就进入到创建 PR 的界面了，这和在一般的论坛里提交一个帖子是很类似的： 提交之后，我们可以等待、或者邀请其他人来做代码的审查（review），往往其他的贡献者都能从他们的角度给出一些代码修改的建议和提示，我们需要经过几轮的代码修改、讨论之后使得代码达到最佳的状态。 而这些审查者中除了社区的贡献者（人类）之外，还有一些自动化的机器人，他们会在代码库中自动化的通过持续集成（CI）的方式运行一些自动化的审查工作，可能包括以下几种： CLA：Contributor License Agreement（贡献者许可协议），这是一个要 PR 作者在首次提交代码到项目时签署的协议，因为代码将被提交到公共空间，这份协议的签署意味着作者同意代码被分享、复用、修改这件事情。 lint：代码风格检查，这也是最常见的 CI 任务 test：各种层面的测试检查任务 通常来说，这些所有的自动化审查机器人所代表的任务也需要全都通过，代码的状态才能被认为是可以合并的，而不出意外，我首次提交的代码果然有测试的失败。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#在个人远程分叉分支上创建-pr"},{"categories":["Nebula Graph"],"content":" 5.2 调试 CI 测试代码NebulaGraph 里所有的 CI 测试代码也都能在本地被触发，并且（显然）都有被单独触发的方式，我们需要掌握它们而不是在每次修改一个小的测试修复之后提交到服务器上等着 CI 做全量的运行（这样常常几十分钟就这么浪费掉了）。 5.2.1 CTest在这个距离的 PR 提交中，我修改的函数代码同一层级下的单元测试 CTest 就有问题，问题可能是测试代码本身造成、我们的修改破坏了原来的测试用例导致、亦或者是我们自己的测试用例发现了代码修改本身的问题。 这次，我们要根据 CTest 失败的报错进行排查和代码修改，然后编译代码，在本地运行一下这个失败的用例： # 我们需要进入到我们的编译容器内部的 build 目录下 $ docker exec -ti nebula_dev bash $ cd build # 在 -DENABLE_TESTING=ON 之中编译，如果之前的编译 job 数下内存已经跑满了的话，这次可以把 job 数调小一点，因为开启测试会占用更多内存 $ cmake -DCMAKE_CXX_COMPILER=$TOOLSET_CLANG_DIR/bin/g++ -DCMAKE_C_COMPILER=$TOOLSET_CLANG_DIR/bin/gcc -DENABLE_WERROR=OFF -DCMAKE_BUILD_TYPE=Debug -DENABLE_TESTING=ON .. $ make -j 48 # 可以看到编译成功了 CTest 的单元测试二进制可执行文件 # [100%] Linking CXX executable ../../../../bin/test/function_manager_test # [100%] Built target function_manager_test # 执行重新修改过的单元测试！ $ bin/test/function_manager_test [==========] Running 11 tests from 1 test suite. [----------] Global test environment set-up. [----------] 11 tests from FunctionManagerTest [ RUN ] FunctionManagerTest.testNull [ OK ] FunctionManagerTest.testNull (0 ms) [ RUN ] FunctionManagerTest.functionCall W20221020 23:35:18.579897 28679 Map.cpp:77] JSON_EXTRACT nested layer 1: Map can be populated only by Bool, Double, Int, String value and null, now trying to parse from: object [ OK ] FunctionManagerTest.functionCall (2 ms) [ RUN ] FunctionManagerTest.time [ OK ] FunctionManagerTest.time (0 ms) [ RUN ] FunctionManagerTest.returnType [ OK ] FunctionManagerTest.returnType (0 ms) [ RUN ] FunctionManagerTest.SchemaRelated [ OK ] FunctionManagerTest.SchemaRelated (0 ms) [ RUN ] FunctionManagerTest.ScalarFunctionTest [ OK ] FunctionManagerTest.ScalarFunctionTest (0 ms) [ RUN ] FunctionManagerTest.ListFunctionTest [ OK ] FunctionManagerTest.ListFunctionTest (0 ms) [ RUN ] FunctionManagerTest.duplicateEdgesORVerticesInPath [ OK ] FunctionManagerTest.duplicateEdgesORVerticesInPath (0 ms) [ RUN ] FunctionManagerTest.ReversePath [ OK ] FunctionManagerTest.ReversePath (0 ms) [ RUN ] FunctionManagerTest.DataSetRowCol [ OK ] FunctionManagerTest.DataSetRowCol (0 ms) [ RUN ] FunctionManagerTest.PurityTest [ OK ] FunctionManagerTest.PurityTest (0 ms) [----------] 11 tests from FunctionManagerTest (5 ms total) [----------] Global test environment tear-down [==========] 11 tests from 1 test suite ran. (5 ms total) [ PASSED ] 11 tests. 成功！ 于是，我把新的更改提交到远程分支上，在 PR 的网页中，可以看到 CI 已经在新的提交的触发下重新编译、执行了，过一会儿果然都 pass 了，于是我兴高采烈地等待着两位以上的审查者帮忙批准代码，然后合并它！ 但是，我收到了新的建议： 另一位贡献者请我添加 TCK 的测试用例。 5.2.2 TCKTCK 的全称是 The Cypher Technology Compatibility Kit，它是 NebulaGraph 从 OpenCypher 社区继承演进而来的一套测试框架，我们用 Python 做了测试用例格式兼容的实现。 它的优雅在于，我们可以像写英语一样去描述我们想实现的端到端功能测试用例，像这样！ # tests/tck/features/function/json_extract.feature Feature: json_extract Function Background: Test json_extract function Scenario: Test Positive Cases When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": \"foo\", \"b\": 0.2, \"c\": true}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: \"foo\", b: 0.2, c: true} | When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": 1, \"b\": {}, \"c\": {\"d\": true}}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: 1, b: {}, c: {d: true}} | When executing query: \"\"\" YIELD JSON_EXTRACT('{}') AS result; \"\"\" Then the result should be, in any order: | result | | {} | 在添加了自己的一个新的 tck 测试用例文本文件之后，我们只需要在测试文件中临时增加标签，并在执行的时候指定标签，就可以单独执行新增的 tck 测试用例了： # 还是在编译容器内部，进入到 tests 目录下 cd ../tests # 安装 tck 测试所需依赖 python3 -m pip install -r requirements.txt python3 -m pip install nebula3-python==3.1.0 # 运行一个单独为 tck 测试准备的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true up # 给 tests/tck/features/function/json_extract.feature 以@开头第一行加上标签，比如 @wey vi tests/tck/features/function/json_extract.feature # 执行 pytest (包含 tck 用例)，因为制定了 -m \"wey\"，只有 tests/tck/features/function/json_extract.feature 会被执行 python3 -m pytest -m \"wey\" # 关闭 pytest 所依赖的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true down 延伸阅读： 基于 BDD 理论的 Nebula 集成测试框架重构，https://nebula-graph.com.cn/posts/bdd-testing-pract","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#调试-ci-测试代码"},{"categories":["Nebula Graph"],"content":" 5.2 调试 CI 测试代码NebulaGraph 里所有的 CI 测试代码也都能在本地被触发，并且（显然）都有被单独触发的方式，我们需要掌握它们而不是在每次修改一个小的测试修复之后提交到服务器上等着 CI 做全量的运行（这样常常几十分钟就这么浪费掉了）。 5.2.1 CTest在这个距离的 PR 提交中，我修改的函数代码同一层级下的单元测试 CTest 就有问题，问题可能是测试代码本身造成、我们的修改破坏了原来的测试用例导致、亦或者是我们自己的测试用例发现了代码修改本身的问题。 这次，我们要根据 CTest 失败的报错进行排查和代码修改，然后编译代码，在本地运行一下这个失败的用例： # 我们需要进入到我们的编译容器内部的 build 目录下 $ docker exec -ti nebula_dev bash $ cd build # 在 -DENABLE_TESTING=ON 之中编译，如果之前的编译 job 数下内存已经跑满了的话，这次可以把 job 数调小一点，因为开启测试会占用更多内存 $ cmake -DCMAKE_CXX_COMPILER=$TOOLSET_CLANG_DIR/bin/g++ -DCMAKE_C_COMPILER=$TOOLSET_CLANG_DIR/bin/gcc -DENABLE_WERROR=OFF -DCMAKE_BUILD_TYPE=Debug -DENABLE_TESTING=ON .. $ make -j 48 # 可以看到编译成功了 CTest 的单元测试二进制可执行文件 # [100%] Linking CXX executable ../../../../bin/test/function_manager_test # [100%] Built target function_manager_test # 执行重新修改过的单元测试！ $ bin/test/function_manager_test [==========] Running 11 tests from 1 test suite. [----------] Global test environment set-up. [----------] 11 tests from FunctionManagerTest [ RUN ] FunctionManagerTest.testNull [ OK ] FunctionManagerTest.testNull (0 ms) [ RUN ] FunctionManagerTest.functionCall W20221020 23:35:18.579897 28679 Map.cpp:77] JSON_EXTRACT nested layer 1: Map can be populated only by Bool, Double, Int, String value and null, now trying to parse from: object [ OK ] FunctionManagerTest.functionCall (2 ms) [ RUN ] FunctionManagerTest.time [ OK ] FunctionManagerTest.time (0 ms) [ RUN ] FunctionManagerTest.returnType [ OK ] FunctionManagerTest.returnType (0 ms) [ RUN ] FunctionManagerTest.SchemaRelated [ OK ] FunctionManagerTest.SchemaRelated (0 ms) [ RUN ] FunctionManagerTest.ScalarFunctionTest [ OK ] FunctionManagerTest.ScalarFunctionTest (0 ms) [ RUN ] FunctionManagerTest.ListFunctionTest [ OK ] FunctionManagerTest.ListFunctionTest (0 ms) [ RUN ] FunctionManagerTest.duplicateEdgesORVerticesInPath [ OK ] FunctionManagerTest.duplicateEdgesORVerticesInPath (0 ms) [ RUN ] FunctionManagerTest.ReversePath [ OK ] FunctionManagerTest.ReversePath (0 ms) [ RUN ] FunctionManagerTest.DataSetRowCol [ OK ] FunctionManagerTest.DataSetRowCol (0 ms) [ RUN ] FunctionManagerTest.PurityTest [ OK ] FunctionManagerTest.PurityTest (0 ms) [----------] 11 tests from FunctionManagerTest (5 ms total) [----------] Global test environment tear-down [==========] 11 tests from 1 test suite ran. (5 ms total) [ PASSED ] 11 tests. 成功！ 于是，我把新的更改提交到远程分支上，在 PR 的网页中，可以看到 CI 已经在新的提交的触发下重新编译、执行了，过一会儿果然都 pass 了，于是我兴高采烈地等待着两位以上的审查者帮忙批准代码，然后合并它！ 但是，我收到了新的建议： 另一位贡献者请我添加 TCK 的测试用例。 5.2.2 TCKTCK 的全称是 The Cypher Technology Compatibility Kit，它是 NebulaGraph 从 OpenCypher 社区继承演进而来的一套测试框架，我们用 Python 做了测试用例格式兼容的实现。 它的优雅在于，我们可以像写英语一样去描述我们想实现的端到端功能测试用例，像这样！ # tests/tck/features/function/json_extract.feature Feature: json_extract Function Background: Test json_extract function Scenario: Test Positive Cases When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": \"foo\", \"b\": 0.2, \"c\": true}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: \"foo\", b: 0.2, c: true} | When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": 1, \"b\": {}, \"c\": {\"d\": true}}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: 1, b: {}, c: {d: true}} | When executing query: \"\"\" YIELD JSON_EXTRACT('{}') AS result; \"\"\" Then the result should be, in any order: | result | | {} | 在添加了自己的一个新的 tck 测试用例文本文件之后，我们只需要在测试文件中临时增加标签，并在执行的时候指定标签，就可以单独执行新增的 tck 测试用例了： # 还是在编译容器内部，进入到 tests 目录下 cd ../tests # 安装 tck 测试所需依赖 python3 -m pip install -r requirements.txt python3 -m pip install nebula3-python==3.1.0 # 运行一个单独为 tck 测试准备的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true up # 给 tests/tck/features/function/json_extract.feature 以@开头第一行加上标签，比如 @wey vi tests/tck/features/function/json_extract.feature # 执行 pytest (包含 tck 用例)，因为制定了 -m \"wey\"，只有 tests/tck/features/function/json_extract.feature 会被执行 python3 -m pytest -m \"wey\" # 关闭 pytest 所依赖的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true down 延伸阅读： 基于 BDD 理论的 Nebula 集成测试框架重构，https://nebula-graph.com.cn/posts/bdd-testing-pract","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#ctest"},{"categories":["Nebula Graph"],"content":" 5.2 调试 CI 测试代码NebulaGraph 里所有的 CI 测试代码也都能在本地被触发，并且（显然）都有被单独触发的方式，我们需要掌握它们而不是在每次修改一个小的测试修复之后提交到服务器上等着 CI 做全量的运行（这样常常几十分钟就这么浪费掉了）。 5.2.1 CTest在这个距离的 PR 提交中，我修改的函数代码同一层级下的单元测试 CTest 就有问题，问题可能是测试代码本身造成、我们的修改破坏了原来的测试用例导致、亦或者是我们自己的测试用例发现了代码修改本身的问题。 这次，我们要根据 CTest 失败的报错进行排查和代码修改，然后编译代码，在本地运行一下这个失败的用例： # 我们需要进入到我们的编译容器内部的 build 目录下 $ docker exec -ti nebula_dev bash $ cd build # 在 -DENABLE_TESTING=ON 之中编译，如果之前的编译 job 数下内存已经跑满了的话，这次可以把 job 数调小一点，因为开启测试会占用更多内存 $ cmake -DCMAKE_CXX_COMPILER=$TOOLSET_CLANG_DIR/bin/g++ -DCMAKE_C_COMPILER=$TOOLSET_CLANG_DIR/bin/gcc -DENABLE_WERROR=OFF -DCMAKE_BUILD_TYPE=Debug -DENABLE_TESTING=ON .. $ make -j 48 # 可以看到编译成功了 CTest 的单元测试二进制可执行文件 # [100%] Linking CXX executable ../../../../bin/test/function_manager_test # [100%] Built target function_manager_test # 执行重新修改过的单元测试！ $ bin/test/function_manager_test [==========] Running 11 tests from 1 test suite. [----------] Global test environment set-up. [----------] 11 tests from FunctionManagerTest [ RUN ] FunctionManagerTest.testNull [ OK ] FunctionManagerTest.testNull (0 ms) [ RUN ] FunctionManagerTest.functionCall W20221020 23:35:18.579897 28679 Map.cpp:77] JSON_EXTRACT nested layer 1: Map can be populated only by Bool, Double, Int, String value and null, now trying to parse from: object [ OK ] FunctionManagerTest.functionCall (2 ms) [ RUN ] FunctionManagerTest.time [ OK ] FunctionManagerTest.time (0 ms) [ RUN ] FunctionManagerTest.returnType [ OK ] FunctionManagerTest.returnType (0 ms) [ RUN ] FunctionManagerTest.SchemaRelated [ OK ] FunctionManagerTest.SchemaRelated (0 ms) [ RUN ] FunctionManagerTest.ScalarFunctionTest [ OK ] FunctionManagerTest.ScalarFunctionTest (0 ms) [ RUN ] FunctionManagerTest.ListFunctionTest [ OK ] FunctionManagerTest.ListFunctionTest (0 ms) [ RUN ] FunctionManagerTest.duplicateEdgesORVerticesInPath [ OK ] FunctionManagerTest.duplicateEdgesORVerticesInPath (0 ms) [ RUN ] FunctionManagerTest.ReversePath [ OK ] FunctionManagerTest.ReversePath (0 ms) [ RUN ] FunctionManagerTest.DataSetRowCol [ OK ] FunctionManagerTest.DataSetRowCol (0 ms) [ RUN ] FunctionManagerTest.PurityTest [ OK ] FunctionManagerTest.PurityTest (0 ms) [----------] 11 tests from FunctionManagerTest (5 ms total) [----------] Global test environment tear-down [==========] 11 tests from 1 test suite ran. (5 ms total) [ PASSED ] 11 tests. 成功！ 于是，我把新的更改提交到远程分支上，在 PR 的网页中，可以看到 CI 已经在新的提交的触发下重新编译、执行了，过一会儿果然都 pass 了，于是我兴高采烈地等待着两位以上的审查者帮忙批准代码，然后合并它！ 但是，我收到了新的建议： 另一位贡献者请我添加 TCK 的测试用例。 5.2.2 TCKTCK 的全称是 The Cypher Technology Compatibility Kit，它是 NebulaGraph 从 OpenCypher 社区继承演进而来的一套测试框架，我们用 Python 做了测试用例格式兼容的实现。 它的优雅在于，我们可以像写英语一样去描述我们想实现的端到端功能测试用例，像这样！ # tests/tck/features/function/json_extract.feature Feature: json_extract Function Background: Test json_extract function Scenario: Test Positive Cases When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": \"foo\", \"b\": 0.2, \"c\": true}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: \"foo\", b: 0.2, c: true} | When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": 1, \"b\": {}, \"c\": {\"d\": true}}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: 1, b: {}, c: {d: true}} | When executing query: \"\"\" YIELD JSON_EXTRACT('{}') AS result; \"\"\" Then the result should be, in any order: | result | | {} | 在添加了自己的一个新的 tck 测试用例文本文件之后，我们只需要在测试文件中临时增加标签，并在执行的时候指定标签，就可以单独执行新增的 tck 测试用例了： # 还是在编译容器内部，进入到 tests 目录下 cd ../tests # 安装 tck 测试所需依赖 python3 -m pip install -r requirements.txt python3 -m pip install nebula3-python==3.1.0 # 运行一个单独为 tck 测试准备的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true up # 给 tests/tck/features/function/json_extract.feature 以@开头第一行加上标签，比如 @wey vi tests/tck/features/function/json_extract.feature # 执行 pytest (包含 tck 用例)，因为制定了 -m \"wey\"，只有 tests/tck/features/function/json_extract.feature 会被执行 python3 -m pytest -m \"wey\" # 关闭 pytest 所依赖的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true down 延伸阅读： 基于 BDD 理论的 Nebula 集成测试框架重构，https://nebula-graph.com.cn/posts/bdd-testing-pract","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#tck"},{"categories":["Nebula Graph"],"content":" 5.3 邀请再次 review待我们把需要的测试调通、再次提交 PR 并且 CI 用例全都通过之后，我们可以再次邀请之前帮助审查代码的同学做做最后的查看，如果一切都顺利，代码就会被合并了！ 题图来自 Jon ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#邀请再次-review"},{"categories":["Nebula Graph"],"content":"本文旨在帮助 NebulaGraph 新手快速了解查询语句调优，读懂查询计划。","date":"2022-09-06","objectID":"/ngql-execution-plan/","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/"},{"categories":["Nebula Graph"],"content":" 本文旨在帮助 NebulaGraph 新手快速了解查询语句调优，读懂查询计划。 很长时间以来，NebulaGraph 社区里最热门之一的话题都是“我如何表达这样的查询最好？“，”我这个查询还有优化空间吗？“这一类的。今天，我就试着介绍一下如何理解查询语句的执行与优化过程，帮助大家脚踩在地上去写自己的查询语句。 同时，这篇文章也是 nGQL 简明教程系列的第二期，通过本文了解面向性能去写查询语句之后，我们在进行图建模的过程（第三期的内容）中也能有更多支撑。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:0:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#"},{"categories":["Nebula Graph"],"content":" 1 一个查询的一生先从一个查询语句从进入 NebulaGraph 一直到返回查询结果的全过程。 在开始之前，推荐阅读如下源码解读、架构设计的文章： 参考文章 https://nebula-graph.com.cn/posts/nebula-graph-architecture-overview https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-01 https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-02 https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-03 https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-04 https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-05 https://nebula-graph.com.cn/posts/how-indexing-works-in-nebula-graph 简单来说，一个查询语句被从 GraphClient 发送给 GraphD 之后，经历了： 在 Parser 中被解析成抽象语法树(AST) 在 Validator, Planner 中被写成执行计划图，图中的每一个顶点 PlanNode 对应着一种算子 通过 Optimizer 中的优化规则（RBO）改写执行计划图 优化过的计划图被执行引擎从图的叶子节点开始执行直到根部 的过程： 举一个例子，在查年龄大于 34 岁的三跳好友的语句被查询之后 GO 3 STEPS FROM \"player100\" OVER follow WHERE $$.player.age \u003e 34 YIELD DISTINCT $$.player.name AS name, $$.player.age AS age | ORDER BY $-.age ASC, $-.name DESC; 语句经过了解析、验证、优化之后，最终的执行计划是， Start -\u003e Loop -\u003e Start -\u003e GetNeighbors -\u003e Project -\u003e Dedup -\u003e Loop -\u003e GetNeighbors -\u003e Project -\u003e GetVertices -\u003e Project -\u003e LeftJoin -\u003e Filter -\u003e Project -\u003e Dedup -\u003e Sort，或者如下图所示。 了解这个优化过程和最终执行计划意味着什么是调优查询、面向性能设计图建模的关键。 这个计划图由添加了 PROFILE FORMAT=\"DOT\" 的执行结果中的 digraph 部分，借助 graphviz 渲染而得，的https://dreampuf.github.io/GraphvizOnline 是一个方便的线上渲染的工具。 另外，值得注意的是，FORMAT=\"DOT\" 省略之后的输出结果是表格形式的，并且，有更多信息会展示出来，后边我们会解读。 (root@nebula) [basketballplayer]\u003e PROFILE FORMAT=\"DOT\" GO 3 STEPS FROM \"player100\" OVER follow WHERE $$.player.age \u003e 34 YIELD DISTINCT $$.player.name AS name, $$.player.age AS age | ORDER BY $-.age ASC, $-.name DESC; +-----------------+-----+ | name | age | +-----------------+-----+ | \"Tony Parker\" | 36 | | \"Manu Ginobili\" | 41 | | \"Tim Duncan\" | 42 | +-----------------+-----+ Got 3 rows (time spent 8885/19871 us) Execution Plan (optimize time 1391 us) ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ plan ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ digraph exec_plan { rankdir=BT; \"Sort_14\"[label=\"{Sort_14|outputVar: \\{\\\"colNames\\\":\\[\\\"name\\\",\\\"age\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Sort_14\\\"\\}|inputVar: __Dedup_13}\", shape=Mrecord]; \"Dedup_13\"-\u003e\"Sort_14\"; \"Dedup_13\"[label=\"{Dedup_13|outputVar: \\{\\\"colNames\\\":\\[\\\"name\\\",\\\"age\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Dedup_13\\\"\\}|inputVar: __Project_12}\", shape=Mrecord]; \"Project_12\"-\u003e\"Dedup_13\"; \"Project_12\"[label=\"{Project_12|outputVar: \\{\\\"colNames\\\":\\[\\\"name\\\",\\\"age\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Project_12\\\"\\}|inputVar: __Filter_11}\", shape=Mrecord]; \"Filter_11\"-\u003e\"Project_12\"; \"Filter_11\"[label=\"{Filter_11|outputVar: \\{\\\"colNames\\\":\\[\\\"JOIN_DST_VID\\\",\\\"__COL_0\\\",\\\"__COL_1\\\",\\\"DST_VID\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Filter_11\\\"\\}|inputVar: __LeftJoin_10}\", shape=Mrecord]; \"LeftJoin_10\"-\u003e\"Filter_11\"; \"LeftJoin_10\"[label=\"{LeftJoin_10|outputVar: \\{\\\"colNames\\\":\\[\\\"JOIN_DST_VID\\\",\\\"__COL_0\\\",\\\"__COL_1\\\",\\\"DST_VID\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__LeftJoin_10\\\"\\}|inputVar: \\{\\\"rightVar\\\":\\{\\\"__Project_9\\\":0\\},\\\"leftVar\\\":\\{\\\"__Project_7\\\":0\\}\\}}\", shape=Mrecord]; \"Project_9\"-\u003e\"LeftJoin_10\"; \"Project_9\"[label=\"{Project_9|outputVar: \\{\\\"colNames\\\":\\[\\\"__COL_0\\\",\\\"__COL_1\\\",\\\"DST_VID\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Project_9\\\"\\}|inputVar: __GetVertices_8}\", shape=Mrecord]; \"GetVertices_8\"-\u003e\"Project_9\"; \"GetVertices_8\"[label=\"{GetVertices_8|outputVar: \\{\\\"colNames\\\":\\[\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__GetVertices_8\\\"\\}|inputVar: __Project_7}\", shape=Mrecord]; \"Project_7\"-\u003e\"GetVertices_8\"; \"Project_7\"[label=\"{Project_7|outputVar: \\{\\\"colNames\\\":\\[\\","date":"2022-09-06","objectID":"/ngql-execution-plan/:1:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#一个查询的一生"},{"categories":["Nebula Graph"],"content":" 1.1 查询计划为了理解一个查询在整个生命周期中，如何反应到执行层面，以及它们的性能代价是多少，我们从认识它的执行计划开始入手。 以前边的图的拓展的 GO 语句为例，它的整个过程经历了如下节点 GetNeighbors 是执行计划中最重要的节点，GetNeighbors 算子会在运行期访问存储服务，拿到通过起点和指定边类型一步拓展后终点的 id 多步拓展通过 Loop 节点实现，Start 到 Loop 之间是 Loop 子计划，当满足条件时 Loop 子计划会被循环执行，最后一步拓展节点在 Loop 外实现 Project 节点用来获取当前拓展的终点 id Dedup 节点对终点 id 进行去重后作为下一步拓展的起点 GetVertices 节点负责取终点 tag 的属性 Filter 做条件过滤 LeftJoin 的作用是合并 GetNeightbors 和 GetVertices 的结果 Sort 做排序 而这些节点就是不同的算子。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:1:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#查询计划"},{"categories":["Nebula Graph"],"content":" 2 认识算子在 NebulaGraph 博客的代码解读文章中已经有很多算子被提及、解释过，这里列举其中部分常见的算子： 注：这里没有提及 GET SUBGRAPH/ FIND PATH 中的算子。 算子 介绍 GetNeighbor 根据指定的 vid ，从存储层获取起始点和边的属性 Traverse 仅用于MATCH 匹配 ()-[e:0..n]-() 模式，获取拓展过程中的起始点和边的属性 AppendVertices 仅用于MATCH ，和 Traverse 配合获取点的属性 GetEdge 获取边的属性 GetVertices 获取点的属性，FETCH PROP 或者 GO 语句中。 ScanEdge 全表扫描边，例如 MATCH ()-[e]-\u003e() RETURN e LIMIT 3 ScanVertices 全表扫描点，例如 MATCH (v) return v LIMIT 3 IndexScan MATCH 语句中找到起始点的索引查询 TagIndexPrefixScan LOOKUP 语句中前缀扫描 LOOKUP ON player where player.name == \"Steve Nash\" YIELD player.name TagIndexRangeScan LOOKUP 语句中范围扫描 LOOKUP ON player where player.name \u003e \"S\" YIELD player.name TagIndexFullScan LOOKUP 语句中全扫描 LOOKUP ON player YIELD player.name Filter 按条件过滤，例如 WHERE 语句 Project 获取上一步算子的列 Dedup 去重 LeftJoin 合并结果 LIMIT 限制输出行数 从这些算子的含义中已经可以更加具体的知道图数据库查询落到查询引擎（GraphD）内部的最小所需操作了，而性能调优的关键就在于如何规划、优化一个查询如何被拆解为算子的执行计划。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:2:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#认识算子"},{"categories":["Nebula Graph"],"content":" 3 认识优化规则对于任何给定的查询，执行计划并不是唯一确定的，相反，在最简单、直接的计划基础之上，优化器（Optimizer）会进行很多性能上的优化。 NebulaGraph 目前的优化器是完全的基于规则的优化（RBO），这些预设的规则的代码都在 src/graph/optimizer 的 rules 里边，它们都是针对执行计划模式的修改规则，之前 Shylock 在这篇文章里给过源码层面的介绍，大家可以去读一下。 值得庆幸的是，今年，大部分优化规则的代码里增加了很多好理解的 asciiart 图形注释，结合优化规则的命名本身的自解释性，我们可以很快速去大概理解优化规则的匹配规则和转换逻辑。 首先，这些规则的转换(transform)代码都在 .cpp 文件里，asciiart 图形注释在同名对应的 .h 里！ ls src/graph/optimizer/rule/*.h src/graph/optimizer/rule/CollapseProjectRule.h src/graph/optimizer/rule/PushFilterDownLeftJoinRule.h src/graph/optimizer/rule/CombineFilterRule.h src/graph/optimizer/rule/PushFilterDownNodeRule.h src/graph/optimizer/rule/EdgeIndexFullScanRule.h src/graph/optimizer/rule/PushFilterDownProjectRule.h src/graph/optimizer/rule/EliminateAppendVerticesRule.h src/graph/optimizer/rule/PushFilterDownScanVerticesRule.h src/graph/optimizer/rule/EliminateRowCollectRule.h src/graph/optimizer/rule/PushLimitDownGetNeighborsRule.h src/graph/optimizer/rule/GeoPredicateEdgeIndexScanRule.h src/graph/optimizer/rule/PushLimitDownIndexScanRule.h src/graph/optimizer/rule/GeoPredicateIndexScanBaseRule.h src/graph/optimizer/rule/PushLimitDownProjectRule.h src/graph/optimizer/rule/GeoPredicateTagIndexScanRule.h src/graph/optimizer/rule/PushLimitDownScanAppendVerticesRule.h src/graph/optimizer/rule/GetEdgesTransformAppendVerticesLimitRule.h src/graph/optimizer/rule/PushLimitDownScanEdgesAppendVerticesRule.h src/graph/optimizer/rule/GetEdgesTransformRule.h src/graph/optimizer/rule/PushLimitDownScanEdgesRule.h src/graph/optimizer/rule/GetEdgesTransformUtils.h src/graph/optimizer/rule/PushStepLimitDownGetNeighborsRule.h src/graph/optimizer/rule/IndexFullScanBaseRule.h src/graph/optimizer/rule/PushStepSampleDownGetNeighborsRule.h src/graph/optimizer/rule/IndexScanRule.h src/graph/optimizer/rule/PushTopNDownIndexScanRule.h src/graph/optimizer/rule/MergeGetNbrsAndDedupRule.h src/graph/optimizer/rule/PushVFilterDownScanVerticesRule.h src/graph/optimizer/rule/MergeGetNbrsAndProjectRule.h src/graph/optimizer/rule/RemoveNoopProjectRule.h src/graph/optimizer/rule/MergeGetVerticesAndDedupRule.h src/graph/optimizer/rule/RemoveProjectDedupBeforeGetDstBySrcRule.h src/graph/optimizer/rule/MergeGetVerticesAndProjectRule.h src/graph/optimizer/rule/TagIndexFullScanRule.h src/graph/optimizer/rule/OptimizeEdgeIndexScanByFilterRule.h src/graph/optimizer/rule/TopNRule.h src/graph/optimizer/rule/OptimizeTagIndexScanByFilterRule.h src/graph/optimizer/rule/UnionAllEdgeIndexScanRule.h src/graph/optimizer/rule/PushEFilterDownRule.h src/graph/optimizer/rule/UnionAllIndexScanBaseRule.h src/graph/optimizer/rule/PushFilterDownAggregateRule.h src/graph/optimizer/rule/UnionAllTagIndexScanRule.h src/graph/optimizer/rule/PushFilterDownGetNbrsRule.h ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#认识优化规则"},{"categories":["Nebula Graph"],"content":" 3.1 GetEdgesTransformRule我们看下这个规则名字的意思是转换 GetEdges 的规则，看起来不够明确，再看看 GetEdgesTransformRule.h // Convert [[ScanVertices]] to [[ScanEdges]] in certain cases // Required conditions: // 1. Match the pattern // Benefits: // 1. Avoid doing Traverse to optimize performance // Quey example: // 1. match ()-[e]-\u003e() return e limit 3 // // Tranformation: // Before: // +---------+---------+ // | Project | // +---------+---------+ // | // +---------+---------+ // | Limit | // +---------+---------+ // | // +---------+---------+ // | Traverse | // +---------+---------+ // | // +---------+---------+ // | ScanVertices | // +---------+---------+ // // After: // +---------+---------+ // | Project | // +---------+---------+ // | // +---------+---------+ // | Limit | // +---------+---------+ // | // +---------+---------+ // | Project | // +---------+---------+ // | // +---------+---------+ // | ScanEdges | // +---------+---------+ 结合 .cpp 中 GetEdgesTransformRule::match 和 GetEdgesTransformRule::transform 的代码，我们可以确定这个优化规则是将 MATCH ()-[e]-\u003e() RETURN e LIMIT 3 原本按照 ScanVertices 去扫描顶点的起点转变为 ScanEdges。 这个规则的背景是没有点、边索引的 LIMIT 情况下，无起点 VID/属性条件的查询是可以通过扫点边数据下推 LIMIT 的，这个扫描边的查询因为只需要返回边，所以直接扫描边是更高效的。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#getedgestransformrule"},{"categories":["Nebula Graph"],"content":" 3.2 PushLimitDownScanEdgesRule我们看看这个规则，在 PushLimitDownScanEdgesRule.h 里有注释 // Embedding limit to [[ScanEdges]] // Required conditions: // 1. Match the pattern // Benefits: // 1. Limit data early to optimize performance // // Transformation: // Before: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | ScanEdges | // +---------+---------+ // // After: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | ScanEdges | // | (limit=3) | // +---------+---------+ 这个规则很简单，当 ScanEdges 算子的下游是 Limit 算子的时候，把 Limit 的过滤条件嵌入到 ScanEdges 之中。这一步的意义是什么呢？这里涉及到一个优化规则里常见的概念，计算下推。 3.2.1 计算下推在计算存储分离的数据库系统中，涉及到读取数据的算子需要从存储层远程捞取数据再做进一步处理。而这个 RPC 的数据传输常常成为性能的瓶颈。然而，如果下一步计算要做的事情是对数据的按条件剪枝，例如 Filter、 Limit、TopN 等等，这时候，让这些剪枝条件在存储层捞数据的时候就考虑到，则可以大大减少数据传输的量。 PushLimitDownScanEdgesRule.h 的优化规则就是一个典型的 Limit 下推（Push Down）的规则。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#pushlimitdownscanedgesrule"},{"categories":["Nebula Graph"],"content":" 3.2 PushLimitDownScanEdgesRule我们看看这个规则，在 PushLimitDownScanEdgesRule.h 里有注释 // Embedding limit to [[ScanEdges]] // Required conditions: // 1. Match the pattern // Benefits: // 1. Limit data early to optimize performance // // Transformation: // Before: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | ScanEdges | // +---------+---------+ // // After: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | ScanEdges | // | (limit=3) | // +---------+---------+ 这个规则很简单，当 ScanEdges 算子的下游是 Limit 算子的时候，把 Limit 的过滤条件嵌入到 ScanEdges 之中。这一步的意义是什么呢？这里涉及到一个优化规则里常见的概念，计算下推。 3.2.1 计算下推在计算存储分离的数据库系统中，涉及到读取数据的算子需要从存储层远程捞取数据再做进一步处理。而这个 RPC 的数据传输常常成为性能的瓶颈。然而，如果下一步计算要做的事情是对数据的按条件剪枝，例如 Filter、 Limit、TopN 等等，这时候，让这些剪枝条件在存储层捞数据的时候就考虑到，则可以大大减少数据传输的量。 PushLimitDownScanEdgesRule.h 的优化规则就是一个典型的 Limit 下推（Push Down）的规则。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#计算下推"},{"categories":["Nebula Graph"],"content":" 3.3 PushLimitDownProjectRule类似的，我们看看这个规则，PushLimitDownProjectRule.h 里有这样一段注释，这个规则只是把 Project 算子 之后的 Limit 算子的顺序调换了一下，我们可以想象在这个变换之后，Limit 就和 ScanEdges 等其他可以下推 Limit 的算子相邻了，然后例如 PushLimitDownScanEdgesRule 的规则变换也可以做了。 // Push [[Limit]] down [[Project]] // Required conditions: // 1. Match the pattern // Benefits: // 1. Limit data early to optimize performance // // Tranformation: // Before: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | Project | // +---------+---------+ // // After: // +---------+---------+ // | Project | // +---------+---------+ // | // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:3","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#pushlimitdownprojectrule"},{"categories":["Nebula Graph"],"content":" 3.4 PushFilterDownGetNbrsRule再介绍一个 Filter 下推的例子，从规则注释里的转换图示可以读出，当 GetNeighbors 之后再双条件交集 Filter 的时候，取一个条件下推到 GetNeighbors，再进行另一个条件的 Filter。这个规则既减少了 GetNeighbors 数据传输的量和 Filter 输入的运算量、又少了一次集合运算。 // Embed the [[Filter]] into [[GetNeighbors]] // Required conditions: // 1. Match the pattern // 2. Filter contains subexpressions that meet pushdown conditions // Benefits: // 1. Filter data early to optimize performance // // Tranformation: // Before: // // +------------------+------------------+ // | Filter | // |($^.player.age\u003e3 and $$.player.age\u003c4)| // +------------------+------------------+ // | // +------+------+ // | GetNeighbors| // +------+------+ // // After: // // +--------+--------+ // | Filter | // |($$.player.age\u003c4)| // +--------+--------+ // | // +--------+--------+ // | GetNeighbors | // |($^.player.age\u003e3)| // +--------+--------+ 3.4.1 下一步 感兴趣的同学可以试着进一步看看所有的规则。 可以试着在多个 GraphD 的集群上，更改其中一个 GraphD 的配置，关闭 enable_optimizer，把同一个 Query 分别在开启了优化和关闭优化的 GraphD 中执行，比较执行计划的区别。 如果你发现可以更优化的规则给到大家，欢迎来论坛、github 提交优化建议、或者 PR！ 简单的介绍就到这里，接下来我们从一些实例出发来进一步实操执行计划调优吧。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#pushfilterdowngetnbrsrule"},{"categories":["Nebula Graph"],"content":" 3.4 PushFilterDownGetNbrsRule再介绍一个 Filter 下推的例子，从规则注释里的转换图示可以读出，当 GetNeighbors 之后再双条件交集 Filter 的时候，取一个条件下推到 GetNeighbors，再进行另一个条件的 Filter。这个规则既减少了 GetNeighbors 数据传输的量和 Filter 输入的运算量、又少了一次集合运算。 // Embed the [[Filter]] into [[GetNeighbors]] // Required conditions: // 1. Match the pattern // 2. Filter contains subexpressions that meet pushdown conditions // Benefits: // 1. Filter data early to optimize performance // // Tranformation: // Before: // // +------------------+------------------+ // | Filter | // |($^.player.age\u003e3 and $$.player.age\u003c4)| // +------------------+------------------+ // | // +------+------+ // | GetNeighbors| // +------+------+ // // After: // // +--------+--------+ // | Filter | // |($$.player.age\u003c4)| // +--------+--------+ // | // +--------+--------+ // | GetNeighbors | // |($^.player.age\u003e3)| // +--------+--------+ 3.4.1 下一步 感兴趣的同学可以试着进一步看看所有的规则。 可以试着在多个 GraphD 的集群上，更改其中一个 GraphD 的配置，关闭 enable_optimizer，把同一个 Query 分别在开启了优化和关闭优化的 GraphD 中执行，比较执行计划的区别。 如果你发现可以更优化的规则给到大家，欢迎来论坛、github 提交优化建议、或者 PR！ 简单的介绍就到这里，接下来我们从一些实例出发来进一步实操执行计划调优吧。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#下一步"},{"categories":["Nebula Graph"],"content":" 4 nGQL 执行计划调优解读实例希望这些具体问题能够给大家带来启发。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#ngql-执行计划调优解读实例"},{"categories":["Nebula Graph"],"content":" 4.1 观察基于索引与数据的扫描我在索引详解中解释过 NebulaGraph 的索引和传统数据库中索引的区别，简单来说，因为以类似于邻接表的方式存储数据，NebulaGraph 里需要明确指定额外创建索引来解决全扫描或者根据属性条件扫描点、边的类似于表结构数据库中的场景。 另外，在无过滤条件 Limit 采样扫描的场景下，NebulaGraph 从 v3.0 以后允许了无索引的查询情形（因为点边数据扫描支持了 Limit 下推，不再像之前那么昂贵），在没有索引可以被选择的情况下，planner 也会选择直接扫点或者边的数据，这个差别可以从 explain, profile 中看出来。 这里用 Basketballplayer 数据集中自带的索引来距离，注意到其中只在 player 这个 TAG 上有两个索引： (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 4.1.1 无索引查询先看一个没有索引的场景的查询： (root@nebula) [basketballplayer]\u003e PROFILE MATCH (n:team) RETURN id(n) LIMIT 1 +-----------+ | id(n) | +-----------+ | \"team206\" | +-----------+ Got 1 rows (time spent 3637/17551 us) Execution Plan (optimize time 265 us) -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 15 | Project | 16 | ver: 0, rows: 1, execTime: 28us, totalTime: 29us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"id(n)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_8\" | | | | | | } | | | | | | inputVar: __Limit_13 | | | | | | columns: [ | | | | | | \"id($-.n)\" | | | | | | ] | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 16 | Limit | 17 | ver: 0, rows: 1, execTime: 3us, totalTime: 8us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Limit_13\" | | | | | | } | | | | | | inputVar: __AppendVertices_17 | | | | | | offset: 0 | | | | | | count: 1 | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 17 | AppendVertices | 18 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 244us, totalTime: 1124us | \"colNames\": [ | | | | | \"storaged0\":9779 exec/total: 257(us)/779(us) | \"n\" | | | | | \"storaged2\":9779 exec/total: 190(us)/870(us) | ], | | | | | total_rpc: 1024(us) | \"type\": \"DATASET\", | | | | | \"storaged1\":9779 exec/total: 195(us)/879(us) | \"name\": \"__AppendVertices_17\" | | | | | } | } | | | | | | inputVar: __ScanVertices_18 | | | | | | space: 2 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: $-._vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 3 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 4 | | | | | | } | | | | | | ] | | | | | | exprs: | | | | | | vertex_filter: | | | | | | if_track_previous_path: false | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 18 | ScanVertices | 3 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 225us, totalTime: 1586us | \"colNames\": [ | | | | | \"storaged2\":9779 exec/total: 532(us)/1303(us) | \"_vid\", | | | | | \"storaged1\":9779 exec/total: 480(us)/1318(us) | \"team._tag\" | | | | | total_rpc: 1502(us) | ], | | | | | \"storaged0\":9779 exec/total: 506(us)/1382(us) | \"type\": \"DATASET\", | | | | | } | \"name\": \"__ScanVertices_18\" | | | | | | } | | | | | | inputVar: | | | | | | space: 2 | | | | | | dedup: false | | | | | | limit: 1 | | | | | | filter: (team._tag IS NOT EMPTY AND team._tag IS NOT EMPTY) | | | | | | orderBy: [] | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#观察基于索引与数据的扫描"},{"categories":["Nebula Graph"],"content":" 4.1 观察基于索引与数据的扫描我在索引详解中解释过 NebulaGraph 的索引和传统数据库中索引的区别，简单来说，因为以类似于邻接表的方式存储数据，NebulaGraph 里需要明确指定额外创建索引来解决全扫描或者根据属性条件扫描点、边的类似于表结构数据库中的场景。 另外，在无过滤条件 Limit 采样扫描的场景下，NebulaGraph 从 v3.0 以后允许了无索引的查询情形（因为点边数据扫描支持了 Limit 下推，不再像之前那么昂贵），在没有索引可以被选择的情况下，planner 也会选择直接扫点或者边的数据，这个差别可以从 explain, profile 中看出来。 这里用 Basketballplayer 数据集中自带的索引来距离，注意到其中只在 player 这个 TAG 上有两个索引： (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 4.1.1 无索引查询先看一个没有索引的场景的查询： (root@nebula) [basketballplayer]\u003e PROFILE MATCH (n:team) RETURN id(n) LIMIT 1 +-----------+ | id(n) | +-----------+ | \"team206\" | +-----------+ Got 1 rows (time spent 3637/17551 us) Execution Plan (optimize time 265 us) -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 15 | Project | 16 | ver: 0, rows: 1, execTime: 28us, totalTime: 29us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"id(n)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_8\" | | | | | | } | | | | | | inputVar: __Limit_13 | | | | | | columns: [ | | | | | | \"id($-.n)\" | | | | | | ] | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 16 | Limit | 17 | ver: 0, rows: 1, execTime: 3us, totalTime: 8us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Limit_13\" | | | | | | } | | | | | | inputVar: __AppendVertices_17 | | | | | | offset: 0 | | | | | | count: 1 | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 17 | AppendVertices | 18 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 244us, totalTime: 1124us | \"colNames\": [ | | | | | \"storaged0\":9779 exec/total: 257(us)/779(us) | \"n\" | | | | | \"storaged2\":9779 exec/total: 190(us)/870(us) | ], | | | | | total_rpc: 1024(us) | \"type\": \"DATASET\", | | | | | \"storaged1\":9779 exec/total: 195(us)/879(us) | \"name\": \"__AppendVertices_17\" | | | | | } | } | | | | | | inputVar: __ScanVertices_18 | | | | | | space: 2 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: $-._vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 3 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 4 | | | | | | } | | | | | | ] | | | | | | exprs: | | | | | | vertex_filter: | | | | | | if_track_previous_path: false | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 18 | ScanVertices | 3 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 225us, totalTime: 1586us | \"colNames\": [ | | | | | \"storaged2\":9779 exec/total: 532(us)/1303(us) | \"_vid\", | | | | | \"storaged1\":9779 exec/total: 480(us)/1318(us) | \"team._tag\" | | | | | total_rpc: 1502(us) | ], | | | | | \"storaged0\":9779 exec/total: 506(us)/1382(us) | \"type\": \"DATASET\", | | | | | } | \"name\": \"__ScanVertices_18\" | | | | | | } | | | | | | inputVar: | | | | | | space: 2 | | | | | | dedup: false | | | | | | limit: 1 | | | | | | filter: (team._tag IS NOT EMPTY AND team._tag IS NOT EMPTY) | | | | | | orderBy: [] | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#无索引查询"},{"categories":["Nebula Graph"],"content":" 4.1 观察基于索引与数据的扫描我在索引详解中解释过 NebulaGraph 的索引和传统数据库中索引的区别，简单来说，因为以类似于邻接表的方式存储数据，NebulaGraph 里需要明确指定额外创建索引来解决全扫描或者根据属性条件扫描点、边的类似于表结构数据库中的场景。 另外，在无过滤条件 Limit 采样扫描的场景下，NebulaGraph 从 v3.0 以后允许了无索引的查询情形（因为点边数据扫描支持了 Limit 下推，不再像之前那么昂贵），在没有索引可以被选择的情况下，planner 也会选择直接扫点或者边的数据，这个差别可以从 explain, profile 中看出来。 这里用 Basketballplayer 数据集中自带的索引来距离，注意到其中只在 player 这个 TAG 上有两个索引： (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 4.1.1 无索引查询先看一个没有索引的场景的查询： (root@nebula) [basketballplayer]\u003e PROFILE MATCH (n:team) RETURN id(n) LIMIT 1 +-----------+ | id(n) | +-----------+ | \"team206\" | +-----------+ Got 1 rows (time spent 3637/17551 us) Execution Plan (optimize time 265 us) -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 15 | Project | 16 | ver: 0, rows: 1, execTime: 28us, totalTime: 29us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"id(n)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_8\" | | | | | | } | | | | | | inputVar: __Limit_13 | | | | | | columns: [ | | | | | | \"id($-.n)\" | | | | | | ] | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 16 | Limit | 17 | ver: 0, rows: 1, execTime: 3us, totalTime: 8us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Limit_13\" | | | | | | } | | | | | | inputVar: __AppendVertices_17 | | | | | | offset: 0 | | | | | | count: 1 | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 17 | AppendVertices | 18 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 244us, totalTime: 1124us | \"colNames\": [ | | | | | \"storaged0\":9779 exec/total: 257(us)/779(us) | \"n\" | | | | | \"storaged2\":9779 exec/total: 190(us)/870(us) | ], | | | | | total_rpc: 1024(us) | \"type\": \"DATASET\", | | | | | \"storaged1\":9779 exec/total: 195(us)/879(us) | \"name\": \"__AppendVertices_17\" | | | | | } | } | | | | | | inputVar: __ScanVertices_18 | | | | | | space: 2 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: $-._vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 3 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 4 | | | | | | } | | | | | | ] | | | | | | exprs: | | | | | | vertex_filter: | | | | | | if_track_previous_path: false | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 18 | ScanVertices | 3 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 225us, totalTime: 1586us | \"colNames\": [ | | | | | \"storaged2\":9779 exec/total: 532(us)/1303(us) | \"_vid\", | | | | | \"storaged1\":9779 exec/total: 480(us)/1318(us) | \"team._tag\" | | | | | total_rpc: 1502(us) | ], | | | | | \"storaged0\":9779 exec/total: 506(us)/1382(us) | \"type\": \"DATASET\", | | | | | } | \"name\": \"__ScanVertices_18\" | | | | | | } | | | | | | inputVar: | | | | | | space: 2 | | | | | | dedup: false | | | | | | limit: 1 | | | | | | filter: (team._tag IS NOT EMPTY AND team._tag IS NOT EMPTY) | | | | | | orderBy: [] | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#有索引查询limit-无下推"},{"categories":["Nebula Graph"],"content":" 4.1 观察基于索引与数据的扫描我在索引详解中解释过 NebulaGraph 的索引和传统数据库中索引的区别，简单来说，因为以类似于邻接表的方式存储数据，NebulaGraph 里需要明确指定额外创建索引来解决全扫描或者根据属性条件扫描点、边的类似于表结构数据库中的场景。 另外，在无过滤条件 Limit 采样扫描的场景下，NebulaGraph 从 v3.0 以后允许了无索引的查询情形（因为点边数据扫描支持了 Limit 下推，不再像之前那么昂贵），在没有索引可以被选择的情况下，planner 也会选择直接扫点或者边的数据，这个差别可以从 explain, profile 中看出来。 这里用 Basketballplayer 数据集中自带的索引来距离，注意到其中只在 player 这个 TAG 上有两个索引： (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 4.1.1 无索引查询先看一个没有索引的场景的查询： (root@nebula) [basketballplayer]\u003e PROFILE MATCH (n:team) RETURN id(n) LIMIT 1 +-----------+ | id(n) | +-----------+ | \"team206\" | +-----------+ Got 1 rows (time spent 3637/17551 us) Execution Plan (optimize time 265 us) -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 15 | Project | 16 | ver: 0, rows: 1, execTime: 28us, totalTime: 29us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"id(n)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_8\" | | | | | | } | | | | | | inputVar: __Limit_13 | | | | | | columns: [ | | | | | | \"id($-.n)\" | | | | | | ] | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 16 | Limit | 17 | ver: 0, rows: 1, execTime: 3us, totalTime: 8us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Limit_13\" | | | | | | } | | | | | | inputVar: __AppendVertices_17 | | | | | | offset: 0 | | | | | | count: 1 | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 17 | AppendVertices | 18 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 244us, totalTime: 1124us | \"colNames\": [ | | | | | \"storaged0\":9779 exec/total: 257(us)/779(us) | \"n\" | | | | | \"storaged2\":9779 exec/total: 190(us)/870(us) | ], | | | | | total_rpc: 1024(us) | \"type\": \"DATASET\", | | | | | \"storaged1\":9779 exec/total: 195(us)/879(us) | \"name\": \"__AppendVertices_17\" | | | | | } | } | | | | | | inputVar: __ScanVertices_18 | | | | | | space: 2 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: $-._vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 3 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 4 | | | | | | } | | | | | | ] | | | | | | exprs: | | | | | | vertex_filter: | | | | | | if_track_previous_path: false | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 18 | ScanVertices | 3 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 225us, totalTime: 1586us | \"colNames\": [ | | | | | \"storaged2\":9779 exec/total: 532(us)/1303(us) | \"_vid\", | | | | | \"storaged1\":9779 exec/total: 480(us)/1318(us) | \"team._tag\" | | | | | total_rpc: 1502(us) | ], | | | | | \"storaged0\":9779 exec/total: 506(us)/1382(us) | \"type\": \"DATASET\", | | | | | } | \"name\": \"__ScanVertices_18\" | | | | | | } | | | | | | inputVar: | | | | | | space: 2 | | | | | | dedup: false | | | | | | limit: 1 | | | | | | filter: (team._tag IS NOT EMPTY AND team._tag IS NOT EMPTY) | | | | | | orderBy: [] | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#有索引查询limit-下推"},{"categories":["Nebula Graph"],"content":" 4.2 观察 filter 下推我们先看看这个查询，它沿着给定起点向外图扩展的查询，根据边的属性条件过滤，返回目的点 ID： GO FROM \"player100\" OVER follow WHERE properties(edge).degree \u003e 1 YIELD follow._dst 它的执行计划是： (root@nebula) [basketballplayer]\u003e explain GO FROM \"player100\" OVER follow WHERE properties(edge).degree \u003e 1 YIELD follow._dst Execution succeeded (time spent 959/7917 us) Execution Plan (optimize time 369 us) -----+--------------+--------------+----------------+----------------------------------------- | id | name | dependencies | profiling data | operator info | -----+--------------+--------------+----------------+----------------------------------------- | 3 | Project | 2 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"follow._dst\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_3\" | | | | | | } | | | | | | inputVar: __Filter_2 | | | | | | columns: [ | | | | | | \"follow._dst\" | | | | | | ] | -----+--------------+--------------+----------------+----------------------------------------- | 2 | Filter | 1 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Filter_2\" | | | | | | } | | | | | | inputVar: __GetNeighbors_1 | | | | | | condition: (properties(EDGE).degree\u003e1) | | | | | | isStable: false | -----+--------------+--------------+----------------+----------------------------------------- | 1 | GetNeighbors | 0 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_1\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: false | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_rank\", | | | | | | \"_src\", | | | | | | \"_type\", | | | | | | \"degree\" | | | | | | ], | | | | | | \"type\": 53 | | | | | | } | | | | | | ] | | | | | | statProps: | | | | | | exprs: | | | | | | random: false | -----+--------------+--------------+----------------+----------------------------------------- | 0 | Start | | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Start_0\" | | | | | | } | -----+--------------+--------------+----------------+----------------------------------------- 可以看到，这个计划里，GetNeighboors 算子取得了所有的 player100 的出边（以及边属性），然后再通过单独 Filter 算子。 我们关注： filter: 是空的 properties(EDGE).degree\u003e1 作为 Filter 算子的条件。 这里，我们有没有可能把 Filter 下推呢？答案是可以的，只要在 WHERE 条件中提供边类型的信息，优化条件就可以把它下推到 GetNeighbors 算子： (root@nebula) [basketballplayer]\u003e explain GO FROM \"player100\" OVER follow WHERE follow.degree \u003e 1 YIELD follow._dst Execution succeeded (time spent 664/6650 us) Execution Plan (optimize time 161 us) -----+--------------+--------------+----------------+---------------------------- | id | name | dependencies | profiling data | operator info | -----+--------------+--------------+----------------+---------------------------- | 3 | Project | 4 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"follow._dst\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_3\" | | | | | | } | | | | | | inputVar: __Filter_2 | | | | | | columns: [ | | | | | | \"follow._dst\" | | | | | | ] | -----+--------------+--------------+----------------+---------------------------- | 4 | GetNeighbors | 0 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Filter_2\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: false | | | | | | limit: -1 | | | | | | filter: (follow.degree\u003e1) | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"degree\" | | | | | | ], | | | | | | \"type\": 53 | | | | | | } | | | | | | ] | | | | | | statProps:","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#观察-filter-下推"},{"categories":["Nebula Graph"],"content":" 4.3 优化原则：减少模糊，增加确定，越早越好这里我给出三对查询的比较： GO FROM \"player100\" OVER follow YIELD dst(edge) 对比 GO FROM \"player100\" OVER follow YIELD follow._dst MATCH (:player)-[e]-(:player) RETURN e 与 MATCH (:player)-[e:follow]-(:player) RETURN e 在 1. 中，两者的差异不像前文中给出的算子有不同，这次的区别在于算子传递的数据量有不同，dst(edge) 的表达里，我们一方面没有给出 edge 的类型，另一方面是针对整个 edge 做了函数 dst() 的运算，这使得 GetNeighbors 算子的 edgeProps 输出是所有的属性，反观 follow._dst 的表达使得 edgeProps 输出只有边的 _dst，这印证了在我们已知返回 follow 边的属性的情况下，提早（而不是等到语句解析到 dst(edge) 之后）而且直接用 follow._dst 表达带来了数据传输上的优化。 (root@nebula) [basketballplayer]\u003e explain GO FROM \"player100\" OVER follow YIELD dst(edge) Execution succeeded (time spent 600/7625 us) Execution Plan (optimize time 101 us) -----+--------------+--------------+----------------+------------------------------- | id | name | dependencies | profiling data | operator info | -----+--------------+--------------+----------------+------------------------------- | 2 | Project | 1 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"dst(EDGE)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_2\" | | | | | | } | | | | | | inputVar: __GetNeighbors_1 | | | | | | columns: [ | | | | | | \"dst(EDGE)\" | | | | | | ] | -----+--------------+--------------+----------------+------------------------------- | 1 | GetNeighbors | 0 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_1\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: false | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_rank\", | | | | | | \"_src\", | | | | | | \"_type\", | | | | | | \"degree\" | | | | | | ], | | | | | | \"type\": 53 | | | | | | } | | | | | | ] | | | | | | statProps: | | | | | | exprs: | | | | | | random: false | -----+--------------+--------------+----------------+------------------------------- | 0 | Start | | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Start_0\" | | | | | | } | -----+--------------+--------------+----------------+------------------------------- Tue, 13 Sep 2022 14:27:27 CST (root@nebula) [basketballplayer]\u003e explain GO FROM \"player100\" OVER follow YIELD follow._dst Execution succeeded (time spent 549/5971 us) Execution Plan (optimize time 91 us) -----+--------------+--------------+----------------+------------------------------- | id | name | dependencies | profiling data | operator info | -----+--------------+--------------+----------------+------------------------------- | 2 | Project | 1 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"follow._dst\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_2\" | | | | | | } | | | | | | inputVar: __GetNeighbors_1 | | | | | | columns: [ | | | | | | \"follow._dst\" | | | | | | ] | -----+--------------+--------------+----------------+------------------------------- | 1 | GetNeighbors | 0 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_1\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: false | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\" | | | | | | ], | | | | | | \"type\": 53 | | | | | | } | | | | | | ] | | | | | | statProps: | | | | | | exprs: | | | | | | random: false | -----+--------------+--------------+----------------+------------------------------- | 0 | Start | | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Start_0\" | | | | | | } | -----+--------------+--------------+--------------","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:3","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#优化原则减少模糊增加确定越早越好"},{"categories":["Nebula Graph"],"content":" 4.4 小练习：等价的多种表达的代价这是一个用户提的一个问题：如何表达两点之间是否存在直连边？ 对于这么简单的表达，大家应该直接能想到应该有好多方法表达： GO FIND PATH MATCH FETCH PROP 这里，利用 FETCH PROP 表达双向边，似乎是两个查询，我们先省略掉，对于剩下的三个表达，哪一种更适合呢？我们先写出来看看 GO FROM \"player100\" over * BIDIRECT WHERE id($$) == \"player101\" YIELD edge AS e FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p MATCH (n)--(m) WHERE id(n) == \"player100\" AND id(m) == \"player101\" RETURN count(*) 4.4.1 GO/MATCH 与 FIND PATH他们都能获得我们想要的信息，感觉上，MATCH 和 GO 会比 FIND PATH 的查询更快一些，因为它们都是从单一起点拓展，而 FIND PATH 是从两端同时查询，在一跳的情况下，这其实是冗余的动作。验证一下的话，我们可以看到 explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p 中果然有两个 GetNeighbors 算子。 (root@nebula) [basketballplayer]\u003e explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p Execution succeeded (time spent 818/16537 us) Execution Plan (optimize time 229 us) -----+-----------------+--------------+----------------+------------------------------------ | id | name | dependencies | profiling data | operator info | -----+-----------------+--------------+----------------+------------------------------------ | 9 | DataCollect | 8 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"p\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_9\" | | | | | | } | | | | | | inputVar: [ | | | | | | { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | ] | | | | | | distinct: false | | | | | | kind: ALL PATHS | -----+-----------------+--------------+----------------+------------------------------------ | 8 | Loop | 7 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Loop_8\" | | | | | | } | | | | | | inputVar: __VAR_1 | | | | | | condition: (++($__VAR_2)\u003c=1) | | | | | | loopBody: 5 | -----+-----------------+--------------+----------------+------------------------------------ | 5 | ProduceAllPaths | 3,4 | | branch: true, nodeId: 8 | | | | | | | | | | | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | inputVar: { | | | | | | \"rightVar\": \"__GetNeighbors_4\", | | | | | | \"leftVar\": \"__GetNeighbors_3\" | | | | | | } | | | | | | LeftNextVidVar: \"__VAR_0\" | | | | | | RightNextVidVar: \"__VAR_1\" | | | | | | noloop : false | | | | | | steps: 1 | -----+-----------------+--------------+----------------+------------------------------------ | 3 | GetNeighbors | 2 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_3\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -52 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -53 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -67 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -68 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -69 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -70 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\"","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#小练习等价的多种表达的代价"},{"categories":["Nebula Graph"],"content":" 4.4 小练习：等价的多种表达的代价这是一个用户提的一个问题：如何表达两点之间是否存在直连边？ 对于这么简单的表达，大家应该直接能想到应该有好多方法表达： GO FIND PATH MATCH FETCH PROP 这里，利用 FETCH PROP 表达双向边，似乎是两个查询，我们先省略掉，对于剩下的三个表达，哪一种更适合呢？我们先写出来看看 GO FROM \"player100\" over * BIDIRECT WHERE id($$) == \"player101\" YIELD edge AS e FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p MATCH (n)--(m) WHERE id(n) == \"player100\" AND id(m) == \"player101\" RETURN count(*) 4.4.1 GO/MATCH 与 FIND PATH他们都能获得我们想要的信息，感觉上，MATCH 和 GO 会比 FIND PATH 的查询更快一些，因为它们都是从单一起点拓展，而 FIND PATH 是从两端同时查询，在一跳的情况下，这其实是冗余的动作。验证一下的话，我们可以看到 explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p 中果然有两个 GetNeighbors 算子。 (root@nebula) [basketballplayer]\u003e explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p Execution succeeded (time spent 818/16537 us) Execution Plan (optimize time 229 us) -----+-----------------+--------------+----------------+------------------------------------ | id | name | dependencies | profiling data | operator info | -----+-----------------+--------------+----------------+------------------------------------ | 9 | DataCollect | 8 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"p\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_9\" | | | | | | } | | | | | | inputVar: [ | | | | | | { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | ] | | | | | | distinct: false | | | | | | kind: ALL PATHS | -----+-----------------+--------------+----------------+------------------------------------ | 8 | Loop | 7 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Loop_8\" | | | | | | } | | | | | | inputVar: __VAR_1 | | | | | | condition: (++($__VAR_2)\u003c=1) | | | | | | loopBody: 5 | -----+-----------------+--------------+----------------+------------------------------------ | 5 | ProduceAllPaths | 3,4 | | branch: true, nodeId: 8 | | | | | | | | | | | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | inputVar: { | | | | | | \"rightVar\": \"__GetNeighbors_4\", | | | | | | \"leftVar\": \"__GetNeighbors_3\" | | | | | | } | | | | | | LeftNextVidVar: \"__VAR_0\" | | | | | | RightNextVidVar: \"__VAR_1\" | | | | | | noloop : false | | | | | | steps: 1 | -----+-----------------+--------------+----------------+------------------------------------ | 3 | GetNeighbors | 2 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_3\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -52 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -53 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -67 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -68 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -69 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -70 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\"","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#gomatch-与-find-path"},{"categories":["Nebula Graph"],"content":" 4.4 小练习：等价的多种表达的代价这是一个用户提的一个问题：如何表达两点之间是否存在直连边？ 对于这么简单的表达，大家应该直接能想到应该有好多方法表达： GO FIND PATH MATCH FETCH PROP 这里，利用 FETCH PROP 表达双向边，似乎是两个查询，我们先省略掉，对于剩下的三个表达，哪一种更适合呢？我们先写出来看看 GO FROM \"player100\" over * BIDIRECT WHERE id($$) == \"player101\" YIELD edge AS e FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p MATCH (n)--(m) WHERE id(n) == \"player100\" AND id(m) == \"player101\" RETURN count(*) 4.4.1 GO/MATCH 与 FIND PATH他们都能获得我们想要的信息，感觉上，MATCH 和 GO 会比 FIND PATH 的查询更快一些，因为它们都是从单一起点拓展，而 FIND PATH 是从两端同时查询，在一跳的情况下，这其实是冗余的动作。验证一下的话，我们可以看到 explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p 中果然有两个 GetNeighbors 算子。 (root@nebula) [basketballplayer]\u003e explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p Execution succeeded (time spent 818/16537 us) Execution Plan (optimize time 229 us) -----+-----------------+--------------+----------------+------------------------------------ | id | name | dependencies | profiling data | operator info | -----+-----------------+--------------+----------------+------------------------------------ | 9 | DataCollect | 8 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"p\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_9\" | | | | | | } | | | | | | inputVar: [ | | | | | | { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | ] | | | | | | distinct: false | | | | | | kind: ALL PATHS | -----+-----------------+--------------+----------------+------------------------------------ | 8 | Loop | 7 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Loop_8\" | | | | | | } | | | | | | inputVar: __VAR_1 | | | | | | condition: (++($__VAR_2)\u003c=1) | | | | | | loopBody: 5 | -----+-----------------+--------------+----------------+------------------------------------ | 5 | ProduceAllPaths | 3,4 | | branch: true, nodeId: 8 | | | | | | | | | | | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | inputVar: { | | | | | | \"rightVar\": \"__GetNeighbors_4\", | | | | | | \"leftVar\": \"__GetNeighbors_3\" | | | | | | } | | | | | | LeftNextVidVar: \"__VAR_0\" | | | | | | RightNextVidVar: \"__VAR_1\" | | | | | | noloop : false | | | | | | steps: 1 | -----+-----------------+--------------+----------------+------------------------------------ | 3 | GetNeighbors | 2 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_3\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -52 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -53 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -67 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -68 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -69 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -70 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\"","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#go-与-match"},{"categories":["Nebula Graph"],"content":" 4.4 小练习：等价的多种表达的代价这是一个用户提的一个问题：如何表达两点之间是否存在直连边？ 对于这么简单的表达，大家应该直接能想到应该有好多方法表达： GO FIND PATH MATCH FETCH PROP 这里，利用 FETCH PROP 表达双向边，似乎是两个查询，我们先省略掉，对于剩下的三个表达，哪一种更适合呢？我们先写出来看看 GO FROM \"player100\" over * BIDIRECT WHERE id($$) == \"player101\" YIELD edge AS e FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p MATCH (n)--(m) WHERE id(n) == \"player100\" AND id(m) == \"player101\" RETURN count(*) 4.4.1 GO/MATCH 与 FIND PATH他们都能获得我们想要的信息，感觉上，MATCH 和 GO 会比 FIND PATH 的查询更快一些，因为它们都是从单一起点拓展，而 FIND PATH 是从两端同时查询，在一跳的情况下，这其实是冗余的动作。验证一下的话，我们可以看到 explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p 中果然有两个 GetNeighbors 算子。 (root@nebula) [basketballplayer]\u003e explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p Execution succeeded (time spent 818/16537 us) Execution Plan (optimize time 229 us) -----+-----------------+--------------+----------------+------------------------------------ | id | name | dependencies | profiling data | operator info | -----+-----------------+--------------+----------------+------------------------------------ | 9 | DataCollect | 8 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"p\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_9\" | | | | | | } | | | | | | inputVar: [ | | | | | | { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | ] | | | | | | distinct: false | | | | | | kind: ALL PATHS | -----+-----------------+--------------+----------------+------------------------------------ | 8 | Loop | 7 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Loop_8\" | | | | | | } | | | | | | inputVar: __VAR_1 | | | | | | condition: (++($__VAR_2)\u003c=1) | | | | | | loopBody: 5 | -----+-----------------+--------------+----------------+------------------------------------ | 5 | ProduceAllPaths | 3,4 | | branch: true, nodeId: 8 | | | | | | | | | | | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | inputVar: { | | | | | | \"rightVar\": \"__GetNeighbors_4\", | | | | | | \"leftVar\": \"__GetNeighbors_3\" | | | | | | } | | | | | | LeftNextVidVar: \"__VAR_0\" | | | | | | RightNextVidVar: \"__VAR_1\" | | | | | | noloop : false | | | | | | steps: 1 | -----+-----------------+--------------+----------------+------------------------------------ | 3 | GetNeighbors | 2 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_3\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -52 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -53 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -67 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -68 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -69 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -70 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\"","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#更优的-go-表达"},{"categories":["Nebula Graph"],"content":" 4.5 索引的命中在本篇结束之前，我还想再给一个索引查询的例子，首先，假设环境里只存在 player() 和 player.name 上的索引，没有 player.age 上的索引。 (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 再次强调一下，在 NebulaGraph 中，只有无 ID 条件的起点才涉及索引，而这类起点查询其实是一个典型的非图库查询。相反，点的拓展是无关 NebulaGraph 索引的。 这里的例子也是只涉及起点查询，类似于 SELECT * FROM player WHERE ... 的表达，这三个查询 MATCH (n:player) WHERE n.player.age \u003e 50 RETURN n MATCH (n:player) WHERE n.player.name \u003e \"T\" RETURN n MATCH (n:team) WHERE n.team.name \u003e \"T\" RETURN n 之中只有 1.，2. 是允许的查询，3. 因为查询涉及数据全扫描而被 NebulaGraph 禁止，因为不存在 team 之中的索引，这样的全扫描是很昂贵的： (root@nebula) [basketballplayer]\u003e match (n:team) WHERE n.team.name \u003e \"T\" RETURN n [ERROR (-1005)]: IndexNotFound: No valid index found 而 1. 与 2. 的情况又有不同，1. 中的过滤条件 n.player.age \u003e 50 涉及未被索引的字段，这个过滤是无法被下推到 IndexScan 算子的，这意味着所有的 player 都会被扫描到 GraphD 中，然后再进一步进行 Filter 算子的过滤计算。 索引设计的文章参考：https://nebula-graph.com.cn/posts/how-indexing-works-in-nebula-graph，如下是文中介绍的点索引在 RocksDB 中的数据结构。 通过两个查询的 profile 分析，我们可以很清楚地看到： IndexScan 在 1. 查询中没有 columnHints 信息，扫描的行数为 rows: 52（这是所有的 player 顶点数量） IndexScan 在 2. 查询中有 columnHints 信息，扫描的行数只有 rows: 6 所以，我们在真的需要这种从属性反查图探索起点的时候，要根据实际查询需求去斟酌索引的创建。 (root@nebula) [basketballplayer]\u003e profile MATCH (n:player) WHERE n.player.age \u003e 50 RETURN n +---+ | n | +---+ +---+ Empty set (time spent 8468/25278 us) Execution Plan (optimize time 442 us) -----+----------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------- | 6 | Project | 5 | ver: 0, rows: 0, execTime: 19us, totalTime: 22us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_6\" | | | | | | } | | | | | | inputVar: __Filter_5 | | | | | | columns: [ | | | | | | \"$n\" | | | | | | ] | -----+----------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------- | 5 | Filter | 9 | ver: 0, rows: 0, execTime: 74us, totalTime: 75us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Filter_5\" | | | | | | } | | | | | | inputVar: __Project_4 | | | | | | condition: (n.player.age\u003e50) | | | | | | isStable: false | -----+----------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------- | 9 | AppendVertices | 7 | { | outputVar: { | | | | | ver: 0, rows: 51, execTime: 841us, totalTime: 4481us | \"colNames\": [ | | | | | total_rpc: 4018(us) | \"n\" | | | | | \"storaged1\":9779 exec/total: 1591(us)/2868(us) | ], | | | | | \"storaged0\":9779 exec/total: 1532(us)/2672(us) | \"type\": \"DATASET\", | | | | | \"storaged2\":9779 exec/total: 2510(us)/3733(us) | \"name\": \"__Project_4\" | | | | | } | } | | | | | | inputVar: __IndexScan_1 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: player._tag IS NOT EMPTY | | | | | | orderBy: [] | | | | | | src: $_vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 59 | | | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:5","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#索引的命中"},{"categories":["Nebula Graph"],"content":" 5 小结在理解了 NebulaGraph 的基本架构设计、存储格式、查询的简单调用流程和常见的优化规则之后，结合 PROFILE/EXPLAIN，我们可以一点点去设计更适合不同场景的图建模与图查询。 优化原则：减少模糊，增加确定，越早越好。 欢迎大家在本文的评论区讨论、提供更多优化查询的例子。 Feature image generated with OpenAI Dall-E, with the keyword “make potions for the nebula magic” and Outpainting. Raw image ","date":"2022-09-06","objectID":"/ngql-execution-plan/:5:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#小结"},{"categories":["Nebula Graph"],"content":"NebulaGraph 教程：一文入门图查询语句：nGQL。本文旨在让新手快速了解 nGQL，掌握方向，之后可以脚踩在地上借助文档写出任何心中的 NebulaGraph 图查询。","date":"2022-08-15","objectID":"/ngql-tutorial/","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/"},{"categories":["Nebula Graph"],"content":" 本文旨在让新手快速了解 nGQL，掌握方向，之后可以脚踩在地上借助文档写出任何心中的 NebulaGraph 图查询。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:0:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#"},{"categories":["Nebula Graph"],"content":" 1 系列教程 nGQL 简明教程，第一期，快速入门，本文 nGQL 简明教程，第二期，查询计划与调优 ","date":"2022-08-15","objectID":"/ngql-tutorial/:1:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#系列教程"},{"categories":["Nebula Graph"],"content":" 2 视频本教程的视频版在这里。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:2:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#视频"},{"categories":["Nebula Graph"],"content":" 3 开始之前本文假设你已经在文档看过快速入门流程，部署、连接过 NebulaGraph，并且看过了常用命令。如果您还没看过这两个文档，强烈建议先快速过一遍。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:3:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#开始之前"},{"categories":["Nebula Graph"],"content":" 3.1 教程目标本教程目的在于让新手大概知道了 NebulaGraph 的查询语句后，解决“不知道什么样的查询应该用什么语句”的问题。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:3:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#教程目标"},{"categories":["Nebula Graph"],"content":" 3.2 nGQL 是什么我们先强调一下概念：nGQL 是 NebulaGraph Graph Query Language 的缩写，它表示 NebulaGraph 的查询语言，而 nGQL 的语句可以不严谨地分为这几部分： NebulaGraph 独有 DQL 查询语句（Data Query Language） NebulaGraph OpenCypher DQL NebulaGraph DML 写语句（Data Mutation Language） NebulaGraph DDL Schema 语句（Data Definition Language) NebulaGraph Admin Queries 管理语句 这里，作为简明教程一把梭，我们只关注前两个部分，后边的内容会在 Part 2 中介绍。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:3:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#ngql-是什么"},{"categories":["Nebula Graph"],"content":" 3.3 nGQL 速查表 Cheatsheet 大家可以报错这份单页速查表，一次了解所有 nGQL 的用法。 原始文件链接 ","date":"2022-08-15","objectID":"/ngql-tutorial/:3:3","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#ngql-速查表-cheatsheet"},{"categories":["Nebula Graph"],"content":" 4 NebulaGraph 独有 DQLNebulaGraph 的独有读查询语句的设计非常简洁，对初学者非常友好，结合了管道的概念，做到了只涉及了几个关键词就可以描述大多数图查询模式。 用一句话描述来说，nGQL 的独有 DQL 一共分成四类语句： 图拓展：GO 索引反查：LOOKUP 取属性：FETCH PROP 路径与子图：FIND PATH 与 GET SUBGRAPH 和几个特别的元素 管道：| 引用属性: $ 开头的几个符号，用来描述一些特定的上下文 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#nebulagraph-独有-dql"},{"categories":["Nebula Graph"],"content":" 4.1 图拓展 GOGO 的语义非常直观：从给定的起点，向外拓展，按需返回终点、起点的信息。 # 图拓展 GO 3 STEPS FROM \"player102\" OVER follow YIELD dst(edge); ───┬─── ───┬─────── ─┬──── ──┬────── │ │ │ ┌─────────┘ │ │ │ │ │ │ │ └── 返回最后一跳边的终点 │ │ │ │ │ └────── 从 follow 这个边[出方向]探索 │ │ │ └───────────────────── 起点是 \"player102\" │ └────────────────────────────────── 探索 3 步 参考 GO 语句文档，了解如何： 指定反方向拓展、双向拓展 指定可变跳数拓展 基于所有类型边拓展 返回其他信息 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#图拓展-go"},{"categories":["Nebula Graph"],"content":" 4.2 LOOKUP 基于索引反查 ID和 GO 为从已知的点出发相反，LOOKUP 是一个类似于 SQL 里 SELECT 语义的关键字，它实际的作用也类似与关系型数据库中的扫表。 LOOKUP 需要手动明确建立相应 TAG、边类型上索引才能允许相应的查询。 4.2.1 为什么 LOOKUP 需要索引？因为 NebulaGraph 中的数据默认是按照邻接表的形式存储，在分布式设计中，扫描一个类型的点、边是非常昂贵的，所以它被默认禁止了。而创建相应的索引类似于增加了类似于表结构数据库的排序数据，可以用来做类似于 SELECT 的查询。 创建索引的代价是什么（增加写入负担）？索引会加速读么（不会，它是提供了 LOOKUP 的可能性，原生图的查询不需要索引加速）？等等更详细的问题请参阅我之前的索引详解文章。 # 索引反查 LOOKUP ON player WHERE player.name == \"Tony Parker\" YIELD id(vertex); ──┬─── ──────┬────────────────────────── ──┬────── │ │ ┌───────────────────┘ │ │ │ │ │ └──────────── 返回查到点的 VID │ │ │ └─────────────────────── 过滤条件是属性 name 的值 │ └─────────────────────────────────── 根据点的类别/TAG player 查询 进一步参考 LOOKUP 语句文档，了解如何： 返回属性 根据边的类型查询边 了解 LOOKUP 查询的前提、索引，索引详解 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#lookup-基于索引反查-id"},{"categories":["Nebula Graph"],"content":" 4.2 LOOKUP 基于索引反查 ID和 GO 为从已知的点出发相反，LOOKUP 是一个类似于 SQL 里 SELECT 语义的关键字，它实际的作用也类似与关系型数据库中的扫表。 LOOKUP 需要手动明确建立相应 TAG、边类型上索引才能允许相应的查询。 4.2.1 为什么 LOOKUP 需要索引？因为 NebulaGraph 中的数据默认是按照邻接表的形式存储，在分布式设计中，扫描一个类型的点、边是非常昂贵的，所以它被默认禁止了。而创建相应的索引类似于增加了类似于表结构数据库的排序数据，可以用来做类似于 SELECT 的查询。 创建索引的代价是什么（增加写入负担）？索引会加速读么（不会，它是提供了 LOOKUP 的可能性，原生图的查询不需要索引加速）？等等更详细的问题请参阅我之前的索引详解文章。 # 索引反查 LOOKUP ON player WHERE player.name == \"Tony Parker\" YIELD id(vertex); ──┬─── ──────┬────────────────────────── ──┬────── │ │ ┌───────────────────┘ │ │ │ │ │ └──────────── 返回查到点的 VID │ │ │ └─────────────────────── 过滤条件是属性 name 的值 │ └─────────────────────────────────── 根据点的类别/TAG player 查询 进一步参考 LOOKUP 语句文档，了解如何： 返回属性 根据边的类型查询边 了解 LOOKUP 查询的前提、索引，索引详解 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#为什么-lookup-需要索引"},{"categories":["Nebula Graph"],"content":" 4.3 FETCH PROP 获取属性如字面意思，如果我们知道一个点、边的 ID，想要获取它上边的属性，这时候我们要用 FETCH PROP 而非 LOOKUP。 # 取属性 FETCH PROP ON player \"player100\" YIELD properties(vertex); ──┬─── ────┬───── ─────────┬──────── │ │ ┌───────────┘ │ │ │ │ │ └─────── 返回点的 player TAG 下所有属性 │ │ │ └───────────────── 从 \"player100\" 这个点获取 │ └─────────────────────────── 获取 player 这个 TAG 下的属性 进一步参考 FETCH PROP 语句文档，了解如何： 返回某一个属性 获取给定边的属性 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:3","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#fetch-prop-获取属性"},{"categories":["Nebula Graph"],"content":" 4.4 路径查找 FIND PATH如果我们从给定的起点、终点中，找到之间的所有路径，一定要用 FIND PATH # 起点终点间路径 FIND SHORTEST PATH FROM \"player102\" TO \"team204\" OVER * \\ ──┬───── ───────────┬─────────── ───┬─── YIELD│path AS p; ┌────────────────┘ │ │────┬──── │ ┌──────────────────────────┘ │ │ │ │ │ │ │ └───────── 经由所有类型的边出向探索 │ │ │ │ │ └─────────────── 从给定的起点、终点 VID │ │ │ └────────────────────── 返回路径为 p 列 │ └─────────────────────────── 查找最短路径 进一步参考 FIND PATH 语句文档，了解如何： 返回路径中的属性 设定拓展方向 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#路径查找-find-path"},{"categories":["Nebula Graph"],"content":" 4.5 单点子图 GET SUBGRAPH和路径查找类似，但是我们只给定一个起点和拓展部署，用 GET SUBGRAPH 可以帮我们获取同样的 BFS 出去的子图 # 单点 BFS 子图 GET SUBGRAPH 5 STEPS FROM \"player101\" \\ ───┬─── ─────┬────────── YIELD VERTICES AS nodes, EDGES AS relationships; ────┬───┼─────────┼─────────────────────── ┌────────┘ │ │ │ │ └─────── 从 \"player101\" 开始触发 │ │ │ └───────────────── 获取 5 步的探索 │ └────────────────────────────── 返回所有的点、边 进一步参考 GET SUBGRAPH 语句文档，了解如何： 返回带有属性的点、边 设定拓展方向 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:5","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#单点子图-get-subgraph"},{"categories":["Nebula Graph"],"content":" 4.6 利用管道和属性引用符NebulaGraph 的管道设计和 Unix-Shell 的设计很像，可以将简单的几种语句结合起来，有强大的表达力。 # 使用通道 GO FROM \"player100\" OVER follow YIELD dst(edge) AS did | \\ ─────┬──────────────────────────────────────────── ─┬─ GO FROM│$-.did OVER follow YIELD dst(edge); │ │────┬── ┌─────────────────────────────────┘ │ │ │ │ │ └──────── 管道将左边的 AS 输出作为右边语句输入 │ │ │ └──────────────── 从管道左边的 did 属性开始探索 │ └───────────────────── 第一个查询语句 进一步参考 引用属性文档、管道文档了解： 更多属性引用定义 更多例子 结合 LOOKUP, GO, FETCH 的语句 除了以上的几种表达之外，NebulaGraph 独有查询语句还有聚合的表达参考 GROUP-BY，另外在文档里还有一个 Cheatsheet 供大家查询一些复杂一点查询的例子。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:6","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#利用管道和属性引用符"},{"categories":["Nebula Graph"],"content":" 4.7 NebulaGraph OpenCypher DQL从 2.0 起，OpenCypher 的 MATCH 语句也被 NebulaGraph 原生支持了，虽然这里是一个方言（有一些细节差异）。 MATCH \u003cpattern\u003e [\u003cclause_1\u003e] RETURN \u003coutput\u003e [\u003cclause_2\u003e]; MATCH 的基本表达是以 (v:tag_a) 包裹的点 --\u003e 或者 \u003c-[:edge_type_1]- 表达的边组成的模式，与 RETURN 表达的输出。 如果您从 Cypher 的查询语句入门图数据库，可以从下边几个例子了解到几个 NebulaGraph 里的细节差异： 增加了 WHERE id(v) == \"foo\" 的表达 == 表达相等判断而不是 = 点的属性表达需要填写 TAG，例如 v3.player.name 而不是 v3.name MATCH (v:`player`{name:\"Tim Duncan\"})--\u003e(v2)\u003c--(v3) \\ RETURN v3.`player`.name AS Name; MATCH (v:`player`) \\ WHERE NOT (v)--() \\ RETURN v; MATCH (v:`player`)--(v2) \\ WHERE id(v2) IN [\"player101\", \"player102\"] \\ RETURN v; MATCH (m)-[]-\u003e(n) WHERE id(m)==\"player100\" \\ OPTIONAL MATCH (n)-[]-\u003e(l) WHERE id(n)==\"player125\" \\ RETURN id(m), id(n), id(l); 进一步参考 MATCH 文档了解： 更多例子 可变跳数的 MATCH 表达 多 MATCH OPTIONAL MATCH 题图版权：DALL·E Open-AI，原图 The featured image was generated with keywords: learning spells of the nebula magic, with DALL·E Open-AI. ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:7","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#nebulagraph-opencypher-dql"},{"categories":["Nebula Graph"],"content":"本文是一个基于 NebulaGraph 上的图算法、图数据库、图神经网络的 ID-Mapping 方法综述，除了基本方法思想的介绍之外，我还给大家弄了可以跑的 Playground。","date":"2022-08-14","objectID":"/identity-resolution/","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/"},{"categories":["Nebula Graph"],"content":" 本文是一个基于 NebulaGraph 上的图算法、图数据库、图神经网络的 ID-Mapping 方法综述，除了基本方法思想的介绍之外，我还给大家弄了可以跑的 Playground。 本文还在撰写中，TBD 的章节还请见谅。 ","date":"2022-08-14","objectID":"/identity-resolution/:0:0","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#"},{"categories":["Nebula Graph"],"content":" 1 基于图数据库的用户 ID 识别方法用户 ID 识别，是一个很常见的图技术应用场景，在不同的语境下它可能还被叫做 Entity Correlation（实体关联）、Entity Linking（实体链接）、ID Mapping（身份映射）等等。ID 识别解决的问题是找出相同的用户在同一个系统或者不同系统中的不同账号。 由于 ID 识别天然地是一个关联关系问题，也是一个典型的图、图数据库应用场景。 ","date":"2022-08-14","objectID":"/identity-resolution/:1:0","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图数据库的用户-id-识别方法"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱 1.1.1 图建模我们从一个最简单、直接的图谱开始，如下边的图结构示意显示，我们定义了点： user Prop: [name, email, birthday, address, phone_num] phone email device ip address 在他们之间有很自然的边： used_device Prop: time logged_in_from Prop: time has_phone has_address has_email 1.1.2 数据这份数据是开源的，地址在 https://github.com/wey-gu/identity-correlation-datagen 1.1.3 写入 NebulaGraph 利用 Nebula Up，一行部署 NebulaGraph 地址：https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 图建模的 Schema 对应的 NebulaGraph DDL 是： # 创建一个叫做 entity_resolution 的图空间 CREATE SPACE entity_resolution (vid_type=FIXED_STRING(30)); USE entity_resolution; # 创建点的类型 TAG CREATE TAG `user` (`name` string NOT NULL, `email` string NOT NULL, `phone_num` string NOT NULL, `birthday` date NOT NULL, `address` string NOT NULL); CREATE TAG `address` (`address` string NOT NULL); CREATE TAG `device` (`uuid` string NOT NULL); CREATE TAG `email` (); CREATE TAG `ip` (); CREATE TAG `phone` (); # 创建边的类型 Edge Type CREATE EDGE `used_device` (`time` timestamp NOT NULL); CREATE EDGE `logged_in_from` (`time` timestamp NOT NULL); CREATE EDGE `has_phone` (); CREATE EDGE `has_address` (); CREATE EDGE `has_email` (); 对于写入数据的 DML，这里只给出 user ，email 类型点、has_email 类型边的例子 INSERT VERTEX `user` (`email`, `name`, `birthday`, `address`, `phone_num`) VALUES \"user_1\":(\"heathermoore@johnson.com\",\"Miranda Miller\",date(\"1957-08-27\"),\"Brittany Forge Apt. 718 East Eric WV 97881\",\"+1-652-450-5443x00562\"), \"user_2\":(\"holly@welch.org\",\"Holly Pollard\",date(\"1990-10-19\"),\"1 Amanda Freeway Lisaland NJ 94933\",\"600-192-2985x041\"), \"user_3\":(\"julia.h.24@gmail.com\",\"Julia Hall\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_4\":(\"franklin.b@gibson.biz\",\"Franklin Barnett\",date(\"2020-03-01\"),\"Richard Curve Kingstad AZ 05660\",\"(224)497-9312\"), \"user_5\":(\"4kelly@yahoo.com\",\"April Kelly\",date(\"1967-12-01\"),\"Schmidt Key Lake Charles AL 36174\",\"410.138.1816x98702\"), \"user_6\":(\"steven.web@johnson.com\",\"Steven Webb\",date(\"1955-04-24\"),\"5 Joanna Key Suite 704 Frankshire OK 03035\",\"3666519376\"), \"user_7\":(\"Jessica_Torres@morris.com\",\"Jessica Torres\",date(\"1958-09-03\"),\"1 Payne Circle Mitchellfort LA 73053\",\"535-357-3112x4903\"), \"user_8\":(\"brettglenn@gmail.com\",\"Brett Glenn\",date(\"1992-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660.391.3730\"), \"user_9\":(\"veronica.j@yahoo.com\",\"Veronica Jordan\",date(\"1947-06-08\"),\"2 Klein Mission New Annetteton HI 05775\",\"810-252-6218\"), \"user_10\":(\"steven@phelps-craig.info\",\"Steven Brooks\",date(\"1954-06-14\"),\"1 Vanessa Stravenue Suite 184 Baileyville NY 46381\",\"+1-665-328-8103x3448\"), \"user_11\":(\"ReginaldTheMan@hotmail.com\",\"Reginald Mccullough\",date(\"1915-04-12\"),\"John Garden Port John LA 54602\",\"030.088.4523x94511\"), \"user_12\":(\"Jennifer.f@carroll-acosta.com\",\"Jennifer Foster\",date(\"1988-04-30\"),\"11 Webb Groves Tiffanyside MN 14566\",\"(489)306-8558x98227\"), \"user_13\":(\"Philip66@yahoo.com\",\"Philip Garcia\",date(\"1955-12-01\"),\"70 Robinson Locks Suite 113 East Veronica ND 87845\",\"490-088-7610x9437\"), \"user_14\":(\"Ann@hernandez.com\",\"Ann Williams\",date(\"1947-05-28\"),\"24 Mcknight Port Apt. 028 Sarahborough MD 38195\",\"868.057.4056x4814\"), \"user_15\":(\"Jessica@turner.com\",\"Jessica Stewart\",date(\"1951-11-28\"),\"0337 Mason Corner Apt. 900 Toddmouth FL 61464\",\"(335)408-3835x883\"), \"user_16\":(\"Sandra311@hotmail.com\",\"Sandra Dougherty\",date(\"1908-06-03\"),\"7 Davis Station Apt. 691 Pittmanfort HI 29746\",\"+1-189-827-0744x27614\"), \"user_17\":(\"Sharon91@gmail.com\",\"Sharon Mccoy\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_18\":(\"Sharon91+001@gmail.com\",\"Kathryn Miller\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_19\":(\"brettglenn@googlemail.com\",\"Bretty Glenn\",date(\"1991-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660-391-3730\"), \"user_20\":(\"julia.h.24@yahoo.com\",\"Julia H.\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_21\":(\"holly@welch.org\",\"Holly\",date(\"0000-10-19\"),\"1 Ama","date":"2022-08-14","objectID":"/identity-resolution/:1:1","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#建立图谱"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱 1.1.1 图建模我们从一个最简单、直接的图谱开始，如下边的图结构示意显示，我们定义了点： user Prop: [name, email, birthday, address, phone_num] phone email device ip address 在他们之间有很自然的边： used_device Prop: time logged_in_from Prop: time has_phone has_address has_email 1.1.2 数据这份数据是开源的，地址在 https://github.com/wey-gu/identity-correlation-datagen 1.1.3 写入 NebulaGraph 利用 Nebula Up，一行部署 NebulaGraph 地址：https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 图建模的 Schema 对应的 NebulaGraph DDL 是： # 创建一个叫做 entity_resolution 的图空间 CREATE SPACE entity_resolution (vid_type=FIXED_STRING(30)); USE entity_resolution; # 创建点的类型 TAG CREATE TAG `user` (`name` string NOT NULL, `email` string NOT NULL, `phone_num` string NOT NULL, `birthday` date NOT NULL, `address` string NOT NULL); CREATE TAG `address` (`address` string NOT NULL); CREATE TAG `device` (`uuid` string NOT NULL); CREATE TAG `email` (); CREATE TAG `ip` (); CREATE TAG `phone` (); # 创建边的类型 Edge Type CREATE EDGE `used_device` (`time` timestamp NOT NULL); CREATE EDGE `logged_in_from` (`time` timestamp NOT NULL); CREATE EDGE `has_phone` (); CREATE EDGE `has_address` (); CREATE EDGE `has_email` (); 对于写入数据的 DML，这里只给出 user ，email 类型点、has_email 类型边的例子 INSERT VERTEX `user` (`email`, `name`, `birthday`, `address`, `phone_num`) VALUES \"user_1\":(\"heathermoore@johnson.com\",\"Miranda Miller\",date(\"1957-08-27\"),\"Brittany Forge Apt. 718 East Eric WV 97881\",\"+1-652-450-5443x00562\"), \"user_2\":(\"holly@welch.org\",\"Holly Pollard\",date(\"1990-10-19\"),\"1 Amanda Freeway Lisaland NJ 94933\",\"600-192-2985x041\"), \"user_3\":(\"julia.h.24@gmail.com\",\"Julia Hall\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_4\":(\"franklin.b@gibson.biz\",\"Franklin Barnett\",date(\"2020-03-01\"),\"Richard Curve Kingstad AZ 05660\",\"(224)497-9312\"), \"user_5\":(\"4kelly@yahoo.com\",\"April Kelly\",date(\"1967-12-01\"),\"Schmidt Key Lake Charles AL 36174\",\"410.138.1816x98702\"), \"user_6\":(\"steven.web@johnson.com\",\"Steven Webb\",date(\"1955-04-24\"),\"5 Joanna Key Suite 704 Frankshire OK 03035\",\"3666519376\"), \"user_7\":(\"Jessica_Torres@morris.com\",\"Jessica Torres\",date(\"1958-09-03\"),\"1 Payne Circle Mitchellfort LA 73053\",\"535-357-3112x4903\"), \"user_8\":(\"brettglenn@gmail.com\",\"Brett Glenn\",date(\"1992-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660.391.3730\"), \"user_9\":(\"veronica.j@yahoo.com\",\"Veronica Jordan\",date(\"1947-06-08\"),\"2 Klein Mission New Annetteton HI 05775\",\"810-252-6218\"), \"user_10\":(\"steven@phelps-craig.info\",\"Steven Brooks\",date(\"1954-06-14\"),\"1 Vanessa Stravenue Suite 184 Baileyville NY 46381\",\"+1-665-328-8103x3448\"), \"user_11\":(\"ReginaldTheMan@hotmail.com\",\"Reginald Mccullough\",date(\"1915-04-12\"),\"John Garden Port John LA 54602\",\"030.088.4523x94511\"), \"user_12\":(\"Jennifer.f@carroll-acosta.com\",\"Jennifer Foster\",date(\"1988-04-30\"),\"11 Webb Groves Tiffanyside MN 14566\",\"(489)306-8558x98227\"), \"user_13\":(\"Philip66@yahoo.com\",\"Philip Garcia\",date(\"1955-12-01\"),\"70 Robinson Locks Suite 113 East Veronica ND 87845\",\"490-088-7610x9437\"), \"user_14\":(\"Ann@hernandez.com\",\"Ann Williams\",date(\"1947-05-28\"),\"24 Mcknight Port Apt. 028 Sarahborough MD 38195\",\"868.057.4056x4814\"), \"user_15\":(\"Jessica@turner.com\",\"Jessica Stewart\",date(\"1951-11-28\"),\"0337 Mason Corner Apt. 900 Toddmouth FL 61464\",\"(335)408-3835x883\"), \"user_16\":(\"Sandra311@hotmail.com\",\"Sandra Dougherty\",date(\"1908-06-03\"),\"7 Davis Station Apt. 691 Pittmanfort HI 29746\",\"+1-189-827-0744x27614\"), \"user_17\":(\"Sharon91@gmail.com\",\"Sharon Mccoy\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_18\":(\"Sharon91+001@gmail.com\",\"Kathryn Miller\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_19\":(\"brettglenn@googlemail.com\",\"Bretty Glenn\",date(\"1991-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660-391-3730\"), \"user_20\":(\"julia.h.24@yahoo.com\",\"Julia H.\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_21\":(\"holly@welch.org\",\"Holly\",date(\"0000-10-19\"),\"1 Ama","date":"2022-08-14","objectID":"/identity-resolution/:1:1","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#图建模"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱 1.1.1 图建模我们从一个最简单、直接的图谱开始，如下边的图结构示意显示，我们定义了点： user Prop: [name, email, birthday, address, phone_num] phone email device ip address 在他们之间有很自然的边： used_device Prop: time logged_in_from Prop: time has_phone has_address has_email 1.1.2 数据这份数据是开源的，地址在 https://github.com/wey-gu/identity-correlation-datagen 1.1.3 写入 NebulaGraph 利用 Nebula Up，一行部署 NebulaGraph 地址：https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 图建模的 Schema 对应的 NebulaGraph DDL 是： # 创建一个叫做 entity_resolution 的图空间 CREATE SPACE entity_resolution (vid_type=FIXED_STRING(30)); USE entity_resolution; # 创建点的类型 TAG CREATE TAG `user` (`name` string NOT NULL, `email` string NOT NULL, `phone_num` string NOT NULL, `birthday` date NOT NULL, `address` string NOT NULL); CREATE TAG `address` (`address` string NOT NULL); CREATE TAG `device` (`uuid` string NOT NULL); CREATE TAG `email` (); CREATE TAG `ip` (); CREATE TAG `phone` (); # 创建边的类型 Edge Type CREATE EDGE `used_device` (`time` timestamp NOT NULL); CREATE EDGE `logged_in_from` (`time` timestamp NOT NULL); CREATE EDGE `has_phone` (); CREATE EDGE `has_address` (); CREATE EDGE `has_email` (); 对于写入数据的 DML，这里只给出 user ，email 类型点、has_email 类型边的例子 INSERT VERTEX `user` (`email`, `name`, `birthday`, `address`, `phone_num`) VALUES \"user_1\":(\"heathermoore@johnson.com\",\"Miranda Miller\",date(\"1957-08-27\"),\"Brittany Forge Apt. 718 East Eric WV 97881\",\"+1-652-450-5443x00562\"), \"user_2\":(\"holly@welch.org\",\"Holly Pollard\",date(\"1990-10-19\"),\"1 Amanda Freeway Lisaland NJ 94933\",\"600-192-2985x041\"), \"user_3\":(\"julia.h.24@gmail.com\",\"Julia Hall\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_4\":(\"franklin.b@gibson.biz\",\"Franklin Barnett\",date(\"2020-03-01\"),\"Richard Curve Kingstad AZ 05660\",\"(224)497-9312\"), \"user_5\":(\"4kelly@yahoo.com\",\"April Kelly\",date(\"1967-12-01\"),\"Schmidt Key Lake Charles AL 36174\",\"410.138.1816x98702\"), \"user_6\":(\"steven.web@johnson.com\",\"Steven Webb\",date(\"1955-04-24\"),\"5 Joanna Key Suite 704 Frankshire OK 03035\",\"3666519376\"), \"user_7\":(\"Jessica_Torres@morris.com\",\"Jessica Torres\",date(\"1958-09-03\"),\"1 Payne Circle Mitchellfort LA 73053\",\"535-357-3112x4903\"), \"user_8\":(\"brettglenn@gmail.com\",\"Brett Glenn\",date(\"1992-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660.391.3730\"), \"user_9\":(\"veronica.j@yahoo.com\",\"Veronica Jordan\",date(\"1947-06-08\"),\"2 Klein Mission New Annetteton HI 05775\",\"810-252-6218\"), \"user_10\":(\"steven@phelps-craig.info\",\"Steven Brooks\",date(\"1954-06-14\"),\"1 Vanessa Stravenue Suite 184 Baileyville NY 46381\",\"+1-665-328-8103x3448\"), \"user_11\":(\"ReginaldTheMan@hotmail.com\",\"Reginald Mccullough\",date(\"1915-04-12\"),\"John Garden Port John LA 54602\",\"030.088.4523x94511\"), \"user_12\":(\"Jennifer.f@carroll-acosta.com\",\"Jennifer Foster\",date(\"1988-04-30\"),\"11 Webb Groves Tiffanyside MN 14566\",\"(489)306-8558x98227\"), \"user_13\":(\"Philip66@yahoo.com\",\"Philip Garcia\",date(\"1955-12-01\"),\"70 Robinson Locks Suite 113 East Veronica ND 87845\",\"490-088-7610x9437\"), \"user_14\":(\"Ann@hernandez.com\",\"Ann Williams\",date(\"1947-05-28\"),\"24 Mcknight Port Apt. 028 Sarahborough MD 38195\",\"868.057.4056x4814\"), \"user_15\":(\"Jessica@turner.com\",\"Jessica Stewart\",date(\"1951-11-28\"),\"0337 Mason Corner Apt. 900 Toddmouth FL 61464\",\"(335)408-3835x883\"), \"user_16\":(\"Sandra311@hotmail.com\",\"Sandra Dougherty\",date(\"1908-06-03\"),\"7 Davis Station Apt. 691 Pittmanfort HI 29746\",\"+1-189-827-0744x27614\"), \"user_17\":(\"Sharon91@gmail.com\",\"Sharon Mccoy\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_18\":(\"Sharon91+001@gmail.com\",\"Kathryn Miller\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_19\":(\"brettglenn@googlemail.com\",\"Bretty Glenn\",date(\"1991-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660-391-3730\"), \"user_20\":(\"julia.h.24@yahoo.com\",\"Julia H.\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_21\":(\"holly@welch.org\",\"Holly\",date(\"0000-10-19\"),\"1 Ama","date":"2022-08-14","objectID":"/identity-resolution/:1:1","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#数据"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱 1.1.1 图建模我们从一个最简单、直接的图谱开始，如下边的图结构示意显示，我们定义了点： user Prop: [name, email, birthday, address, phone_num] phone email device ip address 在他们之间有很自然的边： used_device Prop: time logged_in_from Prop: time has_phone has_address has_email 1.1.2 数据这份数据是开源的，地址在 https://github.com/wey-gu/identity-correlation-datagen 1.1.3 写入 NebulaGraph 利用 Nebula Up，一行部署 NebulaGraph 地址：https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 图建模的 Schema 对应的 NebulaGraph DDL 是： # 创建一个叫做 entity_resolution 的图空间 CREATE SPACE entity_resolution (vid_type=FIXED_STRING(30)); USE entity_resolution; # 创建点的类型 TAG CREATE TAG `user` (`name` string NOT NULL, `email` string NOT NULL, `phone_num` string NOT NULL, `birthday` date NOT NULL, `address` string NOT NULL); CREATE TAG `address` (`address` string NOT NULL); CREATE TAG `device` (`uuid` string NOT NULL); CREATE TAG `email` (); CREATE TAG `ip` (); CREATE TAG `phone` (); # 创建边的类型 Edge Type CREATE EDGE `used_device` (`time` timestamp NOT NULL); CREATE EDGE `logged_in_from` (`time` timestamp NOT NULL); CREATE EDGE `has_phone` (); CREATE EDGE `has_address` (); CREATE EDGE `has_email` (); 对于写入数据的 DML，这里只给出 user ，email 类型点、has_email 类型边的例子 INSERT VERTEX `user` (`email`, `name`, `birthday`, `address`, `phone_num`) VALUES \"user_1\":(\"heathermoore@johnson.com\",\"Miranda Miller\",date(\"1957-08-27\"),\"Brittany Forge Apt. 718 East Eric WV 97881\",\"+1-652-450-5443x00562\"), \"user_2\":(\"holly@welch.org\",\"Holly Pollard\",date(\"1990-10-19\"),\"1 Amanda Freeway Lisaland NJ 94933\",\"600-192-2985x041\"), \"user_3\":(\"julia.h.24@gmail.com\",\"Julia Hall\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_4\":(\"franklin.b@gibson.biz\",\"Franklin Barnett\",date(\"2020-03-01\"),\"Richard Curve Kingstad AZ 05660\",\"(224)497-9312\"), \"user_5\":(\"4kelly@yahoo.com\",\"April Kelly\",date(\"1967-12-01\"),\"Schmidt Key Lake Charles AL 36174\",\"410.138.1816x98702\"), \"user_6\":(\"steven.web@johnson.com\",\"Steven Webb\",date(\"1955-04-24\"),\"5 Joanna Key Suite 704 Frankshire OK 03035\",\"3666519376\"), \"user_7\":(\"Jessica_Torres@morris.com\",\"Jessica Torres\",date(\"1958-09-03\"),\"1 Payne Circle Mitchellfort LA 73053\",\"535-357-3112x4903\"), \"user_8\":(\"brettglenn@gmail.com\",\"Brett Glenn\",date(\"1992-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660.391.3730\"), \"user_9\":(\"veronica.j@yahoo.com\",\"Veronica Jordan\",date(\"1947-06-08\"),\"2 Klein Mission New Annetteton HI 05775\",\"810-252-6218\"), \"user_10\":(\"steven@phelps-craig.info\",\"Steven Brooks\",date(\"1954-06-14\"),\"1 Vanessa Stravenue Suite 184 Baileyville NY 46381\",\"+1-665-328-8103x3448\"), \"user_11\":(\"ReginaldTheMan@hotmail.com\",\"Reginald Mccullough\",date(\"1915-04-12\"),\"John Garden Port John LA 54602\",\"030.088.4523x94511\"), \"user_12\":(\"Jennifer.f@carroll-acosta.com\",\"Jennifer Foster\",date(\"1988-04-30\"),\"11 Webb Groves Tiffanyside MN 14566\",\"(489)306-8558x98227\"), \"user_13\":(\"Philip66@yahoo.com\",\"Philip Garcia\",date(\"1955-12-01\"),\"70 Robinson Locks Suite 113 East Veronica ND 87845\",\"490-088-7610x9437\"), \"user_14\":(\"Ann@hernandez.com\",\"Ann Williams\",date(\"1947-05-28\"),\"24 Mcknight Port Apt. 028 Sarahborough MD 38195\",\"868.057.4056x4814\"), \"user_15\":(\"Jessica@turner.com\",\"Jessica Stewart\",date(\"1951-11-28\"),\"0337 Mason Corner Apt. 900 Toddmouth FL 61464\",\"(335)408-3835x883\"), \"user_16\":(\"Sandra311@hotmail.com\",\"Sandra Dougherty\",date(\"1908-06-03\"),\"7 Davis Station Apt. 691 Pittmanfort HI 29746\",\"+1-189-827-0744x27614\"), \"user_17\":(\"Sharon91@gmail.com\",\"Sharon Mccoy\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_18\":(\"Sharon91+001@gmail.com\",\"Kathryn Miller\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_19\":(\"brettglenn@googlemail.com\",\"Bretty Glenn\",date(\"1991-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660-391-3730\"), \"user_20\":(\"julia.h.24@yahoo.com\",\"Julia H.\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_21\":(\"holly@welch.org\",\"Holly\",date(\"0000-10-19\"),\"1 Ama","date":"2022-08-14","objectID":"/identity-resolution/:1:1","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#写入-nebulagraph"},{"categories":["Nebula Graph"],"content":" 1.2 根据确定规则获取 ID 映射关系最简单、直接的方法，在特定的场景下也可能是有用的，试想像 email、IP 地址、上网设备这些有严格结构的数据，在它们成为图谱中的点的时候，简单的相等关系就足以找出这样对应关系，比如： 拥有相同的 email 使用过相同的 IP 地址 使用过相同的设备 在前边的图谱、图数据库中，拥有相同的 email 可以直接表达为如下的图模式（Graph Pattern）。 (:`user`)-[:`has_email`]-\u003e(:`email`)\u003c-[:`has_email`]-[:`user`] 下图为顶点： user 与边：has_email 的一个图的可视化结果，可以看到这其中有两个三个点相连的串正是符合拥有相同 email 的模式的点。 注： 这个结果的数据源在 https://github.com/wey-gu/identity-correlation-datagen/tree/main/sample/hand_crafted 如果通过线上访问本文，你可以鼠标悬停（获取点上的属性）和框选放大每一个点和子图哦。 IFrame not supported 显然，在构建 ID Mapping 系统的过程中，我们就是通过在图数据库中直接查询，可视化渲染结果来看到等效的洞察，这个查询可以写成： MATCH p=(:`user`)-[:`has_email`]-\u003e(:`email`)\u003c-[:`has_email`]-(:`user`) RETURN p limit 10 NebulaGraph 中的查询结果 同样，在上边交互图中可以放大看到这两对拥有相同 email 关联起来的账号： 然而，在更多真实世界中，这样的模式匹配往往不能解决更多稍微复杂一点的情形： 比如从上边的图中我们可以看到这两个匹配了的映射中，holly@welch.org 关联下的两个用户的姓名是不同的，而 veronica.j@yahoo.com 关联下的两个用户姓名是完全相同的。 user_2,holly@welch.org,Holly Pollard,1990-10-19,1 Amanda Freeway Lisaland NJ 94933,600-192-2985x041 user_21,holly@welch.org,Holly,0000-10-19,1 Amanda Freeway Lisaland NJ 94933,(600)-192-2985 再比如 Sharon91@gmail.com 和 Sharon91+001@gmail.com ，这两个人的姓名不同，但是手机和地址却是相同的。 user_17,Sharon91@gmail.com,Sharon Mccoy,1958-09-01,1 Southport Street Apt. 098 Westport KY 85907,(814)898-9079x898 user_18,Sharon91+001@gmail.com,Kathryn Miller,1958-09-01,1 Southport Street Apt. 098 Westport KY 85907,(814)898-9079x898 比较庆幸的是我们只需要增加类似于\"拥有相同邮箱\"、“拥有相同地址”、“拥有相同电话\"等其他条件就可以把这种情况考虑进来了，而随之而来的问题是： 不是所有的数据都至少存在某一个确定条件的相等（二元的是与否），所以不存在一条确定的边去连接它们，比如这两个账户中： user_5,4kelly@yahoo.com,April Kelly,1967-12-01,Schmidt Key Lake Charles AL 36174,410.138.1816x98702 user_23,4kelly@hotmail.com,Kelly April,2010-01-01,Schmidt Key Lake Charles AL 13617,410-138-1816 如何表现 4kelly@yahoo.com 与 4kelly@hotmail.com 的相似性？ 如何将多种匹配规则的信息都纳入关联系统？ ","date":"2022-08-14","objectID":"/identity-resolution/:1:2","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#根据确定规则获取-id-映射关系"},{"categories":["Nebula Graph"],"content":" 1.3 非确定规则基于复合条件量化方法前边提到了几种确定规则无法处理的情况，它们可以归结为这两点： 需要多因素（规则）进行综合考虑与判定 需要对非确定条件（属性）进行处理，挖掘隐含相等、相似的关联关系（边） 对于 1. ，很自然可以想到对多种关联条件进行量化评分（score），按照多种条件的重要程度进行加权，给出认定为关联的总分的阈值。 有了多因素评分的机制，我们只需要考虑如何在确定的多因素基础之上，增加对不确定因素的处理，从而解决 2.的情况。这里，非确定的条件可能是： a. 表现结构化数据的相似性：Sharon91@gmail.com 与 Sharon91+001@gmail.com b. 表现非结构化数据的相似性： Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 600-192-2985x041 与(600)-192-2985 对于 a. 的结构化数据中的相似性，有两个思路是可以考虑的： 直接进行两个值的相似度 直接判定子字符串 运算 Jaccard index 等类似的相似度 拆分为更细粒的多个属性 将 email foo+num@bar.com 拆分成三个子属性 email_handle: foo, email_alias: num, email_domain: bar.com 然后就可以设计详细的确定性规则：email.handle 相等、甚至再在此基础上应用其他非确定规则 有时候，比如对于 email_domain 字段，我们还知道 gmail.com 和 googlemail.com 是等价的，这里的处理也是可以考虑的（像是user_19,brettglenn@googlemail.com 与 user_8,brettglenn@gmail.com，但从邮箱判断背后就是同一个持有者) 而对于 b. 的非结构属性相似性距离，处理方式可以根据具体的 domain knowledge 千差万别： 像 Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 的地址信息，除了可以用值的相似度之外，还可以把它转换成地理类型的属性，比如一个经纬度组成的点，从而计算两个点之间的地理距离，根据给定的距离值来打分。 注，你知道吗？NebulaGraph 图数据库中原生支持地理类型的属性与索引，可以直接创建 Point 类型的地理属性，并计算两个 Point 之间的距离。 对于 600-192-2985x041 与(600)-192-2985 这种字符串形式的电话号码，则可以统一转化为\u003c国家码\u003e+\u003c区域码\u003e+\u003c本地号码\u003e+\u003c分机号\u003e这样的结构化数据，进一步按照结构化数据的方式处理。 如果账号存在图片对象 URL，可以对比其文件相似度。 另外，对于非结构属性的相似性计算我们要尽量避免两两穷举运算的方式（笛卡尔积），因为这是一个指数增长的量级，一个可行的方法是只比较建立了确定性关系（比如相同邮件前缀：email_handle，地址在相同街区，IP 在同一个网段等）的实体。 小结 总结来看，为了解决真实世界数据的复杂情形，基于复合条件的量化方法有： 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 在有限存在确定性关联的点之间（避免两两穷举），运算其他量化、非确定相似性（字符距离、地理距离等、图片文件相似度）； 为不同关系赋予加权，计算相似度总分； 1.3.1 基于复合条件量化方法实操下边，我们来给出这系列方法的实操案例。 1. 细化结构数据 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 首先，我们把 email 的点拆成前缀 email_handle 与后缀 email_domain，自然地，会产生这样的边： has_email_with_handle (user -\u003e email_handle) has_email_with_domain (user -\u003e email_domain) with_handle (email -\u003e email_handle) with_domain (email -\u003e email_domain) 然而，可以想见 email_domain 是一个潜在的超级节点，并且，它的区分度在很多情况下是很小的，比如 gmail.com 这个公共邮箱后缀没有很大的关联性意义。我们可以只留下 email.handle 作为点，而对于 email_domain，把它留在边中作为属性： has_email_with_handle (user -\u003e email_handle) Prop: email_domain with_handle (email -\u003e email_handle) Prop: email_domain 对应的新的点类型、边类型的 NebulaGraph DDL 语句： # 新的点类型 CREATE TAG `email_handle` (); # 新的边类型 CREATE EDGE `has_email_with_handle` (`email_domain` string NOT NULL); CREATE EDGE `with_handle` (`email_domain` string NOT NULL); 对应新的点、边的 DML 语句： INSERT VERTEX `email_handle` () VALUES \"4kelly\":(), \"Ann\":(), \"brettglenn\":(), \"franklin.b\":(), \"heathermoore\":(), \"holly\":(), \"Jennifer.f\":(), \"Jessica\":(), \"Jessica_Torres\":(), \"julia.h.24\":(), \"Philip66\":(), \"ReginaldTheMan\":(), \"Sandra311\":(), \"Sharon91\":(), \"steven\":(), \"steven.web\":(), \"veronica.j\":(); INSERT EDGE `has_email_with_handle` (`email_domain`) VALUES \"user_1\"-\u003e\"heathermoore\":(\"johnson.com\"), \"user_2\"-\u003e\"holly\":(\"welch.org\"), \"user_3\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"user_4\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"user_5\"-\u003e\"4kelly\":(\"yahoo.com\"), \"user_6\"-\u003e\"steven.web\":(\"johnson.com\"), \"user_7\"-\u003e\"Jessica_Torres\":(\"morris.com\"), \"user_8\"-\u003e\"brettglenn\":(\"gmail.com\"), \"user_9\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_10\"-\u003e\"steven\":(\"phelps-craig.info\"), \"user_11\"-\u003e\"ReginaldTheMan\":(\"hotmail.com\"), \"user_12\"-\u003e\"Jennifer.f\":(\"carroll-acosta.com\"), \"user_13\"-\u003e\"Philip66\":(\"yahoo.com\"), \"user_14\"-\u003e\"Ann\":(\"hernandez.com\"), \"user_15\"-\u003e\"Jessica\":(\"turner.com\"), \"user_16\"-\u003e\"Sandra311\":(\"hotmail.com\"), \"user_17\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_18\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_19\"-\u003e\"brettglenn\":(\"googlemail.com\"), \"user_20\"-\u003e\"julia.h.24\":(\"yahoo.com\"), \"user_21\"-\u003e\"holly\":(\"welch.org\"), \"user_22\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_23\"-\u003e\"4kelly\":(\"hotmail.com\"); INSERT EDGE `with_handle` (`email_domain`) VALUES \"heathermoore@johnson.com\"-\u003e\"heathermoore\":(\"johnson.com\"), \"holly@welch.org\"-\u003e\"holly\":(\"welch.org\"), \"julia.h.24@gmail.com\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"franklin.b@gibson.biz\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"4kelly@yahoo.com\"-\u003e\"4kelly\":(\"yahoo.com\"), \"steven.web@johnson.com\"-\u003e\"steven.web\":(\"johnson.com\"), \"Jessica_Torres@morris.c","date":"2022-08-14","objectID":"/identity-resolution/:1:3","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#非确定规则基于复合条件量化方法"},{"categories":["Nebula Graph"],"content":" 1.3 非确定规则基于复合条件量化方法前边提到了几种确定规则无法处理的情况，它们可以归结为这两点： 需要多因素（规则）进行综合考虑与判定 需要对非确定条件（属性）进行处理，挖掘隐含相等、相似的关联关系（边） 对于 1. ，很自然可以想到对多种关联条件进行量化评分（score），按照多种条件的重要程度进行加权，给出认定为关联的总分的阈值。 有了多因素评分的机制，我们只需要考虑如何在确定的多因素基础之上，增加对不确定因素的处理，从而解决 2.的情况。这里，非确定的条件可能是： a. 表现结构化数据的相似性：Sharon91@gmail.com 与 Sharon91+001@gmail.com b. 表现非结构化数据的相似性： Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 600-192-2985x041 与(600)-192-2985 对于 a. 的结构化数据中的相似性，有两个思路是可以考虑的： 直接进行两个值的相似度 直接判定子字符串 运算 Jaccard index 等类似的相似度 拆分为更细粒的多个属性 将 email foo+num@bar.com 拆分成三个子属性 email_handle: foo, email_alias: num, email_domain: bar.com 然后就可以设计详细的确定性规则：email.handle 相等、甚至再在此基础上应用其他非确定规则 有时候，比如对于 email_domain 字段，我们还知道 gmail.com 和 googlemail.com 是等价的，这里的处理也是可以考虑的（像是user_19,brettglenn@googlemail.com 与 user_8,brettglenn@gmail.com，但从邮箱判断背后就是同一个持有者) 而对于 b. 的非结构属性相似性距离，处理方式可以根据具体的 domain knowledge 千差万别： 像 Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 的地址信息，除了可以用值的相似度之外，还可以把它转换成地理类型的属性，比如一个经纬度组成的点，从而计算两个点之间的地理距离，根据给定的距离值来打分。 注，你知道吗？NebulaGraph 图数据库中原生支持地理类型的属性与索引，可以直接创建 Point 类型的地理属性，并计算两个 Point 之间的距离。 对于 600-192-2985x041 与(600)-192-2985 这种字符串形式的电话号码，则可以统一转化为\u003c国家码\u003e+\u003c区域码\u003e+\u003c本地号码\u003e+\u003c分机号\u003e这样的结构化数据，进一步按照结构化数据的方式处理。 如果账号存在图片对象 URL，可以对比其文件相似度。 另外，对于非结构属性的相似性计算我们要尽量避免两两穷举运算的方式（笛卡尔积），因为这是一个指数增长的量级，一个可行的方法是只比较建立了确定性关系（比如相同邮件前缀：email_handle，地址在相同街区，IP 在同一个网段等）的实体。 小结 总结来看，为了解决真实世界数据的复杂情形，基于复合条件的量化方法有： 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 在有限存在确定性关联的点之间（避免两两穷举），运算其他量化、非确定相似性（字符距离、地理距离等、图片文件相似度）； 为不同关系赋予加权，计算相似度总分； 1.3.1 基于复合条件量化方法实操下边，我们来给出这系列方法的实操案例。 1. 细化结构数据 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 首先，我们把 email 的点拆成前缀 email_handle 与后缀 email_domain，自然地，会产生这样的边： has_email_with_handle (user -\u003e email_handle) has_email_with_domain (user -\u003e email_domain) with_handle (email -\u003e email_handle) with_domain (email -\u003e email_domain) 然而，可以想见 email_domain 是一个潜在的超级节点，并且，它的区分度在很多情况下是很小的，比如 gmail.com 这个公共邮箱后缀没有很大的关联性意义。我们可以只留下 email.handle 作为点，而对于 email_domain，把它留在边中作为属性： has_email_with_handle (user -\u003e email_handle) Prop: email_domain with_handle (email -\u003e email_handle) Prop: email_domain 对应的新的点类型、边类型的 NebulaGraph DDL 语句： # 新的点类型 CREATE TAG `email_handle` (); # 新的边类型 CREATE EDGE `has_email_with_handle` (`email_domain` string NOT NULL); CREATE EDGE `with_handle` (`email_domain` string NOT NULL); 对应新的点、边的 DML 语句： INSERT VERTEX `email_handle` () VALUES \"4kelly\":(), \"Ann\":(), \"brettglenn\":(), \"franklin.b\":(), \"heathermoore\":(), \"holly\":(), \"Jennifer.f\":(), \"Jessica\":(), \"Jessica_Torres\":(), \"julia.h.24\":(), \"Philip66\":(), \"ReginaldTheMan\":(), \"Sandra311\":(), \"Sharon91\":(), \"steven\":(), \"steven.web\":(), \"veronica.j\":(); INSERT EDGE `has_email_with_handle` (`email_domain`) VALUES \"user_1\"-\u003e\"heathermoore\":(\"johnson.com\"), \"user_2\"-\u003e\"holly\":(\"welch.org\"), \"user_3\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"user_4\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"user_5\"-\u003e\"4kelly\":(\"yahoo.com\"), \"user_6\"-\u003e\"steven.web\":(\"johnson.com\"), \"user_7\"-\u003e\"Jessica_Torres\":(\"morris.com\"), \"user_8\"-\u003e\"brettglenn\":(\"gmail.com\"), \"user_9\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_10\"-\u003e\"steven\":(\"phelps-craig.info\"), \"user_11\"-\u003e\"ReginaldTheMan\":(\"hotmail.com\"), \"user_12\"-\u003e\"Jennifer.f\":(\"carroll-acosta.com\"), \"user_13\"-\u003e\"Philip66\":(\"yahoo.com\"), \"user_14\"-\u003e\"Ann\":(\"hernandez.com\"), \"user_15\"-\u003e\"Jessica\":(\"turner.com\"), \"user_16\"-\u003e\"Sandra311\":(\"hotmail.com\"), \"user_17\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_18\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_19\"-\u003e\"brettglenn\":(\"googlemail.com\"), \"user_20\"-\u003e\"julia.h.24\":(\"yahoo.com\"), \"user_21\"-\u003e\"holly\":(\"welch.org\"), \"user_22\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_23\"-\u003e\"4kelly\":(\"hotmail.com\"); INSERT EDGE `with_handle` (`email_domain`) VALUES \"heathermoore@johnson.com\"-\u003e\"heathermoore\":(\"johnson.com\"), \"holly@welch.org\"-\u003e\"holly\":(\"welch.org\"), \"julia.h.24@gmail.com\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"franklin.b@gibson.biz\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"4kelly@yahoo.com\"-\u003e\"4kelly\":(\"yahoo.com\"), \"steven.web@johnson.com\"-\u003e\"steven.web\":(\"johnson.com\"), \"Jessica_Torres@morris.c","date":"2022-08-14","objectID":"/identity-resolution/:1:3","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于复合条件量化方法实操"},{"categories":["Nebula Graph"],"content":" 1.3 非确定规则基于复合条件量化方法前边提到了几种确定规则无法处理的情况，它们可以归结为这两点： 需要多因素（规则）进行综合考虑与判定 需要对非确定条件（属性）进行处理，挖掘隐含相等、相似的关联关系（边） 对于 1. ，很自然可以想到对多种关联条件进行量化评分（score），按照多种条件的重要程度进行加权，给出认定为关联的总分的阈值。 有了多因素评分的机制，我们只需要考虑如何在确定的多因素基础之上，增加对不确定因素的处理，从而解决 2.的情况。这里，非确定的条件可能是： a. 表现结构化数据的相似性：Sharon91@gmail.com 与 Sharon91+001@gmail.com b. 表现非结构化数据的相似性： Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 600-192-2985x041 与(600)-192-2985 对于 a. 的结构化数据中的相似性，有两个思路是可以考虑的： 直接进行两个值的相似度 直接判定子字符串 运算 Jaccard index 等类似的相似度 拆分为更细粒的多个属性 将 email foo+num@bar.com 拆分成三个子属性 email_handle: foo, email_alias: num, email_domain: bar.com 然后就可以设计详细的确定性规则：email.handle 相等、甚至再在此基础上应用其他非确定规则 有时候，比如对于 email_domain 字段，我们还知道 gmail.com 和 googlemail.com 是等价的，这里的处理也是可以考虑的（像是user_19,brettglenn@googlemail.com 与 user_8,brettglenn@gmail.com，但从邮箱判断背后就是同一个持有者) 而对于 b. 的非结构属性相似性距离，处理方式可以根据具体的 domain knowledge 千差万别： 像 Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 的地址信息，除了可以用值的相似度之外，还可以把它转换成地理类型的属性，比如一个经纬度组成的点，从而计算两个点之间的地理距离，根据给定的距离值来打分。 注，你知道吗？NebulaGraph 图数据库中原生支持地理类型的属性与索引，可以直接创建 Point 类型的地理属性，并计算两个 Point 之间的距离。 对于 600-192-2985x041 与(600)-192-2985 这种字符串形式的电话号码，则可以统一转化为\u003c国家码\u003e+\u003c区域码\u003e+\u003c本地号码\u003e+\u003c分机号\u003e这样的结构化数据，进一步按照结构化数据的方式处理。 如果账号存在图片对象 URL，可以对比其文件相似度。 另外，对于非结构属性的相似性计算我们要尽量避免两两穷举运算的方式（笛卡尔积），因为这是一个指数增长的量级，一个可行的方法是只比较建立了确定性关系（比如相同邮件前缀：email_handle，地址在相同街区，IP 在同一个网段等）的实体。 小结 总结来看，为了解决真实世界数据的复杂情形，基于复合条件的量化方法有： 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 在有限存在确定性关联的点之间（避免两两穷举），运算其他量化、非确定相似性（字符距离、地理距离等、图片文件相似度）； 为不同关系赋予加权，计算相似度总分； 1.3.1 基于复合条件量化方法实操下边，我们来给出这系列方法的实操案例。 1. 细化结构数据 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 首先，我们把 email 的点拆成前缀 email_handle 与后缀 email_domain，自然地，会产生这样的边： has_email_with_handle (user -\u003e email_handle) has_email_with_domain (user -\u003e email_domain) with_handle (email -\u003e email_handle) with_domain (email -\u003e email_domain) 然而，可以想见 email_domain 是一个潜在的超级节点，并且，它的区分度在很多情况下是很小的，比如 gmail.com 这个公共邮箱后缀没有很大的关联性意义。我们可以只留下 email.handle 作为点，而对于 email_domain，把它留在边中作为属性： has_email_with_handle (user -\u003e email_handle) Prop: email_domain with_handle (email -\u003e email_handle) Prop: email_domain 对应的新的点类型、边类型的 NebulaGraph DDL 语句： # 新的点类型 CREATE TAG `email_handle` (); # 新的边类型 CREATE EDGE `has_email_with_handle` (`email_domain` string NOT NULL); CREATE EDGE `with_handle` (`email_domain` string NOT NULL); 对应新的点、边的 DML 语句： INSERT VERTEX `email_handle` () VALUES \"4kelly\":(), \"Ann\":(), \"brettglenn\":(), \"franklin.b\":(), \"heathermoore\":(), \"holly\":(), \"Jennifer.f\":(), \"Jessica\":(), \"Jessica_Torres\":(), \"julia.h.24\":(), \"Philip66\":(), \"ReginaldTheMan\":(), \"Sandra311\":(), \"Sharon91\":(), \"steven\":(), \"steven.web\":(), \"veronica.j\":(); INSERT EDGE `has_email_with_handle` (`email_domain`) VALUES \"user_1\"-\u003e\"heathermoore\":(\"johnson.com\"), \"user_2\"-\u003e\"holly\":(\"welch.org\"), \"user_3\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"user_4\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"user_5\"-\u003e\"4kelly\":(\"yahoo.com\"), \"user_6\"-\u003e\"steven.web\":(\"johnson.com\"), \"user_7\"-\u003e\"Jessica_Torres\":(\"morris.com\"), \"user_8\"-\u003e\"brettglenn\":(\"gmail.com\"), \"user_9\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_10\"-\u003e\"steven\":(\"phelps-craig.info\"), \"user_11\"-\u003e\"ReginaldTheMan\":(\"hotmail.com\"), \"user_12\"-\u003e\"Jennifer.f\":(\"carroll-acosta.com\"), \"user_13\"-\u003e\"Philip66\":(\"yahoo.com\"), \"user_14\"-\u003e\"Ann\":(\"hernandez.com\"), \"user_15\"-\u003e\"Jessica\":(\"turner.com\"), \"user_16\"-\u003e\"Sandra311\":(\"hotmail.com\"), \"user_17\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_18\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_19\"-\u003e\"brettglenn\":(\"googlemail.com\"), \"user_20\"-\u003e\"julia.h.24\":(\"yahoo.com\"), \"user_21\"-\u003e\"holly\":(\"welch.org\"), \"user_22\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_23\"-\u003e\"4kelly\":(\"hotmail.com\"); INSERT EDGE `with_handle` (`email_domain`) VALUES \"heathermoore@johnson.com\"-\u003e\"heathermoore\":(\"johnson.com\"), \"holly@welch.org\"-\u003e\"holly\":(\"welch.org\"), \"julia.h.24@gmail.com\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"franklin.b@gibson.biz\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"4kelly@yahoo.com\"-\u003e\"4kelly\":(\"yahoo.com\"), \"steven.web@johnson.com\"-\u003e\"steven.web\":(\"johnson.com\"), \"Jessica_Torres@morris.c","date":"2022-08-14","objectID":"/identity-resolution/:1:3","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#利用-active-learning-的方法交互式学习评分权重"},{"categories":["Nebula Graph"],"content":" 1.4 利用新的边连接不同方法进一步，对于这些确定（是否二元的）或非确定（量化的）关系，利用图库与外部系统获得了关联关系之后，常常可以直接把它们定义为图谱中直连的边，写回图库，提供给其他算法、系统作为输入，做进一步迭代、计算。 1.4.1 创建单独的直连边假设之前对邮件、地址、姓名的处理之后，把结果作为用户实体之前的直连边插入图谱，这些种边叫做： shared_similar_email shared_similar_location shared_name # DDL CREATE EDGE `shared_similar_email` (); CREATE EDGE `shared_similar_location` (); CREATE EDGE `shared_name` (); # DML INSERT EDGE `shared_similar_email` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); INSERT EDGE `shared_name` () VALUES \"user_9\" -\u003e\"user_22\":(), \"user_22\"-\u003e\"user_9\" :(); INSERT EDGE `shared_similar_location` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); 1.4.2 创建复合评分之后的边比如，我们查询综合分数大于 2 的点： MATCH (v_start:`user`)-[:has_email_with_handle]-\u003e(:email_handle)\u003c-[:has_email_with_handle]-(v_end:`user`) MATCH (v_start:`user`)-[:has_address]-\u003e(a_start:address) MATCH (v_end:`user`)-[:has_address]-\u003e(a_end:address) WITH id(v_start) AS s, id(v_end) AS e, v_start.`user`.name AS s_name, v_end.`user`.name AS e_name, ST_Distance(a_start.address.geo_point, a_end.address.geo_point) AS distance WITH s, e, 1 AS shared_email_handle, CASE WHEN s_name == e_name THEN 1 ELSE 0 END AS shared_name, CASE WHEN distance \u003c 10000 THEN 1 ELSE 0 END AS shared_location WITH s, e, (shared_email_handle + shared_name + shared_location) AS score WHERE score \u003e 2 RETURN s, e, score ORDER BY score DESC 然后根据返回结果建立新的边： # DDL CREATE EDGE `is_similar_to` (score int NOT NULL); # DML INSERT EDGE `is_similar_to` (`score`) VALUES \"user_22\" -\u003e\"user_9\":(3), \"user_9\" -\u003e\"user_22\":(3); ","date":"2022-08-14","objectID":"/identity-resolution/:1:4","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#利用新的边连接不同方法"},{"categories":["Nebula Graph"],"content":" 1.4 利用新的边连接不同方法进一步，对于这些确定（是否二元的）或非确定（量化的）关系，利用图库与外部系统获得了关联关系之后，常常可以直接把它们定义为图谱中直连的边，写回图库，提供给其他算法、系统作为输入，做进一步迭代、计算。 1.4.1 创建单独的直连边假设之前对邮件、地址、姓名的处理之后，把结果作为用户实体之前的直连边插入图谱，这些种边叫做： shared_similar_email shared_similar_location shared_name # DDL CREATE EDGE `shared_similar_email` (); CREATE EDGE `shared_similar_location` (); CREATE EDGE `shared_name` (); # DML INSERT EDGE `shared_similar_email` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); INSERT EDGE `shared_name` () VALUES \"user_9\" -\u003e\"user_22\":(), \"user_22\"-\u003e\"user_9\" :(); INSERT EDGE `shared_similar_location` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); 1.4.2 创建复合评分之后的边比如，我们查询综合分数大于 2 的点： MATCH (v_start:`user`)-[:has_email_with_handle]-\u003e(:email_handle)\u003c-[:has_email_with_handle]-(v_end:`user`) MATCH (v_start:`user`)-[:has_address]-\u003e(a_start:address) MATCH (v_end:`user`)-[:has_address]-\u003e(a_end:address) WITH id(v_start) AS s, id(v_end) AS e, v_start.`user`.name AS s_name, v_end.`user`.name AS e_name, ST_Distance(a_start.address.geo_point, a_end.address.geo_point) AS distance WITH s, e, 1 AS shared_email_handle, CASE WHEN s_name == e_name THEN 1 ELSE 0 END AS shared_name, CASE WHEN distance \u003c 10000 THEN 1 ELSE 0 END AS shared_location WITH s, e, (shared_email_handle + shared_name + shared_location) AS score WHERE score \u003e 2 RETURN s, e, score ORDER BY score DESC 然后根据返回结果建立新的边： # DDL CREATE EDGE `is_similar_to` (score int NOT NULL); # DML INSERT EDGE `is_similar_to` (`score`) VALUES \"user_22\" -\u003e\"user_9\":(3), \"user_9\" -\u003e\"user_22\":(3); ","date":"2022-08-14","objectID":"/identity-resolution/:1:4","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#创建单独的直连边"},{"categories":["Nebula Graph"],"content":" 1.4 利用新的边连接不同方法进一步，对于这些确定（是否二元的）或非确定（量化的）关系，利用图库与外部系统获得了关联关系之后，常常可以直接把它们定义为图谱中直连的边，写回图库，提供给其他算法、系统作为输入，做进一步迭代、计算。 1.4.1 创建单独的直连边假设之前对邮件、地址、姓名的处理之后，把结果作为用户实体之前的直连边插入图谱，这些种边叫做： shared_similar_email shared_similar_location shared_name # DDL CREATE EDGE `shared_similar_email` (); CREATE EDGE `shared_similar_location` (); CREATE EDGE `shared_name` (); # DML INSERT EDGE `shared_similar_email` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); INSERT EDGE `shared_name` () VALUES \"user_9\" -\u003e\"user_22\":(), \"user_22\"-\u003e\"user_9\" :(); INSERT EDGE `shared_similar_location` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); 1.4.2 创建复合评分之后的边比如，我们查询综合分数大于 2 的点： MATCH (v_start:`user`)-[:has_email_with_handle]-\u003e(:email_handle)\u003c-[:has_email_with_handle]-(v_end:`user`) MATCH (v_start:`user`)-[:has_address]-\u003e(a_start:address) MATCH (v_end:`user`)-[:has_address]-\u003e(a_end:address) WITH id(v_start) AS s, id(v_end) AS e, v_start.`user`.name AS s_name, v_end.`user`.name AS e_name, ST_Distance(a_start.address.geo_point, a_end.address.geo_point) AS distance WITH s, e, 1 AS shared_email_handle, CASE WHEN s_name == e_name THEN 1 ELSE 0 END AS shared_name, CASE WHEN distance \u003c 10000 THEN 1 ELSE 0 END AS shared_location WITH s, e, (shared_email_handle + shared_name + shared_location) AS score WHERE score \u003e 2 RETURN s, e, score ORDER BY score DESC 然后根据返回结果建立新的边： # DDL CREATE EDGE `is_similar_to` (score int NOT NULL); # DML INSERT EDGE `is_similar_to` (`score`) VALUES \"user_22\" -\u003e\"user_9\":(3), \"user_9\" -\u003e\"user_22\":(3); ","date":"2022-08-14","objectID":"/identity-resolution/:1:4","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#创建复合评分之后的边"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图算法的方法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#图相似性算法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#社区发现算法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图算法的方法-1"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图查询的-jaccard-实现"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于-nebulagraph-algorithm-图计算平台的-jaccard-方法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#前面方法的局限"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#更-scale-的方法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于-nebulagraph-algorithm-图计算平台社区发现算法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:`user`) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:`user`)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#上手基于-nebulagraph-algorithm-图计算方法"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图神经网络的方法"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于-gnn-的实操"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#hdeicdm2021httpsieeexploreieeeorgdocument9679130"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#数据集"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#数据处理"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#模型训练"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#保存模型"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#应用落地"},{"categories":["Nebula Graph"],"content":"本文是一个基于 NebulaGraph 上的图算法、图数据库、机器学习、图神经网络的 Fraud Detection 方法综述，除了基本方法思想的介绍之外，我还给大家弄了可以跑的 Playground。值得一提的是，这还我第一次给大家介绍 Nebula-DGL 这个项目 😁。","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/"},{"categories":["Nebula Graph"],"content":" 本文是一个基于 NebulaGraph 上图算法、图数据库、机器学习、GNN 的 Fraud Detection 方法综述，除了基本方法思想的介绍之外，我还给大家弄了可以跑的 Playground。 值得一提的是，这还我第一次给大家介绍 Nebula-DGL 这个项目 😁。 ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:0:0","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#"},{"categories":["Nebula Graph"],"content":" 1 基于图数据库的欺诈检测方法","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:0","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#基于图数据库的欺诈检测方法"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱首先，对现有的历史数据、标注信息面向关联关系进行属性图建模。这种原始数据是多个表结构中的银行、电子商务或者保险行业里的交易事件记录、用户数据和风控标注，而建模过程就是抽象出我们关心的实体、实体间的关联关系、和其中有意义的属性。 一般来说，自然人、公司实体、电话号码、地址、设备（比如终端设备、网络地址、终端设备所连接的 WiFi SSID 等）、订单都是实体本身，其他信息比如风险标注（是否高风险、风险描述等）、自然人和公司实体的信息（职业、收入、学历等）都作为实体的属性来建模。 下图是一个可以参考的贷款反欺诈的示例建模，它来自一份作者开源的图结构数据生成项目。 注，你可以访问 https://github.com/wey-gu/fraud-detection-datagen 获取这个开源的数据生成器代码和一份示例的数据。 ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:1","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#建立图谱"},{"categories":["Nebula Graph"],"content":" 1.2 图数据库查询识别风险有了一张囊括了人、公司、历史贷款申请记录、电话、线上申请网络设备的图谱，我们可以挖掘一些有意思的信息。 事实上，很多值得被发现、并有效阻止从而止损的骗保行为是具有群体聚集性的。比如欺诈团伙可能是一小批人（比如3到5人）有组织地收集更大规模的身份证信息（比如30张），同时发起多个金融机构大量贷款，然后在放款后选择丢弃这批留下了违约记录的身份证，再进一步选择下一批身份证信息如法炮制。 这种团伙作案的方式因为利用了大量新的身份信息，完全利用历史记录去黑名单规避风险的方式是无效的。不过，借助于关联关系的视角，这些模式是一定程度上可以被及时识别出来的。 这些可以被识别出的规律我把它分成两种： 一种是风控专家可以直接用某种模式来描述的，例如：和已经被标注为高风险的实体有直接或者间接的关联关系（新订单申请人使用了和过往高风险记录相同的网络设备），这种模式对应到图谱中，通过一个图查询就可以实时给出结果。 另一种是隐含在数据的关联关系背后，需要通过图算法挖掘得出的一些风险提示，例如：尽管给定的实体与有限的标注高风险实体没有匹配的关联，但是它在图中形成了聚集性可能提示我们这可能是一个尚未得手的进行中的团伙贷款诈骗的其中一次申请，这种情况可以通过定期在历史数据中批量执行社区发现算法得出，并在高聚集社区中利用中心性算法给出核心实体，一并提示给风险专家进行后续评估和风险标注。 1.2.1 基于图谱与专家图模式匹配的欺诈检测示例在开始之前，我们利用 Nebula-UP 来一键部署一套 NebulaGraph 图数据库： 更多请参考 https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 首先，我们把前边建模的图谱加载到 NebulaGraph 里： # 克隆数据集代码仓库 git clone https://github.com/wey-gu/fraud-detection-datagen.git cp -r data_sample_numerical_vertex_id data # 去掉表头 sed -i '1d' data/*.csv docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/data/:/data \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/nebula_graph_importer.yaml 有了这样一个图谱，风控专家可以在可视化探索工具中按需探索实体之间的关系，绘制相应的风险模式： 在这个探索截图里，我们可以明显看到一个群控设备的风险模式，这个模式可以被交给图数据库开发者，抽象成可以被风控应用定期、实时查询的语句： ## 针对一笔交易申请关联查询 MATCH (n) WHERE id(n) == \"200000010265\" OPTIONAL MATCH p_shared_d=(n)-[:`used_device`]-\u003e(d)\u003c-[:`used_device`]-(:`applicant`)-[:`with_phone_num`]-\u003e(pn:phone_num)\u003c-[e:`with_phone_num`]-(:`applicant`) RETURN p_shared_d 我们可以很容易在此模型之上，通过修改返回的关联设备计数，作为意向指标查询的判断 API： ## 群控指标 MATCH (n) WHERE id(n) == \"200000010265\" OPTIONAL MATCH p_shared_d=(n)-[:`used_device`]-\u003e(d)\u003c-[:`used_device`]-(:`applicant`)-[:`with_phone_num`]-\u003e(pn:phone_num)\u003c-[e:`with_phone_num`]-(:`applicant`) RETURN count(e) 如此，我们可以建立一个相对有效的风控系统，利用有限的标注数据和专家资源，去更高效控制团伙欺诈作案风险。 另一个利用标注风险节点的查询是找到相关联节点高风险属性的数量： MATCH p_=(p:`applicant`)-[*1..2]-(p2:`applicant`) WHERE id(p)==\"200000014810\" AND p2.`applicant`.is_risky == \"True\" RETURN p_ LIMIT 100 可以从这个路径查询看到 200000014810 的相连接的申请人中有不少是高风险的（也能看出聚集的 device）。 如此，我们可以定义相连高风险点数量为一个指标： MATCH (p:`applicant`)-[*1..2]-(p2:`applicant`) WHERE id(p)==\"200000014810\" AND p2.`applicant`.is_risky == \"True\" RETURN count(p2) 然而，在现实情况下，我们的大多数标注数据的获取还是过于昂贵，那么有没有什么方法是更有效利用有限的风险标注和图结构，来预测出风险呢？ ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:2","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#图数据库查询识别风险"},{"categories":["Nebula Graph"],"content":" 1.2 图数据库查询识别风险有了一张囊括了人、公司、历史贷款申请记录、电话、线上申请网络设备的图谱，我们可以挖掘一些有意思的信息。 事实上，很多值得被发现、并有效阻止从而止损的骗保行为是具有群体聚集性的。比如欺诈团伙可能是一小批人（比如3到5人）有组织地收集更大规模的身份证信息（比如30张），同时发起多个金融机构大量贷款，然后在放款后选择丢弃这批留下了违约记录的身份证，再进一步选择下一批身份证信息如法炮制。 这种团伙作案的方式因为利用了大量新的身份信息，完全利用历史记录去黑名单规避风险的方式是无效的。不过，借助于关联关系的视角，这些模式是一定程度上可以被及时识别出来的。 这些可以被识别出的规律我把它分成两种： 一种是风控专家可以直接用某种模式来描述的，例如：和已经被标注为高风险的实体有直接或者间接的关联关系（新订单申请人使用了和过往高风险记录相同的网络设备），这种模式对应到图谱中，通过一个图查询就可以实时给出结果。 另一种是隐含在数据的关联关系背后，需要通过图算法挖掘得出的一些风险提示，例如：尽管给定的实体与有限的标注高风险实体没有匹配的关联，但是它在图中形成了聚集性可能提示我们这可能是一个尚未得手的进行中的团伙贷款诈骗的其中一次申请，这种情况可以通过定期在历史数据中批量执行社区发现算法得出，并在高聚集社区中利用中心性算法给出核心实体，一并提示给风险专家进行后续评估和风险标注。 1.2.1 基于图谱与专家图模式匹配的欺诈检测示例在开始之前，我们利用 Nebula-UP 来一键部署一套 NebulaGraph 图数据库： 更多请参考 https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 首先，我们把前边建模的图谱加载到 NebulaGraph 里： # 克隆数据集代码仓库 git clone https://github.com/wey-gu/fraud-detection-datagen.git cp -r data_sample_numerical_vertex_id data # 去掉表头 sed -i '1d' data/*.csv docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/data/:/data \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/nebula_graph_importer.yaml 有了这样一个图谱，风控专家可以在可视化探索工具中按需探索实体之间的关系，绘制相应的风险模式： 在这个探索截图里，我们可以明显看到一个群控设备的风险模式，这个模式可以被交给图数据库开发者，抽象成可以被风控应用定期、实时查询的语句： ## 针对一笔交易申请关联查询 MATCH (n) WHERE id(n) == \"200000010265\" OPTIONAL MATCH p_shared_d=(n)-[:`used_device`]-\u003e(d)\u003c-[:`used_device`]-(:`applicant`)-[:`with_phone_num`]-\u003e(pn:phone_num)\u003c-[e:`with_phone_num`]-(:`applicant`) RETURN p_shared_d 我们可以很容易在此模型之上，通过修改返回的关联设备计数，作为意向指标查询的判断 API： ## 群控指标 MATCH (n) WHERE id(n) == \"200000010265\" OPTIONAL MATCH p_shared_d=(n)-[:`used_device`]-\u003e(d)\u003c-[:`used_device`]-(:`applicant`)-[:`with_phone_num`]-\u003e(pn:phone_num)\u003c-[e:`with_phone_num`]-(:`applicant`) RETURN count(e) 如此，我们可以建立一个相对有效的风控系统，利用有限的标注数据和专家资源，去更高效控制团伙欺诈作案风险。 另一个利用标注风险节点的查询是找到相关联节点高风险属性的数量： MATCH p_=(p:`applicant`)-[*1..2]-(p2:`applicant`) WHERE id(p)==\"200000014810\" AND p2.`applicant`.is_risky == \"True\" RETURN p_ LIMIT 100 可以从这个路径查询看到 200000014810 的相连接的申请人中有不少是高风险的（也能看出聚集的 device）。 如此，我们可以定义相连高风险点数量为一个指标： MATCH (p:`applicant`)-[*1..2]-(p2:`applicant`) WHERE id(p)==\"200000014810\" AND p2.`applicant`.is_risky == \"True\" RETURN count(p2) 然而，在现实情况下，我们的大多数标注数据的获取还是过于昂贵，那么有没有什么方法是更有效利用有限的风险标注和图结构，来预测出风险呢？ ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:2","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#基于图谱与专家图模式匹配的欺诈检测示例"},{"categories":["Nebula Graph"],"content":" 1.3 利用图扩充标注答案是肯定的， Xiaojin Z. 和 Zoubin G. 在论文：Learning from Labeled and Unlabeled Data with Label Propagation （CMU-CALD-02-107）中，利用标签传播（Label Propagation）算法来把有限的标注信息在图上通过关联关系传播到更多实体中。 这样，在我们建立的图谱中，我们可以很容易地借助有限的高风险标注，去“传播”产生更多的标注信息。这些扩展出来的标注信息一方面可以在实时的图查询中给出更多的结果，另一方面，它还能作为风控专家重要的输入信息，帮助推进反欺诈调查行动的开展。 一般来说，我们可以通过定期离线地全图扫描数据，通过图算法扩充、更新标注，再将有效的更新标注写回到图谱之中。 注，类似的方法还有 SIGNDiffusion，感兴趣的同学可以去了解一下。 1.3.1 图算法扩充欺诈风险标注的示例下面，我给出一个可以跑通的案例： 这个例子中，我用到了 Yelp 这个欺诈识别的经典数据，这份数据不只会用在这个例子中，后边 GNN 方法中的案例我也会用到它，所以大家可以耐心把数据导入 NebulaGraph。 导入数据到图库 生成导入的方法在这里，https://github.com/wey-gu/nebulagraph-yelp-frauddetection cd ~ git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection cd nebulagraph-yelp-frauddetection python3 -m pip install -r requirements.txt python3 data_download.py # 导入图库 docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 结束之后，我们可以看一下图上的统计： ~/.nebula-up/console.sh -e \"USE yelp; SHOW STATS\" 然后，我们可以看到： (root@nebula) [(none)]\u003e USE yelp; SHOW STATS +---------+---------------------------------------+---------+ | Type | Name | Count | +---------+---------------------------------------+---------+ | \"Tag\" | \"review\" | 45954 | | \"Edge\" | \"shares_restaurant_in_one_month_with\" | 1147232 | | \"Edge\" | \"shares_restaurant_rating_with\" | 6805486 | | \"Edge\" | \"shares_user_with\" | 98630 | | \"Space\" | \"vertices\" | 45954 | | \"Space\" | \"edges\" | 8051348 | +---------+---------------------------------------+---------+ Got 6 rows (time spent 1911/4488 us) 目前，市面上的 LPA 标签传播算法都是用来做社区检测的，很少有实现是用来做标签拓展的（只有 SK-Learn 中有这个实现），这里，我们参考 Thibaud M 给出来的实现。 原始的讨论参考：https://datascience.stackexchange.com/a/55720/138720 为了让这个算法跑的快一点，会从 NebulaGraph 里取一个点的子图，在这个小的子图上做标注的扩充： 首先，我们启动一个 Jupyter 的 Playground， 参考 https://github.com/wey-gu/nebula-dgl 中的 Playground 过程： git clone https://github.com/wey-gu/nebula-dgl.git cd nebula-dgl # 运行 Jupyter Notebook docker run -it --name dgl -p 8888:8888 --network nebula-net \\ -v \"$PWD\":/home/jovyan/work jupyter/datascience-notebook \\ start-notebook.sh --NotebookApp.token='nebulagraph' 访问：http://localhost:8888/lab/tree/work?token=nebulagraph 安装依赖（这些依赖在后边的 GNN 例子中也会被用到） !python3 -m pip install git+https://github.com/vesoft-inc/nebula-python.git@8c328c534413b04ccecfd42e64ce6491e09c6ca8 !python3 -m pip install . 然后，我们从图中读取一个子图，从 2048 这个点开始探索两步内的所有边。 import torch import json from torch import tensor from dgl import DGLHeteroGraph, heterograph from nebula3.gclient.net import ConnectionPool from nebula3.Config import Config config = Config() config.max_connection_pool_size = 2 connection_pool = ConnectionPool() connection_pool.init([('graphd', 9669)], config) vertex_id = 2048 client = connection_pool.get_session('root', 'nebula') r = client.execute_json( \"USE yelp;\" f\"GET SUBGRAPH WITH PROP 2 STEPS FROM {vertex_id} YIELD VERTICES AS nodes, EDGES AS relationships;\") r = json.loads(r) data = r.get('results', [{}])[0].get('data') columns = r.get('results', [{}])[0].get('columns') # create node and nodedata node_id_map = {} # key: vertex id in NebulaGraph, value: node id in dgl_graph node_idx = 0 features = [[] for _ in range(32)] + [[]] for i in range(len(data)): for index, node in enumerate(data[i]['meta'][0]): nodeid = data[i]['meta'][0][index]['id'] if nodeid not in node_id_map: node_id_map[nodeid] = node_idx node_idx += 1 for f in range(32): features[f].append(data[i]['row'][0][index][f\"review.f{f}\"]) features[32].append(data[i]['row'][0][index]['review.is_fraud']) rur_start, rur_end, rsr_start, rsr_end, rtr_start, rtr_end = [], [], [], [], [], [] for i in range(len(data)): for edge in data[i]['meta'][1]: edge = edge['id'] if edge['name'] == 'shares_user_with': rur_start.append(node_id_map[edge['src']]) rur_end.append(node_id_map[edge['dst']]) elif edge['name'] == 'shares_restaurant_rating_with': rsr_start.append(node_id_map[edge['src']]) rsr_end.append(node_id_map[edge['dst']]) elif edge['name'] == 'shar","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:3","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#利用图扩充标注"},{"categories":["Nebula Graph"],"content":" 1.3 利用图扩充标注答案是肯定的， Xiaojin Z. 和 Zoubin G. 在论文：Learning from Labeled and Unlabeled Data with Label Propagation （CMU-CALD-02-107）中，利用标签传播（Label Propagation）算法来把有限的标注信息在图上通过关联关系传播到更多实体中。 这样，在我们建立的图谱中，我们可以很容易地借助有限的高风险标注，去“传播”产生更多的标注信息。这些扩展出来的标注信息一方面可以在实时的图查询中给出更多的结果，另一方面，它还能作为风控专家重要的输入信息，帮助推进反欺诈调查行动的开展。 一般来说，我们可以通过定期离线地全图扫描数据，通过图算法扩充、更新标注，再将有效的更新标注写回到图谱之中。 注，类似的方法还有 SIGNDiffusion，感兴趣的同学可以去了解一下。 1.3.1 图算法扩充欺诈风险标注的示例下面，我给出一个可以跑通的案例： 这个例子中，我用到了 Yelp 这个欺诈识别的经典数据，这份数据不只会用在这个例子中，后边 GNN 方法中的案例我也会用到它，所以大家可以耐心把数据导入 NebulaGraph。 导入数据到图库 生成导入的方法在这里，https://github.com/wey-gu/nebulagraph-yelp-frauddetection cd ~ git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection cd nebulagraph-yelp-frauddetection python3 -m pip install -r requirements.txt python3 data_download.py # 导入图库 docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 结束之后，我们可以看一下图上的统计： ~/.nebula-up/console.sh -e \"USE yelp; SHOW STATS\" 然后，我们可以看到： (root@nebula) [(none)]\u003e USE yelp; SHOW STATS +---------+---------------------------------------+---------+ | Type | Name | Count | +---------+---------------------------------------+---------+ | \"Tag\" | \"review\" | 45954 | | \"Edge\" | \"shares_restaurant_in_one_month_with\" | 1147232 | | \"Edge\" | \"shares_restaurant_rating_with\" | 6805486 | | \"Edge\" | \"shares_user_with\" | 98630 | | \"Space\" | \"vertices\" | 45954 | | \"Space\" | \"edges\" | 8051348 | +---------+---------------------------------------+---------+ Got 6 rows (time spent 1911/4488 us) 目前，市面上的 LPA 标签传播算法都是用来做社区检测的，很少有实现是用来做标签拓展的（只有 SK-Learn 中有这个实现），这里，我们参考 Thibaud M 给出来的实现。 原始的讨论参考：https://datascience.stackexchange.com/a/55720/138720 为了让这个算法跑的快一点，会从 NebulaGraph 里取一个点的子图，在这个小的子图上做标注的扩充： 首先，我们启动一个 Jupyter 的 Playground， 参考 https://github.com/wey-gu/nebula-dgl 中的 Playground 过程： git clone https://github.com/wey-gu/nebula-dgl.git cd nebula-dgl # 运行 Jupyter Notebook docker run -it --name dgl -p 8888:8888 --network nebula-net \\ -v \"$PWD\":/home/jovyan/work jupyter/datascience-notebook \\ start-notebook.sh --NotebookApp.token='nebulagraph' 访问：http://localhost:8888/lab/tree/work?token=nebulagraph 安装依赖（这些依赖在后边的 GNN 例子中也会被用到） !python3 -m pip install git+https://github.com/vesoft-inc/nebula-python.git@8c328c534413b04ccecfd42e64ce6491e09c6ca8 !python3 -m pip install . 然后，我们从图中读取一个子图，从 2048 这个点开始探索两步内的所有边。 import torch import json from torch import tensor from dgl import DGLHeteroGraph, heterograph from nebula3.gclient.net import ConnectionPool from nebula3.Config import Config config = Config() config.max_connection_pool_size = 2 connection_pool = ConnectionPool() connection_pool.init([('graphd', 9669)], config) vertex_id = 2048 client = connection_pool.get_session('root', 'nebula') r = client.execute_json( \"USE yelp;\" f\"GET SUBGRAPH WITH PROP 2 STEPS FROM {vertex_id} YIELD VERTICES AS nodes, EDGES AS relationships;\") r = json.loads(r) data = r.get('results', [{}])[0].get('data') columns = r.get('results', [{}])[0].get('columns') # create node and nodedata node_id_map = {} # key: vertex id in NebulaGraph, value: node id in dgl_graph node_idx = 0 features = [[] for _ in range(32)] + [[]] for i in range(len(data)): for index, node in enumerate(data[i]['meta'][0]): nodeid = data[i]['meta'][0][index]['id'] if nodeid not in node_id_map: node_id_map[nodeid] = node_idx node_idx += 1 for f in range(32): features[f].append(data[i]['row'][0][index][f\"review.f{f}\"]) features[32].append(data[i]['row'][0][index]['review.is_fraud']) rur_start, rur_end, rsr_start, rsr_end, rtr_start, rtr_end = [], [], [], [], [], [] for i in range(len(data)): for edge in data[i]['meta'][1]: edge = edge['id'] if edge['name'] == 'shares_user_with': rur_start.append(node_id_map[edge['src']]) rur_end.append(node_id_map[edge['dst']]) elif edge['name'] == 'shares_restaurant_rating_with': rsr_start.append(node_id_map[edge['src']]) rsr_end.append(node_id_map[edge['dst']]) elif edge['name'] == 'shar","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:3","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#图算法扩充欺诈风险标注的示例"},{"categories":["Nebula Graph"],"content":" 1.4 带有图特征的机器学习在风控领域开始利用图的思想和能力之前，已经有很多利用机器学习的分类算法基于历史数据预测高风险行为的方法了，这些方法把记录中领域专家认为有关的信息（例如：年龄、学历、收入）作为特征，历史标注信息作为标签去训练风险预测模型。 那么读到的这里，我们是否会想到在这些方法的基础之上，如果把基于图结构的属性也考虑进来，作为特征去训练的模型可能更有效呢？答案也是肯定的，已经有很多论文和工程实践揭示这样的模型比未考虑图特征的算法更加有效：这些被尝试有效的图结构特征可能是实体的 PageRank 值、Degree 值或者是某一个社区发现算法得出的社区 id。 在生产上，我们可以定期从图谱中获得实时的全图信息，在图计算平台中分析运算获得所需特征，经过预定的数据管道，导入机器学习模型中周期获得新的风险提示，并将部分结果写回图谱方便其他系统和专家抽取、参考。 1.4.1 带有图特征的机器学习欺诈检测示例这里，机器学习的方法我就不演示了，就是常见的分类方法，在此之上，我们可以在数据中通过图算法获得一些新的属性，这些属性再处理一下作为新的特征。我只演示一个社区发现的方法，我们可以对全图跑一个 Louvain，得出不同节点的社区归属，然后把社区的值当做一个分类处理成为数值的特征。 这个例子里我们还用 https://github.com/wey-gu/fraud-detection-datagen 这个数据，在此基础上，这个例子我用到了 Nebula-Algorithm 这个项目，它是一个 Spark 应用，可以在 NebulaGraph 图库上运行很多常用的图算法。 首先，我们部署 Spark 和 Nebula Algorithm，还是利用 Nebula-UP，一键部署： curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 集群起来之后，因为需要的配置文件我已经放在了 Nebula-UP 内部，我们只需要一行就可以运行算法啦！ cd ~/.nebula-up/nebula-up/spark \u0026\u0026 ls -l docker exec -it sparkmaster /spark/bin/spark-submit \\ --master \"local\" --conf spark.rpc.askTimeout=6000s \\ --class com.vesoft.nebula.algorithm.Main \\ --driver-memory 4g /root/download/nebula-algo.jar \\ -p /root/louvain.conf 而最终的结果就在 sparkmaster 容器内的 /output 里： # docker exec -it sparkmaster bash ls -l /output 之后，我们可以对这个 Louvain 的图特征做一些处理，并开始传统的模型训练了。 ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:4","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#带有图特征的机器学习"},{"categories":["Nebula Graph"],"content":" 1.4 带有图特征的机器学习在风控领域开始利用图的思想和能力之前，已经有很多利用机器学习的分类算法基于历史数据预测高风险行为的方法了，这些方法把记录中领域专家认为有关的信息（例如：年龄、学历、收入）作为特征，历史标注信息作为标签去训练风险预测模型。 那么读到的这里，我们是否会想到在这些方法的基础之上，如果把基于图结构的属性也考虑进来，作为特征去训练的模型可能更有效呢？答案也是肯定的，已经有很多论文和工程实践揭示这样的模型比未考虑图特征的算法更加有效：这些被尝试有效的图结构特征可能是实体的 PageRank 值、Degree 值或者是某一个社区发现算法得出的社区 id。 在生产上，我们可以定期从图谱中获得实时的全图信息，在图计算平台中分析运算获得所需特征，经过预定的数据管道，导入机器学习模型中周期获得新的风险提示，并将部分结果写回图谱方便其他系统和专家抽取、参考。 1.4.1 带有图特征的机器学习欺诈检测示例这里，机器学习的方法我就不演示了，就是常见的分类方法，在此之上，我们可以在数据中通过图算法获得一些新的属性，这些属性再处理一下作为新的特征。我只演示一个社区发现的方法，我们可以对全图跑一个 Louvain，得出不同节点的社区归属，然后把社区的值当做一个分类处理成为数值的特征。 这个例子里我们还用 https://github.com/wey-gu/fraud-detection-datagen 这个数据，在此基础上，这个例子我用到了 Nebula-Algorithm 这个项目，它是一个 Spark 应用，可以在 NebulaGraph 图库上运行很多常用的图算法。 首先，我们部署 Spark 和 Nebula Algorithm，还是利用 Nebula-UP，一键部署： curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 集群起来之后，因为需要的配置文件我已经放在了 Nebula-UP 内部，我们只需要一行就可以运行算法啦！ cd ~/.nebula-up/nebula-up/spark \u0026\u0026 ls -l docker exec -it sparkmaster /spark/bin/spark-submit \\ --master \"local\" --conf spark.rpc.askTimeout=6000s \\ --class com.vesoft.nebula.algorithm.Main \\ --driver-memory 4g /root/download/nebula-algo.jar \\ -p /root/louvain.conf 而最终的结果就在 sparkmaster 容器内的 /output 里： # docker exec -it sparkmaster bash ls -l /output 之后，我们可以对这个 Louvain 的图特征做一些处理，并开始传统的模型训练了。 ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:4","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#带有图特征的机器学习欺诈检测示例"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#图神经网络的方法"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#基于图表示的图神经网络欺诈检测系统示例"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#数据集"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#数据处理"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#模型训练"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#推理接口"},{"categories":["Nebula Graph"],"content":" 1.6 总结总结起来，欺诈检测的方法有： 在一个交易历史、风控的图谱上，通过图模式查询直接获得风险提示 定期利用图算法扩充风险标注，写回图库 定期计算图谱中的图特征，和其他特征一起用传统机器学习方法离线预测风险 将图谱中的属性处理成为点、边特征，用图神经网络方法离线预测风险，部分可以 Inductive Learning 的方法结合图库可以实现在线风险预测 Feature Image credit goes to https://unsplash.com/photos/BW0vK-FA3eg ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:6","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#总结"},{"categories":["Nebula Graph"],"content":"Nebula Graph 生态中有哪些 Spark 项目？ 本文为大家介绍 Spark-connector（包括 PySpark）， Nebula Algorithm 和 Nebula Exchange。","date":"2022-06-06","objectID":"/spark-on-nebula-graph/","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/"},{"categories":["Nebula Graph"],"content":" Nebula Graph 生态中有哪些 Spark 项目？ 本文为大家介绍 Spark-connector（包括 PySpark）， Nebula Algorithm 和 Nebula Exchange。 最近我试着搭建了方便大家一键试玩的 Nebula Graph 中的 Spark 相关的项目，今天就把它们整理成文分享给大家。而且，我趟出来了 PySpark 下的 Nebula Spark Connector 的使用方式，后边也会一并贡献到文档里。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:0:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#"},{"categories":["Nebula Graph"],"content":" 1 Nebula Graph 的三个 Spark 子项目我曾经围绕 Nebula Graph 的所有数据导入方法画过一个草图，其中已经包含了 Spark Connector，Nebula Exchange 的简单介绍。在这篇文章中我将它们和另外的 Nebula Algorithm 进行稍微深入的探讨。 TL;DR Nebula Spark Connector 是一个 Spark Lib，它能让 Spark 应用程序能够以 dataframe 的形式从 Nebula Graph 中读取和写入图数据。 Nebula Exchange 建立在 Nebula Spark Connector 之上，作为一个 Spark Lib 同时可以直接被 Spark 提交 JAR 包执行的应用程序，它的设计目标是和 Nebula Graph 交换不同的数据源（对于开源版本，它是单向的：写入，而对于企业版本，它是双向的）。Nebula Exchange 支持的很多不同类型的数据源如：MySQL、Neo4j、PostgreSQL、ClickHouse、Hive 等。除了直接写入 Nebula Graph，它还可以选择生成 SST 文件，并将其注入 Nebula Graph，以便使用 Nebula Graph 集群之外算力帮助排序底层。 Nebula Algorithm，建立在 Nebula Spark Connector 和 GraphX 之上，也是一个Spark Lib 和 Spark 上的应用程序，它用来在 Nebula Graph 的图上运行常用的图算法（pagerank，LPA等）。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:1:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-graph-的三个-spark-子项目"},{"categories":["Nebula Graph"],"content":" 2 Nebula Spark Connector 代码：https://github.com/vesoft-inc/nebula-spark-connector 文档：https://docs.nebula-graph.io/3.1.0/nebula-spark-connector/ JAR 包：https://repo1.maven.org/maven2/com/vesoft/nebula-spark-connector/ 代码例子：example ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-spark-connector"},{"categories":["Nebula Graph"],"content":" 2.1 Nebula Graph Spark Reader为了从 Nebula Graph 中读取数据，比如读 vertex，Nebula Spark Connector 将扫描所有带有给定 TAG 的 Nebula StorageD，比如这样表示扫描 player 这个 TAG ：withLabel(\"player\")，我们还可以指定 vertex 的属性：withReturnCols(List(\"name\", \"age\"))。 指定好所有的读 TAG 相关的配置之后，调用 spark.read.nebula.loadVerticesToDF 返回得到的就是扫描 Nebula Graph 之后转换为 Dataframe 的图数据，像这样： def readVertex(spark: SparkSession): Unit = { LOG.info(\"start to read nebula vertices\") val config = NebulaConnectionConfig .builder() .withMetaAddress(\"metad0:9559,metad1:9559,metad2:9559\") .withConenctionRetry(2) .build() val nebulaReadVertexConfig: ReadNebulaConfig = ReadNebulaConfig .builder() .withSpace(\"basketballplayer\") .withLabel(\"player\") .withNoColumn(false) .withReturnCols(List(\"name\", \"age\")) .withLimit(10) .withPartitionNum(10) .build() val vertex = spark.read.nebula(config, nebulaReadVertexConfig).loadVerticesToDF() vertex.printSchema() vertex.show(20) println(\"vertex count: \" + vertex.count()) } 写入的例子我这里不列出，不过，前边给出的代码示例的链接里是有更详细的例子，这里值得一提的是，Spark Connector 读数据为了满足图分析、图计算的大量数据场景，和大部分其他客户端非常不同，它直接绕过了 GraphD，通过扫描 MetaD 和 StorageD 获得数据，但是写入的情况则是通过 GraphD 发起 nGQL DML 语句写入的。 接下来我们来做一个上手练习吧。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-graph-spark-reader"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#上手-nebula-spark-connector"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#拉起环境"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#进入-spark-环境"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#跑-spark-connector-的例子"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#选项-1推荐通过-pyspark"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#选项-2编译提交示例-jar-包"},{"categories":["Nebula Graph"],"content":" 3 Nebula Exchange 代码：https://github.com/vesoft-inc/nebula-exchange/ 文档：https://docs.nebula-graph.com.cn/3.1.0/nebula-exchange/about-exchange/ex-ug-what-is-exchange/ JAR 包：https://github.com/vesoft-inc/nebula-exchange/releases 配置例子： exchange-common/src/test/resources/application.conf Nebula Exchange 是一个 Spark Lib，也是一个可以直接提交执行的 Spark 应用，它被用来从多个数据源读取数据写入 Nebula Graph 或者输出 Nebula Graph SST 文件。 通过 spark-submit 的方式使用 Nebula Exchange 的方法很直接： 首先创建配置文件，让 Exchange 知道应该如何获取和写入数据 然后用指定的配置文件调用 Exchange 包 现在，让我们用上一章中创建的相同环境做一个实际测试。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:3:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-exchange"},{"categories":["Nebula Graph"],"content":" 3.1 一键试玩 Exchange 3.1.1 先跑起来看看吧 请参考前边拉起环境这一章节，先一键装好环境。 一键执行： ~/.nebula-up/nebula-exchange-example.sh 恭喜你，已经第一次执行成功一个 Exchange 的数据导入任务啦！ 3.1.2 再看看一些细节这个例子里，我们实际上是用 Exchange 从 CSV 文件这一其中支持的数据源中读取数据写入 Nebula Graph 集群的。这个 CSV 文件中第一列是顶点 ID，第二和第三列是 “姓名 “和 “年龄 “的属性： player800,\"Foo Bar\",23 player801,\"Another Name\",21 咱们可以进到 Spark 环境里看看 docker exec -it sparkmaster bash cd /root 可以看到我们提交 Exchange 任务时候指定的配置文件 exchange.conf 它是一个 HOCON 格式的文件： 在 .nebula 中描述了 Nebula Graph 集群的相关信息 在 .tags 中描述了如何将必填字段对应到我们的数据源（这里是 CSV 文件）等有关 Vertecies 的信息。 { # Spark relation config spark: { app: { name: Nebula Exchange } master:local driver: { cores: 1 maxResultSize: 1G } executor: { memory: 1G } cores:{ max: 16 } } # Nebula Graph relation config nebula: { address:{ graph:[\"graphd:9669\"] meta:[\"metad0:9559\", \"metad1:9559\", \"metad2:9559\"] } user: root pswd: nebula space: basketballplayer # parameters for SST import, not required path:{ local:\"/tmp\" remote:\"/sst\" hdfs.namenode: \"hdfs://localhost:9000\" } # nebula client connection parameters connection { # socket connect \u0026 execute timeout, unit: millisecond timeout: 30000 } error: { # max number of failures, if the number of failures is bigger than max, then exit the application. max: 32 # failed import job will be recorded in output path output: /tmp/errors } # use google's RateLimiter to limit the requests send to NebulaGraph rate: { # the stable throughput of RateLimiter limit: 1024 # Acquires a permit from RateLimiter, unit: MILLISECONDS # if it can't be obtained within the specified timeout, then give up the request. timeout: 1000 } } # Processing tags # There are tag config examples for different dataSources. tags: [ # HDFS csv # Import mode is client, just change type.sink to sst if you want to use client import mode. { name: player type: { source: csv sink: client } path: \"file:///root/player.csv\" # if your csv file has no header, then use _c0,_c1,_c2,.. to indicate fields fields: [_c1, _c2] nebula.fields: [name, age] vertex: { field:_c0 } separator: \",\" header: false batch: 256 partition: 32 } ] } 我们应该能看到那个 CSV 数据源和这个配置文件都在同一个目录下了： bash-5.0# ls -l total 24 drwxrwxr-x 2 1000 1000 4096 Jun 1 04:26 download -rw-rw-r-- 1 1000 1000 1908 Jun 1 04:23 exchange.conf -rw-rw-r-- 1 1000 1000 2593 Jun 1 04:23 hadoop.env drwxrwxr-x 7 1000 1000 4096 Jun 6 03:27 nebula-spark-connector -rw-rw-r-- 1 1000 1000 51 Jun 1 04:23 player.csv 然后，实际上我们可以手动再次提交一下这个 Exchange 任务 /spark/bin/spark-submit --master local \\ --class com.vesoft.nebula.exchange.Exchange download/nebula-exchange.jar \\ -c exchange.conf 部分返回结果 22/06/06 03:56:26 INFO Exchange$: Processing Tag player 22/06/06 03:56:26 INFO Exchange$: field keys: _c1, _c2 22/06/06 03:56:26 INFO Exchange$: nebula keys: name, age 22/06/06 03:56:26 INFO Exchange$: Loading CSV files from file:///root/player.csv ... 22/06/06 03:56:41 INFO Exchange$: import for tag player cost time: 3.35 s 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchSuccess.player: 2 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchFailure.player: 0 ... 更多的数据源，请参考文档和配置的例子。 关于 Exchange 输出 SST 文件的实践，你可以参考文档和我的旧文 Nebula Exchange SST 2.x实践指南。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:3:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#一键试玩-exchange"},{"categories":["Nebula Graph"],"content":" 3.1 一键试玩 Exchange 3.1.1 先跑起来看看吧 请参考前边拉起环境这一章节，先一键装好环境。 一键执行： ~/.nebula-up/nebula-exchange-example.sh 恭喜你，已经第一次执行成功一个 Exchange 的数据导入任务啦！ 3.1.2 再看看一些细节这个例子里，我们实际上是用 Exchange 从 CSV 文件这一其中支持的数据源中读取数据写入 Nebula Graph 集群的。这个 CSV 文件中第一列是顶点 ID，第二和第三列是 “姓名 “和 “年龄 “的属性： player800,\"Foo Bar\",23 player801,\"Another Name\",21 咱们可以进到 Spark 环境里看看 docker exec -it sparkmaster bash cd /root 可以看到我们提交 Exchange 任务时候指定的配置文件 exchange.conf 它是一个 HOCON 格式的文件： 在 .nebula 中描述了 Nebula Graph 集群的相关信息 在 .tags 中描述了如何将必填字段对应到我们的数据源（这里是 CSV 文件）等有关 Vertecies 的信息。 { # Spark relation config spark: { app: { name: Nebula Exchange } master:local driver: { cores: 1 maxResultSize: 1G } executor: { memory: 1G } cores:{ max: 16 } } # Nebula Graph relation config nebula: { address:{ graph:[\"graphd:9669\"] meta:[\"metad0:9559\", \"metad1:9559\", \"metad2:9559\"] } user: root pswd: nebula space: basketballplayer # parameters for SST import, not required path:{ local:\"/tmp\" remote:\"/sst\" hdfs.namenode: \"hdfs://localhost:9000\" } # nebula client connection parameters connection { # socket connect \u0026 execute timeout, unit: millisecond timeout: 30000 } error: { # max number of failures, if the number of failures is bigger than max, then exit the application. max: 32 # failed import job will be recorded in output path output: /tmp/errors } # use google's RateLimiter to limit the requests send to NebulaGraph rate: { # the stable throughput of RateLimiter limit: 1024 # Acquires a permit from RateLimiter, unit: MILLISECONDS # if it can't be obtained within the specified timeout, then give up the request. timeout: 1000 } } # Processing tags # There are tag config examples for different dataSources. tags: [ # HDFS csv # Import mode is client, just change type.sink to sst if you want to use client import mode. { name: player type: { source: csv sink: client } path: \"file:///root/player.csv\" # if your csv file has no header, then use _c0,_c1,_c2,.. to indicate fields fields: [_c1, _c2] nebula.fields: [name, age] vertex: { field:_c0 } separator: \",\" header: false batch: 256 partition: 32 } ] } 我们应该能看到那个 CSV 数据源和这个配置文件都在同一个目录下了： bash-5.0# ls -l total 24 drwxrwxr-x 2 1000 1000 4096 Jun 1 04:26 download -rw-rw-r-- 1 1000 1000 1908 Jun 1 04:23 exchange.conf -rw-rw-r-- 1 1000 1000 2593 Jun 1 04:23 hadoop.env drwxrwxr-x 7 1000 1000 4096 Jun 6 03:27 nebula-spark-connector -rw-rw-r-- 1 1000 1000 51 Jun 1 04:23 player.csv 然后，实际上我们可以手动再次提交一下这个 Exchange 任务 /spark/bin/spark-submit --master local \\ --class com.vesoft.nebula.exchange.Exchange download/nebula-exchange.jar \\ -c exchange.conf 部分返回结果 22/06/06 03:56:26 INFO Exchange$: Processing Tag player 22/06/06 03:56:26 INFO Exchange$: field keys: _c1, _c2 22/06/06 03:56:26 INFO Exchange$: nebula keys: name, age 22/06/06 03:56:26 INFO Exchange$: Loading CSV files from file:///root/player.csv ... 22/06/06 03:56:41 INFO Exchange$: import for tag player cost time: 3.35 s 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchSuccess.player: 2 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchFailure.player: 0 ... 更多的数据源，请参考文档和配置的例子。 关于 Exchange 输出 SST 文件的实践，你可以参考文档和我的旧文 Nebula Exchange SST 2.x实践指南。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:3:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#先跑起来看看吧"},{"categories":["Nebula Graph"],"content":" 3.1 一键试玩 Exchange 3.1.1 先跑起来看看吧 请参考前边拉起环境这一章节，先一键装好环境。 一键执行： ~/.nebula-up/nebula-exchange-example.sh 恭喜你，已经第一次执行成功一个 Exchange 的数据导入任务啦！ 3.1.2 再看看一些细节这个例子里，我们实际上是用 Exchange 从 CSV 文件这一其中支持的数据源中读取数据写入 Nebula Graph 集群的。这个 CSV 文件中第一列是顶点 ID，第二和第三列是 “姓名 “和 “年龄 “的属性： player800,\"Foo Bar\",23 player801,\"Another Name\",21 咱们可以进到 Spark 环境里看看 docker exec -it sparkmaster bash cd /root 可以看到我们提交 Exchange 任务时候指定的配置文件 exchange.conf 它是一个 HOCON 格式的文件： 在 .nebula 中描述了 Nebula Graph 集群的相关信息 在 .tags 中描述了如何将必填字段对应到我们的数据源（这里是 CSV 文件）等有关 Vertecies 的信息。 { # Spark relation config spark: { app: { name: Nebula Exchange } master:local driver: { cores: 1 maxResultSize: 1G } executor: { memory: 1G } cores:{ max: 16 } } # Nebula Graph relation config nebula: { address:{ graph:[\"graphd:9669\"] meta:[\"metad0:9559\", \"metad1:9559\", \"metad2:9559\"] } user: root pswd: nebula space: basketballplayer # parameters for SST import, not required path:{ local:\"/tmp\" remote:\"/sst\" hdfs.namenode: \"hdfs://localhost:9000\" } # nebula client connection parameters connection { # socket connect \u0026 execute timeout, unit: millisecond timeout: 30000 } error: { # max number of failures, if the number of failures is bigger than max, then exit the application. max: 32 # failed import job will be recorded in output path output: /tmp/errors } # use google's RateLimiter to limit the requests send to NebulaGraph rate: { # the stable throughput of RateLimiter limit: 1024 # Acquires a permit from RateLimiter, unit: MILLISECONDS # if it can't be obtained within the specified timeout, then give up the request. timeout: 1000 } } # Processing tags # There are tag config examples for different dataSources. tags: [ # HDFS csv # Import mode is client, just change type.sink to sst if you want to use client import mode. { name: player type: { source: csv sink: client } path: \"file:///root/player.csv\" # if your csv file has no header, then use _c0,_c1,_c2,.. to indicate fields fields: [_c1, _c2] nebula.fields: [name, age] vertex: { field:_c0 } separator: \",\" header: false batch: 256 partition: 32 } ] } 我们应该能看到那个 CSV 数据源和这个配置文件都在同一个目录下了： bash-5.0# ls -l total 24 drwxrwxr-x 2 1000 1000 4096 Jun 1 04:26 download -rw-rw-r-- 1 1000 1000 1908 Jun 1 04:23 exchange.conf -rw-rw-r-- 1 1000 1000 2593 Jun 1 04:23 hadoop.env drwxrwxr-x 7 1000 1000 4096 Jun 6 03:27 nebula-spark-connector -rw-rw-r-- 1 1000 1000 51 Jun 1 04:23 player.csv 然后，实际上我们可以手动再次提交一下这个 Exchange 任务 /spark/bin/spark-submit --master local \\ --class com.vesoft.nebula.exchange.Exchange download/nebula-exchange.jar \\ -c exchange.conf 部分返回结果 22/06/06 03:56:26 INFO Exchange$: Processing Tag player 22/06/06 03:56:26 INFO Exchange$: field keys: _c1, _c2 22/06/06 03:56:26 INFO Exchange$: nebula keys: name, age 22/06/06 03:56:26 INFO Exchange$: Loading CSV files from file:///root/player.csv ... 22/06/06 03:56:41 INFO Exchange$: import for tag player cost time: 3.35 s 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchSuccess.player: 2 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchFailure.player: 0 ... 更多的数据源，请参考文档和配置的例子。 关于 Exchange 输出 SST 文件的实践，你可以参考文档和我的旧文 Nebula Exchange SST 2.x实践指南。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:3:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#再看看一些细节"},{"categories":["Nebula Graph"],"content":" 4 Nebula Algorithm 代码仓库： https://github.com/vesoft-inc/nebula-algorithm 文档：https://docs.nebula-graph.com.cn/3.1.0/nebula-algorithm/ JAR 包：https://repo1.maven.org/maven2/com/vesoft/nebula-algorithm/ 示例代码：example/src/main/scala/com/vesoft/nebula/algorithm ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:4:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-algorithm"},{"categories":["Nebula Graph"],"content":" 4.1 通过 spark-submit 提交任务 我在这个代码仓库里给出了例子，今天我们借助 Nebula-UP 可以更方便体验它。 参考前边拉起环境这一章节，先一键装好环境。 在如上通过 Nebula-UP 的 Spark 模式部署了需要的依赖之后 加载 LiveJournal 数据集 ~/.nebula-up/load-LiveJournal-dataset.sh 在 LiveJournal 数据集上执行一个 PageRank 算法，结果输出到 CSV 文件中 ~/.nebula-up/nebula-algo-pagerank-example.sh 检查输出结果： docker exec -it sparkmaster bash head /output/part*000.csv _id,pagerank 637100,0.9268620883822242 108150,1.1855749056722755 957460,0.923720299211093 257320,0.9967932799358413 4.1.1 配置文件解读完整文件在这里，这里，我们介绍一下主要的字段： .data 指定了源是 Nebula，表示从集群获取图数据，输出sink是 csv，表示写到本地文件里。 data: { # data source. optional of nebula,csv,json source: nebula # data sink, means the algorithm result will be write into this sink. optional of nebula,csv,text sink: csv # if your algorithm needs weight hasWeight: false } .nebula.read 规定了读 Nebula Graph 集群的对应关系，这里是读取所有 edge type: follow 的边数据为一整张图 nebula: { # algo's data source from Nebula. If data.source is nebula, then this nebula.read config can be valid. read: { # Nebula metad server address, multiple addresses are split by English comma metaAddress: \"metad0:9559\" # Nebula space space: livejournal # Nebula edge types, multiple labels means that data from multiple edges will union together labels: [\"follow\"] # Nebula edge property name for each edge type, this property will be as weight col for algorithm. # Make sure the weightCols are corresponding to labels. weightCols: [] } .algorithm 里配置了我们要调用的算法，和算法的配置 algorithm: { executeAlgo: pagerank # PageRank parameter pagerank: { maxIter: 10 resetProb: 0.15 # default 0.15 } ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:4:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#通过-spark-submit-提交任务"},{"categories":["Nebula Graph"],"content":" 4.1 通过 spark-submit 提交任务 我在这个代码仓库里给出了例子，今天我们借助 Nebula-UP 可以更方便体验它。 参考前边拉起环境这一章节，先一键装好环境。 在如上通过 Nebula-UP 的 Spark 模式部署了需要的依赖之后 加载 LiveJournal 数据集 ~/.nebula-up/load-LiveJournal-dataset.sh 在 LiveJournal 数据集上执行一个 PageRank 算法，结果输出到 CSV 文件中 ~/.nebula-up/nebula-algo-pagerank-example.sh 检查输出结果： docker exec -it sparkmaster bash head /output/part*000.csv _id,pagerank 637100,0.9268620883822242 108150,1.1855749056722755 957460,0.923720299211093 257320,0.9967932799358413 4.1.1 配置文件解读完整文件在这里，这里，我们介绍一下主要的字段： .data 指定了源是 Nebula，表示从集群获取图数据，输出sink是 csv，表示写到本地文件里。 data: { # data source. optional of nebula,csv,json source: nebula # data sink, means the algorithm result will be write into this sink. optional of nebula,csv,text sink: csv # if your algorithm needs weight hasWeight: false } .nebula.read 规定了读 Nebula Graph 集群的对应关系，这里是读取所有 edge type: follow 的边数据为一整张图 nebula: { # algo's data source from Nebula. If data.source is nebula, then this nebula.read config can be valid. read: { # Nebula metad server address, multiple addresses are split by English comma metaAddress: \"metad0:9559\" # Nebula space space: livejournal # Nebula edge types, multiple labels means that data from multiple edges will union together labels: [\"follow\"] # Nebula edge property name for each edge type, this property will be as weight col for algorithm. # Make sure the weightCols are corresponding to labels. weightCols: [] } .algorithm 里配置了我们要调用的算法，和算法的配置 algorithm: { executeAlgo: pagerank # PageRank parameter pagerank: { maxIter: 10 resetProb: 0.15 # default 0.15 } ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:4:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#配置文件解读"},{"categories":["Nebula Graph"],"content":" 4.2 作为一个库在 Spark 中调用 Nebula Algoritm请注意另一方面，我们可以将 Nebula Algoritm 作为一个库调用，它的好处在于： 对算法的输出格式有更多的控制/定制功能 可以对非数字 ID 的情况进行转换，见这里 这里我先不给出例子了，如果大家感兴趣可以给 Nebula-UP 提需求，我也会增加相应的例子。 题图来源： Sander ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:4:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#作为一个库在-spark-中调用-nebula-algoritm"},{"categories":["Nebula Graph"],"content":"得益于 Nebula 的原生 ARM64v8 的支持，在树莓派等 ARM 单板上跑 Nebula Graph 也非常容易。","date":"2022-03-23","objectID":"/nebula-graph-on-pi/","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/"},{"categories":["Nebula Graph"],"content":" 得益于 Nebula 的原生 ARM64v8 的支持，在树莓派等 ARM 单板上跑 Nebula Graph 非常容易。 ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:0:0","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#"},{"categories":["Nebula Graph"],"content":" 1 背景最近，在 Nebula Graph 社区 Yee 老师的（再）一次修复了 Nebula Graph 的构建依赖的 ARM 支持问题（nebula-third-party#37）之后，我们又可以愉快地在 M1 Mac 上玩这个分布式开源图数据库了。 苦于树莓派的价格，一直没找机会把 Nebula 跑在小板子上玩玩。至于为什么要跑在树莓派上我的回答当然是 Because I can 在非常非常边缘计算的场景下（这里挖个坑，我一定要找一个这样的场景分享出来）。 终于，一周多之前在 @laixintao 和 @andelf 的一个讨论下我决定找一个树莓派的 alternative，最后下单了 Rock Pi 3A，在因为深圳疫情影响下拖到了这个礼拜才终于发货了！ 它看起来真的很棒！ ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:1:0","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#背景"},{"categories":["Nebula Graph"],"content":" 2 在 ARM64 板子上装 Nebula Graph 图数据库 实际上 Nebula Graph 在 3.0 之后提供了一个单机版，这使得 Nebula 在边缘计算情况下有了更小的 footprint，不过这次我还没有使用这个版本，下次试试再给大家分享。 我在附录列出了安装 Ubuntu Server 的步骤，这里假设大家已经在树莓派或者其他单板 ARM 电脑里拉起来了 64 位的 Linux Server。 ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:2:0","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#在-arm64-板子上装-nebula-graph-图数据库"},{"categories":["Nebula Graph"],"content":" 2.1 第 0 步，安装 Docker 和 Docker-Compose这里，我假设是 Debian/Ubuntu，其他分发版直接参考这里就好。 sudo apt-get update sudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release echo \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io # follow https://docs.docker.com/engine/install/linux-postinstall/ sudo groupadd docker sudo usermod -aG docker $USER exit # login again newgrp docker 安装好了 Docker 之后，安装 Compose，它 Docker 官方的步骤是有问题的，因为它其实是一个 Python 的包，我们通过 PIP 去装就好了。 sudo apt-get install -y python3 python3-pip sudo pip3 install docker-compose ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:2:1","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#第-0-步安装-docker-和-docker-compose"},{"categories":["Nebula Graph"],"content":" 2.2 第 1 步，拉起 Nebula Graph首先，我们克隆 Nebula Docker Compose 这个 Repo，在 Master Branch，用 Compose 把服务拉起来。 git clone https://github.com/vesoft-inc/nebula-docker-compose.git \u0026\u0026 cd nebula-docker-compose docker-compose up -d 然后，我们下载 Console，连上 GraphD 服务。 wget https://github.com/vesoft-inc/nebula-console/releases/download/v3.0.0/nebula-console-linux-arm64-v3.0.0 chmod +x nebula-console-linux-arm64-v3.0.0 ./nebula-console-linux-arm64-v3.0.0 -addr localhost -port 9669 -u root -p nebula 并激活 Storage 服务。 ADD HOSTS \"storaged0\":9779,\"storaged1\":9779,\"storaged2\":9779; SHOW HOSTS; ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:2:2","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#第-1-步拉起-nebula-graph"},{"categories":["Nebula Graph"],"content":" 2.3 第 2 步，玩转 Nebula Graph on Pi这时候，透过 SHOW HOSTS 看到三个 StorageD 服务都是 ONLINE 之后，我们可以给 Nebula 里加载进去测试数据集。 $:play basketballplayer; 差不多一分钟之后，数据库加载成功，我们进入这个图空间，玩一下吧！ USE basketballplayer; GO FROM \"player100\" OVER follow YIELD dst(edge); Check this out and… Happy Graphing! ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:2:3","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#第-2-步玩转-nebula-graph-on-pi"},{"categories":["Nebula Graph"],"content":" 3 附录：安装 Ubuntu Server 在 Rock Pi 3A 上 准备一个 micro SD card，在 https://wiki.radxa.com/Rock3/downloads 下载镜像，解压为 .img 文件 把镜像写进 SD card，比如用 etcher 插入电源（5V，3A）启动！ feature image credit: @_louisreed ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:3:0","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#附录安装-ubuntu-server-在-rock-pi-3a-上"},{"categories":["Nebula Graph"],"content":"我发现用 Nebula Graph 的图查询解 Antfu 的汉兜特别有意思！","date":"2022-02-28","objectID":"/resolve-wordle/","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/"},{"categories":["Nebula Graph"],"content":" 我发现用 Nebula Graph 的图查询解 Antfu 的汉兜（最好的中文成语版 wordle 👉🏻 handle.antfu.me）特别有意思，很适合每天写图库语句的体操练习，本文揭示如何用知识图谱作弊解汉兜😁 ","date":"2022-02-28","objectID":"/resolve-wordle/:0:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#"},{"categories":["Nebula Graph"],"content":" 1 什么是汉兜？汉兜（https://handle.antfu.me）是由 Vue/Vite 核心团队的 Antfu 的又一个非常酷的作品，一个非常精致的汉字版的 Wordle，他是是一个每日挑战的填字游戏的中文成语版。 每天，汉兜会发起一个猜成语挑战，人们要在十次内才对它才能获胜，每一步之后都会收到相应的文字、声母、韵母、声调的匹配情况的提示，其中：绿色表示这个因素存在并且位置匹配、橘色表示这个元素存在但是位置不对，详细的规则可见如下的网页截图： 汉兜的乐趣就我们在于在有限的尝试过程中，在大脑中搜寻可能的答案，不断去逼近真理，任何试图作弊、讨巧去泄漏结果的行为都是很无趣、倒胃口的（比如从开源的汉兜代码里窃取信息），这个过程就像在做大脑的体操。 说到大脑的成语词汇量体操，我突然想到，为什么我们不能在大脑之外造一个汉语成语知识图谱，然后基于这个图谱去做图数据库查询语法体操呢？ ","date":"2022-02-28","objectID":"/resolve-wordle/:1:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#什么是汉兜"},{"categories":["Nebula Graph"],"content":" 2 构造解决汉兜的成语知识图谱","date":"2022-02-28","objectID":"/resolve-wordle/:2:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#构造解决汉兜的成语知识图谱"},{"categories":["Nebula Graph"],"content":" 2.1 什么是知识图谱？简单来说，知识图谱是一个连接实体之间关联关系的网络，它最初由 Google 提出并用来满足搜索引擎中基于知识推理才可获得（而不是网页倒排索引）的搜索问题，比如：”姚明妻子的年龄？“、”火箭队得过几次总冠军？“ 这里边，我们关注的条件。到 2022 年的现在，知识图谱已经被广泛应用在推荐系统、问答系统、安全风控等等更多搜索之外的领域。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:1","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#什么是知识图谱"},{"categories":["Nebula Graph"],"content":" 2.2 为什么需要用知识图谱解决汉兜？原因就是：because I can 实际上，我们在大脑中解决字谜游戏的过程像极了图谱网络中的信息搜寻的过程，汉兜的解谜反馈提示条件天然适合被用图谱的语义来进行表达。在本文后边，你们会发现解谜条件翻译成图语义是非常非常自然的，这个问题就像是一个天然的为图谱而存在的练习一样，我相信这和知识图谱的结构和人脑中的知识结构非常接近有很大的关系。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:2","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#为什么需要用知识图谱解决汉兜"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#如何构建面向汉兜解谜的知识图谱"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#图建模"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#最初的想法"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#最终的版本"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#构建成语知识图谱"},{"categories":["Nebula Graph"],"content":" 3 开始知识图谱查询体操至此，我假设咱们都已经有了我帮大家搭建的成语作弊知识图谱了，开始我们的图谱查询体操吧！ 首先，打开汉兜 👉🏻 https://handle.antfu.me/ 假设我们想从一个成语开始，如果你没有想法的话可以试试这个： // 匹配成语中的一个结果 MATCH (x:`idiom`) RETURN x LIMIT 1 // 返回结果 // (\"爱憎分明\" :idiom{pinyin: \"['ai4', 'zeng1', 'fen1', 'ming2']\"}) 然后我们把它填到汉兜之中，获得第一次尝试的提示条件： 我们运气不错，得到了三个位置上的条件！ 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱（爱） 有一个一声的字，不在第二个位置（憎） 有一个字韵母是 ing，不在第四个位置（明） 第四个字是二声（明） 下面，我们开始图数据库语句体操！ // 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱 MATCH (char0:`character`)\u003c-[with_char_0:`with_character`]-(x:`idiom`)-[with_pinyin_0:`with_pinyin`]-\u003e(pinyin_0:`character_pinyin`)-[:`with_pinyin_part`]-\u003e(`final_part_0`:`pinyin_part`{part_type: \"final\"}) WHERE id(`final_part_0`) == \"ai\" AND pinyin_0.`character_pinyin`.tone == 4 AND with_pinyin_0.`position` != 0 AND with_char_0.`position` != 0 AND id(char0) != \"爱\" // 有一个一声的字，不在第二个位置 MATCH (x:`idiom`) -[with_pinyin_1:`with_pinyin`]-\u003e(pinyin_1:`character_pinyin`) WHERE pinyin_1.`character_pinyin`.tone == 1 AND with_pinyin_1.`position` != 1 // 有一个字韵母是 ing，不在第四个位置 MATCH (x:`idiom`) -[with_pinyin_2:`with_pinyin`]-\u003e(:`character_pinyin`)-[:`with_pinyin_part`]-\u003e(final_part_2:`pinyin_part`{part_type: \"final\"}) WHERE id(final_part_2) == \"ing\" AND with_pinyin_2.`position` != 3 // 第四个字是二声 MATCH (x:`idiom`) -[with_pinyin_3:`with_pinyin`]-\u003e(pinyin_3:`character_pinyin`) WHERE pinyin_3.`character_pinyin`.tone == 2 AND with_pinyin_3.`position` == 3 RETURN x, count(x) as c ORDER BY c DESC 在图数据库之中运行，得到了 7 个答案： (\"惊愚骇俗\" :idiom{pinyin: \"['jing1', 'yu2', 'hai4', 'su2']\"}) (\"惊世骇俗\" :idiom{pinyin: \"['jing1', 'shi4', 'hai4', 'su2']\"}) (\"惊见骇闻\" :idiom{pinyin: \"['jing1', 'jian4', 'hai4', 'wen2']\"}) (\"沽名卖直\" :idiom{pinyin: \"['gu1', 'ming2', 'mai4', 'zhi2']\"}) (\"惊心骇神\" :idiom{pinyin: \"['jing1', 'xin1', 'hai4', 'shen2']\"}) (\"荆棘载途\" :idiom{pinyin: \"['jing1', 'ji2', 'zai4', 'tu2']\"}) (\"出卖灵魂\" :idiom{pinyin: \"['chu1', 'mai4', 'ling2', 'hun2']\"}) 看起来 惊世骇俗 比较主流，试试！ 我们很幸运，借助于成语作弊知识图谱，居然一次就找到了答案，当然这实际上得益于第一次随机选取的词带来的限制条件的个数，不过在大部分情况下，两次尝试获得最终答案的可能性还是非常大的！ 注，这中间很长的253分钟是因为我在查询中发现之前代码里构造的图谱有点 bug，是“披枷带锁”这个词引起的读音图谱的错误数据，还好后来被修复了。 大家知道“披枷带锁”的正确读音么？😭 接下来，我给大家详细解释一下这个语句的意思。 ","date":"2022-02-28","objectID":"/resolve-wordle/:3:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#开始知识图谱查询体操"},{"categories":["Nebula Graph"],"content":" 3.1 语句的含义我们从第一个字的条件开始，这是一个既有声音、又有字形信息的条件。 声音信息：存在一个韵母为 ai4 的发音，位置不在第一个字 文字信息：这个韵母为 ai4 的字，不是爱字 对于声音信息条件，转换为图模式匹配为：(成语)-一个字发音-(拼音) -包含声母-(韵母) WHERE 拼音韵母为 ai4 AND 位置不是第一个。 因为建模的时候，属性名称我用的是英文（其实中文也是支持的），实际上的语句为： // 有一个非第一个位置的字，拼音是 4 声，韵母是 ai MATCH (x:idiom)-[with_pinyin_0:with_pinyin]-\u003e(pinyin_0:`character_pinyin`)-[:`with_pinyin_part`]-\u003e(`final_part_0`:`pinyin_part`{part_type: \"final\"}) WHERE id(`final_part_0`) == \"ai\" AND pinyin_0.`character_pinyin`.tone == 4 AND with_pinyin_0.`position` != 0 // ... RETURN x 类似的，表示非第一个位置的字，不是爱 的表达是： // 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱 MATCH (char0:`character`)\u003c-[with_char_0:`with_character`]-(x:`idiom`) WHERE with_char_0.`position` != 0 AND id(char0) != \"爱\" // ... RETURN x, count(x) as c ORDER BY c DESC 而因为这两个条件最终描述的是同一个字，所以它们是可以被写在一个路径下的： // 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱 MATCH (char0:`character`)\u003c-[with_char_0:`with_character`]-(x:`idiom`)-[with_pinyin_0:`with_pinyin`]-\u003e(pinyin_0:`character_pinyin`)-[:`with_pinyin_part`]-\u003e(`final_part_0`:`pinyin_part`{part_type: \"final\"}) WHERE id(`final_part_0`) == \"ai\" AND pinyin_0.`character_pinyin`.tone == 4 AND with_pinyin_0.`position` != 0 AND with_char_0.`position` != 0 AND id(char0) != \"爱\" // ... RETURN x 更多的 MATCH 语法和例子细节，请大家参考文档： MATCH https://docs.nebula-graph.com.cn/3.0.0/3.ngql-guide/7.general-query-statements/2.match/ 图模式 https://docs.nebula-graph.com.cn/3.0.0/3.ngql-guide/1.nGQL-overview/3.graph-patterns/ nGQL 命令 cheatsheet https://docs.nebula-graph.com.cn/3.0.0/2.quick-start/6.cheatsheet-for-ngql-command/ ","date":"2022-02-28","objectID":"/resolve-wordle/:3:1","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#语句的含义"},{"categories":["Nebula Graph"],"content":" 4 可视化展示线索我们把每一个条件的匹配路径作为输出，利用 Nebula Graph 的可视化能力，可以得到： // 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱 MATCH p0=(char0:`character`)\u003c-[with_char_0:`with_character`]-(x:`idiom`)-[with_pinyin_0:`with_pinyin`]-\u003e(pinyin_0:`character_pinyin`)-[:`with_pinyin_part`]-\u003e(`final_part_0`:`pinyin_part`{part_type: \"final\"}) WHERE id(`final_part_0`) == \"ai\" AND pinyin_0.`character_pinyin`.tone == 4 AND with_pinyin_0.`position` != 0 AND with_char_0.`position` != 0 AND id(char0) != \"爱\" // 有一个一声的字，不在第二个位置 MATCH p1=(x:`idiom`) -[with_pinyin_1:`with_pinyin`]-\u003e(pinyin_1:`character_pinyin`) WHERE pinyin_1.`character_pinyin`.tone == 1 AND with_pinyin_1.`position` != 1 // 有一个字韵母是 ing，不在第四个位置 MATCH p2=(x:`idiom`) -[with_pinyin_2:`with_pinyin`]-\u003e(:`character_pinyin`)-[:`with_pinyin_part`]-\u003e(final_part_2:`pinyin_part`{part_type: \"final\"}) WHERE id(final_part_2) == \"ing\" AND with_pinyin_2.`position` != 3 // 第四个字是二声 MATCH p3=(x:`idiom`) -[with_pinyin_3:`with_pinyin`]-\u003e(pinyin_3:`character_pinyin`) WHERE pinyin_3.`character_pinyin`.tone == 2 AND with_pinyin_3.`position` == 3 RETURN p0,p1,p2,p3 在可视化工具的 Console 控制台里执行上边的语句之后，选择导入图探索，就可以看到 ","date":"2022-02-28","objectID":"/resolve-wordle/:4:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#可视化展示线索"},{"categories":["Nebula Graph"],"content":" 5 下一步如果大家是从本文第一次了解到 Nebula Graph 图数据库，那么大家可以下一步从 Nebula Graph 项目和 Nebula Graph 社区的官方 Bilibili 站点 👉🏻 https://space.bilibili.com/472621355 了解更多有意思的入门知识。 另外，这里是 Nebula Graph 的官方线上试玩环境，大家可以照着文档，利用试玩环境尝鲜。 后边，Nebula Graph 会开展每天的汉兜 nGQL 体操活动，敬请关注哈！ Happy Graphing! ","date":"2022-02-28","objectID":"/resolve-wordle/:5:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#下一步"},{"categories":["Nebula Graph"],"content":" 6 附录：搭建成语知识图谱","date":"2022-02-28","objectID":"/resolve-wordle/:6:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#附录搭建成语知识图谱"},{"categories":["Nebula Graph"],"content":" 6.1 收集、生成图谱数据 $ python3 graph_data_generator.py ","date":"2022-02-28","objectID":"/resolve-wordle/:6:1","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#收集生成图谱数据"},{"categories":["Nebula Graph"],"content":" 6.2 导入数据到 Nebula Graph 图数据库 6.2.1 部署图数据库 借助于 Nebula-Up https://github.com/wey-gu/nebula-up/ ，一行就可以了。 $ curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v3.0.0 部署成功的话，会看到这样的结果： ┌────────────────────────────────────────┐ │ 🌌 Nebula-Graph Playground is Up now! │ ├────────────────────────────────────────┤ │ │ │ 🎉 Congrats! Your Nebula is Up now! │ │ $ cd ~/.nebula-up │ │ │ │ 🌏 You can access it from browser: │ │ http://127.0.0.1:7001 │ │ http://\u003cother_interface\u003e:7001 │ │ │ │ 🔥 Or access via Nebula Console: │ │ $ ~/.nebula-up/console.sh │ │ │ │ To remove the playground: │ │ $ ~/.nebula-up/uninstall.sh │ │ │ │ 🚀 Have Fun! │ │ │ └────────────────────────────────────────┘ 6.2.2 图谱入库 借助于 Nebula-Importer https://github.com/vesoft-inc/nebula-importer/ ，一行就可以了。 $ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v ${PWD}/importer_conf.yaml:/root/importer_conf.yaml \\ -v ${PWD}/output:/root \\ vesoft/nebula-importer:v3.0.0 \\ --config /root/importer_conf.yaml 大概一两分钟数据就导入成功了，命令也会正常退出。 连到图数据库的 console 进入 Console 的容器执行下边的命令： $ ~/.nebula-up/console.sh # nebula-console -addr graphd -port 9669 -user root -p nebula 检查一下导入的数据： (root@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"chinese_idiom\" | +--------------------+ (root@nebula) [(none)]\u003e use chinese_idiom Execution succeeded (time spent 1510/2329 us) Fri, 25 Feb 2022 08:53:11 UTC (root@nebula) [chinese_idiom]\u003e MATCH p=(成语:`idiom`) RETURN p LIMIT 2 +------------------------------------------------------------------+ | p | +------------------------------------------------------------------+ | \u003c(\"一丁不识\" :idiom{pinyin: \"['yi1', 'ding1', 'bu4', 'shi2']\"})\u003e | | \u003c(\"一丝不挂\" :idiom{pinyin: \"['yi1', 'si1', 'bu4', 'gua4']\"})\u003e | +------------------------------------------------------------------+ (root@nebula) [chinese_idiom]\u003e SUBMIT JOB STATS +------------+ | New Job Id | +------------+ | 11 | +------------+ (root@nebula) [chinese_idiom]\u003e SHOW STATS +---------+--------------------+--------+ | Type | Name | Count | +---------+--------------------+--------+ | \"Tag\" | \"character\" | 4847 | | \"Tag\" | \"character_pinyin\" | 1336 | | \"Tag\" | \"idiom\" | 29503 | | \"Tag\" | \"pinyin_part\" | 57 | | \"Edge\" | \"with_character\" | 116090 | | \"Edge\" | \"with_pinyin\" | 5943 | | \"Edge\" | \"with_pinyin_part\" | 3290 | | \"Space\" | \"vertices\" | 35739 | | \"Space\" | \"edges\" | 125323 | +---------+--------------------+--------+ ","date":"2022-02-28","objectID":"/resolve-wordle/:6:2","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#导入数据到-nebula-graph-图数据库"},{"categories":["Nebula Graph"],"content":" 6.2 导入数据到 Nebula Graph 图数据库 6.2.1 部署图数据库 借助于 Nebula-Up https://github.com/wey-gu/nebula-up/ ，一行就可以了。 $ curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v3.0.0 部署成功的话，会看到这样的结果： ┌────────────────────────────────────────┐ │ 🌌 Nebula-Graph Playground is Up now! │ ├────────────────────────────────────────┤ │ │ │ 🎉 Congrats! Your Nebula is Up now! │ │ $ cd ~/.nebula-up │ │ │ │ 🌏 You can access it from browser: │ │ http://127.0.0.1:7001 │ │ http://:7001 │ │ │ │ 🔥 Or access via Nebula Console: │ │ $ ~/.nebula-up/console.sh │ │ │ │ To remove the playground: │ │ $ ~/.nebula-up/uninstall.sh │ │ │ │ 🚀 Have Fun! │ │ │ └────────────────────────────────────────┘ 6.2.2 图谱入库 借助于 Nebula-Importer https://github.com/vesoft-inc/nebula-importer/ ，一行就可以了。 $ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v ${PWD}/importer_conf.yaml:/root/importer_conf.yaml \\ -v ${PWD}/output:/root \\ vesoft/nebula-importer:v3.0.0 \\ --config /root/importer_conf.yaml 大概一两分钟数据就导入成功了，命令也会正常退出。 连到图数据库的 console 进入 Console 的容器执行下边的命令： $ ~/.nebula-up/console.sh # nebula-console -addr graphd -port 9669 -user root -p nebula 检查一下导入的数据： (root@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"chinese_idiom\" | +--------------------+ (root@nebula) [(none)]\u003e use chinese_idiom Execution succeeded (time spent 1510/2329 us) Fri, 25 Feb 2022 08:53:11 UTC (root@nebula) [chinese_idiom]\u003e MATCH p=(成语:`idiom`) RETURN p LIMIT 2 +------------------------------------------------------------------+ | p | +------------------------------------------------------------------+ | \u003c(\"一丁不识\" :idiom{pinyin: \"['yi1', 'ding1', 'bu4', 'shi2']\"})\u003e | | \u003c(\"一丝不挂\" :idiom{pinyin: \"['yi1', 'si1', 'bu4', 'gua4']\"})\u003e | +------------------------------------------------------------------+ (root@nebula) [chinese_idiom]\u003e SUBMIT JOB STATS +------------+ | New Job Id | +------------+ | 11 | +------------+ (root@nebula) [chinese_idiom]\u003e SHOW STATS +---------+--------------------+--------+ | Type | Name | Count | +---------+--------------------+--------+ | \"Tag\" | \"character\" | 4847 | | \"Tag\" | \"character_pinyin\" | 1336 | | \"Tag\" | \"idiom\" | 29503 | | \"Tag\" | \"pinyin_part\" | 57 | | \"Edge\" | \"with_character\" | 116090 | | \"Edge\" | \"with_pinyin\" | 5943 | | \"Edge\" | \"with_pinyin_part\" | 3290 | | \"Space\" | \"vertices\" | 35739 | | \"Space\" | \"edges\" | 125323 | +---------+--------------------+--------+ ","date":"2022-02-28","objectID":"/resolve-wordle/:6:2","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#部署图数据库"},{"categories":["Nebula Graph"],"content":" 6.2 导入数据到 Nebula Graph 图数据库 6.2.1 部署图数据库 借助于 Nebula-Up https://github.com/wey-gu/nebula-up/ ，一行就可以了。 $ curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v3.0.0 部署成功的话，会看到这样的结果： ┌────────────────────────────────────────┐ │ 🌌 Nebula-Graph Playground is Up now! │ ├────────────────────────────────────────┤ │ │ │ 🎉 Congrats! Your Nebula is Up now! │ │ $ cd ~/.nebula-up │ │ │ │ 🌏 You can access it from browser: │ │ http://127.0.0.1:7001 │ │ http://:7001 │ │ │ │ 🔥 Or access via Nebula Console: │ │ $ ~/.nebula-up/console.sh │ │ │ │ To remove the playground: │ │ $ ~/.nebula-up/uninstall.sh │ │ │ │ 🚀 Have Fun! │ │ │ └────────────────────────────────────────┘ 6.2.2 图谱入库 借助于 Nebula-Importer https://github.com/vesoft-inc/nebula-importer/ ，一行就可以了。 $ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v ${PWD}/importer_conf.yaml:/root/importer_conf.yaml \\ -v ${PWD}/output:/root \\ vesoft/nebula-importer:v3.0.0 \\ --config /root/importer_conf.yaml 大概一两分钟数据就导入成功了，命令也会正常退出。 连到图数据库的 console 进入 Console 的容器执行下边的命令： $ ~/.nebula-up/console.sh # nebula-console -addr graphd -port 9669 -user root -p nebula 检查一下导入的数据： (root@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"chinese_idiom\" | +--------------------+ (root@nebula) [(none)]\u003e use chinese_idiom Execution succeeded (time spent 1510/2329 us) Fri, 25 Feb 2022 08:53:11 UTC (root@nebula) [chinese_idiom]\u003e MATCH p=(成语:`idiom`) RETURN p LIMIT 2 +------------------------------------------------------------------+ | p | +------------------------------------------------------------------+ | \u003c(\"一丁不识\" :idiom{pinyin: \"['yi1', 'ding1', 'bu4', 'shi2']\"})\u003e | | \u003c(\"一丝不挂\" :idiom{pinyin: \"['yi1', 'si1', 'bu4', 'gua4']\"})\u003e | +------------------------------------------------------------------+ (root@nebula) [chinese_idiom]\u003e SUBMIT JOB STATS +------------+ | New Job Id | +------------+ | 11 | +------------+ (root@nebula) [chinese_idiom]\u003e SHOW STATS +---------+--------------------+--------+ | Type | Name | Count | +---------+--------------------+--------+ | \"Tag\" | \"character\" | 4847 | | \"Tag\" | \"character_pinyin\" | 1336 | | \"Tag\" | \"idiom\" | 29503 | | \"Tag\" | \"pinyin_part\" | 57 | | \"Edge\" | \"with_character\" | 116090 | | \"Edge\" | \"with_pinyin\" | 5943 | | \"Edge\" | \"with_pinyin_part\" | 3290 | | \"Space\" | \"vertices\" | 35739 | | \"Space\" | \"edges\" | 125323 | +---------+--------------------+--------+ ","date":"2022-02-28","objectID":"/resolve-wordle/:6:2","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#图谱入库"},{"categories":["Nebula Graph"],"content":" 7 附录：图建模的 Schema nGQL CREATE SPACE IF NOT EXISTS chinese_idiom(partition_num=5, replica_factor=1, vid_type=FIXED_STRING(24)); USE chinese_idiom; // 创建点的类型 CREATE TAG idiom(pinyin string); #成语 CREATE TAG character(); #汉字 CREATE TAG character_pinyin(tone int); #单字的拼音 CREATE TAG pinyin_part(part_type string); #拼音的声部 // 创建边的类型 CREATE EDGE with_character(`position` int); #包含汉字 CREATE EDGE with_pinyin(`position` int); #读作 CREATE EDGE with_pinyin_part(part_type string); #包含声部 ","date":"2022-02-28","objectID":"/resolve-wordle/:7:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#附录图建模的-schema-ngql"},{"categories":["Nebula Graph"],"content":"找不到索引？为什么我要创建 NebulaGraph 索引？什么时候要用到 NebulaGraph 原生索引，一文把这些搞清楚。","date":"2022-02-20","objectID":"/nebula-index-explained/","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/"},{"categories":["Nebula Graph"],"content":" index not found？ 找不到索引？为什么我要创建 NebulaGraph 索引？什么时候要用到 Nebula Graph 原生索引，一文把这些搞清楚。 updated: 3.x 之后，缺乏索引造成的新报错是： need to specify a limit number, or limit number can not push down. NebulaGraph 的索引其实和传统的关系型数据库中的索引很像，但是又有一些容易让人疑惑的区别。刚开始了解 NebulaGraph 的同学会疑惑于： 不清楚 NebulaGraph 图数据库中的索引到的是什么概念 我应该什么时候使用 NebulaGraph 索引 NebulaGraph 索引怎么影响到写入性能 这篇文章里，我们就把这些问题回答好。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:0:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#"},{"categories":["Nebula Graph"],"content":" 1 到底 NebulaGraph 索引是什么简而言之，NebulaGraph 索引是用来，且只用来针对纯属性条件出发查询场景的 图游走（walk）查询中的属性条件过滤不需要它 纯属性条件出发查询（注：非采样情况）必须创建索引 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#到底-nebulagraph-索引是什么"},{"categories":["Nebula Graph"],"content":" 1.1 纯属性条件出发查询我们知道在传统关系型数据库中，索引是对表数据的一个或多个针对特定列重排序的副本，它用来加速特定列过滤条件的读查询并带来了额外的数据写入（加速而非这样查询的必须前提）。 在 NebulaGraph 图数据库里，索引则是对点、边特定属性数据重排序的副本，用来提供纯属性条件出发查询（如下边的查询：从只给定了点边属性条件，而非点的 ID 出发去获取图数据） #### 必须 Nebula Graph 索引存在的查询 # query 0 纯属性条件出发查询 LOOKUP ON tag1 WHERE col1 \u003e 1 AND col2 == \"foo\" \\ YIELD tag1.col1 as col1, tag1.col3 as col3; # query 1 纯属性条件出发查询 MATCH (v:player { name: 'Tim Duncan' })--\u003e(v2:player) \\ RETURN v2.player.name AS Name; 上边这两个纯属性条件出发查询就是字面意思的”根据给定的属性条件获取点或者边本身“ ，反面的例子则是给定了点的 ID： #### 不基于索引的查询 # query 2, 从给定的点做的游走查询 vertex VID: \"player100\" GO FROM \"player100\" OVER follow REVERSELY \\ YIELD src(edge) AS id | \\ GO FROM $-.id OVER serve \\ WHERE properties($^).age \u003e 20 \\ YIELD properties($^).name AS FriendOf, properties($$).name AS Team; # query 3, 从给定的点做的游走查询 vertex VID: \"player101\" 或者 \"player102\" MATCH (v:player { name: 'Tim Duncan' })--(v2) \\ WHERE id(v2) IN [\"player101\", \"player102\"] \\ RETURN v2.player.name AS Name; 我们仔细看前边的 query 1 和 query 3，尽管语句中条件都有针对 tag 为 player 的过滤： { name: 'Tim Duncan' } ： query 3之中不需要索引，因为它可以： 更直接的从已知的 v2 顶点： [\"player101\", \"player102\"] 向外扩展、游走（GetNeighbors() 获得边的另一端的点，然后GetVertices() 得到下一跳的 v），根据 v.player.name 过滤掉不要的数据 query 1 则不同，它因为没有任何给定的顶点 ID： 只能从属性条件入手，{ name: 'Tim Duncan' }，在按照 name 排序了的索引数据中先找到符合的点：IndexScan() 得到 v 然后再从 v 做 GetNeighbors() 获得边的另一端 的 v2 ，在通过 GetVertices() 去获得下一跳 v2 中的数据 其实，这里的关键就是在于是查询是否存在给定的顶点 ID（Vertex ID），下边两个查询的执行计划里更清晰地比较了他们的区别： query 1, 需要基于索引，纯属性条件出发查询 query 3, 从已知 VID，不需要索引 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:1","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#纯属性条件出发查询"},{"categories":["Nebula Graph"],"content":" 1.2 为什么纯属性条件出发查询里必须要索引呢？因为 NebulaGraph 在存储数据的时候，它的结构是面向分布式与关联关系设计的，类似表结构数据库中无索引的全扫描条件搜索实际上更加昂贵，所以设计上被有意禁止了。 注: 如果不追求全部数据，只要采样一部分，3.0 里之后是支持不强制索引 LIMIT 的情况的，如下查询（有 LIMIT）不需要索引： # sample vertex MATCH (v:`team`) RETURN v LIMIT 3 # or sample edge MATCH ()-[e:`follow`]-\u003e() RETURN e LIMIT 3 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:2","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#为什么纯属性条件出发查询里必须要索引呢"},{"categories":["Nebula Graph"],"content":" 1.3 为什么只有纯属性条件出发查询我们比较一下正常的图查询 graph-queries 和纯属性条件出发查询 pure-prop-condition queries： graph-queries： 如 query 2 、 query 3是沿着边一路找到特定路径条件的扩展游走 pure-prop-condition queries：如 query 0 and query 1 是只通过一定属性条件（或者是无限制条件）找到满足的点、边 而在 NebulaGraph 里，graph-queries 在扩展的时候，图的原始数据已经按照 VID（点和边都是）排序过了（或者说在数据里已经索引过了），这个排序带来连续存储（物理上临接）使得扩展游走本身就是优化、很快的。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:3","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#为什么只有纯属性条件出发查询"},{"categories":["Nebula Graph"],"content":" 1.4 总结：索引是什么，索引不是什么？索引是什么？ NebulaGraph 索引是为了从给定属性条件查点、边的一份属性数据的排序，它用写入的代价是的这种读查询模式成为可能。 索引不是什么？ NebulaGraph 索引不是用来加速一般图查询的：从一个点开始向外拓展的查询（即使是过滤属性条件的）不会依赖原生索引，因为 Nebula 数据自身的存储就是面向这种查询优化、排序的。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:4","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#总结索引是什么索引不是什么"},{"categories":["Nebula Graph"],"content":" 2 一些 Nebula Graph 索引的设计细节为了更好理解索引的限制、代价、能力，咱们来解释更多他的细节 NebulaGraph 索引是在本地（不是分开、中心化）和点数据被一起存储、分片的。 它只支持左匹配 因为底层是 RocksDB Prefix Scan 性能代价: 写入时候的路径：不只是多一分数据，为了保证一致性，还有昂贵的读操作 读路径：基于规则的优化选择索引，Fan Out 到所有 StorageD 这些信息也在我的手绘图和视频里可以看到： 因为左匹配的设计，在有更复杂的针对纯属性条件出发查询里涉及到通配、REGEXP这样的全文搜索情况，Nebula Graph 提供了全文索引的功能，它是利用 Raft Listener 去异步将数据写到外部 Elasticsearch 集群之中，并在查询的时候去查 ES 去做到的，见文档。 在这个手绘图中，我们还可以看出 Write path 写入索引数据是同步操作的 Read path 这部分画了一个 RBO 的例子，查询里的规则假设 col2 相等匹配排在左边的情况下，性能优于 col1 的大小比较匹配，所以选择了第二个索引 选好了索引之后，扫描索引的请求被 fan out 到存储节点上，这其中有些过滤条件比如 top n 是可以下推的 结论： 因为写入的代价，只有必须用索引的时候采用，如果采样查询能满足读的要求，可以不创建索引而用 LIMIT 。 索引有左匹配的限制 符合查询的顺序要仔细设计 有时候需要使用全文索引 full-text index。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:2:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#一些-nebula-graph-索引的设计细节"},{"categories":["Nebula Graph"],"content":" 3 索引的使用具体要参考索引文档一些要点是： 在 tag 或者 edge type 上针对想要被条件反查点边的属性创建索引 CREATE INDEX 创建索引之后的索引部分数据会同步写入，但是如果创建索引之前已经有的点边数据对应的索引是需要明确指定去创建的，这是一个异步的 job： REBUILD INDEX 触发了异步的 REBUILD INDEX 之后，可以查询状态： SHOW INDEX STATUS 利用到索引的查询可以是 LOOKUP，并且常常可以借助管道符在此之上做拓展查询（Graph Query）： LOOKUP ON player \\ WHERE player.name == \"Kobe Bryant\"\\ YIELD id(vertex) AS VertexID, properties(vertex).name AS name |\\ GO FROM $-.VertexID OVER serve \\ YIELD $-.name, properties(edge).start_year, properties(edge).end_year, properties($$).name; 也可以是 MATCH ，这里边 v 是通过索引得到的，而 v2 则是在数据（非索引）部分拓展查询获得的。 MATCH (v:`player`{name:\"Tim Duncan\"})--(v2:`player`) \\ RETURN v2.`player`.name AS Name; 复合索引的能力与限制 理解原生索引的匹配是左匹配能让我们知道对于超过一个属性的索引：复合索引，并且能帮助我们理解它的能力有限制，这里说几个结论： 我们创建针对多个属性的复合索引是顺序有关的 比如，我们创建一个双属性复合索引 index_a: (isRisky: bool, age: int)，和 index_b: (age: int, isRisky: bool) 在根据 WHERE n.user.isRisky == true AND n.user.age \u003e 18 这个条件查询时候，index_a 因为左匹配一个相等的短字段，显然效率更高。 只有复合左匹配的被复合索引的属性真子集的过滤条件才能被只支持 比如，index_a: (isRisky: bool, age: int)，和 index_b: (age: int, isRisky: bool) 在查询 WHERE n.user.age \u003e 18 这个语句的时候, 只有 index_b 复合最左匹配，能满足这个查询。 针对一些从属性作为查询的起点，找点、边的情况，原生索引是不能满足全文搜索的匹配场景的，这时候，我们应该考虑使用 Nebula 全文索引，它是 Nebula 社区支持的开箱即用的外置 Elastic Search，通过配置，创建了全文索引的数据会通过 Raft listener 异步更新到 Elastic 集群中，他的查询入口也是 LOOKUP，详细的信息请参考文档。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:3:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#索引的使用"},{"categories":["Nebula Graph"],"content":" 4 回顾 NebulaGraph 索引在只提供属性条件情况下通过对属性的排序副本扫描查点、边 NebulaGraph 索引不是用来图拓展查询的 NebulaGraph 索引是左匹配，不是用来做模糊全文搜索的 NebulaGraph 索引在写入时候有性能代价 记得如果创建 NebulaGraph 索引之前已经有相应点边上的数据，要重建索引 Happy Graphing! Feature image credit to Alina ","date":"2022-02-20","objectID":"/nebula-index-explained/:4:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#回顾"},{"categories":["Nebula Graph"],"content":"一文了解 K8s 部署的 Nebula Graph 集群的 Nebula-Algorithm 使用方法。","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/"},{"categories":["Nebula Graph"],"content":" 一文了解 K8s 部署的 Nebula Graph 集群的 Nebula-Algorithm 使用方法。 ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:0:0","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#"},{"categories":["Nebula Graph"],"content":" 1 步骤最方便的方法是将 Nebula Algorithm/ Spark 运行在与 Nebula-Operator 相同的网络命名空间里，将 show hosts meta 的 MetaD 域名:端口 格式的地址填进配置里就可以了。 注：需要 2.6.2 或者更新的版本，Spark-Connector/Algorithm 才支持域名形式的 MetaD 地址。 获取 MetaD 地址 (root@nebula) [(none)]\u003e show hosts meta +------------------------------------------------------------------+------+----------+--------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +------------------------------------------------------------------+------+----------+--------+--------------+---------+ | \"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local\" | 9559 | \"ONLINE\" | \"META\" | \"d113f4a\" | \"2.6.2\" | +------------------------------------------------------------------+------+----------+--------+--------------+---------+ Got 1 rows (time spent 1378/2598 us) Mon, 14 Feb 2022 08:22:33 UTC 填写 Algorithm 的配置文件 Ref: https://github.com/vesoft-inc/nebula-algorithm/blob/master/nebula-algorithm/src/main/resources/application.conf # ... nebula: { # algo's data source from Nebula. If data.source is nebula, then this nebula.read config can be valid. read: { # Nebula metad server address, multiple addresses are split by English comma metaAddress: \"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local:9559\" #... 或者是调用 spark-connector 的代码 Ref: https://github.com/vesoft-inc/nebula-spark-connector val config = NebulaConnectionConfig .builder() .withMetaAddress(\"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local:9559\") .withConenctionRetry(2) .build() val nebulaReadVertexConfig: ReadNebulaConfig = ReadNebulaConfig .builder() .withSpace(\"foo_bar_space\") .withLabel(\"person\") .withNoColumn(false) .withReturnCols(List(\"birthday\")) .withLimit(10) .withPartitionNum(10) .build() val vertex = spark.read.nebula(config, nebulaReadVertexConfig).loadVerticesToDF() 看起来非常简单，那么，为什么这么简单的过程却值得一篇文章呢？ ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:1:0","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#步骤"},{"categories":["Nebula Graph"],"content":" 1.1 容易忽略的问题这里的问题在于： a. 它隐含地需要保证 StorageD 的地址能被 spark 环境访问； b. 但是这些 StorageD 地址是从 MetaD 获取的； c. Nebula K8s Operator 里，MetaD 中存储的 StorageD 地址（服务发现）的来源是 StorageD 的配置文件，而它是 k8s 的内部地址。 ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:1:1","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#容易忽略的问题"},{"categories":["Nebula Graph"],"content":" 1.2 背景知识a. 的理由比较直接，和 nebula 的架构有关：图的数据都存在 Storage Service 之中，通常用语句的查询是透过 Graph Service 来透传，只需要 GraphD 的连接就足够，而 Spark-Connector 使用 Nebula Graph 的场景是扫描全图或者子图，这时候计算存储分离的设计使得我们可以绕过查询、计算层直接高效读取图数据。 那么问题来了，为什么需要、且只需要 MetaD 的地址呢？ 这也是和架构有关，Meta Service 里包含了全图的分布数据与分布式的 Storage Service 的各个分片和实例的分布，所以一方面因为只有 Meta 才有全图的信息（需要），另一方面因为从 Meta 可以获得这部分信息（只需要）。到这里 b. 的答案也有了。 详细的 Nebula Graph 架构信息可以参考博客系列文章：nebula-graph.com.cn/tags/架构设计 另外请确保您已经读了架构介绍的文档哦：Nebula 架构总览 下面我们看看 c. c. Nebula K8s Operator 里，MetaD 中存储的 StorageD 地址（服务发现）的来源是 StorageD 的配置文件，而它是 k8s 的内部地址。 这和 Nebula Graph 里的服务发现机制有关：在 Nebula Graph 集群中，Graph Service 和 Storage Service 都是通过心跳将自己的信息上报给 Meta Service 的，而这其中服务自身的地址的来源则来自于他们相应的配置文件中的网络配置。 关于服务自身的地址配置请参考文档：Storage networking 配置 关于服务发现详细的信息请参考四王的文章：图数据库 Nebula Graph 集群通信：从心跳说起。 最后，我们知道 Nebula Operator 是一个在 K8s 集群中按照配置，自动创建、维护、扩缩容 Nebula 集群的 K8s 控制面的应用，它需要抽象一部分内部资源相关的配置，这就包括了 GraphD 和 StorageD 实例的实际地址，他们是被配置的地址实际上是 headless service 地址。 而这些地址（如下）默认是没法被 k8s 外部网络访问的，所以针对 GraphD、MetaD 我们可以方便创建服务将其暴露出来。 (root@nebula) [(none)]\u003e show hosts meta +------------------------------------------------------------------+------+----------+--------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +------------------------------------------------------------------+------+----------+--------+--------------+---------+ | \"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local\" | 9559 | \"ONLINE\" | \"META\" | \"d113f4a\" | \"2.6.2\" | +------------------------------------------------------------------+------+----------+--------+--------------+---------+ Got 1 rows (time spent 1378/2598 us) Mon, 14 Feb 2022 09:22:33 UTC (root@nebula) [(none)]\u003e show hosts graph +---------------------------------------------------------------+------+----------+---------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +---------------------------------------------------------------+------+----------+---------+--------------+---------+ | \"nebula-graphd-0.nebula-graphd-svc.default.svc.cluster.local\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"d113f4a\" | \"2.6.2\" | +---------------------------------------------------------------+------+----------+---------+--------------+---------+ Got 1 rows (time spent 2072/3403 us) Mon, 14 Feb 2022 10:03:58 UTC (root@nebula) [(none)]\u003e show hosts storage +------------------------------------------------------------------------+------+----------+-----------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +------------------------------------------------------------------------+------+----------+-----------+--------------+---------+ | \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"d113f4a\" | \"2.6.2\" | | \"nebula-storaged-1.nebula-storaged-headless.default.svc.cluster.local\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"d113f4a\" | \"2.6.2\" | | \"nebula-storaged-2.nebula-storaged-headless.default.svc.cluster.local\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"d113f4a\" | \"2.6.2\" | +------------------------------------------------------------------------+------+----------+-----------+--------------+---------+ Got 3 rows (time spent 1603/2979 us) Mon, 14 Feb 2022 10:05:24 UTC 然而，因为前边提到的 Spark-Connector 通过 Meta Service 去获取 StorageD 的地址，且这个地址是服务发现而得，所以 Spark-Connector 实际上获取的 StorageD 地址就是上边的这种 headless 的服务地址，没法直接从外部访问。 所以，我们在有条件的情况下，只需要让 Spark 运行在和 Nebula Cluster 相同的 K8s 网络里，一切就迎刃而解了，否则，我们需要： 将 MetaD 和 StorageD 的地址利用 Ingress 等方式将其 L4（TCP）暴露出来。 可以参考 Nebula Operator 的文档：doc/user/client_service.md 通过反向代理和DNS让这些 headless 服务能被解析到相应的 StorageD。 参考：TBD 那么，有没有更方便的方式？ 非常抱歉的是，目前最方便的方式依然是如文章最开头所介绍：让 Spark 运行在 Nebula Cluster 内部。实际上，我在努力推进 Nebula Spark 社区去支持可以配置的 StorageAddresses 选项，有了它之后，前边提到的 2. 就是不必要的了。 ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:1:2","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#背景知识"},{"categories":["Nebula Graph"],"content":" 2 Bonus：一键体验 nebula-algorithm + nebula-operator为了方便在 k8s 上尝鲜 nebula-graph nebula-algorithm 的同学，这里我要再次安利一下我写的一个小工具 Neubla-Operator-KinD，它是一个一键在 Docker 环境内部单独部署一个 k8s 集群并在其中部署 Nebula Operator 以及所有依赖（包括 storage provider）并部署一个小 Nebula Cluster 的工具。有点绕，不过可以看下边的步骤哈： 第一步，部署 K8s+Nebula-Operator+Nebula Cluster： curl -sL nebula-kind.siwei.io/install.sh | bash 第二步，照着工具文档里的 what’s next a. 用 console 连接集群，并加载示例数据集 b. 在这个 k8s 里跑一个图算法 创建一个 Spark 环境 kubectl create -f http://nebula-kind.siwei.io/deployment/spark.yaml kubectl wait pod --timeout=-1s --for=condition=Ready -l '!job-name' 等上边的 wait 都 ready 之后，进入 spark 的 pod。 kubectl exec -it deploy/spark-deployment -- bash 下载 nebula-algorithm 比如 2.6.2 这个版本，更多版本请参考 https://github.com/vesoft-inc/nebula-algorithm/。 注意： 官方发布的版本在这里可以获取：https://repo1.maven.org/maven2/com/vesoft/nebula-algorithm/ 因为这个问题 https://github.com/vesoft-inc/nebula-algorithm/issues/42 只有 2.6.2 或者更新的版本才支持域名访问 MetaD。 # 下载 nebula-algorithm-2.6.2.jar wget https://repo1.maven.org/maven2/com/vesoft/nebula-algorithm/2.6.2/nebula-algorithm-2.6.2.jar # 下载 nebula-algorthm 配置文件 wget https://github.com/vesoft-inc/nebula-algorithm/raw/v2.6/nebula-algorithm/src/main/resources/application.conf 修改Then we could change the config file of nebula-algorithm on meta and graph addresses: sed -i '/^ metaAddress/c\\ metaAddress: \\\"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local:9559\\\"' application.conf sed -i '/^ graphAddress/c\\ graphAddress: \\\"nebula-graphd-0.nebula-graphd-svc.default.svc.cluster.local:9669\\\"' application.conf ##### change space sed -i '/^ space/c\\ space: basketballplayer' application.conf ##### read data from nebula graph sed -i '/^ source/c\\ source: nebula' application.conf ##### execute algorithm: labelpropagation sed -i '/^ executeAlgo/c\\ executeAlgo: labelpropagation' application.conf 执行 LPA 算法在 basketballplayer 图空间 /spark/bin/spark-submit --master \"local\" --conf spark.rpc.askTimeout=6000s \\ --class com.vesoft.nebula.algorithm.Main \\ nebula-algorithm-2.6.2.jar \\ -p application.conf 结果如下： bash-5.0# ls /tmp/count/ _SUCCESS part-00000-5475f9f4-66b9-426b-b0c2-704f946e54d3-c000.csv bash-5.0# head /tmp/count/part-00000-5475f9f4-66b9-426b-b0c2-704f946e54d3-c000.csv _id,lpa 1100,1104 2200,2200 2201,2201 1101,1104 2202,2202 Happy Graphing! Picture Credit: Timelab Pro ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:2:0","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#bonus一键体验-nebula-algorithm--nebula-operator"},{"categories":["Nebula Graph","Mini Project"],"content":"如何利用图数据库从0-1构建一个特定领域问答助手？本文手把手带你构建一个简易版的篮球领域智能问答机器人。","date":"2021-12-30","objectID":"/siwi/","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/"},{"categories":["Nebula Graph","Mini Project"],"content":" 如何利用图数据库从0-1构建一个特定领域问答助手？本文手把手带你构建一个简易版的篮球领域智能问答机器人。 ","date":"2021-12-30","objectID":"/siwi/:0:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#"},{"categories":["Nebula Graph","Mini Project"],"content":" 1 前言「问答机器人」在我们日常生活中并不少见到 ：比如在一些电商客服、智能问诊、技术支持等人工输入与沟通界面的场景下，机器人“智能”问答系统一定程度上可以在无需人力、不需要耗费终端用户心智去做知识库、商品搜索、科室选择等等的情况下实时给出问题答案。 问答机器人系统背后的技术有多重可能： 基于检索，全文搜索接近的问题 基于机器学习阅读理解 基于知识图谱（Knowledge-Based Question Answering system: KBQA） 其他 基于知识图谱构建问答系统在以下三个情况下很有优势： 对于领域类型是结构化数据场景：电商、医药、系统运维（微服务、服务器、事件）、产品支持系统等，其中作为问答系统的参考对象已经是结构化数据； 问题的解答过程涉及多跳查询，比如“姚明的妻子今年是本命年吗？”，“你们家的产品 A 和 A+ 的区别是什么？”； 为了解决其他需求（风控、推荐、管理），已经构建了图结构数据、知识图谱的情况。 为了方便读者最快速了解如何构建 KBQA 系统，我写了非常简陋的小 KBQA 项目，在本文中，我会带领大家从头到尾把它搭起来。 💡：这个小项目叫做 Siwi，它的代码就在 GitHub 上：github.com/wey-gu/nebula-siwi Siwi 的发音是：/ˈsɪwi/ 或者叫：思二为 ，它是一个能解答 NBA 相关问题的机器人。 我们开始吧。 ","date":"2021-12-30","objectID":"/siwi/:1:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#前言"},{"categories":["Nebula Graph","Mini Project"],"content":" 2 鸟瞰 TL;DRKBQA 用一句话说就是把问题解析、转换成在知识图谱中的查询，查询得到结果之后进行筛选、翻译成结果（句子、卡片或者任何方便人理解的答案格式）。 💡：知识图谱的构建实际上是非常重要的过程，在本文中，我们专注在串起来 KBQA 系统的骨架，我们假设需求是基于一个已经有的图谱之上，为其增加一个 QA 系统。 「问题到图谱查询的转换」有不同的方法可以实现。 可以是对语义进行分析：理解问题的意图，针对不同意图匹配最可能的问题类型，从而构建这个类型问题的图谱查询，查得结果； 也可以是基于信息的抽取：从问题中抽取主要的实体，在图谱中获取实体的所有知识、关系条目（子图），再对结果根据问题中的约束条件匹配、排序选择结果。 💡：美团技术团队在这篇文章里分享了他们的真实世界实践，下图是美团结合了机器学习和 NLP 的方案。 而在 Siwi 里，我们一切从简，单独选择了语义分析这条路，它的特点是需要人为去标注或者编码一些问题类型的查询方式，但实际上在大多数场景下，尤其单一领域图谱的场景下反而是轻量却效果不差的方案，也是一个便于新手理解 KBQA 的合适的入门方式。 除了核心的问答部分，我还为 Siwi 增加了语音识别和语音回答（感谢浏览器接口标准的发展）的功能，于是，这个项目的结构和问答调用流程就是这样的了：一个语音问题自上而下分别经过三个部分： 基于网页的 Siwi Frontend 语音、文字问答界面 Python Flask 实现的 Siwi Backend/API 系统 Nebula Graph 开源分布式高性能图数据库之上的知识图谱 ┌────────────────┬──────────────────────────────────────┐ │ │ │ │ │ Speech │ │ ┌──────────▼──────────┐ │ │ │ Frontend │ Siwi, /ˈsɪwi/ │ │ │ Web_Speech_API │ A PoC of │ │ │ │ Dialog System │ │ │ Vue.JS │ With Graph Database │ │ │ │ Backed Knowledge Graph │ │ └──────────┬──────────┘ │ │ │ Sentence │ │ ┌────────────┼──────────────────────────────┐ │ │ │ │ Backend │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ Web API, Flask │ ./app/ │ │ │ │ └──────────┬──────────┘ │ │ │ │ │ Sentence ./bot/ │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ Intent matching, │ ./bot/classifier│ │ │ │ │ Symentic Processing │ │ │ │ │ └──────────┬──────────┘ │ │ │ │ │ Intent, Entities │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ Intent Actor │ ./bot/actions │ │ │ └─┴──────────┬──────────┴───────────────────┘ │ │ │ Graph Query │ │ ┌──────────▼──────────┐ │ │ │ Graph Database │ Nebula Graph │ │ └─────────────────────┘ │ └───────────────────────────────────────────────────────┘ 💡：图数据库相比于其他知识图谱存储系统来说，因为其设计专注于数据内的数据关系，非常擅长实时获取海量数据下实体之间的复杂关联关系。 Nebula Graph 的原生分布式设计和 share-nothing 架构使得它擅长于巨大数据量和高并发读写的场景，加上它的开源社区特别活跃，已经被国内很多团队用于支撑生产上的各种业务，这里有一些他们分享的选型、落地实践。 ","date":"2021-12-30","objectID":"/siwi/:2:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#鸟瞰-tldr"},{"categories":["Nebula Graph","Mini Project"],"content":" 3 知识图谱Siwi 构建于一个篮球相关的知识图谱之上，它其实是 Siwi 采用的开源分布式图数据库 Nebula Graph 社区的官方文档里的示例数据集。 在这个非常简单的图谱之中，只有两种点： player，球员 team，球队 两种关系： serve 服役于（比如：姚明 -服役于-\u003e 休斯顿火箭） follow 关注 （比如：姚明 -关注-\u003e 奥尼尔） 💡：这个数据集在 Nebula 社区上有一个 在线体验 环境，任何人都无需登录，通过Nebula Graph Studio 可视化探索篮球图谱。 下图就是这个图谱的可视化探索截图，可以看到左边的中心节点勇士队（Warriors）有杜兰特（Durant）还有其他几个队员在其中服役（serve）；除了服役之外，还可以看到队员和队员之中也有关注（follow）的关系存在。 有了这个知识图谱，咱们接下来就在它之上搭一个简单的基于语法解析的 QA 系统吧😁。 ","date":"2021-12-30","objectID":"/siwi/:3:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#知识图谱"},{"categories":["Nebula Graph","Mini Project"],"content":" 4 Siwi-backend ┌────────────┼──────────────────────────────┐ │ │ Backend │ │ ┌──────────▼──────────┐ │ │ │ Web API, Flask │ ./app/ │ │ └──────────┬──────────┘ │ │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ │ Graph Query ┌──────────▼──────────┐ │ Graph Database │ Nebula Graph └─────────────────────┘ 如上图的设计流程，Siwi 的后端部分需要接收问句，处理之后访问知识图谱（图数据库），然后将处理结果返回给用户。 ","date":"2021-12-30","objectID":"/siwi/:4:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#siwi-backend"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.1 接收 HTTP 请求(app)对于请求，就简单地用 Flask 作为 web server 来接收 HTTP 的 POST 请求： 💡：还不熟悉 Flask 的同学，可以在 freeCodeCamp 上搜索一下，有一些不错的课程哈。 下边的代码就是告诉 Flask ： 如果用户发过来 http://\u003cserver\u003e/query 的 POST 请求，提的问题就在请求的 body 里的 question 的 Key 之下。 取得问题之后，调用把请求传给 siwi_bot 的 query()，得到 answer 。 代码段：src/siwi/app/__init__.py #... from siwi.bot import bot #... @app.route(\"/query\", methods=[\"POST\"]) def query(): request_data = request.get_json() question = request_data.get(\"question\", \"\") # \u003c----- 1. if question: answer = siwi_bot.query( request_data.get(\"question\", \"\")) # \u003c----- 2. else: answer = \"Sorry, what did you say?\" return jsonify({\"answer\": answer}) 接下来我们来实现 siwi_bot，真正处理提问的逻辑。 ","date":"2021-12-30","objectID":"/siwi/:4:1","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#接收-http-请求app"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#处理请求bot"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#语义解析classifier"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#意图识别intent"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#实体识别entity"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#构造图谱查询action"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.3 测试一下 4.3.1 启动图数据库我们在 Nebula Graph 里建立（导入数据）一个篮球的知识图谱。 💡：在导入数据之前，请先部署一个 Nebula Graph 集群。最简便的部署方式是使用 Nebula-UP 这个小工具，只需要一行命令就能在 Linux 机器上同时启动一个 Nebula Graph 核心和可视化图探索工具 Nebula Graph Studio。如果你更愿意用 Docker 部署，请参考这个文档。 本文假设我们使用 Nebula-UP 来部署一个 Nebula Graph： curl -fsSL nebula-up.siwei.io/install.sh | bash 之后，我们会看到这样的提示： 按照提示，我们可以通过这个命令进入到有 Nebula Console 的容器里： 💡：Nebula Console 是命令行访问 Nebula Graph 图数据库的客户端，支持 Linux，Windows 和 macOS，下载地址：这里 ~/.nebula-up/console.sh 然后，在 # 的提示符下就表示我们进来了，我们在里边可以执行： nebula-console -addr graphd -port 9669 -user root -p nebula 这样就表示我们连接上了 Nebula Graph 图数据库： / # nebula-console -addr graphd -port 9669 -user root -p nebula Welcome to Nebula Graph! (root@nebula) [(none)]\u003e 在这里，我们就可以通过 nGQL 去操作 Nebula Graph，不过我们先退出来，执行 exit： (root@nebula) [(none)]\u003e exit Bye root! Fri, 31 Dec 2021 04:11:28 UTC 我们在这个容器内把基于 nGQL 语句的数据下载下来： / # wget https://docs.nebula-graph.io/2.0/basketballplayer-2.X.ngql 然后通过 Nebula Console 的 -f \u003cfile_path\u003e 把数据导入进去： nebula-console -addr graphd -port 9669 -user root -p nebula -f basketballplayer-2.X.ngql 至此，我们就启动了一个 Nebula Graph 图数据库，还在里边加载了篮球的知识图谱！ 💡：还记得前边我们提到的 在线体验 环境么？现在，我们可以在这个利用 Nebula-UP 部署了 Nebula 的环境里启动自己的 Nebula Studio 啦，按照上边 Nebula-UP 的提示：http://\u003c本机IP\u003e:7001 就是它的地址，然后大家可以参考文档和在线体验介绍去了解更多。 4.3.2 启动 Siwi-backend大家可以直接 clone 我的代码：git clone https://github.com/wey-gu/nebula-siwi/ 然后安装、启动 Siwi Backend： cd nebula-siwi # Install dependencies python3 -m pip install -r src/requirements.txt # Install siwi backend python3 -m build # Configure Nebula Graph Endpoint export NG_ENDPOINTS=127.0.0.1:9669 # Run Backend API server gunicorn --bind :5000 wsgi --workers 1 --threads 1 --timeout 60 启动之后，我们可以另外开窗口，通过 cURL 去发起问题给 backend，更多细节大家可以参考 GitHub 上的 README： 至此，我们已经写好了 QA 系统的重要的代码啦，大家是不是对一个 KBQA 的构成有了更清晰的概念了呢？ 接下来，我们为它增加一个界面！ ","date":"2021-12-30","objectID":"/siwi/:4:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#测试一下"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.3 测试一下 4.3.1 启动图数据库我们在 Nebula Graph 里建立（导入数据）一个篮球的知识图谱。 💡：在导入数据之前，请先部署一个 Nebula Graph 集群。最简便的部署方式是使用 Nebula-UP 这个小工具，只需要一行命令就能在 Linux 机器上同时启动一个 Nebula Graph 核心和可视化图探索工具 Nebula Graph Studio。如果你更愿意用 Docker 部署，请参考这个文档。 本文假设我们使用 Nebula-UP 来部署一个 Nebula Graph： curl -fsSL nebula-up.siwei.io/install.sh | bash 之后，我们会看到这样的提示： 按照提示，我们可以通过这个命令进入到有 Nebula Console 的容器里： 💡：Nebula Console 是命令行访问 Nebula Graph 图数据库的客户端，支持 Linux，Windows 和 macOS，下载地址：这里 ~/.nebula-up/console.sh 然后，在 # 的提示符下就表示我们进来了，我们在里边可以执行： nebula-console -addr graphd -port 9669 -user root -p nebula 这样就表示我们连接上了 Nebula Graph 图数据库： / # nebula-console -addr graphd -port 9669 -user root -p nebula Welcome to Nebula Graph! (root@nebula) [(none)]\u003e 在这里，我们就可以通过 nGQL 去操作 Nebula Graph，不过我们先退出来，执行 exit： (root@nebula) [(none)]\u003e exit Bye root! Fri, 31 Dec 2021 04:11:28 UTC 我们在这个容器内把基于 nGQL 语句的数据下载下来： / # wget https://docs.nebula-graph.io/2.0/basketballplayer-2.X.ngql 然后通过 Nebula Console 的 -f 把数据导入进去： nebula-console -addr graphd -port 9669 -user root -p nebula -f basketballplayer-2.X.ngql 至此，我们就启动了一个 Nebula Graph 图数据库，还在里边加载了篮球的知识图谱！ 💡：还记得前边我们提到的 在线体验 环境么？现在，我们可以在这个利用 Nebula-UP 部署了 Nebula 的环境里启动自己的 Nebula Studio 啦，按照上边 Nebula-UP 的提示：http://\u003c本机IP\u003e:7001 就是它的地址，然后大家可以参考文档和在线体验介绍去了解更多。 4.3.2 启动 Siwi-backend大家可以直接 clone 我的代码：git clone https://github.com/wey-gu/nebula-siwi/ 然后安装、启动 Siwi Backend： cd nebula-siwi # Install dependencies python3 -m pip install -r src/requirements.txt # Install siwi backend python3 -m build # Configure Nebula Graph Endpoint export NG_ENDPOINTS=127.0.0.1:9669 # Run Backend API server gunicorn --bind :5000 wsgi --workers 1 --threads 1 --timeout 60 启动之后，我们可以另外开窗口，通过 cURL 去发起问题给 backend，更多细节大家可以参考 GitHub 上的 README： 至此，我们已经写好了 QA 系统的重要的代码啦，大家是不是对一个 KBQA 的构成有了更清晰的概念了呢？ 接下来，我们为它增加一个界面！ ","date":"2021-12-30","objectID":"/siwi/:4:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#启动图数据库"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.3 测试一下 4.3.1 启动图数据库我们在 Nebula Graph 里建立（导入数据）一个篮球的知识图谱。 💡：在导入数据之前，请先部署一个 Nebula Graph 集群。最简便的部署方式是使用 Nebula-UP 这个小工具，只需要一行命令就能在 Linux 机器上同时启动一个 Nebula Graph 核心和可视化图探索工具 Nebula Graph Studio。如果你更愿意用 Docker 部署，请参考这个文档。 本文假设我们使用 Nebula-UP 来部署一个 Nebula Graph： curl -fsSL nebula-up.siwei.io/install.sh | bash 之后，我们会看到这样的提示： 按照提示，我们可以通过这个命令进入到有 Nebula Console 的容器里： 💡：Nebula Console 是命令行访问 Nebula Graph 图数据库的客户端，支持 Linux，Windows 和 macOS，下载地址：这里 ~/.nebula-up/console.sh 然后，在 # 的提示符下就表示我们进来了，我们在里边可以执行： nebula-console -addr graphd -port 9669 -user root -p nebula 这样就表示我们连接上了 Nebula Graph 图数据库： / # nebula-console -addr graphd -port 9669 -user root -p nebula Welcome to Nebula Graph! (root@nebula) [(none)]\u003e 在这里，我们就可以通过 nGQL 去操作 Nebula Graph，不过我们先退出来，执行 exit： (root@nebula) [(none)]\u003e exit Bye root! Fri, 31 Dec 2021 04:11:28 UTC 我们在这个容器内把基于 nGQL 语句的数据下载下来： / # wget https://docs.nebula-graph.io/2.0/basketballplayer-2.X.ngql 然后通过 Nebula Console 的 -f 把数据导入进去： nebula-console -addr graphd -port 9669 -user root -p nebula -f basketballplayer-2.X.ngql 至此，我们就启动了一个 Nebula Graph 图数据库，还在里边加载了篮球的知识图谱！ 💡：还记得前边我们提到的 在线体验 环境么？现在，我们可以在这个利用 Nebula-UP 部署了 Nebula 的环境里启动自己的 Nebula Studio 啦，按照上边 Nebula-UP 的提示：http://\u003c本机IP\u003e:7001 就是它的地址，然后大家可以参考文档和在线体验介绍去了解更多。 4.3.2 启动 Siwi-backend大家可以直接 clone 我的代码：git clone https://github.com/wey-gu/nebula-siwi/ 然后安装、启动 Siwi Backend： cd nebula-siwi # Install dependencies python3 -m pip install -r src/requirements.txt # Install siwi backend python3 -m build # Configure Nebula Graph Endpoint export NG_ENDPOINTS=127.0.0.1:9669 # Run Backend API server gunicorn --bind :5000 wsgi --workers 1 --threads 1 --timeout 60 启动之后，我们可以另外开窗口，通过 cURL 去发起问题给 backend，更多细节大家可以参考 GitHub 上的 README： 至此，我们已经写好了 QA 系统的重要的代码啦，大家是不是对一个 KBQA 的构成有了更清晰的概念了呢？ 接下来，我们为它增加一个界面！ ","date":"2021-12-30","objectID":"/siwi/:4:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#启动-siwi-backend"},{"categories":["Nebula Graph","Mini Project"],"content":" 5 Siwi-frontend","date":"2021-12-30","objectID":"/siwi/:5:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#siwi-frontend"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.1 聊天界面我们利用 Vue Bot UI 这个可爱的机器人界面的 Vue 实现可以很容易构造一个 代码段：src/siwi/frontend/src/App.vue \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cVueBotUI :messages=\"msg\" :options=\"botOptions\" :bot-typing=\"locking\" :input-disable=\"locking\" @msg-send=\"msgSender\" /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import { VueBotUI } from 'vue-bot-ui' 注意到那个小飞机按钮了吧，它是发出问题请求的按键，我们要在按下它的时候对后端做出请求。 ","date":"2021-12-30","objectID":"/siwi/:5:1","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#聊天界面"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.2 访问后端这部分用到了Axios，它是浏览器里访问其他地址的 HTTP 客户端。 在按下的时候，@msg-send=\"msgSender\" 会触发 msgSender() msgSender()去构造axios.post(this.apiEndpoint, { \"question\": data.text }) 的请求给 Siwi 的后端 后端的结果被 push() 到界面的聊天消息里，渲染出来 this.msg.push() 代码段：src/siwi/frontend/src/App.vue \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cVueBotUI :messages=\"msg\" :options=\"botOptions\" :bot-typing=\"locking\" :input-disable=\"locking\" @msg-send=\"msgSender\" ---------------- 1. /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import { VueBotUI } from 'vue-bot-ui' import axios from \"axios\"; export default { name: 'App', components: { VueBotUI, }, methods: { msgSender(data) { this.msg.push({ agent: \"user\", type: \"text\", text: data.text, }); this.locking = true; axios.post(this.apiEndpoint, { \"question\": data.text }).then((response) =\u003e { console.log(response); ----------------- 2. this.msg.push({ ----------------- 3. agent: \"bot\", type: \"text\", text: response.data.answer, }); this.synthText = response.data.answer; this.agentSpeak = true; this.locking = false; }); }, } } 现在，我们已经有了一个图形界面的机器人啦，不过，更进一步，我们可以利用现代浏览器的接口，实现语音识别和机器人说话！ ","date":"2021-12-30","objectID":"/siwi/:5:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#访问后端"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.3 语音识别我们借助于 Vue Web Speech, 这个语音 API 的 VueJS 的绑定，可以很容易在按下 🎙️ 的时候接收人的语音，并把语音转换成文字发出去，在回答被返回之后，它（还是他/她😁？）也会把回答的句子读出来给用户。 record 在 🎙️ 被按下之后，变成 👂 触发 onResults() 监听 把返回结果发给 this.synthText 合成器，准备读出 \u003cvue-web-speech-synth\u003e 把语音读出 代码段：src/siwi/frontend/src/App.vue \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cbutton id=\"mic_btn\" @click=\"record = !record\"\u003e {{record?'👂':'🎙️'}} --------------------------\u003e 1. \u003c/button\u003e \u003cvue-web-speech v-model=\"record\" @results=\"onResults\" --------------------------\u003e 1. @unrecognized=\"unrecognized\" \u003e \u003c/vue-web-speech\u003e ... \u003cvue-web-speech-synth v-model=\"agentSpeak\" :voice=\"synthVoice\" :text=\"synthText\" @list-voices=\"listVoices\" --------------------------\u003e 4. /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import { VueBotUI } from 'vue-bot-ui' import axios from \"axios\"; export default { name: 'App', components: { VueBotUI, }, onResults (data) { -------------------------\u003e 2. this.results = data; this.locking = true; this.msg.push({ agent: \"user\", type: \"text\", text: data[0], }); this.locking = true; console.log(data[0]); axios.post(this.apiEndpoint, { \"question\": data[0] }).then((response) =\u003e { console.log(response.data); this.msg.push({ agent: \"bot\", type: \"text\", text: response.data.answer, }); this.synthText = response.data.answer; ----------\u003e 3. this.agentSpeak = true; }); this.locking = false; }, } } \u003c/script\u003e ","date":"2021-12-30","objectID":"/siwi/:5:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#语音识别"},{"categories":["Nebula Graph","Mini Project"],"content":" 6 总结至此，我们已经学会了搭建自己的第一个 KBQA：知识图谱驱动的问答系统。 回顾下它的代码结构： src/siwi 对应后端 App 是 Flask API 处理的部分 Bot 是处理请求、访问 Nebula Graph 的部分 src/siwi_frontend 是前端 希望大家在这个简陋的基础之上，多多探索，做出来更加成熟的聊天机器人，欢迎你来给我邮件、留言告诉我呀，这里：https://siwei.io/about 有我的联系方式。 . ├── README.md ├── src │ ├── siwi # Siwi-API Backend │ │ ├── app # Web Server, take HTTP requests and calls Bot API │ │ └── bot # Bot API │ │ ├── actions # Take Intent, Slots, Query Knowledge Graph here │ │ ├── bot # Entrypoint of the Bot API │ │ ├── classifier # Symentic Parsing, Intent Matching, Slot Filling │ │ └── test # Example Data Source as equivalent/mocked module │ └── siwi_frontend # Browser End │ ├── README.md │ ├── package.json │ └── src │ ├── App.vue # Listening to user and pass Questions to Siwi-API │ └── main.js └── wsgi.py 如果你很喜欢这样的小项目，欢迎来看看我之前的分享： 「从0-1：如何构建一个企业股权图谱系统？」哦。 💡：你知道吗，我其实借助于 Katacoda 已经为大家搭建了一个交互式体验 Siwi + Nebula 的部署的环境，如果您的网络条件够快（Katacoda服务器在国外），可以在这里点点鼠标就交互式体验它。 视频介绍 ","date":"2021-12-30","objectID":"/siwi/:6:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#总结"},{"categories":["Nebula Graph","Mini Project"],"content":" 7 感谢用到的开源项目 ❤️这个小项目里我们用到了好多开源的项目，非常感谢这些贡献者们的慷慨与无私，开源是不是很酷呢？ ","date":"2021-12-30","objectID":"/siwi/:7:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#感谢用到的开源项目-"},{"categories":["Nebula Graph","Mini Project"],"content":" 7.1 Backend KGQA on MedicalKG by Huanyong Liu Flask pyahocorasick created by Wojciech Muła PyYaml ","date":"2021-12-30","objectID":"/siwi/:7:1","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#backend"},{"categories":["Nebula Graph","Mini Project"],"content":" 7.2 Frontend VueJS for frontend framework Vue Bot UI, as a lovely bot UI in vue Vue Web Speech, for speech API vue wrapper Axios for browser http client Solarized for color scheme Vitesome for landing page design ","date":"2021-12-30","objectID":"/siwi/:7:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#frontend"},{"categories":["Nebula Graph","Mini Project"],"content":" 7.3 Graph Database Nebula Graph 高性能、云原生的开源分布式图数据库 ","date":"2021-12-30","objectID":"/siwi/:7:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#graph-database"},{"categories":["Nebula Graph"],"content":"Docker 部署情况下使用 Python Storage Client 指南","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/"},{"categories":["Nebula Graph"],"content":" Python Storage Client 连不上第一次安装的 Nebula Graph？ Docker 部署情况下使用 Python Storage Client 指南 ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:0:0","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#"},{"categories":["Nebula Graph"],"content":" 1 前置条件 注意：一个重要的前置条件是我们真的需要 Storage Client，如果我们只需要在 Python Client 里通过 nGQL 来请求数据，那么 GraphClient 才是你需要的，可以跳过本文。 对于刚接触 Nebula 的同学，部署集群最快速的方式是用 Docker Compose，安装部署可以参考文档：deploy-nebula-graph-with-docker-compose。 在 docker compose up -d 之后，我们的 nebula 集群就起来了，我们可以用 docker ps 看看运行着的容器： ❯ docker ps --format \"table {{.Names}}\\t{{.Ports}}\" NAMES PORTS nebula-docker-compose-graphd1-1 0.0.0.0:61852-\u003e9669/tcp, 0.0.0.0:61850-\u003e19669/tcp, 0.0.0.0:61851-\u003e19670/tcp nebula-docker-compose-graphd-1 0.0.0.0:9669-\u003e9669/tcp, 0.0.0.0:61858-\u003e19669/tcp, 0.0.0.0:61859-\u003e19670/tcp nebula-docker-compose-graphd2-1 0.0.0.0:61855-\u003e9669/tcp, 0.0.0.0:61853-\u003e19669/tcp, 0.0.0.0:61854-\u003e19670/tcp nebula-docker-compose-storaged2-1 9777-9778/tcp, 9780/tcp, 0.0.0.0:61868-\u003e9779/tcp, 0.0.0.0:61869-\u003e19779/tcp, 0.0.0.0:61870-\u003e19780/tcp nebula-docker-compose-storaged1-1 9777-9778/tcp, 9780/tcp, 0.0.0.0:61865-\u003e9779/tcp, 0.0.0.0:61866-\u003e19779/tcp, 0.0.0.0:61864-\u003e19780/tcp nebula-docker-compose-storaged0-1 9777-9778/tcp, 9780/tcp, 0.0.0.0:61845-\u003e9779/tcp, 0.0.0.0:61843-\u003e19779/tcp, 0.0.0.0:61844-\u003e19780/tcp nebula-docker-compose-metad1-1 9560/tcp, 0.0.0.0:61705-\u003e9559/tcp, 0.0.0.0:61706-\u003e19559/tcp, 0.0.0.0:61707-\u003e19560/tcp nebula-docker-compose-metad2-1 9560/tcp, 0.0.0.0:61699-\u003e9559/tcp, 0.0.0.0:61700-\u003e19559/tcp, 0.0.0.0:61701-\u003e19560/tcp nebula-docker-compose-metad0-1 9560/tcp, 0.0.0.0:61704-\u003e9559/tcp, 0.0.0.0:61702-\u003e19559/tcp, 0.0.0.0:61703-\u003e19560/tcp 这里边有三种容器 ： GrpahD，查询引擎，也是我们用户进行登录、连接、发 Query 请求直接访问的唯一一种服务、接口。 MetaD，元数据服务，它一般不会暴露给外部，只有 GraphD 、StorageD 会直接访问它。 StorageD，存储引擎，它一般不会暴露给外部，只有 GraphD、StorageD 会直接访问它。 我们可以从 Stuido Console，或者 Nebula Console （连接到 GraphD 之后）里通过 SHOW HOSTS \u003cType\u003e，来获取每种服务的信息，其中第一列的信息就是他们的 IP 或者 Host，下边的例子是 Docker Compose 默认配置下的情况。 (root@nebula) [(none)]\u003e SHOW HOSTS GRAPH +-----------+------+----------+---------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +-----------+------+----------+---------+--------------+---------+ | \"graphd\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\" | \"2.6.0\" | +-----------+------+----------+---------+--------------+---------+ | \"graphd1\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\" | \"2.6.0\" | +-----------+------+----------+---------+--------------+---------+ | \"graphd2\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\" | \"2.6.0\" | +-----------+------+----------+---------+--------------+---------+ (root@nebula) [(none)]\u003e SHOW HOSTS META +----------+------+----------+--------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +----------+------+----------+--------+--------------+---------+ | \"metad1\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\" | \"2.6.0\" | +----------+------+----------+--------+--------------+---------+ | \"metad0\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\" | \"2.6.0\" | +----------+------+----------+--------+--------------+---------+ | \"metad2\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\" | \"2.6.0\" | +----------+------+----------+--------+--------------+---------+ (root@nebula) [(none)]\u003e SHOW HOSTS STORAGE +-------------+------+----------+-----------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +-------------+------+----------+-----------+--------------+---------+ | \"storaged0\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\" | \"2.6.0\" | +-------------+------+----------+-----------+--------------+---------+ | \"storaged1\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\" | \"2.6.0\" | +-------------+------+----------+-----------+--------------+---------+ | \"storaged2\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\" | \"2.6.0\" | +-------------+------+----------+-----------+--------------+---------+ 在默认的 nebula-docker-compose 的配置下各个服务为graphd, metad1, storaged0 这种域名的 Host 格式，这其实是假设了我们使用 Docker 启动的服务一般是作为单机测试之用，除了其中的 graphd之外，其他的服务都没有指定固定的外部映射端口（见前边的 docker ps 的结果里，它暴露在0.0.0.0:9669)。 这意味着，如果客户端不是运行在本机，访问其他服务的端口都是动态的，这会让很多第一次想用 Python Storage Client 连接服务的同学卡住。 所以我这里给大家分享一个快速用 Python 去调试 Storage Client 的方法： 本质上我们可以通过修改 Compose 的配置文件、通过其他部署或者配置的方式安装 Nebula 来保证 Python Client 能够","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:0","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#前置条件"},{"categories":["Nebula Graph"],"content":" 1.1 第一步，把 Python 容器在 nebula-docker-compose_nebula-net 这个容器网络启动一个 Jupyter 的容器。 这里采用了 https://github.com/jupyter/docker-stacks 维护的 Docker Image。 docker run \\ -p 8888:8888 \\ --network nebula-docker-compose_nebula-net \\ jupyter/scipy-notebook:33add21fab64 可以看到容器了，并且在监听端口：8888。 [I 07:06:31.060 NotebookApp] Jupyter Notebook 6.3.0 is running at: [I 07:06:31.060 NotebookApp] http://e170a5eb4858:8888/?token=5beafb26fc6995b081c611d5d2cc96d557897b74bfdaac53 [I 07:06:31.060 NotebookApp] or http://127.0.0.1:8888/?token=5beafb26fc6995b081c611d5d2cc96d557897b74bfdaac53 这时候我们可在浏览器打开 http://127.0.0.1:8888/?token=5beafb26fc6995b081c611d5d2cc96d557897b74bfdaac53. 在里边新建一个 Notebook。 ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:1","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#第一步把-python-容器"},{"categories":["Nebula Graph"],"content":" 1.2 第二步，安装 Nebula Python SDK我们只需要在 Jupyter 里执行 !pip install nebula2-python==2.6.0 就可以了，具体的版本要根据 Nebula Python 的 README 里的版本对应关系来给定。 ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:2","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#第二步安装-nebula-python-sdk"},{"categories":["Nebula Graph"],"content":" 1.3 第三步，实例化 MetaCache 和 GraphStorageClient from nebula2.mclient import MetaCache, HostAddr from nebula2.sclient.GraphStorageClient import GraphStorageClient # Docker Compose 下默认 meta 的地址是 metad1 metad0 metad2 meta_cache = MetaCache([('metad1',9559),('metad0',9559),('metad2',9559)]) graph_storage_client = GraphStorageClient(meta_cache) ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:3","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#第三步实例化-metacache-和-graphstorageclient"},{"categories":["Nebula Graph"],"content":" 1.4 第四步，扫数据 按空间、点类型扫点 resp = graph_storage_client.scan_vertex( space_name='basketballplayer', tag_name='player') while resp.has_next(): result = resp.next() for vertex_data in result: print(vertex_data) 按空间、边类型扫边 resp = graph_storage_client.scan_edge( space_name='basketballplayer', edge_name='follow') while resp.has_next(): result = resp.next() for edge_data in result: print(edge_data) Jupyter 的过程我也记录在这个 notebook 里方便大家参考。 Happy Graphing! Picture Credit：Borderpolar Photographer ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:4","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#第四步扫数据"},{"categories":["Nebula Graph"],"content":"如何快速、即时、符合直觉地去处理 Nebula Java Client 中的数据解析？","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/"},{"categories":["Nebula Graph"],"content":" 如何快速、即时、符合直觉地去处理 Nebula Java Client 中的数据解析？读这一篇就够了。 更新: 2022-Aug-10, adapted to nebulagraph 3.x ","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:0:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#"},{"categories":["Nebula Graph"],"content":" 1 关键步骤：几行准备一个干净的交互式 Nebula Java REPL 环境多亏了 Java-REPL 我们可以很方便地（像 iPython 那样）去实时交互地调试、分析 Nebula Java 客户端，我们用它的 Docker 镜像可以很干净的去搞定： docker pull albertlatacz/java-repl docker run --rm -it \\ --network=nebula-net \\ -v ~:/root \\ albertlatacz/java-repl \\ bash apt update -y \u0026\u0026 apt install ca-certificates -y wget https://dlcdn.apache.org/maven/maven-3/3.8.6/binaries/apache-maven-3.8.6-bin.tar.gz --no-check-certificate tar xzvf apache-maven-3.8.6-bin.tar.gz wget https://github.com/vesoft-inc/nebula-java/archive/refs/tags/v3.0.0.tar.gz tar xzvf v3.0.0.tar.gz cd nebula-java-3.0.0/ ../apache-maven-3.8.6/bin/mvn dependency:copy-dependencies ../apache-maven-3.8.6/bin/mvn -B package -Dmaven.test.skip=true java -jar ../javarepl/javarepl.jar 这时候，在执行完 java -jar ../javarepl/javarepl.jar 之后，我们就进入了交互式的 Java Shell（REPL），我们可以无需做编译，执行，print 这样的慢反馈来调试和研究我们的代码了，是不是很方便？ root@a2e26ba62bb6:/javarepl/nebula-java-3.0.0# java -jar ../javarepl/javarepl.jar Welcome to JavaREPL version 428 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_111) Type expression to evaluate, :help for more options or press tab to auto-complete. Connected to local instance at http://localhost:43707 java\u003e System.out.println(\"Hello, World!\"); Hello, World! java\u003e 首先我们在 java\u003e 提示符下，这些来把必须的类路径和导入： :cp /javarepl/nebula-java-3.0.0/client/target/client-3.0.0.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/fastjson-1.2.78.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/slf4j-api-1.7.25.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/slf4j-log4j12-1.7.25.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/commons-pool2-2.2.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/log4j-1.2.17.jar import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONObject; import com.vesoft.nebula.ErrorCode; import com.vesoft.nebula.client.graph.NebulaPoolConfig; import com.vesoft.nebula.client.graph.data.CASignedSSLParam; import com.vesoft.nebula.client.graph.data.HostAddress; import com.vesoft.nebula.client.graph.data.ResultSet; import com.vesoft.nebula.client.graph.data.SelfSignedSSLParam; import com.vesoft.nebula.client.graph.data.ValueWrapper; import com.vesoft.nebula.client.graph.net.NebulaPool; import com.vesoft.nebula.client.graph.net.Session; import java.io.UnsupportedEncodingException; import java.util.Arrays; import java.util.List; import java.util.concurrent.TimeUnit; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.lang.reflect.*; 我们可以从这 Java 环境连接到 Nebula Graph 里，下边的例子里我用了自己的 GraphD 的 IP 和端口作为例子： NebulaPoolConfig nebulaPoolConfig = new NebulaPoolConfig(); nebulaPoolConfig.setMaxConnSize(10); List\u003cHostAddress\u003e addresses = Arrays.asList(new HostAddress(\"192.168.8.127\", 9669)); NebulaPool pool = new NebulaPool(); pool.init(addresses, nebulaPoolConfig); Session session = pool.getSession(\"root\", \"nebula\", false); ","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:1:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#关键步骤几行准备一个干净的交互式-nebula-java-repl-环境"},{"categories":["Nebula Graph"],"content":" 2 通过调用 execute 方法获得不太容易懂的 ResultSet 对象刚接触这里的大家一定对这个 ResultSet 对象有些愁，借助我们的环境，咱们来十分钟把它搞通吧，这里我们执行一个简单的返回 Vertex 顶点的结果看看： ResultSet resp = session.execute(\"USE basketballplayer;MATCH (n:player) WHERE n.name==\\\"Tim Duncan\\\" RETURN n\"); 这里我们可以参考 ResultSet 的代码： Reference: client/graph/data/ResultSet.java 好吧，其实可以先不看，跟着我的教程往下走吧，我们知道结果都是二维的表，ResultSet 提供了常见的针对行、列的一些方法，通常，我们是获取每一行，然后解析它，而关键的问题是每一个值要怎么处理，对吧。 java\u003e resp.isSucceeded() java.lang.Boolean res9 = true java\u003e resp.rowsSize() java.lang.Integer res16 = 1 java\u003e rows = resp.getRows() java.util.ArrayList rows = [Row ( values : [ \u003cValue vVal:Vertex ( vid : \u003cValue sVal:70 6c 61 79 65 72 31 30 30\u003e, tags : [ Tag ( name : 70 6C 61 79 65 72, props : { [B@5264a468 : \u003cValue iVal:42\u003e [B@496b8e10 : \u003cValue sVal:54 69 6d 20 44 75 6e 63 61 6e\u003e } ) ] )\u003e ] )] java\u003e row0 = resp.rowValues(0) java.lang.Iterable\u003ccom.vesoft.nebula.client.graph.data.ValueWrapper\u003e res10 = ColumnName: [n], Values: [(\"player100\" :player {name: \"Tim Duncan\", age: 42})] 我们其实回到这次的 query ，其实是返回一个 vertex：顶点： (root@nebula) [basketballplayer]\u003e match (n:player) WHERE n.name == \"Tim Duncan\" return n +----------------------------------------------------+ | n | +----------------------------------------------------+ | (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) | +----------------------------------------------------+ Got 1 rows (time spent 2116/44373 us) 通过上边的几个方法，我们其实能够获得这个顶点的值： v = Class.forName(\"com.vesoft.nebula.Value\") v.getDeclaredMethods() 然而，我们可以看出来这个 com.vesoft.nebula.Value 的值的类提供的方法特别特别原始，这也是让大家犯愁的原因，在这个教程里最重要的一个带走的经验（除了利用 REPL之外）就是：除非必要，不要去取这个原始的类，我们应该去取得 ValueWrapper 封装之后的值！！！ 注意：其实我们有更轻松地方法，就是用 executeJson 直接获得 JSON string，别担心，会在后边提到，不过这个方法要 2.6 之后才支持。 那么问题来了，如何使用 ValueWrapper 封装呢？其实答案已经在上边了，大家可以回去看看，resp.rowValues(0) 的类型正是 ValueWrapper 的可迭代对象！ 所以，正确打开方式是迭它！迭它！迭它！其实这个就是代码库里的 GraphClientExample 的一部分例子了，我们把它迭代取出来，放到 wrappedValueList 里慢慢把玩： import java.util.ArrayList; import java.util.List; List\u003cValueWrapper\u003e wrappedValueList = new ArrayList\u003c\u003e(); for (int i = 0; i \u003c resp.rowsSize(); i++) { ResultSet.Record record = resp.rowValues(i); for (ValueWrapper value : record.values()) { wrappedValueList.add(value); if (value.isLong()) { System.out.printf(\"%15s |\", value.asLong()); } if (value.isBoolean()) { System.out.printf(\"%15s |\", value.asBoolean()); } if (value.isDouble()) { System.out.printf(\"%15s |\", value.asDouble()); } if (value.isString()) { System.out.printf(\"%15s |\", value.asString()); } if (value.isTime()) { System.out.printf(\"%15s |\", value.asTime()); } if (value.isDate()) { System.out.printf(\"%15s |\", value.asDate()); } if (value.isDateTime()) { System.out.printf(\"%15s |\", value.asDateTime()); } if (value.isVertex()) { System.out.printf(\"%15s |\", value.asNode()); } if (value.isEdge()) { System.out.printf(\"%15s |\", value.asRelationship()); } if (value.isPath()) { System.out.printf(\"%15s |\", value.asPath()); } if (value.isList()) { System.out.printf(\"%15s |\", value.asList()); } if (value.isSet()) { System.out.printf(\"%15s |\", value.asSet()); } if (value.isMap()) { System.out.printf(\"%15s |\", value.asMap()); } } System.out.println(); } 上边这些很丑的 if 就是关键了，我们知道 query 的返回值可能是多种类型的，他们分为： 图语义的：点、边、路径 数据类型：String，日期，列表，集合 等等等 这里的关键是，我们要使用 ValueWrapper 为我们准备好的 asXxx 方法，如果这个值是一个顶点，么这个 Xxx 就是 Node，同理如果是边的话，这个 Xxx 就是 Relationship。 所以，我给大家看看咱们这个返回点结果的情况下的 asNode() 方法： java\u003e v = wrappedValueList.get(0) com.vesoft.nebula.client.graph.data.ValueWrapper v = (\"player100\" :player {name: \"Tim Duncan\", age: 42}) java\u003e v.asNode() com.vesoft.nebula.client.graph.data.Node res16 = (\"player100\" :player {name: \"Tim Duncan\", age: 42}) java\u003e node = v.asNode() com.vesoft.nebula.client.graph.data.Node node = (\"player100\" :player {name: \"Tim Duncan\", age: 42}) 顺便说一下，借助于 Java 的 reflection ，我们可以在这个交互程序里做类似于 Python 里 dir() 的事情，实时地去获取一个类支持的方法，像这样，省去了查代码。 java\u003e rClass=Class.forName(\"com.vesoft.nebula.client.graph.data.ResultSet\") java.lang.Class r = class com.vesoft.nebula.client.graph.data.ResultSet java\u003e rClass.getDeclaredMethods() java.lang.reflect.","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:2:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#通过调用-execute-方法获得不太容易懂的-resultset-对象"},{"categories":["Nebula Graph"],"content":" 3 直接返回 JSON 的 executeJson 方法最后，好消息是，从 2.6 开始，nebula 可以直接返回 JSON 的 String 了，我们上边的纠结也都不是必要的了： java\u003e String resp_json = session.executeJson(\"USE basketballplayer;MATCH (n:player) WHERE n.name==\\\"Tim Duncan\\\" RETURN n\"); java.lang.String resp_json = \" { \"errors\":[ { \"code\":0 } ], \"results\":[ { \"spaceName\":\"basketballplayer\", \"data\":[ { \"meta\":[ { \"type\":\"vertex\", \"id\":\"player100\" } ], \"row\":[ { \"player.age\":42, \"player.name\":\"Tim Duncan\" } ] } ], \"columns\":[ \"n\" ], \"errors\":{ \"code\":0 }, \"latencyInUs\":4761 } ] } \" 我相信大家肯定比我更擅长处理 JSON 的结果了哈~~ ","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:3:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#直接返回-json-的-executejson-方法"},{"categories":["Nebula Graph"],"content":" 4 结论 如果我们有条件（2.6以后）用 JSON，情况会很容易，可能大家不太需要本文的方法（不过有交互环境还是很方便吧？） 如果我们不得不和 resultSet 打交道，记得用 ValueWrapper ，因为我们可以用 asNode()，asRelationship() 和 asPath() ，封装之后的值比原始的值可爱太多了！ 通过 REPL 工具，结合 Java 的 reflection 加上 源代码本身，分析数据的处理将变得异常顺滑 Happy Graphing! Picture Credit：leunesmedia ","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:4:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#结论"},{"categories":["Nebula Graph","Mini Project"],"content":"如何利用图数据库从零到一构建一个具有股权分析的图谱与线上系统呢？本文手把手带你构建一个简易版的股权穿透图谱系统。","date":"2021-11-24","objectID":"/corp-rel-graph/","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/"},{"categories":["Nebula Graph","Mini Project"],"content":" 如何构建一个具有股权分析的图谱与线上系统呢？本文里，我将利用图数据库从零到一带你构建一个简易版的股权穿透图谱系统。 我们知道无论是监管部门、企业还是个人，都有需求去针对一个企业、法人做一些背景调查，这些调查可以是法律诉讼、公开持股、企业任职等等多种多样的信息。这些背景信息可以辅助我们做商业上的重要决策，规避风险：比如根据公司的股权关系，了解是否存在利益冲突比如是否选择与一家公司进行商业往来。 在满足这样的关系分析需求的时候，我们往往面临一些挑战，比如： 如何将这些数据的关联关系体现在系统之中？使得它们可以被挖掘、利用 多种异构数据、数据源之间的关系可能随着业务的发展引申出更多的变化，在结构数据库中，这意味着 Schema 变更 分析系统需要尽可能实时获取需要的查询结果，这通常涉及到多跳关系查询 领域专家能否快速灵活、可视化获取分享信息 那么如何构建这样一个系统解决以上挑战呢？ ","date":"2021-11-24","objectID":"/corp-rel-graph/:0:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#"},{"categories":["Nebula Graph","Mini Project"],"content":" 1 数据存在哪里？ 前提：数据集准备，为了更好的给大家演示解决这个问题，我写了一个轮子能随机生成股权结构相关的数据，生成的数据的例子在这里。 这里，我们有法人、公司的数据，更有公司与子公司之间的关系，公司持有公司股份，法人任职公司，法人持有公司股份和法人之间亲密度的关系数据。 数据存在哪里？这是一个关键的问题，这里我们剧透一下，答案是：图数据库。然后我们再简单解释一下为什么这样一个股权图谱系统跑在图数据库上是更好的。 在这样一个简单的数据模型之下，我们可以很直接的在关系型数据库中这么建模： 而这么建模的问题在于：这种逻辑关联的方式使得无论数据的关联关系查询表达、存储、还是引入新的关联关系都不是很高效。 查询表达不高效是因为关系型数据库是面向表结构设计的，这决定了关系查询要写嵌套的 JOIN。 这就是前边提到的挑战 1：能够表达，但是比较勉强，遇到稍微复杂的情况就变得很难。 存储不高效是因为表结构被设计的模式是面向数据记录，而非数据之间的关系：我们虽然习惯了将数据中实体（比如法人）和实体关联（比如持有股权 hold_sharing_relationship）以另外一个表中的记录来表达、存储起来，这逻辑上完全行得通，但是到了多跳、大量需要请求数据关系跳转的情况下，这样跨表 JOIN 的代价就成为了瓶颈。 这就是前边提到的挑战 3：无法应对多条查询的性能需要。 引入新的关联关系代价大，还是前边提到的，表结构下，用新的表来表达持有股权 hold_sharing_relationship这个关联关系是可行的，但是这非常不灵活、而且昂贵，它意味着我们在引入这个关系的时候限定了起点终点的类型，比如股权持有的关系可能是法人-\u003e公司，也可能是公司-\u003e公司，随着业务的演进，我们可能还需要引入政府-\u003e公司的新关系，而这些变化都需要做有不小代价的工作：改动 Schema。 这就是前边提到的挑战 2：无法应对业务上对数据关系上灵活多变的要求。 当一个通用系统无法满足不可忽视的具体需求的时候，一个新的系统就会诞生，这就是图数据库，针对这样的场景，图数据库很自然地特别针对关联关系场景去设计整个数据库： 面向关联关系表达的语义。（挑战 1） 如下表，我列举了一个等价的一跳查询在表结构数据库与图数据库中，查询语句的区别。大家应该可以看出“找到所有持有和 p_100 共同持有公司股份的人”这样的查询表达可以在图数据库如何自然表达，这仅仅是一条查询的区别，如果是多跳的话，他们的复杂度区分还会更明显一些。 表结构数据库 图数据库（属性图） 将关联关系存储为物理连接，从而使得跳转查询代价最小。（挑战 3、2） 图数据之中，从点拓展（找到一个或者多个关系的另一头）出去的代价是非常小的，这因为图数据库是一个专有的系统，得益于它主要关心“图”结构的设计，查找确定的实体（比如和一个法人 A ）所有关联（可能是任职、亲戚、持有、等等关系）其他所有实体（公司、法人）这个查找的代价是 O(1) 的，因为它们在图数据库的数据机构里是真的链接在一起的。 大家可以从下表的定量参考数据一窥图数据库在这种查询下的优势，这种优势在多跳高并发情况下的区别是“能”与”不能“作为线上系统的区别，是“实时”与“离线”的区别。 在面向关联关系的数据建模和数据结构之下，引入新的实体、关联关系的代价要小很多，还是前边提到的例子： 在 Nebula Graph 图数据中引入一个新的“政府机构”类型的实体，并增加政府机构-\u003e公司的“持有股份”的关联关系相比于在非图模型的数据库中的代价小很多。 表结构数据库 图数据库（属性图） 4 跳查询时延 1544 秒 4 跳查询时延 1.36 秒 建模符合直觉；图数据库有面向数据连接的数据可视化能力（挑战 4） 大家在下表第二列中可以对比我们本文中进行的股权分析数据在两种数据库之中的建模的区别，尤其是在关心关联关系的场景下，我们可以感受到属性图的模型建立是很符合人类大脑直觉的，而这和大脑之中神经元的结构可能也有一些关系。 图数据库中内置的可视化工具提供了一般用户便捷理解数据关系的能力，也给领域专家用户提供了表达请求复杂数据关系的直观接口。 表结构数据库 图数据库（属性图） 表结构数据库与图数据库的总体比较： 表结构数据库 图数据库（属性图） 查询 建模 性能 4 跳查询时延 1544 秒 4 跳查询时延 1.36 秒 综上，在本教程里，我们将利用图数据库来进行数据存储。 ","date":"2021-11-24","objectID":"/corp-rel-graph/:1:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#数据存在哪里"},{"categories":["Nebula Graph","Mini Project"],"content":" 2 图数据建模前面在讨论数据存在哪里的时候，我们已经揭示了在图数据库中建模的方式：本质上，在这张图中，将会有两种实体： 人 公司 四种关系： 人 –作为亲人–\u003e人 人 –作为角色–\u003e 公司 人 或者 公司 –持有股份–\u003e 公司 公司 –作为子机构–\u003e 公司 这里面，实体与关系本身都可以包含更多的信息，这些信息在图数据库里就是实体、关系自身的属性。如下图表示： 人的属性包括 name，age 公司的属性包括 name，location 持有股份 这个关系有属性 share(份额) 任职这个关系有属性 role，level ","date":"2021-11-24","objectID":"/corp-rel-graph/:2:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#图数据建模"},{"categories":["Nebula Graph","Mini Project"],"content":" 3 数据入库本教程中，我们使用的图数据库叫做 Nebula Graph（星云图数据库），它是一个以 Apache 2.0 许可证开源的分布式图数据库。 Nebula Graph in Github: https://github.com/vesoft-inc/nebula 在向 Nebula Graph 导入数据的时候，关于如何选择工具，请参考这篇文档和这个视频。 这里，由于数据格式是 csv 文件并且利用单机的客户端资源就足够了，我们可以选择使用 nebula-importer 来完成这个工作。 提示：在导入数据之前，请先部署一个 Nebula Graph 集群，最简便的部署方式是使用 nebula-up 这个小工具，只需要一行命令就能在 Linux 机器上同时启动一个 Nebula Graph 核心和可视化图探索工具 Nebula Graph Studio。如果你更愿意用 Docker 部署，请参考这个文档。 本文假设我们使用 Nebula-UP 来部署： curl -fsSL nebula-up.siwei.io/install.sh | bash 这里的数据是生成器生成的，你可以按需生成任意规模随机数据集，或者选择一份生成好了的数据在这里 有了这些数据，我们可以开始导入了。 $ pip install Faker==2.0.5 pydbgen==1.0.5 $ python3 data_generator.py $ ls -l data total 1688 -rw-r--r-- 1 weyl staff 23941 Jul 14 13:28 corp.csv -rw-r--r-- 1 weyl staff 1277 Jul 14 13:26 corp_rel.csv -rw-r--r-- 1 weyl staff 3048 Jul 14 13:26 corp_share.csv -rw-r--r-- 1 weyl staff 211661 Jul 14 13:26 person.csv -rw-r--r-- 1 weyl staff 179770 Jul 14 13:26 person_corp_role.csv -rw-r--r-- 1 weyl staff 322965 Jul 14 13:26 person_corp_share.csv -rw-r--r-- 1 weyl staff 17689 Jul 14 13:26 person_rel.csv 导入工具 nebula-importer 是一个 golang 的二进制文件，使用方式就是将导入的 Nebula Graph 连接信息、数据源中字段的含义的信息写进 YAML 格式的配置文件里，然后通过命令行调用它。可以参考文档或者它的 GitHub 仓库里的例子。 这里我已经写好了准备好了一份 nebula-importer 的配置文件，在数据生成器同一个 repo 之下的这里。 最后，只需要执行如下命令就可以开始数据导入了： 注意，在写本文的时候，nebula 的新版本是 2.6.1，这里对应的 nebula-importer 是 v2.6.0，如果您出现导入错误可能是版本不匹配，可以相应调整下边命令中的版本号。 git clone https://github.com/wey-gu/nebula-shareholding-example cp -r data_sample /tmp/data cp nebula-importer.yaml /tmp/data/ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v /tmp/data:/root \\ vesoft/nebula-importer:v2.6.0 \\ --config /root/nebula-importer.yaml 你知道吗？TL;DR 实际上，这份 importer 的配置里帮我们做了 Nebula Graph 之中的图建模的操作，它们的指令在下边，我们不需要手动去执行了。 CREATE SPACE IF NOT EXISTS shareholding(partition_num=5, replica_factor=1, vid_type=FIXED_STRING(10)); USE shareholding; CREATE TAG person(name string); CREATE TAG corp(name string); CREATE TAG INDEX person_name on person(name(20)); CREATE TAG INDEX corp_name on corp(name(20)); CREATE EDGE `role_as`(role string); CREATE EDGE is_branch_of(); CREATE EDGE hold_share(share float); CREATE EDGE reletive_with(degree int); ","date":"2021-11-24","objectID":"/corp-rel-graph/:3:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#数据入库"},{"categories":["Nebula Graph","Mini Project"],"content":" 4 图库中查询数据 Tips: 你知道吗，你也可以无需部署安装，通过 Nebula-Playground 之中，找到股权穿透来在线访问同一份数据集。 我们可以借助 Nebula Graph Studio 来访问数据，访问我们部署 Nebula-UP 的服务器地址的 7001 端口就可以了： 假设服务器地址为 192.168.8.127，则有： Nebula Studio 地址：192.168.8.127:7001 Nebula Graph 地址：192.168.8.127:9669 默认用户名：root 默认密码：nebula 访问 Nebula Studio： 选择图空间: Shareholding 之后，我们就可以在里边探索比如一个公司的三跳以内的股权穿透，具体的操作可以参考：股权穿透在线 Playground 的介绍： ","date":"2021-11-24","objectID":"/corp-rel-graph/:4:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#图库中查询数据"},{"categories":["Nebula Graph","Mini Project"],"content":" 5 构建一个图谱系统 这部分的代码开源在 GitHub 上： https://github.com/wey-gu/nebula-corp-rel-search 本项目的 Demo 也在 PyCon China 2021 上的演讲中有过展示：视频地址 在此基础之上，我们可以构建一个提供给终端用户来使用的股权查询系统了，我们已经有了图数据库作为这个图谱的存储引擎，理论上，如果业务允许，我们可以直接使用或者封装 Nebula Graph Studio 来提供服务，这完全是可行也是合规的，不过，有一些情况下，我们需要自己去实现界面、或者我们需要封装出一个 API 给上游（多端）提供图谱查询的功能。 为此，我为大家写了一个简单的实例项目，提供这样的服务，他的架构也很直接： 前端接受用户要查询的穿透法人、公司，按需发请求给后端，并用 D3.js 将返回结果渲染为关系图 后端接受前端的 API 请求，将请求转换为 Graph DB 的查询，并返回前端期待的结果 ┌───────────────┬───────────────┐ │ │ Frontend │ │ │ │ │ ┌──────────▼──────────┐ │ │ │ Vue.JS │ │ │ │ D3.JS │ │ │ └──────────┬──────────┘ │ │ │ Backend │ │ ┌──────────┴──────────┐ │ │ │ Flask │ │ │ │ Nebula-Python │ │ │ └──────────┬──────────┘ │ │ │ Graph Query │ │ ┌──────────▼──────────┐ │ │ │ Graph Database │ │ │ └─────────────────────┘ │ │ │ └───────────────────────────────┘ ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#构建一个图谱系统"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.1 后端服务–\u003e图数据库 详细的数据格式分析大家可以参考这里 5.1.1 查询语句我们假设用户请求的实体是 c_132 ，那么请求 1 到 3 步的关系穿透的语法是： MATCH p=(v)-[e:`hold_share`|:`is_branch_of`|:`reletive_with`|:`role_as`*1..3]-(v2) \\ WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 这里边 ()包裹的是图之中的点，而[] 包裹的则是点之间的关系：边，所以： (v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) 之中的： (v)-[xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]-(v2)应该比较好理解，意思是从 v 到v2 做拓展。 现在我们介绍中间[]包裹的部分，这里，它的语义是：经由四种类型的边（:之后的是边的类型，|代表或者）通过可变的跳数：*1..3 （一跳到三跳）。 所以，简单来说整理看开，我们的拓展的路径是：从点 v 开始，经由四种关系一到三跳拓展到点v2，返回整个拓展路径 p，限制 100 个路径结果，其中 v 是 c_132。 5.1.2 Nebula Python Client/ SDK我们已经知道了查询语句的语法，那么就只需要在后端程序里根据请求、通过图数据库的客户端来发出查询请求，并处理返回结构就好了。在今天的例子中，我选择使用 Python 来实现后端的逻辑，所以我用了 Nebula-python 这个库，它是 Nebula 的 Python Client。 你知道么？截至到现在，Nebula 在 GitHub 上有 Java，GO，Python，C++，Spark，Flink，Rust（未GA），NodeJS（未GA） 的客户端支持，更多的语言的客户端也会慢慢被发布哦。 下边是一个 Python Client 执行一个查询并返回结果的例子，值得注意的是，在我实现这个代码的时候，Nebula Python 尚未支持返回 JSON （通过session.execute_json()）结果，如果你要实现自己的代码，我非常推荐试试 JSON 哈，就可以不用从对象中一点点取数据了，不过借助 iPython/IDLE 这种 REPL，快速了解返回对象的结构也没有那么麻烦。 $ python3 -m pip install nebula2-python==2.5.0 # 注意这里我引用旧的记录，它是 2.5.0， $ ipython In [1]: from nebula2.gclient.net import ConnectionPool In [2]: from nebula2.Config import Config In [3]: config = Config() ...: config.max_connection_pool_size = 10 ...: # init connection pool ...: connection_pool = ConnectionPool() ...: # if the given servers are ok, return true, else return false ...: ok = connection_pool.init([('192.168.8.137', 9669)], config) ...: session = connection_pool.get_session('root', 'nebula') [2021-10-13 13:44:24,242]:Get connection to ('192.168.8.137', 9669) In [4]: resp = session.execute(\"use shareholding\") In [5]: query = ''' ...: MATCH p=(v)-[e:`hold_share`|:`is_branch_of`|:`reletive_with`|:`role_as`*1..3]-(v2) \\ ...: WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 ...: ''' In [6]: resp = session.execute(query) # Note: after nebula graph 2.6.0, we could use execute_json as well In [7]: resp.col_size() Out[7]: 1 In [9]: resp.row_size() Out[10]: 100 我们往下分析看看，我们知道这个请求本质上结果是路径，它有一个 .nodes() 方法和 .relationships()方法来获得路径上的点和边： In [11]: p=resp.row_values(22)[0].as_path() In [12]: p.nodes() Out[12]: [(\"c_132\" :corp{name: \"Chambers LLC\"}), (\"p_4000\" :person{name: \"Colton Bailey\"})] In [13]: p.relationships() Out[13]: [(\"p_4000\")-[:`role_as`@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\")] 对于边来说有这些方法 .edge_name(), .properties(), .start_vertex_id(), .end_vertex_id()，这里 edge_name 是获得边的类型。 In [14]: rel=p.relationships()[0] In [15]: rel Out[15]: (\"p_4000\")-[:`role_as`@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\") In [16]: rel.edge_name() Out[16]: '`role_as`' In [17]: rel.properties() Out[17]: {'role': \"Editorial assistant\"} In [18]: rel.start_vertex_id() Out[18]: \"p_4000\" In [19]: rel.end_vertex_id() Out[19]: \"c_132\" 对于点来说，可以用到这些方法 .tags(), properties, get_id()，这里边 tags 是获得点的类型，它在 Nebula 里叫标签tag。 这些概念可以在文档里获得更详细的解释。 In [20]: node=p.nodes()[0] In [21]: node.tags() Out[21]: ['corp'] In [22]: node.properties('corp') Out[22]: {'name': \"Chambers LLC\"} In [23]: node.get_id() Out[23]: \"c_132\" ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:1","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#后端服务--图数据库"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.1 后端服务–\u003e图数据库 详细的数据格式分析大家可以参考这里 5.1.1 查询语句我们假设用户请求的实体是 c_132 ，那么请求 1 到 3 步的关系穿透的语法是： MATCH p=(v)-[e:`hold_share`|:`is_branch_of`|:`reletive_with`|:`role_as`*1..3]-(v2) \\ WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 这里边 ()包裹的是图之中的点，而[] 包裹的则是点之间的关系：边，所以： (v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) 之中的： (v)-[xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]-(v2)应该比较好理解，意思是从 v 到v2 做拓展。 现在我们介绍中间[]包裹的部分，这里，它的语义是：经由四种类型的边（:之后的是边的类型，|代表或者）通过可变的跳数：*1..3 （一跳到三跳）。 所以，简单来说整理看开，我们的拓展的路径是：从点 v 开始，经由四种关系一到三跳拓展到点v2，返回整个拓展路径 p，限制 100 个路径结果，其中 v 是 c_132。 5.1.2 Nebula Python Client/ SDK我们已经知道了查询语句的语法，那么就只需要在后端程序里根据请求、通过图数据库的客户端来发出查询请求，并处理返回结构就好了。在今天的例子中，我选择使用 Python 来实现后端的逻辑，所以我用了 Nebula-python 这个库，它是 Nebula 的 Python Client。 你知道么？截至到现在，Nebula 在 GitHub 上有 Java，GO，Python，C++，Spark，Flink，Rust（未GA），NodeJS（未GA） 的客户端支持，更多的语言的客户端也会慢慢被发布哦。 下边是一个 Python Client 执行一个查询并返回结果的例子，值得注意的是，在我实现这个代码的时候，Nebula Python 尚未支持返回 JSON （通过session.execute_json()）结果，如果你要实现自己的代码，我非常推荐试试 JSON 哈，就可以不用从对象中一点点取数据了，不过借助 iPython/IDLE 这种 REPL，快速了解返回对象的结构也没有那么麻烦。 $ python3 -m pip install nebula2-python==2.5.0 # 注意这里我引用旧的记录，它是 2.5.0， $ ipython In [1]: from nebula2.gclient.net import ConnectionPool In [2]: from nebula2.Config import Config In [3]: config = Config() ...: config.max_connection_pool_size = 10 ...: # init connection pool ...: connection_pool = ConnectionPool() ...: # if the given servers are ok, return true, else return false ...: ok = connection_pool.init([('192.168.8.137', 9669)], config) ...: session = connection_pool.get_session('root', 'nebula') [2021-10-13 13:44:24,242]:Get connection to ('192.168.8.137', 9669) In [4]: resp = session.execute(\"use shareholding\") In [5]: query = ''' ...: MATCH p=(v)-[e:`hold_share`|:`is_branch_of`|:`reletive_with`|:`role_as`*1..3]-(v2) \\ ...: WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 ...: ''' In [6]: resp = session.execute(query) # Note: after nebula graph 2.6.0, we could use execute_json as well In [7]: resp.col_size() Out[7]: 1 In [9]: resp.row_size() Out[10]: 100 我们往下分析看看，我们知道这个请求本质上结果是路径，它有一个 .nodes() 方法和 .relationships()方法来获得路径上的点和边： In [11]: p=resp.row_values(22)[0].as_path() In [12]: p.nodes() Out[12]: [(\"c_132\" :corp{name: \"Chambers LLC\"}), (\"p_4000\" :person{name: \"Colton Bailey\"})] In [13]: p.relationships() Out[13]: [(\"p_4000\")-[:`role_as`@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\")] 对于边来说有这些方法 .edge_name(), .properties(), .start_vertex_id(), .end_vertex_id()，这里 edge_name 是获得边的类型。 In [14]: rel=p.relationships()[0] In [15]: rel Out[15]: (\"p_4000\")-[:`role_as`@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\") In [16]: rel.edge_name() Out[16]: '`role_as`' In [17]: rel.properties() Out[17]: {'role': \"Editorial assistant\"} In [18]: rel.start_vertex_id() Out[18]: \"p_4000\" In [19]: rel.end_vertex_id() Out[19]: \"c_132\" 对于点来说，可以用到这些方法 .tags(), properties, get_id()，这里边 tags 是获得点的类型，它在 Nebula 里叫标签tag。 这些概念可以在文档里获得更详细的解释。 In [20]: node=p.nodes()[0] In [21]: node.tags() Out[21]: ['corp'] In [22]: node.properties('corp') Out[22]: {'name': \"Chambers LLC\"} In [23]: node.get_id() Out[23]: \"c_132\" ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:1","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#查询语句"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.1 后端服务–\u003e图数据库 详细的数据格式分析大家可以参考这里 5.1.1 查询语句我们假设用户请求的实体是 c_132 ，那么请求 1 到 3 步的关系穿透的语法是： MATCH p=(v)-[e:`hold_share`|:`is_branch_of`|:`reletive_with`|:`role_as`*1..3]-(v2) \\ WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 这里边 ()包裹的是图之中的点，而[] 包裹的则是点之间的关系：边，所以： (v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) 之中的： (v)-[xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]-(v2)应该比较好理解，意思是从 v 到v2 做拓展。 现在我们介绍中间[]包裹的部分，这里，它的语义是：经由四种类型的边（:之后的是边的类型，|代表或者）通过可变的跳数：*1..3 （一跳到三跳）。 所以，简单来说整理看开，我们的拓展的路径是：从点 v 开始，经由四种关系一到三跳拓展到点v2，返回整个拓展路径 p，限制 100 个路径结果，其中 v 是 c_132。 5.1.2 Nebula Python Client/ SDK我们已经知道了查询语句的语法，那么就只需要在后端程序里根据请求、通过图数据库的客户端来发出查询请求，并处理返回结构就好了。在今天的例子中，我选择使用 Python 来实现后端的逻辑，所以我用了 Nebula-python 这个库，它是 Nebula 的 Python Client。 你知道么？截至到现在，Nebula 在 GitHub 上有 Java，GO，Python，C++，Spark，Flink，Rust（未GA），NodeJS（未GA） 的客户端支持，更多的语言的客户端也会慢慢被发布哦。 下边是一个 Python Client 执行一个查询并返回结果的例子，值得注意的是，在我实现这个代码的时候，Nebula Python 尚未支持返回 JSON （通过session.execute_json()）结果，如果你要实现自己的代码，我非常推荐试试 JSON 哈，就可以不用从对象中一点点取数据了，不过借助 iPython/IDLE 这种 REPL，快速了解返回对象的结构也没有那么麻烦。 $ python3 -m pip install nebula2-python==2.5.0 # 注意这里我引用旧的记录，它是 2.5.0， $ ipython In [1]: from nebula2.gclient.net import ConnectionPool In [2]: from nebula2.Config import Config In [3]: config = Config() ...: config.max_connection_pool_size = 10 ...: # init connection pool ...: connection_pool = ConnectionPool() ...: # if the given servers are ok, return true, else return false ...: ok = connection_pool.init([('192.168.8.137', 9669)], config) ...: session = connection_pool.get_session('root', 'nebula') [2021-10-13 13:44:24,242]:Get connection to ('192.168.8.137', 9669) In [4]: resp = session.execute(\"use shareholding\") In [5]: query = ''' ...: MATCH p=(v)-[e:`hold_share`|:`is_branch_of`|:`reletive_with`|:`role_as`*1..3]-(v2) \\ ...: WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 ...: ''' In [6]: resp = session.execute(query) # Note: after nebula graph 2.6.0, we could use execute_json as well In [7]: resp.col_size() Out[7]: 1 In [9]: resp.row_size() Out[10]: 100 我们往下分析看看，我们知道这个请求本质上结果是路径，它有一个 .nodes() 方法和 .relationships()方法来获得路径上的点和边： In [11]: p=resp.row_values(22)[0].as_path() In [12]: p.nodes() Out[12]: [(\"c_132\" :corp{name: \"Chambers LLC\"}), (\"p_4000\" :person{name: \"Colton Bailey\"})] In [13]: p.relationships() Out[13]: [(\"p_4000\")-[:`role_as`@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\")] 对于边来说有这些方法 .edge_name(), .properties(), .start_vertex_id(), .end_vertex_id()，这里 edge_name 是获得边的类型。 In [14]: rel=p.relationships()[0] In [15]: rel Out[15]: (\"p_4000\")-[:`role_as`@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\") In [16]: rel.edge_name() Out[16]: '`role_as`' In [17]: rel.properties() Out[17]: {'role': \"Editorial assistant\"} In [18]: rel.start_vertex_id() Out[18]: \"p_4000\" In [19]: rel.end_vertex_id() Out[19]: \"c_132\" 对于点来说，可以用到这些方法 .tags(), properties, get_id()，这里边 tags 是获得点的类型，它在 Nebula 里叫标签tag。 这些概念可以在文档里获得更详细的解释。 In [20]: node=p.nodes()[0] In [21]: node.tags() Out[21]: ['corp'] In [22]: node.properties('corp') Out[22]: {'name': \"Chambers LLC\"} In [23]: node.get_id() Out[23]: \"c_132\" ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:1","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#nebula-python-client-sdk"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.2 前端渲染点边为图 详细的分析大家也可以参考这里 为了方便实现，我们采用了 Vue.js 和 vue-network-d3（D3 的 Vue Binding）。 通过 vue-network-d3 的抽象，能看出来喂给他这样的数据，就可以把点边信息渲染成很好看的图 nodes: [ {\"id\": \"c_132\", \"name\": \"Chambers LLC\", \"tag\": \"corp\"}, {\"id\": \"p_4000\", \"name\": \"Colton Bailey\", \"tag\": \"person\"}], relationships: [ {\"source\": \"p_4000\", \"target\": \"c_132\", \"properties\": { \"role\": \"Editorial assistant\" }, \"edge\": \"`role_as`\"}] ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:2","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#前端渲染点边为图"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.3 前端\u003c–后端 详细信息可以参考这里 我们从 D3 的初步研究上可以知道，后端只需要返回如下的 JSON 格式数据就好了 Nodes: [{\"id\": \"c_132\", \"name\": \"Chambers LLC\", \"tag\": \"corp\"}, {\"id\": \"p_4000\", \"name\": \"Colton Bailey\", \"tag\": \"person\"}] Relationships: [{\"source\": \"p_4000\", \"target\": \"c_132\", \"properties\": { \"role\": \"Editorial assistant\" }, \"edge\": \"`role_as`\"}, {\"source\": \"p_1039\", \"target\": \"c_132\", \"properties\": { \"share\": \"3.0\" }, \"edge\": \"hold_share\"}] 于是，，结合前边我们用 iPython 分析 Python 返回结果看，这个逻辑大概是： def make_graph_response(resp) -\u003e dict: nodes, relationships = list(), list() for row_index in range(resp.row_size()): path = resp.row_values(row_index)[0].as_path() _nodes = [ { \"id\": node.get_id(), \"tag\": node.tags()[0], \"name\": node.properties(node.tags()[0]).get(\"name\", \"\") } for node in path.nodes() ] nodes.extend(_nodes) _relationships = [ { \"source\": rel.start_vertex_id(), \"target\": rel.end_vertex_id(), \"properties\": rel.properties(), \"edge\": rel.edge_name() } for rel in path.relationships() ] relationships.extend(_relationships) return {\"nodes\": nodes, \"relationships\": relationships} 前端到后端的通信是 HTTP ，所以我们可以借助 Flask，把这个函数封装成一个 RESTful API： 前端程序通过 HTTP POST 到 /api 参考这里 from flask import Flask, jsonify, request app = Flask(__name__) @app.route(\"/\") def root(): return \"Hey There?\" @app.route(\"/api\", methods=[\"POST\"]) def api(): request_data = request.get_json() entity = request_data.get(\"entity\", \"\") if entity: resp = query_shareholding(entity) data = make_graph_response(resp) else: data = dict() # tbd return jsonify(data) def parse_nebula_graphd_endpoint(): ng_endpoints_str = os.environ.get( 'NG_ENDPOINTS', '127.0.0.1:9669,').split(\",\") ng_endpoints = [] for endpoint in ng_endpoints_str: if endpoint: parts = endpoint.split(\":\") # we dont consider IPv6 now ng_endpoints.append((parts[0], int(parts[1]))) return ng_endpoints def query_shareholding(entity): query_string = ( f\"USE shareholding; \" f\"MATCH p=(v)-[e:`hold_share`|:`is_branch_of`|:`reletive_with`|:`role_as`*1..3]-(v2) \" f\"WHERE id(v) IN ['{ entity }'] RETURN p LIMIT 100\" ) session = connection_pool.get_session('root', 'nebula') resp = session.execute(query_string) return resp 这个请求的结果则是前边前端期待的 JSON，像这样： curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{\"entity\": \"c_132\"}' \\ http://192.168.10.14:5000/api | jq { \"nodes\": [ { \"id\": \"c_132\", \"name\": \"\\\"Chambers LLC\\\"\", \"tag\": \"corp\" }, { \"id\": \"c_245\", \"name\": \"\\\"Thompson-King\\\"\", \"tag\": \"corp\" }, { \"id\": \"c_132\", \"name\": \"\\\"Chambers LLC\\\"\", \"tag\": \"corp\" }, ... } ], \"relationships\": [ { \"edge\": \"hold_share\", \"properties\": \"{'share': 0.0}\", \"source\": \"c_245\", \"target\": \"c_132\" { \"edge\": \"hold_share\", \"properties\": \"{'share': 9.0}\", \"source\": \"p_1767\", \"target\": \"c_132\" }, { \"edge\": \"hold_share\", \"properties\": \"{'share': 11.0}\", \"source\": \"p_1997\", \"target\": \"c_132\" }, ... }, { \"edge\": \"reletive_with\", \"properties\": \"{'degree': 51}\", \"source\": \"p_7283\", \"target\": \"p_4723\" } ] } ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:3","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#前端--后端"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.4 放到一起项目的代码都在 GitHub 上，最后其实只有一两百行的代码，把所有东西拼起来之后的代码是： ├── README.md # You could find Design Logs here ├── corp-rel-backend │ └── app.py # Flask App to handle Requst and calls GDB ├── corp-rel-frontend │ └── src │ ├── App.vue │ └── main.js # Vue App to call Flask App and Renders Graph └── requirements.txt ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:4","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#放到一起"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.5 最终效果我们做出来了一个简陋但是足够具有参考性的小系统，它接受一个用户输入的实体的 ID，再回车之后： 前端程序把请求发给后端 后端拼接 Nebula Graph 的查询语句，通过 Nebula Python 客户端请求 Nebula Graph Nebula Graph 接受请求做出穿透查询，返回结构给后端 后端将结果构建成前端 D3 接受的格式，传给前端 前端接收到图结构的数据，渲染股权穿透的数据如下： ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:5","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#最终效果"},{"categories":["Nebula Graph","Mini Project"],"content":" 6 总结现在，我们知道得益于图数据库的设计，在它上边构建一个方便的股权分析系统非常自然、高效，我们或者利用图数据库的图探索可视化能力、或者自己搭建，可以为用户提供非常高效、直观的多跳股权穿透分析。 如果你想了解更多关于分布式图数据库的知识，欢迎关注 Nebula Graph 这个开源项目，它已经被国内很多团队、公司认可选为图时代数据技术存储层的利器，大家可以访问这里，或者这里，了解更多相关的分享和文章。 未来，我会给大家分享更多图数据库相关的文章、视频和开源示例项目思路分享和教程，欢迎大家关注我的网站: siwei.io。 题图版权：fabioha ","date":"2021-11-24","objectID":"/corp-rel-graph/:6:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#总结"},{"categories":["Nebula Graph"],"content":"Dialog System With Graph Database Backed Knowledge Graph. 基于图数据库的智能问答助手","date":"2021-09-18","objectID":"/nebula-siwi/","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/"},{"categories":["Nebula Graph"],"content":" 一个基于图数据库的智能问答助手项目。 GitHub Repo: https://github.com/wey-gu/nebula-siwi/ 这个项目我也做成了互动教程，可以按照这里的步骤搭建起来 👉🏻 https://siwei.io/cources/ update: 写了一篇完整介绍 Siwi 设计的文章 👉🏻 https://siwei.io/siwi 您也可以在 Nebula Playground 上直接玩这个数据集啦：https://nebula-graph.com.cn/demo/ ","date":"2021-09-18","objectID":"/nebula-siwi/:0:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#"},{"categories":["Nebula Graph"],"content":" Siwi the voice assistantSiwi (/ˈsɪwi/) is a PoC of Dialog System With Graph Database Backed Knowledge Graph. For now, it’s a demo for task-driven(not general purpose) dialog bots with KG(Knowledge Graph) leveraging Nebula Graph with the minimal/sample dataset from Nebula Graph Manual/ NG中文手册. Tips: Now you can play with the graph online without installing yourself! Nebula Playground | Nebula Playground - China Mainland Supported queries: relation: What is the relationship between Yao Ming and Lakers? How does Yao Ming and Lakers connected? serving: Which team had Yao Ming served? friendship: Whom does Tim Duncan follow? Who are Yao Ming’s friends? ","date":"2021-09-18","objectID":"/nebula-siwi/:0:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#siwi-the-voice-assistant"},{"categories":["Nebula Graph"],"content":" 1 Deploy and TryTBD (leveraging docker and nebula-up) ","date":"2021-09-18","objectID":"/nebula-siwi/:1:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#deploy-and-try"},{"categories":["Nebula Graph"],"content":" 2 How does it work?This is one of the most naive pipeline for a specific domain/ single purpose chat bot built on a Knowledge Graph. ","date":"2021-09-18","objectID":"/nebula-siwi/:2:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#how-does-it-work"},{"categories":["Nebula Graph"],"content":" 2.1 Backend The Backend(Siwi API) is a Flask based API server: Flask API server takes questions in HTTP POST, and calls the bot API. In bot API part there are classfier(Symentic Parsing, Intent Matching, Slot Filling), and question actors(Call corresponding actions to query Knowledge Graph with intents and slots). Knowledge Graph is built on an Open-Source Graph Database: Nebula Graph ","date":"2021-09-18","objectID":"/nebula-siwi/:2:1","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#backend"},{"categories":["Nebula Graph"],"content":" 2.2 Frontend The Frontend is a VueJS Single Page Applicaiton(SPA): I reused a Vue Bot UI to showcase a chat window in this human-agent interaction, typing is supported. In addtion, leverating Chrome’s Web Speech API, a button to listen to human voice is introduced ","date":"2021-09-18","objectID":"/nebula-siwi/:2:2","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#frontend"},{"categories":["Nebula Graph"],"content":" 2.3 A Query Flow ┌────────────────┬──────────────────────────────────────┐ │ │ │ │ │ Speech │ │ ┌──────────▼──────────┐ │ │ │ Frontend │ Siwi, /ˈsɪwi/ │ │ │ Web_Speech_API │ A PoC of │ │ │ │ Dialog System │ │ │ Vue.JS │ With Graph Database │ │ │ │ Backed Knowledge Graph │ │ └──────────┬──────────┘ │ │ │ Sentence │ │ │ │ │ ┌────────────┼──────────────────────────────┐ │ │ │ │ │ │ │ │ │ Backend │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ Web API, Flask │ ./app/ │ │ │ │ └──────────┬──────────┘ │ │ │ │ │ Sentence ./bot/ │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ │ │ │ │ │ │ Intent matching, │ ./bot/classifier│ │ │ │ │ Symentic Processing │ │ │ │ │ │ │ │ │ │ │ └──────────┬──────────┘ │ │ │ │ │ Intent, Entities │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ │ │ │ │ │ │ Intent Actor │ ./bot/actions │ │ │ │ │ │ │ │ │ └─┴──────────┬──────────┴───────────────────┘ │ │ │ Graph Query │ │ ┌──────────▼──────────┐ │ │ │ │ │ │ │ Graph Database │ Nebula Graph │ │ │ │ │ │ └─────────────────────┘ │ │ │ │ │ │ │ └───────────────────────────────────────────────────────┘ ","date":"2021-09-18","objectID":"/nebula-siwi/:2:3","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#a-query-flow"},{"categories":["Nebula Graph"],"content":" 2.4 Source Code Tree . ├── README.md ├── src │ ├── siwi # Siwi-API Backend │ │ ├── app # Web Server, take HTTP requests and calls Bot API │ │ └── bot # Bot API │ │ ├── actions # Take Intent, Slots, Query Knowledge Graph here │ │ ├── bot # Entrypoint of the Bot API │ │ ├── classifier # Symentic Parsing, Intent Matching, Slot Filling │ │ └── test # Example Data Source as equivalent/mocked module │ └── siwi_frontend # Browser End │ ├── README.md │ ├── package.json │ └── src │ ├── App.vue # Listening to user and pass Questions to Siwi-API │ └── main.js └── wsgi.py ","date":"2021-09-18","objectID":"/nebula-siwi/:2:4","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#source-code-tree"},{"categories":["Nebula Graph"],"content":" 3 Manually Run Components","date":"2021-09-18","objectID":"/nebula-siwi/:3:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#manually-run-components"},{"categories":["Nebula Graph"],"content":" 3.1 BackendInstall and run. # Install siwi backend python3 -m build # Configure Nebula Graph Endpoint export NG_ENDPOINTS=127.0.0.1:9669 # Run Backend API server gunicorn --bind :5000 wsgi --workers 1 --threads 1 --timeout 60 For OpenFunction/ KNative docker build -t weygu/siwi-api . docker run --rm --name siwi-api \\ --env=PORT=5000 \\ --env=NG_ENDPOINTS=127.0.0.1:9669 \\ --net=host \\ weygu/siwi-api Try it out Web API: $ curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{\"question\": \"What is the relationship between Yao Ming and Lakers?\"}' \\ http://192.168.8.128:5000/query | jq { \"answer\": \"There are at least 23 relations between Yao Ming and Lakers, one relation path is: Yao Ming follows Shaquille O'Neal serves Lakers.\" } Call Bot Python API: from nebula2.gclient.net import ConnectionPool from nebula2.Config import Config # define a config config = Config() config.max_connection_pool_size = 10 # init connection pool connection_pool = ConnectionPool() # if the given servers are ok, return true, else return false ok = connection_pool.init([('127.0.0.1', 9669)], config) # import siwi bot from siwi.bot import bot # instantiate a bot b = bot.SiwiBot(connection_pool) # make the question query b.query(\"Which team had Jonathon Simmons served?\") Then a response will be like this: In [4]: b.query(\"Which team had Jonathon Simmons serv ...: ed?\") [DEBUG] ServeAction intent: {'entities': {'Jonathon Simmons': 'player'}, 'intents': ('serve',)} [DEBUG] query for RelationshipAction: USE basketballplayer; MATCH p=(v)-[e:serve*1]-\u003e(v1) WHERE id(v) == \"player112\" RETURN p LIMIT 100; [2021-07-02 02:59:36,392]:Get connection to ('127.0.0.1', 9669) Out[4]: 'Jonathon Simmons had served 3 teams. Spurs from 2015 to 2015; 76ers from 2019 to 2019; Magic from 2017 to 2017; ' ","date":"2021-09-18","objectID":"/nebula-siwi/:3:1","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#backend-1"},{"categories":["Nebula Graph"],"content":" 3.2 FrontendReferring to siwi_frontend ","date":"2021-09-18","objectID":"/nebula-siwi/:3:2","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#frontend-1"},{"categories":["Nebula Graph"],"content":" 4 Further work Use NBA-API to fallback undefined pattern questions Wrap and manage sessions instead of get and release session per request, this is somehow costly actually. Use NLP methods to implement proper Symentic Parsing, Intent Matching, Slot Filling Build Graph to help with Intent Matching, especially for a general purpose bot Use larger Dataset i.e. from wyattowalsh/basketball ","date":"2021-09-18","objectID":"/nebula-siwi/:4:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#further-work"},{"categories":["Nebula Graph"],"content":" 5 Thanks to Upstream Projects ❤️","date":"2021-09-18","objectID":"/nebula-siwi/:5:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#thanks-to-upstream-projects-"},{"categories":["Nebula Graph"],"content":" 5.1 Backend I learnt a lot from the KGQA on MedicalKG created by Huanyong Liu Flask pyahocorasick created by Wojciech Muła PyYaml ","date":"2021-09-18","objectID":"/nebula-siwi/:5:1","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#backend-2"},{"categories":["Nebula Graph"],"content":" 5.2 Frontend VueJS for frontend framework Vue Bot UI, as a lovely bot UI in vue Vue Web Speech, for speech API vue wrapper Axios for browser http client Solarized for color scheme Vitesome for landing page design Image credit goes to https://unsplash.com/photos/0E_vhMVqL9g ","date":"2021-09-18","objectID":"/nebula-siwi/:5:2","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#frontend-2"},{"categories":["Nebula Graph"],"content":"Setup Nebula Graph Dev Env with CLion and Docker 搭建基于 Docker 的 Nebula Graph CLion 开发环境","date":"2021-09-18","objectID":"/nebula-clion/","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/"},{"categories":["Nebula Graph"],"content":" 之前卡比同学向我咨询搭建 CLion 环境，开发 Nebula 的一些问题，我做了一些工作方便利用 Docker 在本地搭建这样一个环境，相关的东西放在：https://github.com/wey-gu/nebula-dev-CLion 。 Related GitHub Repo: https://github.com/wey-gu/nebula-dev-CLion ","date":"2021-09-18","objectID":"/nebula-clion/:0:0","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#"},{"categories":["Nebula Graph"],"content":" 1 Run Docker Env for Nebula-Graph with CLionBuild Docker Image git clone https://github.com/wey-gu/nebula-dev-CLion.git cd nebula-dev-CLion docker build -t wey/nebula-dev-clion:v2.0 . Run Docker Container for Nebula-Dev with CLion Integration Readiness(actually mostly Rsync \u0026 SSH). cd \u003cnebula-graph-repo-you-worked-on\u003e export DOCKER_DEFAULT_PLATFORM=linux/amd64 docker run --rm -d \\ --name nebula-dev \\ --security-opt seccomp=unconfined \\ -p 2222:22 -p 2873:873 --cap-add=ALL \\ -v $PWD:/home/nebula \\ -w /home/nebula \\ wey/nebula-dev-clion:v2.0 Verify cmake with SSH. The default password is password ssh -o StrictHostKeyChecking=no root@localhost -p 2222 # in docker cd /home/nebula mkdir build \u0026\u0026 cd build cmake -DENABLE_TESTING=OFF -DCMAKE_BUILD_TYPE=Release .. Access container w/o SSH. docker exec -it nebula-dev bash mkdir -p build \u0026\u0026 cd build cmake -DENABLE_TESTING=OFF -DCMAKE_BUILD_TYPE=Release .. ","date":"2021-09-18","objectID":"/nebula-clion/:1:0","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#run-docker-env-for-nebula-graph-with-clion"},{"categories":["Nebula Graph"],"content":" 2 Configurations in CLion Ref: https://www.jetbrains.com/help/clion/clion-toolchains-in-docker.html#build-and-run Toolchains Add a remote host root@localhost:2222 password Put /opt/vesoft/toolset/cmake/bin/cmake as CMake CMake Toochain: Select the one created in last step Build directory: /home/nebula/build ","date":"2021-09-18","objectID":"/nebula-clion/:2:0","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#configurations-in-clion"},{"categories":["Nebula Graph"],"content":" 3 The appendix","date":"2021-09-18","objectID":"/nebula-clion/:3:0","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#the-appendix"},{"categories":["Nebula Graph"],"content":" 3.1 References of CMake output: [root@4c98e3f77ce8 build]# cmake -DENABLE_TESTING=OFF -DCMAKE_BUILD_TYPE=Release .. \u003e\u003e\u003e\u003e Options of Nebula Graph \u003c\u003c\u003c\u003c -- ENABLE_ASAN : OFF (Build with AddressSanitizer) -- ENABLE_BUILD_STORAGE : OFF (Whether to build storage) -- ENABLE_CCACHE : ON (Use ccache to speed up compiling) -- ENABLE_CLANG_TIDY : OFF (Enable clang-tidy if present) -- ENABLE_COMPRESSED_DEBUG_INFO : ON (Compress debug info to reduce binary size) -- ENABLE_COVERAGE : OFF (Build with coverage report) -- ENABLE_FRAME_POINTER : OFF (Build with frame pointer) -- ENABLE_FUZZY_TESTING : OFF (Enable Fuzzy tests) -- ENABLE_GDB_SCRIPT_SECTION : OFF (Add .debug_gdb_scripts section) -- ENABLE_JEMALLOC : ON (Use jemalloc as memory allocator) -- ENABLE_MODULE_FORCE_CHECKOUT : ON (Whether checkout branch of module to same as graph.) -- ENABLE_MODULE_UPDATE : OFF (Automatically update module) -- ENABLE_PACK_ONE : ON (Whether to package into one) -- ENABLE_PIC : OFF (Build with -fPIC) -- ENABLE_STATIC_ASAN : OFF (Statically link against libasan) -- ENABLE_STATIC_UBSAN : OFF (Statically link against libubsan) -- ENABLE_STRICT_ALIASING : OFF (Build with -fstrict-aliasing) -- ENABLE_TESTING : OFF (Build unit tests) -- ENABLE_TSAN : OFF (Build with ThreadSanitizer) -- ENABLE_UBSAN : OFF (Build with UndefinedBehaviourSanitizer) -- ENABLE_VERBOSE_BISON : OFF (Enable Bison to report state) -- ENABLE_WERROR : ON (Regard warnings as errors) -- CMAKE_BUILD_TYPE : Release (Choose the type of build, options are: None Debug Release RelWithDebInfo MinSizeRel ...) -- CMAKE_INSTALL_PREFIX : /usr/local/nebula (Install path prefix, prepended onto install directories.) -- CMAKE_CXX_STANDARD : 17 -- CMAKE_CXX_COMPILER : /opt/vesoft/toolset/clang/9.0.0/bin/c++ (CXX compiler) -- CMAKE_CXX_COMPILER_ID : GNU -- NEBULA_USE_LINKER : bfd -- CCACHE_DIR : /root/.ccache \u003e\u003e\u003e\u003e Configuring third party for 'Nebula Graph' \u003c\u003c\u003c\u003c -- NEBULA_THIRDPARTY_ROOT : /opt/vesoft/third-party/2.0 -- Build info of nebula third party: Package : Nebula Third Party Version : 2.0 Date : Mon Jun 28 15:07:38 UTC 2021 glibc : 2.17 Arch : x86_64 Compiler : GCC 9.2.0 C++ ABI : 11 Vendor : VEsoft Inc. -- CMAKE_INCLUDE_PATH : /opt/vesoft/third-party/2.0/include -- CMAKE_LIBRARY_PATH : /opt/vesoft/third-party/2.0/lib64;/opt/vesoft/third-party/2.0/lib -- CMAKE_PROGRAM_PATH : /opt/vesoft/third-party/2.0/bin -- GLIBC_VERSION : 2.17 -- found krb5-config here /opt/vesoft/third-party/2.0/bin/krb5-config -- Found kerberos 5 headers: /opt/vesoft/third-party/2.0/include -- Found kerberos 5 libs: /opt/vesoft/third-party/2.0/lib/libgssapi_krb5.a;/opt/vesoft/third-party/2.0/lib/libkrb5.a;/opt/vesoft/third-party/2.0/lib/libk5crypto.a;/opt/vesoft/third-party/2.0/lib/libcom_err.a;/opt/vesoft/third-party/2.0/lib/libkrb5support.a \u003e\u003e\u003e\u003e Configuring third party for 'Nebula Graph' done \u003c\u003c\u003c\u003c -- Create the pre-commit hook -- Creating pre-commit hook done \u003e\u003e\u003e\u003e Configuring Nebula Common \u003c\u003c\u003c\u003c \u003e\u003e\u003e\u003e Options of Nebula Common \u003c\u003c\u003c\u003c -- ENABLE_ASAN : OFF (Build with AddressSanitizer) -- ENABLE_CCACHE : ON (Use ccache to speed up compiling) -- ENABLE_CLANG_TIDY : OFF (Enable clang-tidy if present) -- ENABLE_COMPRESSED_DEBUG_INFO : ON (Compress debug info to reduce binary size) -- ENABLE_COVERAGE : OFF (Build with coverage report) -- ENABLE_FRAME_POINTER : OFF (Build with frame pointer) -- ENABLE_FUZZY_TESTING : OFF (Enable Fuzzy tests) -- ENABLE_GDB_SCRIPT_SECTION : OFF (Add .debug_gdb_scripts section) -- ENABLE_JEMALLOC : ON (Use jemalloc as memory allocator) -- ENABLE_PIC : OFF (Build with -fPIC) -- ENABLE_STATIC_ASAN : OFF (Statically link against libasan) -- ENABLE_STATIC_UBSAN : OFF (Statically link against libubsan) -- ENABLE_STRICT_ALIASING : OFF (Build with -fstrict-aliasing) -- ENABLE_TESTING : OFF (Build unit tests) -- ENABLE_TSAN : OFF (Build with ThreadSanitizer) -- ENABLE_UBSAN : OFF (Build with UndefinedBehaviourSanitizer) -- ENABLE_WERROR : ON (Regard warnings as errors) -- Set D_GLIBCXX_USE_CXX11_ABI to 1 -- CMAKE_BUI","date":"2021-09-18","objectID":"/nebula-clion/:3:1","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#references-of-cmake-output"},{"categories":["courses"],"content":"Hands-on Course: Breakdown multistage relationship of Persons and Corporations leverating the Nebula Graph Database.","date":"2021-09-04","objectID":"/learn/nebula-101-shareholding/","series":null,"tags":["Nebula Graph","katacoda","shareholding","Nebula Solution","Knowledge Graph"],"title":"上手实战图数据库股权关系穿透","uri":"/learn/nebula-101-shareholding/"},{"categories":["courses"],"content":"Walk you through in actions to do below sections exercises! Bootstrap a Nebula Graph Cluster and Studio Web App Import a graph of dataset about shareholding Exploring the shareholding data with Nebula Importer Visually Exploring the shareholding data with Nebula Studio Run Graph Algorithm on Nebula Cluster Graph Data The dataset comes from https://github.com/wey-gu/nebula-shareholding-example/tree/main/data_sample 课程开源在 https://github.com/wey-gu/katacoda-scenarios ，欢迎来反馈，贡献 ","date":"2021-09-04","objectID":"/learn/nebula-101-shareholding/:0:0","series":null,"tags":["Nebula Graph","katacoda","shareholding","Nebula Solution","Knowledge Graph"],"title":"上手实战图数据库股权关系穿透","uri":"/learn/nebula-101-shareholding/#"},{"categories":null,"content":" 您可以通过这个导图开始了解、入门图数据库和 Nebula Graph，上边的区域是入门的部分，下边还有进阶的部分，我们会持续更新、维护这个导图的~ Tips: 加载成功之后，点击 [See the board] 可以开始浏览，双击放大缩小。 或者点导图区域右上角的箭头在新的窗口打开，可以更方面浏览器中内容。 ","date":"2021-09-04","objectID":"/path/:0:0","series":null,"tags":null,"title":"图数据库学习路径","uri":"/path/#"},{"categories":["courses"],"content":"Hands-on Course: Setup a KGQA system from scratch with Nebula Graph, VueJS, Flask on K8s.","date":"2021-09-03","objectID":"/learn/nebula-101-siwi-kgqa/","series":null,"tags":["Nebula Graph","katacoda","Dialog System","Nebula Solution"],"title":"上手实战从0制作一个基于图谱的语音智能助手","uri":"/learn/nebula-101-siwi-kgqa/"},{"categories":["courses"],"content":"A full solution walkthrough for a Knowledge Graph Dialog System. Boostrap a Nebula Cluster in K8s Scale out the Nebula Cluster in K8s way Import the basketballplayer Dataset Siwi, the Knowledge Graph Dialog System with Nebula Graph Siwi (/ˈsɪwi/) is a PoC of Dialog System With Graph Database Backed Knowledge Graph. The code of Siwi is here: https://github.com/wey-gu/nebula-siwi. 课程开源在 https://github.com/wey-gu/katacoda-scenarios ，欢迎来反馈，贡献 ","date":"2021-09-03","objectID":"/learn/nebula-101-siwi-kgqa/:0:0","series":null,"tags":["Nebula Graph","katacoda","Dialog System","Nebula Solution"],"title":"上手实战从0制作一个基于图谱的语音智能助手","uri":"/learn/nebula-101-siwi-kgqa/#"},{"categories":["Nebula Graph"],"content":"A demo of Shareholding Breakthrough with Distributed open-source Graph Database: Nebula Graph. 图数据库应用示例：股权关系穿透","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/"},{"categories":["Nebula Graph"],"content":" A demo of Shareholding Breakthrough with Distributed open-source Graph Database: Nebula Graph. 图数据库应用示例：股权关系穿透 Related GitHub Repo: https://github.com/wey-gu/nebula-shareholding-example 更新：在这个数据集生成的工作基础上，我又做了一个全栈示例项目 👉🏻 https://siwei.io/corp-rel-graph/ 这个项目我也做成了互动教程，可以按照这里的步骤搭建起来 👉🏻 https://siwei.io/cources/ I created the Katacoda Interactive Env for this project 👉🏻 https://siwei.io/cources/ 您也可以在 Nebula Playground 上直接玩这个数据集啦：https://nebula-graph.com.cn/demo/ Now you can play with the data on Nebula Playground: https://nebula-graph.io/demo/ This is a demo of Shareholding Relationship Analysis with Distributed open-source Graph Database: Nebula Graph. ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:0:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#"},{"categories":["Nebula Graph"],"content":" 1 Data","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:1:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#data"},{"categories":["Nebula Graph"],"content":" 1.1 Data Modeling There are various kinds of relationships when we checking companies’ shareholding breakthrough, here let’s simplify it with only two kind of entities: person and corp, and with following relationship types. person can hold a corp in {share} % person can be relative with another person corp can hold another corp in {share} % corp can be a branch of another corp person can be as a role of a corp Below is the lines to reflect this graph modele in Nebula Graph, it’s quite straightforward, right? CREATE TAG person(name string); CREATE TAG corp(name string); CREATE EDGE role_as(role string); CREATE EDGE is_branch_of(); CREATE EDGE hold_share(share float); CREATE EDGE reletive_with(degree int); ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:1:1","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#data-modeling"},{"categories":["Nebula Graph"],"content":" 1.2 Data GenerationWe just randomly generate some data to help with this demo, you can call data_generator.py directly to generate or reuse what’s already done under data_sample folder. The generated data are records to be fit in above data model from below .csv files. $ pip install Faker==2.0.5 pydbgen==1.0.5 $ python3 data_generator.py $ ls -l data total 1688 -rw-r--r-- 1 weyl staff 23941 Jul 14 13:28 corp.csv -rw-r--r-- 1 weyl staff 1277 Jul 14 13:26 corp_rel.csv -rw-r--r-- 1 weyl staff 3048 Jul 14 13:26 corp_share.csv -rw-r--r-- 1 weyl staff 211661 Jul 14 13:26 person.csv -rw-r--r-- 1 weyl staff 179770 Jul 14 13:26 person_corp_role.csv -rw-r--r-- 1 weyl staff 322965 Jul 14 13:26 person_corp_share.csv -rw-r--r-- 1 weyl staff 17689 Jul 14 13:26 person_rel.csv ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:1:2","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#data-generation"},{"categories":["Nebula Graph"],"content":" 1.3 Data ImportWith those data in .csv files, we can easily import them into a Nebula Graph Cluster with the help of Nebula-Importer. nebula-importer.yaml in this repo describes rules and configurations on how this import will be done by the importer. For Nebula Graph Database, plesae refer to Doc , Doc-CN to deploy on any Linux Servers, for study and test, you can run it via Docker following the Quick Start Chapter of the documentation. For Nebula-Importer, if you already have Docker env, you can run it as the following without installing anything. Or, if you prefer to install it, it’s quite easy as it’s written in Golang and you can run its single file binary quite easily, go check both Documentation and Nebula-Importer Repo: https://github.com/vesoft-inc/nebula-importer. Let’s start! Below is the commands I used to import our data into a Nebula Graph Database. # put generated data \u0026 nebula-importor.yaml to nebula-importer server $ scp -r data nebula_graph_host:~ $ scp nebula-importer.yaml data nebula_graph_host:~/data $ ssh nebula_graph_host $ ls -l ${HOME}/data total 756 -rw-r--r--. 1 wei.gu wei.gu 23941 Jul 14 05:44 corp.csv -rw-r--r--. 1 wei.gu wei.gu 1277 Jul 14 05:44 corp_rel.csv -rw-r--r--. 1 wei.gu wei.gu 3048 Jul 14 05:44 corp_share.csv -rw-r--r--. 1 wei.gu wei.gu 3893 Jul 14 05:44 nebula-importer.yaml -rw-r--r--. 1 wei.gu wei.gu 211661 Jul 14 05:44 person.csv -rw-r--r--. 1 wei.gu wei.gu 179770 Jul 14 05:44 person_corp_role.csv -rw-r--r--. 1 wei.gu wei.gu 322965 Jul 14 05:44 person_corp_share.csv -rw-r--r--. 1 wei.gu wei.gu 17689 Jul 14 05:44 person_rel.csv # import data into our nebula graph database $ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v ${HOME}/data/nebula-importer.yaml:/root/nebula-importer.yaml \\ -v ${HOME}/data:/root \\ vesoft/nebula-importer:v2 \\ --config /root/nebula-importer.yaml 2021/07/14 05:49:32 --- START OF NEBULA IMPORTER --- 2021/07/14 05:49:32 [WARN] config.go:491: Not set files[0].schema.vertex.vid.Type, reset to default value `string' ... 2021/07/14 05:49:43 [INFO] reader.go:180: Total lines of file(/root/person_corp_role.csv) is: 5000, error lines: 1287 2021/07/14 05:49:43 [INFO] statsmgr.go:61: Done(/root/person_corp_role.csv): Time(11.39s), Finished(12523), Failed(0), Latency AVG(1514us), Batches Req AVG(1824us), Rows AVG(1099.43/s) 2021/07/14 05:49:47 [INFO] statsmgr.go:61: Tick: Time(15.00s), Finished(25807), Failed(0), Latency AVG(1500us), Batches Req AVG(1805us), Rows AVG(1720.46/s) 2021/07/14 05:49:48 [INFO] reader.go:180: Total lines of file(/root/person.csv) is: 10000, error lines: 0 2021/07/14 05:49:48 [INFO] statsmgr.go:61: Done(/root/person.csv): Time(16.10s), Finished(29731), Failed(0), Latency AVG(1505us), Batches Req AVG(1810us), Rows AVG(1847.17/s) 2021/07/14 05:49:50 [INFO] reader.go:180: Total lines of file(/root/person_corp_share.csv) is: 20000, error lines: 0 2021/07/14 05:49:50 [INFO] statsmgr.go:61: Done(/root/person_corp_share.csv): Time(17.74s), Finished(36013), Failed(0), Latency AVG(1531us), Batches Req AVG(1844us), Rows AVG(2030.29/s) 2021/07/14 05:49:50 Finish import data, consume time: 18.25s 2021/07/14 05:49:51 --- END OF NEBULA IMPORTER --- ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:1:3","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#data-import"},{"categories":["Nebula Graph"],"content":" 2 Corporation sharehold relationship breakthrough 2.0.1 Query in nGQLWe can query from corp: c_132 over *(all relationships) in BIDIRECT: GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT Below are lines I call this query in nebula-console: / # nebula-console -addr 192.168.8.128 -port 9669 -user user -password password 2021/07/14 07:07:41 [INFO] connection pool is initialized successfully Welcome to Nebula Graph! (user@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"basketballplayer\" | +--------------------+ | \"shareholding\" | +--------------------+ Got 2 rows (time spent 3851/4595 us) Wed, 14 Jul 2021 07:07:57 UTC (user@nebula) [(none)]\u003e use shareholding Execution succeeded (time spent 1822/2342 us) Wed, 14 Jul 2021 07:08:02 UTC (user@nebula) [shareholding]\u003e GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT +--------------+-------------------+-----------------+--------------------+ | role_as._dst | is_branch_of._dst | hold_share._dst | reletive_with._dst | +--------------+-------------------+-----------------+--------------------+ | \"p_2024\" | | | | +--------------+-------------------+-----------------+--------------------+ | \"p_4000\" | | | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1039\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1399\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1767\" | | ... +--------------+-------------------+-----------------+--------------------+ | | | \"c_132\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_25\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_649\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_753\" | | +--------------+-------------------+-----------------+--------------------+ Got 1519 rows (time spent 12190/14702 us) Wed, 14 Jul 2021 07:08:06 UTC 2.0.2 In a Visual WayOf course, we can also be done in a visual way: Step 1, login from Nebula Graph Studio, explore with one VID: c_132: Step2, click this explored vertex dot, then you can explore from select vertices by selecting: Edge Type Direction Steps Query Limit(Optional) note, you can click the 👁️ icon to add options to show fields of the graph, Step3, after click Expand, you will see all quried relations with c_132 the Chambers LLC. ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:2:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#corporation-sharehold-relationship-breakthrough"},{"categories":["Nebula Graph"],"content":" 2 Corporation sharehold relationship breakthrough 2.0.1 Query in nGQLWe can query from corp: c_132 over *(all relationships) in BIDIRECT: GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT Below are lines I call this query in nebula-console: / # nebula-console -addr 192.168.8.128 -port 9669 -user user -password password 2021/07/14 07:07:41 [INFO] connection pool is initialized successfully Welcome to Nebula Graph! (user@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"basketballplayer\" | +--------------------+ | \"shareholding\" | +--------------------+ Got 2 rows (time spent 3851/4595 us) Wed, 14 Jul 2021 07:07:57 UTC (user@nebula) [(none)]\u003e use shareholding Execution succeeded (time spent 1822/2342 us) Wed, 14 Jul 2021 07:08:02 UTC (user@nebula) [shareholding]\u003e GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT +--------------+-------------------+-----------------+--------------------+ | role_as._dst | is_branch_of._dst | hold_share._dst | reletive_with._dst | +--------------+-------------------+-----------------+--------------------+ | \"p_2024\" | | | | +--------------+-------------------+-----------------+--------------------+ | \"p_4000\" | | | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1039\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1399\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1767\" | | ... +--------------+-------------------+-----------------+--------------------+ | | | \"c_132\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_25\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_649\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_753\" | | +--------------+-------------------+-----------------+--------------------+ Got 1519 rows (time spent 12190/14702 us) Wed, 14 Jul 2021 07:08:06 UTC 2.0.2 In a Visual WayOf course, we can also be done in a visual way: Step 1, login from Nebula Graph Studio, explore with one VID: c_132: Step2, click this explored vertex dot, then you can explore from select vertices by selecting: Edge Type Direction Steps Query Limit(Optional) note, you can click the 👁️ icon to add options to show fields of the graph, Step3, after click Expand, you will see all quried relations with c_132 the Chambers LLC. ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:2:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#query-in-ngql"},{"categories":["Nebula Graph"],"content":" 2 Corporation sharehold relationship breakthrough 2.0.1 Query in nGQLWe can query from corp: c_132 over *(all relationships) in BIDIRECT: GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT Below are lines I call this query in nebula-console: / # nebula-console -addr 192.168.8.128 -port 9669 -user user -password password 2021/07/14 07:07:41 [INFO] connection pool is initialized successfully Welcome to Nebula Graph! (user@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"basketballplayer\" | +--------------------+ | \"shareholding\" | +--------------------+ Got 2 rows (time spent 3851/4595 us) Wed, 14 Jul 2021 07:07:57 UTC (user@nebula) [(none)]\u003e use shareholding Execution succeeded (time spent 1822/2342 us) Wed, 14 Jul 2021 07:08:02 UTC (user@nebula) [shareholding]\u003e GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT +--------------+-------------------+-----------------+--------------------+ | role_as._dst | is_branch_of._dst | hold_share._dst | reletive_with._dst | +--------------+-------------------+-----------------+--------------------+ | \"p_2024\" | | | | +--------------+-------------------+-----------------+--------------------+ | \"p_4000\" | | | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1039\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1399\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1767\" | | ... +--------------+-------------------+-----------------+--------------------+ | | | \"c_132\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_25\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_649\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_753\" | | +--------------+-------------------+-----------------+--------------------+ Got 1519 rows (time spent 12190/14702 us) Wed, 14 Jul 2021 07:08:06 UTC 2.0.2 In a Visual WayOf course, we can also be done in a visual way: Step 1, login from Nebula Graph Studio, explore with one VID: c_132: Step2, click this explored vertex dot, then you can explore from select vertices by selecting: Edge Type Direction Steps Query Limit(Optional) note, you can click the 👁️ icon to add options to show fields of the graph, Step3, after click Expand, you will see all quried relations with c_132 the Chambers LLC. ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:2:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#in-a-visual-way"},{"categories":["Nebula Graph"],"content":" 3 Thanks to Upstream Projects ❤️ Python Faker https://github.com/joke2k/faker/ pydbgen https://github.com/tirthajyoti/pydbgen Nebula Graph https://github.com/vesoft-inc/nebula-graph ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:3:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#thanks-to-upstream-projects-"},{"categories":["Nebula Graph"],"content":" 3.1 Tips: You can deploy nebula graph in one line with: Nebula-UP, it helps install a nebula graph with Docker Nebula-operator-KIND , it helps setup all dependencies of Nebula-K8s-Operator including a K8s in Docker, PV Provider and then install a Nebula Graph with Nebula-Operator in K8s. Image Credit goes to https://unsplash.com/photos/3fPXt37X6UQ ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:3:1","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#tips"},{"categories":null,"content":" 股权穿透教程 1. 上手实战图数据库股权关系穿透 2. 体验 Nebula-Up 一键部署 Nebula Core + Studio 阅读全文 Siwi 1. 上手实战从 0 制作一个基于图谱的语音智能助手 2. 体验 Nebula-Kind-Operator 一键部署 K8s + Nebula Operator 阅读全文 ","date":"2021-08-26","objectID":"/cources/:0:0","series":null,"tags":null,"title":"上手课程","uri":"/cources/#"},{"categories":null,"content":" 掘金春招活动 那些我希望过去的自己可以知道的事实 阅读全文 DoK Talks #116 Nebula Graph: Open Source Distributed GraphDB 阅读全文 Data on K8s Community 2021 GraphDB on Kubesphere 阅读全文 K8s Community Day 2021 Openfunction + GraphDB 阅读全文 COScon 2021 我的开源之路 阅读全文 PyCon China 2021 图数据库解谜与 Python 的图库应用实践 阅读全文 K8s 上的图数据库 Nebula K8s Operator 的实现解析，图数据库应用在 K8s + OpenFunction 上的落地演示 阅读全文 nMeetup: Nebula 应用上手实操 从头实操 Nebula 的部署，股权穿透，图算法运算，语音智能助手。 阅读全文 How to Train your Dragon 如何成为开源开发者（布道师）。 阅读全文 ","date":"2021-08-26","objectID":"/talk/:0:0","series":null,"tags":null,"title":"我的演讲","uri":"/talk/#"},{"categories":["Nebula Graph"],"content":"Import LiveJournal Dataset into Nebula Graph and Run Nebula Algorithm 导入 Livejournal 数据集到 Nebula 并运行 Nebula Algorithm 图算法","date":"2021-08-24","objectID":"/nebula-livejournal/","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/"},{"categories":["Nebula Graph"],"content":" 一个导入 Livejournal 数据集到 Nebula Graph 图数据库，并执行 Nebula Algorithm 图算法的过程分享。 Related GitHub Repo: https://github.com/wey-gu/nebula-LiveJournal ","date":"2021-08-24","objectID":"/nebula-livejournal/:0:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#"},{"categories":["Nebula Graph"],"content":" nebula-LiveJournalLiveJournal Dataset is a Social Network Dataset in one file with two columns(FromNodeId, ToNodeId). $ head soc-LiveJournal1.txt # Directed graph (each unordered pair of nodes is saved once): soc-LiveJournal1.txt # Directed LiveJournal friednship social network # Nodes: 4847571 Edges: 68993773 # FromNodeId ToNodeId 0 1 0 2 0 3 0 4 0 5 0 6 It could be accessed in https://snap.stanford.edu/data/soc-LiveJournal1.html. Dataset statistics Nodes 4847571 Edges 68993773 Nodes in largest WCC 4843953 (0.999) Edges in largest WCC 68983820 (1.000) Nodes in largest SCC 3828682 (0.790) Edges in largest SCC 65825429 (0.954) Average clustering coefficient 0.2742 Number of triangles 285730264 Fraction of closed triangles 0.04266 Diameter (longest shortest path) 16 90-percentile effective diameter 6.5 ","date":"2021-08-24","objectID":"/nebula-livejournal/:0:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#nebula-livejournal"},{"categories":["Nebula Graph"],"content":" 1 Dataset Download and Preprocessing","date":"2021-08-24","objectID":"/nebula-livejournal/:1:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#dataset-download-and-preprocessing"},{"categories":["Nebula Graph"],"content":" 1.1 DownloadIt is accesissiable from the official web page: $ cd nebula-livejournal/data $ wget https://snap.stanford.edu/data/soc-LiveJournal1.txt.gz Comments in data file should be removed to make the data import tool happy. ","date":"2021-08-24","objectID":"/nebula-livejournal/:1:1","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#download"},{"categories":["Nebula Graph"],"content":" 1.2 Preprocessing $ gzip -d soc-LiveJournal1.txt.gz $ sed -i '1,4d' soc-LiveJournal1.txt ","date":"2021-08-24","objectID":"/nebula-livejournal/:1:2","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#preprocessing"},{"categories":["Nebula Graph"],"content":" 2 Import dataset to Nebula Graph","date":"2021-08-24","objectID":"/nebula-livejournal/:2:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#import-dataset-to-nebula-graph"},{"categories":["Nebula Graph"],"content":" 2.1 With Nebula ImporterNebula-Importer is a Golang Headless import tool for Nebula Graph. You may need to edit the config file under nebula-importer/importer.yaml on Nebula Graph’s address and credential。 Then, Nebula-Importer could be called in Docker as follow: $ cd nebula-livejournal $ docker run --rm -ti \\ --network=nebula-net \\ -v nebula-importer/importer.yaml:/root/importer.yaml \\ -v data/:/root \\ vesoft/nebula-importer:v2 \\ --config /root/importer.yaml Or if you have the binary nebula-importer locally: $ cd data $ \u003cpath_to_nebula-importer_binary\u003e --config ../nebula-importer/importer.yaml ","date":"2021-08-24","objectID":"/nebula-livejournal/:2:1","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#with-nebula-importer"},{"categories":["Nebula Graph"],"content":" 2.2 With Nebula ExchangeNebula-Exchange is a Spark Application to enable batch and streaming data import from multiple data sources to Nebula Graph. To be done. (You can refer to https://siwei.io/nebula-exchange-sst-2.x/) ","date":"2021-08-24","objectID":"/nebula-livejournal/:2:2","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#with-nebula-exchange"},{"categories":["Nebula Graph"],"content":" 3 Run Algorithms with Nebula GraphNebula-Algorithm is a Spark/GraphX Application to run Graph Algorithms with data consumed from files or a Nebula Graph Cluster. Supported Algorithms for now: Name Use Case PageRank page ranking, important node digging Louvain community digging, hierarchical clustering KCore community detection, financial risk control LabelPropagation community detection, consultation propagation, advertising recommendation ConnectedComponent community detection, isolated island detection StronglyConnectedComponent community detection ShortestPath path plan, network plan TriangleCount network structure analysis BetweennessCentrality important node digging, node influence calculation DegreeStatic graph structure analysis ","date":"2021-08-24","objectID":"/nebula-livejournal/:3:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#run-algorithms-with-nebula-graph"},{"categories":["Nebula Graph"],"content":" 3.1 Ad-hoc Spark Env setupHere I assume the Nebula Graph was bootstraped with Nebula-Up, thus nebula is running in a Docker Network named nebula-docker-compose_nebula-net. Then let’s start a single server spark: docker run --name spark-master --network nebula-docker-compose_nebula-net \\ -h spark-master -e ENABLE_INIT_DAEMON=false -d \\ -v nebula-algorithm/:/root \\ bde2020/spark-master:2.4.5-hadoop2.7 Thus we could make spark application submt inside this container: docker exec -it spark-master bash cd /root/ # download Nebula-Algorithm Jar Packagem, 2.0.0 for example, for other versions, refer to nebula-algorithm github repo and documentations. wget https://repo1.maven.org/maven2/com/vesoft/nebula-algorithm/2.0.0/nebula-algorithm-2.0.0.jar ","date":"2021-08-24","objectID":"/nebula-livejournal/:3:1","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#ad-hoc-spark-env-setup"},{"categories":["Nebula Graph"],"content":" 3.2 Run AlgorithmsThere are many altorithms supported by Nebula-Algorithm, here some of their configuration files were put under nebula-algorithm as an example. Before using them, please first edit and change Nebula Graph Cluster Addresses and credentials. vim nebula-altorithm/algo-pagerank.conf Then we could enter the spark container and call corresponding algorithms as follow. Please adjust your --driver-memeory accordingly, i.e. pagerank altorithm: /spark/bin/spark-submit --master \"local\" --conf spark.rpc.askTimeout=6000s \\ --class com.vesoft.nebula.algorithm.Main \\ --driver-memory 16g nebula-algorithm-2.0.0.jar \\ -p pagerank.conf After the algorithm finished, the output will be under the path insdie the container defined in conf file: write:{ resultPath:/output/ } 题图版权：@sigmund ","date":"2021-08-24","objectID":"/nebula-livejournal/:3:2","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#run-algorithms"},{"categories":["Nebula Graph"],"content":"这篇文章带大家以最小方式，快速趟一下 Nebula Exchange 中 SST 写入方式的步骤。","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/"},{"categories":["Nebula Graph"],"content":"这篇文章带大家以最小方式，快速趟一下 Nebula Exchange 中 SST 写入方式的步骤。 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:0:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#"},{"categories":["Nebula Graph"],"content":" 1 什么是 Nebula Exchange ?之前我在 Nebula Data Import Options 之中介绍过，Nebula Exchange 是一个 Nebula Graph 社区开源的 Spark Applicaiton，它专门用来支持批量或者流式地把数据导入 Nebula Graph Database 之中。 Nebula Exchange 支持多种多样的数据源（从 Apache Parquet, ORC, JSON, CSV, HBase, Hive MaxCompute 到 Neo4j, MySQL, ClickHouse, 再有 Kafka, Pulsar，更多的数据源也在不断增加之中）。 如上图所示，在 Exchange 内部，从除了不同 Reader 可以读取不同数据源之外，在数据经过 Processor 处理之后通过 Writer写入（sink） Nebula Graph 图数据库的时候，除了走正常的 ServerBaseWriter 的写入流程之外，它还可以绕过整个写入流程，利用 Spark 的计算能力并行生成底层 RocksDB 的 SST 文件，从而实现超高性能的数据导入，这个 SST 文件导入的场景就是本文带大家上手熟悉的部分。 详细信息请参阅：Nebula Graph 手册:什么是 Nebula Exchange Nebula Graph 官方博客也有更多 Nebula Exchange 的实践文章 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:1:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#什么是-nebula-exchange-"},{"categories":["Nebula Graph"],"content":" 2 步骤概观 实验环境 配置 Exchange 生成 SST 文件 写入 SST 文件到 Nebula Graph ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:2:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#步骤概观"},{"categories":["Nebula Graph"],"content":" 3 实验环境准备为了最小化使用 Nebula Exchange 的 SST 功能，我们需要： 搭建一个 Nebula Graph 集群，创建导入数据的 Schema，我们选择使用 Docker-Compose 方式、利用 Nebula-Up 快速部署，并简单修改其网络，以方便同样容器化的 Exchange 程序对其访问。 搭建容器化的 Spark 运行环境 搭建容器化的 HDFS ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:3:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#实验环境准备"},{"categories":["Nebula Graph"],"content":" 3.1 1. 搭建 Nebula Graph 集群借助于 Nebula-Up 我们可以在 Linux 环境下一键部署一套 Nebula Graph 集群： curl -fsSL nebula-up.siwei.io/install.sh | bash 待部署成功之后，我们需要对环境做一些修改，这里我做的修改其实就是两点： 只保留一个 metaD 服务 起用 Docker 的外部网络 详细修改的部分参考附录一 应用 docker-compose 的修改： cd ~/.nebula-up/nebula-docker-compose vim docker-compose.yaml # 参考附录一 docker network create nebula-net # 需要创建外部网络 docker-compose up -d --remove-orphans 之后，我们来创建要测试的图空间，并创建图的 Schema，为此，我们可以利用 nebula-console ，同样，Nebula-Up 里自带了容器化的 nebula-console。 进入 Nebula-Console 所在的容器 ~/.nebula-up/console.sh / # 在 console 容器里发起链接到图数据库，其中 192.168.x.y 是我所在的 Linux VM 的第一个网卡地址，请换成您的 / # nebula-console -addr 192.168.x.y -port 9669 -user root -p password [INFO] connection pool is initialized successfully Welcome to Nebula Graph! 创建图空间（我们起名字叫 sst ），以及 schema create space sst(partition_num=5,replica_factor=1,vid_type=fixed_string(32)); :sleep 20 use sst create tag player(name string, age int); 示例输出 (root@nebula) [(none)]\u003e create space sst(partition_num=5,replica_factor=1,vid_type=fixed_string(32)); Execution succeeded (time spent 1468/1918 us) (root@nebula) [(none)]\u003e :sleep 20 (root@nebula) [(none)]\u003e use sst Execution succeeded (time spent 1253/1566 us) Wed, 18 Aug 2021 08:18:13 UTC (root@nebula) [sst]\u003e create tag player(name string, age int); Execution succeeded (time spent 1312/1735 us) Wed, 18 Aug 2021 08:18:23 UTC ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:3:1","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#1-搭建-nebula-graph-集群"},{"categories":["Nebula Graph"],"content":" 3.2 搭建容器化的 Spark 环境利用 big data europe 做的工作，这个过程非常容易。 值得注意的是： 现在的 Nebula Exchange 对 Spark 的版本有要求，在现在的 2021 年 8 月，我是用了 spark-2.4.5-hadoop-2.7 的版本。 为了方便，我让 Spark 运行在 Nebula Graph 相同的机器上，并且指定了运行在同一个 Docker 网络下 docker run --name spark-master --network nebula-net \\ -h spark-master -e ENABLE_INIT_DAEMON=false -d \\ bde2020/spark-master:2.4.5-hadoop2.7 然后，我们就可以进入到环境中了： docker exec -it spark-master bash 进到 Spark 容器中之后，可以像这样安装 maven: export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 还可以这样在容器里下载 nebula-exchange 的 jar 包： cd ~ wget https://repo1.maven.org/maven2/com/vesoft/nebula-exchange/2.1.0/nebula-exchange-2.1.0.jar ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:3:2","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#搭建容器化的-spark-环境"},{"categories":["Nebula Graph"],"content":" 3.3 搭建容器化的 HDFS同样借助 big-data-euroupe 的工作，这非常简单，不过我们要做一点修改，让它的 docker-compose.yml 文件里使用 nebula-net 这个之前创建的 Docker 网络。 详细修改的部分参考附录二 git clone https://github.com/big-data-europe/docker-hadoop.git cd docker-hadoop vim docker-compose.yml docker-compose up -d ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:3:3","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#搭建容器化的-hdfs"},{"categories":["Nebula Graph"],"content":" 4 配置Exchange这个配置主要填入的信息就是 Nebula Graph 集群本身和将要写入数据的 Space Name，以及数据源相关的配置（这里我们用 csv 作为例子），最后再配置输出（sink）为 sst Nebula Graph GraphD 地址 MetaD 地址 credential Space Name 数据源 source: csv path fields etc. ink: sst 详细的配置参考附录二 注意，这里 metaD 的地址可以这样获取，可以看到 0.0.0.0:49377-\u003e9559 表示 49377 是外部的地址。 $ docker ps | grep meta 887740c15750 vesoft/nebula-metad:v2.0.0 \"./bin/nebula-metad …\" 6 hours ago Up 6 hours (healthy) 9560/tcp, 0.0.0.0:49377-\u003e9559/tcp, :::49377-\u003e9559/tcp, 0.0.0.0:49376-\u003e19559/tcp, :::49376-\u003e19559/tcp, 0.0.0.0:49375-\u003e19560/tcp, :::49375-\u003e19560/tcp nebula-docker-compose_metad0_1 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:4:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#配置exchange"},{"categories":["Nebula Graph"],"content":" 5 生成SST文件","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:5:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#生成sst文件"},{"categories":["Nebula Graph"],"content":" 5.1 准备源文件、配置文件 docker cp exchange-sst.conf spark-master:/root/ docker cp player.csv spark-master:/root/ 其中 player.csv 的例子： 1100,Tim Duncan,42 1101,Tony Parker,36 1102,LaMarcus Aldridge,33 1103,Rudy Gay,32 1104,Marco Belinelli,32 1105,Danny Green,31 1106,Kyle Anderson,25 1107,Aron Baynes,32 1108,Boris Diaw,36 1109,Tiago Splitter,34 1110,Cory Joseph,27 1111,David West,38 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:5:1","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#准备源文件配置文件"},{"categories":["Nebula Graph"],"content":" 5.2 执行 exchange 程序进入 spark-master 容器，提交执行 exchange 应用。 docker exec -it spark-master bash cd /root/ /spark/bin/spark-submit --master local \\ --class com.vesoft.nebula.exchange.Exchange nebula-exchange-2.1.0.jar\\ -c exchange-sst.conf 检查执行结果： spark-submit 输出： 21/08/17 03:37:43 INFO TaskSetManager: Finished task 31.0 in stage 2.0 (TID 33) in 1093 ms on localhost (executor driver) (32/32) 21/08/17 03:37:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 21/08/17 03:37:43 INFO DAGScheduler: ResultStage 2 (foreachPartition at VerticesProcessor.scala:179) finished in 22.336 s 21/08/17 03:37:43 INFO DAGScheduler: Job 1 finished: foreachPartition at VerticesProcessor.scala:179, took 22.500639 s 21/08/17 03:37:43 INFO Exchange$: SST-Import: failure.player: 0 21/08/17 03:37:43 WARN Exchange$: Edge is not defined 21/08/17 03:37:43 INFO SparkUI: Stopped Spark web UI at http://spark-master:4040 21/08/17 03:37:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped! 验证 HDFS 上生成的 SST 文件： docker exec -it namenode /bin/bash root@2db58903fb53:/# hdfs dfs -ls /sst Found 10 items drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/1 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/10 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/2 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/3 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/4 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/5 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/6 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/7 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/8 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/9 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:5:2","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#执行-exchange-程序"},{"categories":["Nebula Graph"],"content":" 6 写入SST到NebulaGraph这里的操作实际上都是参考文档：SST 导入，得来。其中就是从 console 之中执行了两步操作： Download Ingest 其中 Download 实际上是触发 Nebula Graph 从服务端发起 HDFS Client 的 download，获取 HDFS 上的 SST 文件，然后放到 storageD 能访问的本地路径下，这里，需要我们在服务端部署 HDFS 的依赖。因为我们是最小实践，我就偷懒手动做了这个 Download 的操作。 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:6:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#写入sst到nebulagraph"},{"categories":["Nebula Graph"],"content":" 6.1 手动下载这里边手动下载我们就要知道 Nebula Graph 服务端下载的路径，实际上是 /data/storage/nebula/\u003cspace_id\u003e/download/，这里的 Space ID 需要手动获取一下： 这个例子里，我们的 Space Name 是 sst，而 Space ID 是 49。 (root@nebula) [sst]\u003e DESC space sst +----+-------+------------------+----------------+---------+------------+--------------------+-------------+-----------+ | ID | Name | Partition Number | Replica Factor | Charset | Collate | Vid Type | Atomic Edge | Group | +----+-------+------------------+----------------+---------+------------+--------------------+-------------+-----------+ | 49 | \"sst\" | 10 | 1 | \"utf8\" | \"utf8_bin\" | \"FIXED_STRING(32)\" | \"false\" | \"default\" | +----+-------+------------------+----------------+---------+------------+--------------------+-------------+-----------+ 于是，下边的操作就是手动把 SST 文件从 HDFS 之中 get 下来，再拷贝到 storageD 之中。 docker exec -it namenode /bin/bash $ hdfs dfs -get /sst /sst exit docker cp namenode:/sst . docker exec -it nebula-docker-compose_storaged0_1 mkdir -p /data/storage/nebula/49/download/ docker exec -it nebula-docker-compose_storaged1_1 mkdir -p /data/storage/nebula/49/download/ docker exec -it nebula-docker-compose_storaged2_1 mkdir -p /data/storage/nebula/49/download/ docker cp sst nebula-docker-compose_storaged0_1:/data/storage/nebula/49/download/ docker cp sst nebula-docker-compose_storaged1_1:/data/storage/nebula/49/download/ docker cp sst nebula-docker-compose_storaged2_1:/data/storage/nebula/49/download/ ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:6:1","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#手动下载"},{"categories":["Nebula Graph"],"content":" 6.2 SST 文件导入 进入 Nebula-Console 所在的容器 ~/.nebula-up/console.sh / # 在 console 容器里发起链接到图数据库，其中 192.168.x.y 是我所在的 Linux VM 的第一个网卡地址，请换成您的 / # nebula-console -addr 192.168.x.y -port 9669 -user root -p password [INFO] connection pool is initialized successfully Welcome to Nebula Graph! 执行 INGEST 开始让 StorageD 读取 SST 文件 (root@nebula) [(none)]\u003e use sst (root@nebula) [sst]\u003e INGEST; 我们可以用如下方法实时查看 Nebula Graph 服务端的日志 tail -f ~/.nebula-up/nebula-docker-compose/logs/*/* 成功的 INGEST 日志： I0817 08:03:28.611877 169 EventListner.h:96] Ingest external SST file: column family default, the external file path /data/storage/nebula/49/download/8/8-6.sst, the internal file path /data/storage/nebula/49/data/000023.sst, the properties of the table: # data blocks=1; # entries=1; # deletions=0; # merge operands=0; # range deletions=0; raw key size=48; raw average key size=48.000000; raw value size=40; raw average value size=40.000000; data block size=75; index block size (user-key? 0, delta-value? 0)=66; filter block size=0; (estimated) table size=141; filter policy name=N/A; prefix extractor name=nullptr; column family ID=N/A; column family name=N/A; comparator name=leveldb.BytewiseComparator; merge operator name=nullptr; property collectors names=[]; SST file compression algo=Snappy; SST file compression options=window_bits=-14; level=32767; strategy=0; max_dict_bytes=0; zstd_max_train_bytes=0; enabled=0; ; creation time=0; time stamp of earliest key=0; file creation time=0; E0817 08:03:28.611912 169 StorageHttpIngestHandler.cpp:63] SSTFile ingest successfully 题图版权：Pietro Jeng ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:6:2","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#sst-文件导入"},{"categories":["Nebula Graph"],"content":" 7 附录","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:7:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#附录"},{"categories":["Nebula Graph"],"content":" 7.1 附录一docker-compose.yaml diff --git a/docker-compose.yaml b/docker-compose.yaml index 48854de..cfeaedb 100644 --- a/docker-compose.yaml +++ b/docker-compose.yaml @@ -6,11 +6,13 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --local_ip=metad0 - --ws_ip=metad0 - --port=9559 - --ws_http_port=19559 + - --ws_storage_http_port=19779 - --data_path=/data/meta - --log_dir=/logs - --v=0 @@ -34,81 +36,14 @@ services: cap_add: - SYS_PTRACE - metad1: - image: vesoft/nebula-metad:v2.0.0 - environment: - USER: root - TZ: \"${TZ}\" - command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 - - --local_ip=metad1 - - --ws_ip=metad1 - - --port=9559 - - --ws_http_port=19559 - - --data_path=/data/meta - - --log_dir=/logs - - --v=0 - - --minloglevel=0 - healthcheck: - test: [\"CMD\", \"curl\", \"-sf\", \"http://metad1:19559/status\"] - interval: 30s - timeout: 10s - retries: 3 - start_period: 20s - ports: - - 9559 - - 19559 - - 19560 - volumes: - - ./data/meta1:/data/meta - - ./logs/meta1:/logs - networks: - - nebula-net - restart: on-failure - cap_add: - - SYS_PTRACE - - metad2: - image: vesoft/nebula-metad:v2.0.0 - environment: - USER: root - TZ: \"${TZ}\" - command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 - - --local_ip=metad2 - - --ws_ip=metad2 - - --port=9559 - - --ws_http_port=19559 - - --data_path=/data/meta - - --log_dir=/logs - - --v=0 - - --minloglevel=0 - healthcheck: - test: [\"CMD\", \"curl\", \"-sf\", \"http://metad2:19559/status\"] - interval: 30s - timeout: 10s - retries: 3 - start_period: 20s - ports: - - 9559 - - 19559 - - 19560 - volumes: - - ./data/meta2:/data/meta - - ./logs/meta2:/logs - networks: - - nebula-net - restart: on-failure - cap_add: - - SYS_PTRACE - storaged0: image: vesoft/nebula-storaged:v2.0.0 environment: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --local_ip=storaged0 - --ws_ip=storaged0 - --port=9779 @@ -119,8 +54,8 @@ services: - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://storaged0:19779/status\"] interval: 30s @@ -146,7 +81,7 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --local_ip=storaged1 - --ws_ip=storaged1 - --port=9779 @@ -157,8 +92,8 @@ services: - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://storaged1:19779/status\"] interval: 30s @@ -184,7 +119,7 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --local_ip=storaged2 - --ws_ip=storaged2 - --port=9779 @@ -195,8 +130,8 @@ services: - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://storaged2:19779/status\"] interval: 30s @@ -222,17 +157,19 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --port=9669 - --ws_ip=graphd - --ws_http_port=19669 + - --ws_meta_http_port=19559 - --log_dir=/logs - --v=0 - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://graphd:19669/status\"] interval: 30s @@ -257,17 +194,19 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --port=9669 - --ws_ip=graphd1 - --ws_http_port=19669 + - --ws_meta_http_port=19559 - --log_dir=/logs - --v=0 - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://graphd1:19669/status\"] interval: 30s @@ -292,17 +231,21 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=me","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:7:1","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#附录一"},{"categories":["Nebula Graph"],"content":" 7.2 附录二https://github.com/big-data-europe/docker-hadoop 的 docker-compose.yml diff --git a/docker-compose.yml b/docker-compose.yml index ed40dc6..66ff1f4 100644 --- a/docker-compose.yml +++ b/docker-compose.yml @@ -14,6 +14,8 @@ services: - CLUSTER_NAME=test env_file: - ./hadoop.env + networks: + - nebula-net datanode: image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8 @@ -25,6 +27,8 @@ services: SERVICE_PRECONDITION: \"namenode:9870\" env_file: - ./hadoop.env + networks: + - nebula-net resourcemanager: image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8 @@ -34,6 +38,8 @@ services: SERVICE_PRECONDITION: \"namenode:9000 namenode:9870 datanode:9864\" env_file: - ./hadoop.env + networks: + - nebula-net nodemanager1: image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8 @@ -43,6 +49,8 @@ services: SERVICE_PRECONDITION: \"namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088\" env_file: - ./hadoop.env + networks: + - nebula-net historyserver: image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8 @@ -54,8 +62,14 @@ services: - hadoop_historyserver:/hadoop/yarn/timeline env_file: - ./hadoop.env + networks: + - nebula-net volumes: hadoop_namenode: hadoop_datanode: hadoop_historyserver: + +networks: + nebula-net: + external: true ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:7:2","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#附录二"},{"categories":["Nebula Graph"],"content":" 7.3 附录三nebula-exchange-sst.conf { # Spark relation config spark: { app: { name: Nebula Exchange 2.1 } master:local driver: { cores: 1 maxResultSize: 1G } executor: { memory:1G } cores:{ max: 16 } } # Nebula Graph relation config nebula: { address:{ graph:[\"192.168.8.128:9669\"] meta:[\"192.168.8.128:49377\"] } user: root pswd: nebula space: sst # parameters for SST import, not required path:{ local:\"/tmp\" remote:\"/sst\" hdfs.namenode: \"hdfs://192.168.8.128:9000\" } # nebula client connection parameters connection { # socket connect \u0026 execute timeout, unit: millisecond timeout: 30000 } error: { # max number of failures, if the number of failures is bigger than max, then exit the application. max: 32 # failed import job will be recorded in output path output: /tmp/errors } # use google's RateLimiter to limit the requests send to NebulaGraph rate: { # the stable throughput of RateLimiter limit: 1024 # Acquires a permit from RateLimiter, unit: MILLISECONDS # if it can't be obtained within the specified timeout, then give up the request. timeout: 1000 } } # Processing tags # There are tag config examples for different dataSources. tags: [ # HDFS csv # Import mode is sst, just change type.sink to client if you want to use client import mode. { name: player type: { source: csv sink: sst } path: \"file:///root/player.csv\" # if your csv file has no header, then use _c0,_c1,_c2,.. to indicate fields fields: [_c1, _c2] nebula.fields: [name, age] vertex: { field:_c0 } separator: \",\" header: false batch: 256 partition: 32 } ] } ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:7:3","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#附录三"},{"categories":["sketches"],"content":"介绍 Nebula Graph 的云原生 K8s Operator 部署","date":"2021-08-06","objectID":"/sketches/nebula-operator-explained/","series":null,"tags":["Nebula Graph","K8s"],"title":"Nebula operator Explained","uri":"/sketches/nebula-operator-explained/"},{"categories":["sketches"],"content":" Nebula Graph operator explained 这个手记里，我介绍了 Nebula Graph 的 K8s Operator: Intro 00:00 Nebula K8s Operator Explained 0:25 How do we use Nebula Operator? 02:23 What is the difference between the Operator based Nebula Graph Cluster and the binary-based one? 03:50 How about the Performance impact when it comes to K8s-Operator deployment? 04:55 What is the easiest way to try out the nebula operator? 06:04 Outra 07:30 ref: https://github.com/vesoft-inc/nebula-operator ","date":"2021-08-06","objectID":"/sketches/nebula-operator-explained/:0:0","series":null,"tags":["Nebula Graph","K8s"],"title":"Nebula operator Explained","uri":"/sketches/nebula-operator-explained/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-08-06","objectID":"/sketches/nebula-operator-explained/:1:0","series":null,"tags":["Nebula Graph","K8s"],"title":"Nebula operator Explained","uri":"/sketches/nebula-operator-explained/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-08-06","objectID":"/sketches/nebula-operator-explained/:2:0","series":null,"tags":["Nebula Graph","K8s"],"title":"Nebula operator Explained","uri":"/sketches/nebula-operator-explained/#youtube"},{"categories":["sketches"],"content":"Nebula Config Explained","date":"2021-07-26","objectID":"/sketches/nebula-config-explained/","series":null,"tags":["Nebula Graph","config"],"title":"Nebula Config Explained","uri":"/sketches/nebula-config-explained/"},{"categories":["sketches"],"content":" Nebula Graph config explained 这个手记帮助我们理解 Nebula Graph 的配置相关的知识： 介绍 Nebula Graph 三种配置方式，它们的优先级、范围、生效条件 0:16 介绍 Nebula Graph 在 Docker-Compose/Swarm 部署情况下配置的方式 03:01 介绍 Nebula Graph 在 K8s Operator 部署情况下配置的方式 03:55 我们是否应该用 Local-Config？（剧透：应该） 05:03 ","date":"2021-07-26","objectID":"/sketches/nebula-config-explained/:0:0","series":null,"tags":["Nebula Graph","config"],"title":"Nebula Config Explained","uri":"/sketches/nebula-config-explained/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-07-26","objectID":"/sketches/nebula-config-explained/:1:0","series":null,"tags":["Nebula Graph","config"],"title":"Nebula Config Explained","uri":"/sketches/nebula-config-explained/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-07-26","objectID":"/sketches/nebula-config-explained/:2:0","series":null,"tags":["Nebula Graph","config"],"title":"Nebula Config Explained","uri":"/sketches/nebula-config-explained/#youtube"},{"categories":["sketches"],"content":"Nebula Index Demystified","date":"2021-07-13","objectID":"/sketches/nebula-index-demystified/","series":null,"tags":["Nebula Graph","index"],"title":"Nebula Graph Index Demystified","uri":"/sketches/nebula-index-demystified/"},{"categories":["sketches"],"content":" Nebula Graph 原生索引解谜，帮助大家深入了解 Nebula Graph Index 原生索引，到底 Nebula Graph 的原生索引是做什么用的？为什么 Nebula Graph 索引对性能有一些影响？带有索引的写入过程是什么样的？ Index Demystified 0:33 When should we use index? 06:37 Index v.s. Fulltext Index 07:12 Index Performance Impact 08:03 ","date":"2021-07-13","objectID":"/sketches/nebula-index-demystified/:0:0","series":null,"tags":["Nebula Graph","index"],"title":"Nebula Graph Index Demystified","uri":"/sketches/nebula-index-demystified/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-07-13","objectID":"/sketches/nebula-index-demystified/:1:0","series":null,"tags":["Nebula Graph","index"],"title":"Nebula Graph Index Demystified","uri":"/sketches/nebula-index-demystified/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-07-13","objectID":"/sketches/nebula-index-demystified/:2:0","series":null,"tags":["Nebula Graph","index"],"title":"Nebula Graph Index Demystified","uri":"/sketches/nebula-index-demystified/#youtube"},{"categories":["sketches"],"content":"Nebula Graph Deployment Options","date":"2021-06-25","objectID":"/sketches/nebula-deployment-options/","series":null,"tags":["Nebula Graph","deployment"],"title":"Nebula Graph Deployment Options","uri":"/sketches/nebula-deployment-options/"},{"categories":["sketches"],"content":" Nebula Graph 有很多种分发、部署方式，我们应该如何选择它们呢？ ","date":"2021-06-25","objectID":"/sketches/nebula-deployment-options/:0:0","series":null,"tags":["Nebula Graph","deployment"],"title":"Nebula Graph Deployment Options","uri":"/sketches/nebula-deployment-options/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-06-25","objectID":"/sketches/nebula-deployment-options/:1:0","series":null,"tags":["Nebula Graph","deployment"],"title":"Nebula Graph Deployment Options","uri":"/sketches/nebula-deployment-options/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-06-25","objectID":"/sketches/nebula-deployment-options/:2:0","series":null,"tags":["Nebula Graph","deployment"],"title":"Nebula Graph Deployment Options","uri":"/sketches/nebula-deployment-options/#youtube"},{"categories":["sketches"],"content":"Nebula Graph Data Import Options","date":"2021-06-15","objectID":"/sketches/nebula-data-import-options/","series":null,"tags":["Nebula Graph","data import"],"title":"Nebula Graph Data Import Options","uri":"/sketches/nebula-data-import-options/"},{"categories":["sketches"],"content":" Nebula Graph 提供了好多种数据导入的工具，我们应该如何选择呢？这一张图帮助大家了解 Nebula Graph 所有的数据导入选项。 ","date":"2021-06-15","objectID":"/sketches/nebula-data-import-options/:0:0","series":null,"tags":["Nebula Graph","data import"],"title":"Nebula Graph Data Import Options","uri":"/sketches/nebula-data-import-options/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-06-15","objectID":"/sketches/nebula-data-import-options/:1:0","series":null,"tags":["Nebula Graph","data import"],"title":"Nebula Graph Data Import Options","uri":"/sketches/nebula-data-import-options/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-06-15","objectID":"/sketches/nebula-data-import-options/:2:0","series":null,"tags":["Nebula Graph","data import"],"title":"Nebula Graph Data Import Options","uri":"/sketches/nebula-data-import-options/#youtube"},{"categories":["Nebula Graph"],"content":"无需依赖，一键安装尝鲜基于 Nebula Operator 的 K8s Nebula Graph Cluster","date":"2021-06-09","objectID":"/nebula-operator-kind/","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/"},{"categories":["Nebula Graph"],"content":" Nebula-Kind，无需依赖，一键安装尝鲜基于 Nebula Operator 的 K8s Nebula Graph Cluster。 注： KIND 是一个 K8s 的 SIG，代表 K8s in Docker。 ","date":"2021-06-09","objectID":"/nebula-operator-kind/:0:0","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/#"},{"categories":["Nebula Graph"],"content":" 1 Nebula-Operator-Kind 是什么Nebula Graph 作为云原生的分布式开源图数据库，有开源的 K8s Operator 供大家在 K8s 上方便的通过 CRD 去维护、部署 Nebula Graph 集群。 对于手头没有方便的 K8s 环境的同学，如果想尝鲜、学习 Nebula Graph 的 K8s Operator 的话，可能需要耗费一些精力才能搭起来一整套的控制平面的依赖。 作为一个懒人，我做利用 K8s in Docker(KIND)，和之前做 Nebula-Up 的 shell 脚本架子，快速的搞了一个一键安装工具：Nebula-Operator-Kind 它能直接帮我们： 安装 Docker 安装 K8s(KIND) 安装 PV Provider 安装 Nebula-Operator 以及依赖 安装 Nebula-Console 配置 nodePort 用以一键直连 Nebula 集群 安装 kubectl 用来体验 Nebula-Operator 的 CRD 配置 ","date":"2021-06-09","objectID":"/nebula-operator-kind/:1:0","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/#nebula-operator-kind-是什么"},{"categories":["Nebula Graph"],"content":" 2 如何使用安装： curl -sL nebula-kind.siwei.io/install.sh | bash 成功之后： 用 ~/.nebula-kind/bin/console 一行连接集群： ~/.nebula-kind/bin/console -u user -p password --address=127.0.0.1 --port=30000 ","date":"2021-06-09","objectID":"/nebula-operator-kind/:2:0","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/#如何使用"},{"categories":["Nebula Graph"],"content":" 3 详细信息Repo 的地址是：https://github.com/wey-gu/nebula-operator-kind ，里边有更多的信息，欢迎大家试用、反馈、PR 哈！ Updated Sept. 2021 如果在 KubeSphere All-in-one 环境安装： curl -sL nebula-kind.siwei.io/install-ks-1.sh | bash 如果在 Minikube、其他 K8s 之中安装 curl -sL nebula-kind.siwei.io/install-on-k8s.sh | bash 题图版权：Maik Hankemann ","date":"2021-06-09","objectID":"/nebula-operator-kind/:3:0","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/#详细信息"},{"categories":null,"content":" 您好，我是古思为。我是一个在上海的软件工程师，我在 vesoft 担任 Nebula Graph（开源的分布式图数据库）的社区开发者布道师。 我的工作是通过围绕 Nebula Graph Database 创作内容，构建工具来改善开发者的学习、开发、社区参与体验。 我在开源社区开放的工作，并（花了职业生涯中的前些年意识到）热爱用自己的思想和学到的技术帮助到别人，我认为这是一种的荣幸和宝贵的机遇。 1 ","date":"2021-06-04","objectID":"/about/:0:0","series":null,"tags":null,"title":"","uri":"/about/#您好我是古思为"},{"categories":null,"content":" 1 最近的开源项目 Nebula-Corp-Rel-Graph Nebula-Corp-Rel-Graph，基于图数据库的股权穿透系统 阅读全文 Nebula-Siwi Nebula-Siwi，基于图数据库的智能问答助手 阅读全文 Nebula-Holdshare Nebula-Holdshare，图数据库应用示例：股权关系穿透 阅读全文 Nebula-KIND Nebula-Kind，无需依赖，一键安装尝鲜基于 Nebula Operator 的 K8s Nebula Graph Cluster。注： KIND 是一个 K8s 的 SIG，代表 K8s in Docker。 阅读全文 Nebula-Up Nebula-up，一键拉起一个 Nebula 测试环境，支持 mscOS，Windows 10，CentOS 和 Ubuntu。 阅读全文 VSCode-nGQL VSCode-nGQL，Nebula Graph 的 VS Code 插件，ngql 语法高亮。 阅读全文 IPython-nGQL Nebula Graph 的 Jupyter Notebook 和 IPython 插件，方便在 Notebook 之中嵌入 nGQL 的 query 和 结果的调试。 阅读全文 nebula-insights 本文介绍我们如何用公有云 Serverless 技术：Google Cloud Scheduler，Google Cloud Functions 和 BigQuery 搭建数据管道，收集探索开源社区洞察。并将全部代码开源在 GitHub。 阅读全文 ","date":"2021-06-04","objectID":"/about/:1:0","series":null,"tags":null,"title":"","uri":"/about/#最近的开源项目"},{"categories":null,"content":" 2 我的手绘 Nebula Operator Explained Nebula Graph K8s Operator 介绍 阅读全文 Nebula Config Explained Nebula Graph 配置详解 阅读全文 Nebula Index Demystified Nebula Graph 原生索引解谜 阅读全文 Nebula Data Import Options Nebula Graph 提供了好多种数据导入的工具，我们应该如何选择呢？ 阅读全文 Nebula Deployment Options Nebula Graph 有很多种分发、部署方式，我们应该如何选择它们呢？ 阅读全文 Nebula Intro 新手玩转 Nebula Graph 系列开篇。 阅读全文 ","date":"2021-06-04","objectID":"/about/:2:0","series":null,"tags":null,"title":"","uri":"/about/#我的手绘"},{"categories":null,"content":" 3 我的上手课程 股权穿透教程 上手实战股权用图数据库关系穿透 阅读全文 Siwi 上手实战从 0 制作一个基于图谱的语音智能助手 阅读全文 ","date":"2021-06-04","objectID":"/about/:3:0","series":null,"tags":null,"title":"","uri":"/about/#我的上手课程"},{"categories":null,"content":" 4 我的演讲 掘金春招活动 那些我希望过去的自己可以知道的事实 阅读全文 DoK Talks #116 Nebula Graph: Open Source Distributed GraphDB 阅读全文 Data on K8s Community 2021 GraphDB on Kubesphere 阅读全文 K8s Community Day 2021 Openfunction + GraphDB 阅读全文 COScon 2021 我的开源之路 阅读全文 PyCon China 2021 图数据库解谜与 Python 的图库应用实践 阅读全文 K8s 上的图数据库 Nebula K8s Operator 的实现解析，图数据库应用在 K8s + OpenFunction 上的落地演示 阅读全文 nMeetup: Nebula 应用上手实操 从头实操 Nebula 的部署，股权穿透，图算法运算，语音智能助手。 阅读全文 How to Train your Dragon 如何成为开源开发者（布道师）。 阅读全文 ","date":"2021-06-04","objectID":"/about/:4:0","series":null,"tags":null,"title":"","uri":"/about/#我的演讲"},{"categories":null,"content":" 5 过往的经历我曾在爱立信工作了近十年：2011 年到 2021 年。 我是云计算产品 Cloud Execution Envrioment (CEE) 2 研发团队的系统经理 3，我大部分的工作是通过设计开发 20 多个 CEE 6.6.2 和 CEE 10 的功能与改进，涵盖计算、存储、网络、生命周期管理和安全等领域，来帮助爱立信 IaaS 产品与解决方案不断进化。 同时，我也负责 CEE 产品在中国区的布道（面向外部与内部）。 我曾在 note.siwei.info 记录一些想法和笔记，从2021年春天开始，我会把想法记录下来留在 siwei.io ","date":"2021-06-04","objectID":"/about/:5:0","series":null,"tags":null,"title":"","uri":"/about/#过往的经历"},{"categories":null,"content":" 6 联系我您最好通过 twitter，邮箱 wey.gu@vesoft.com 找到我。 如果必须，您也可以通过微信找到我，微信 ID 如下，请添加注明您的来意。 echo c2l2dmVpCg== | base64 -d 或者和我约一个 Zoom Call 我和 Ahmet Alp Balkan 的 这个推文 感同身受： Working in open source (and getting paid for it) is a privilege. It’s a career boost, makes you lots of friends across the industry, and gives you a public brand. I am one of the “lucky few” \u0026 thankful to Microsoft and Google who let me work on OSS nearly all my career. — ahmetb (@ahmetb) February 19, 2021  ↩︎ Ericsson’s Telco. Infrastructure as a Service product offerring: Cloud Execution Environment ↩︎ System Manager, PDU Cloud: 工作描述 ↩︎ ","date":"2021-06-04","objectID":"/about/:6:0","series":null,"tags":null,"title":"","uri":"/about/#联系我"},{"categories":["Nebula Graph"],"content":"本文作者分析了 Chia Network 的全链数据，并做了将全链数据导入图数据库：Nebula Graph 之中的尝试，从而可视化地探索了 Chia 图中数据之间的关联关系。","date":"2021-05-26","objectID":"/nebula-chia/","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/"},{"categories":["Nebula Graph"],"content":" 这篇文章里，我全网首次地分析了 Chia Network 的全链数据，并做了将全链数据导入图数据库：Nebula Graph 之中的尝试，从而可视化地探索了 Chia 图中数据之间的关联关系。 我把涉及的代码开源在了这里：https://github.com/wey-gu/nebula-chia ","date":"2021-05-26","objectID":"/nebula-chia/:0:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#"},{"categories":["Nebula Graph"],"content":" 1 Chia 是什么?Chia Network 是由 BitTorrent 的作者 Bram Cohen 的团队在 2017 年创建的区块链项目。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#chia-是什么"},{"categories":["Nebula Graph"],"content":" 1.1 为什么再搞一个区块链?Chia 用了全新的中本聪共识算法，这个算法通过不允许并行计算，让挖矿（Proof of Work）所需算力和能耗降到非常低，这使得超大组织、玩家没法像在其他的区块链项目那样有算力的绝对优势，也一定程度上规避了能源的浪费。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#为什么再搞一个区块链"},{"categories":["Nebula Graph"],"content":" 1.2 如何连接Chia?我们可以通过 Chia Network 的客户端来访问它，这个客户端是 Electron + Python 的程序，天然跨平台，既有 GUI 又有 CLI 的方式。 1.2.1 安装只需要按照官方的 Guide 来下载安装就好， https://github.com/Chia-Network/chia-blockchain/wiki/INSTALL，我在 M1 Mac 下安装的时候脚本出了点小问题，大概是因为拉取二进制 wheel 文件网络出问题走到了编译 wheel的逻辑，而那里是依赖 cargo的，如果大家遇到了这个问题，可以提前手动安装一下 rust，或者 cherry-pick 我的这个 PR 。 1.2.2 运行 按照官方 guide，比如 macOS 来说，最后一步执行npm run electron \u0026 就是运行它的GUI客户端。 如果大家像我一样喜欢 CLI，直接在执行完 . ./activate 之后就可以 chia --help了哈☺，里边有只启动部分服务的方式（相比 GUI 启动所有来说)。 在运行之后，如果你的网络不是多层 NAT 的那种，理论上您可以连到 mainnet 并且自动和主链同步数据了，如果您是第二次运行，连接主链，一开始可能有一阵子同步的block 数是不变的，也没有 peer 连过来，不必惊慌，等一下就好了。 Tips: 第一次连到 Chia Network 的同学们，客户端会自动生成一个钱包，及的保存那一串词，它们就是你的私钥哦。 万一，如果真的连不上的话，可能需要在路由上配置，UPnP，防火墙要允许 8444。 1.2.3 访问 Chia 的数据Chia 的客户端把数据存在了几个 SQLite 数据库里，它们的路径是我们安装客户端的用户的家目录：~/.chia/mainnet 下边就是运行起来 Chia 之后生成的主要的两个数据库的二进制文件： ~/.chia/mainnet/db ❯ ll -h total 4350416 -rw-r--r-- 1 weyl staff 2.0G May 6 12:06 blockchain_v1_mainnet.sqlite -rw-r--r-- 1 weyl staff 64K May 6 11:17 blockchain_v1_mainnet.sqlite-shm -rw-r--r-- 1 weyl staff 20M May 6 12:10 blockchain_v1_mainnet.sqlite-wal -rw-r--r-- 1 weyl staff 1.8M May 6 11:46 peer_table_node.sqlite -rw-r--r-- 1 weyl staff 32K May 5 17:30 peer_table_node.sqlite-shm -rw-r--r-- 1 weyl staff 5.4M May 6 11:46 peer_table_node.sqlite-wal ~/.chia/mainnet/wallet/db ❯ ll -h total 3055848 -rw-r--r-- 1 weyl staff 1.4G May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite -rw-r--r-- 1 weyl staff 32K May 7 15:24 blockchain_wallet_v1_mainnet_903996200.sqlite-shm -rw-r--r-- 1 weyl staff 4.0M May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite-wal -rw-r--r-- 1 weyl staff 16K May 7 15:24 wallet_peers.sqlite 然后，我们可以先用 SQLite Browser，一个 SQlite 数据库（文件）的浏览器来看看它。 SQlite 浏览器的官网是 https://sqlitebrowser.org/ 。在下载，安装之后，我们可以通过点击 Open Database/打开数据库 选择浏览上边列出来的两个 .sqlite 扩展名的数据库文件。 打开数据库之后，我们可以选择第一个标签 Database Schema 来看看表的结构。 我们还能像类似于 Excel 一样去看表的数据，还可以 Filter/过滤、Sort/排序任意列。 下一部分，我们来简单看看表里的数据。 Tips: 这里边，~/.chia/mainnet/wallet 和裸目录 ~/.chia/mainnet 下边的 db 里分别都有表文件，他们的信息是有重复的，大家可以分别打开看看哦，即使是相同的表的名字，比如 block_record 内里的信息也略有差别，如果大家知道为什么有这样的差别，欢迎浏览告诉大家哈，可能要仔细研究一下客户端、钱包等代码才行，幸运的是，它们相对比较好阅读，是 Python 写的： https://github.com/Chia-Network/chia-blockchain 。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#如何连接chia"},{"categories":["Nebula Graph"],"content":" 1.2 如何连接Chia?我们可以通过 Chia Network 的客户端来访问它，这个客户端是 Electron + Python 的程序，天然跨平台，既有 GUI 又有 CLI 的方式。 1.2.1 安装只需要按照官方的 Guide 来下载安装就好， https://github.com/Chia-Network/chia-blockchain/wiki/INSTALL，我在 M1 Mac 下安装的时候脚本出了点小问题，大概是因为拉取二进制 wheel 文件网络出问题走到了编译 wheel的逻辑，而那里是依赖 cargo的，如果大家遇到了这个问题，可以提前手动安装一下 rust，或者 cherry-pick 我的这个 PR 。 1.2.2 运行 按照官方 guide，比如 macOS 来说，最后一步执行npm run electron \u0026 就是运行它的GUI客户端。 如果大家像我一样喜欢 CLI，直接在执行完 . ./activate 之后就可以 chia --help了哈☺，里边有只启动部分服务的方式（相比 GUI 启动所有来说)。 在运行之后，如果你的网络不是多层 NAT 的那种，理论上您可以连到 mainnet 并且自动和主链同步数据了，如果您是第二次运行，连接主链，一开始可能有一阵子同步的block 数是不变的，也没有 peer 连过来，不必惊慌，等一下就好了。 Tips: 第一次连到 Chia Network 的同学们，客户端会自动生成一个钱包，及的保存那一串词，它们就是你的私钥哦。 万一，如果真的连不上的话，可能需要在路由上配置，UPnP，防火墙要允许 8444。 1.2.3 访问 Chia 的数据Chia 的客户端把数据存在了几个 SQLite 数据库里，它们的路径是我们安装客户端的用户的家目录：~/.chia/mainnet 下边就是运行起来 Chia 之后生成的主要的两个数据库的二进制文件： ~/.chia/mainnet/db ❯ ll -h total 4350416 -rw-r--r-- 1 weyl staff 2.0G May 6 12:06 blockchain_v1_mainnet.sqlite -rw-r--r-- 1 weyl staff 64K May 6 11:17 blockchain_v1_mainnet.sqlite-shm -rw-r--r-- 1 weyl staff 20M May 6 12:10 blockchain_v1_mainnet.sqlite-wal -rw-r--r-- 1 weyl staff 1.8M May 6 11:46 peer_table_node.sqlite -rw-r--r-- 1 weyl staff 32K May 5 17:30 peer_table_node.sqlite-shm -rw-r--r-- 1 weyl staff 5.4M May 6 11:46 peer_table_node.sqlite-wal ~/.chia/mainnet/wallet/db ❯ ll -h total 3055848 -rw-r--r-- 1 weyl staff 1.4G May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite -rw-r--r-- 1 weyl staff 32K May 7 15:24 blockchain_wallet_v1_mainnet_903996200.sqlite-shm -rw-r--r-- 1 weyl staff 4.0M May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite-wal -rw-r--r-- 1 weyl staff 16K May 7 15:24 wallet_peers.sqlite 然后，我们可以先用 SQLite Browser，一个 SQlite 数据库（文件）的浏览器来看看它。 SQlite 浏览器的官网是 https://sqlitebrowser.org/ 。在下载，安装之后，我们可以通过点击 Open Database/打开数据库 选择浏览上边列出来的两个 .sqlite 扩展名的数据库文件。 打开数据库之后，我们可以选择第一个标签 Database Schema 来看看表的结构。 我们还能像类似于 Excel 一样去看表的数据，还可以 Filter/过滤、Sort/排序任意列。 下一部分，我们来简单看看表里的数据。 Tips: 这里边，~/.chia/mainnet/wallet 和裸目录 ~/.chia/mainnet 下边的 db 里分别都有表文件，他们的信息是有重复的，大家可以分别打开看看哦，即使是相同的表的名字，比如 block_record 内里的信息也略有差别，如果大家知道为什么有这样的差别，欢迎浏览告诉大家哈，可能要仔细研究一下客户端、钱包等代码才行，幸运的是，它们相对比较好阅读，是 Python 写的： https://github.com/Chia-Network/chia-blockchain 。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#安装"},{"categories":["Nebula Graph"],"content":" 1.2 如何连接Chia?我们可以通过 Chia Network 的客户端来访问它，这个客户端是 Electron + Python 的程序，天然跨平台，既有 GUI 又有 CLI 的方式。 1.2.1 安装只需要按照官方的 Guide 来下载安装就好， https://github.com/Chia-Network/chia-blockchain/wiki/INSTALL，我在 M1 Mac 下安装的时候脚本出了点小问题，大概是因为拉取二进制 wheel 文件网络出问题走到了编译 wheel的逻辑，而那里是依赖 cargo的，如果大家遇到了这个问题，可以提前手动安装一下 rust，或者 cherry-pick 我的这个 PR 。 1.2.2 运行 按照官方 guide，比如 macOS 来说，最后一步执行npm run electron \u0026 就是运行它的GUI客户端。 如果大家像我一样喜欢 CLI，直接在执行完 . ./activate 之后就可以 chia --help了哈☺，里边有只启动部分服务的方式（相比 GUI 启动所有来说)。 在运行之后，如果你的网络不是多层 NAT 的那种，理论上您可以连到 mainnet 并且自动和主链同步数据了，如果您是第二次运行，连接主链，一开始可能有一阵子同步的block 数是不变的，也没有 peer 连过来，不必惊慌，等一下就好了。 Tips: 第一次连到 Chia Network 的同学们，客户端会自动生成一个钱包，及的保存那一串词，它们就是你的私钥哦。 万一，如果真的连不上的话，可能需要在路由上配置，UPnP，防火墙要允许 8444。 1.2.3 访问 Chia 的数据Chia 的客户端把数据存在了几个 SQLite 数据库里，它们的路径是我们安装客户端的用户的家目录：~/.chia/mainnet 下边就是运行起来 Chia 之后生成的主要的两个数据库的二进制文件： ~/.chia/mainnet/db ❯ ll -h total 4350416 -rw-r--r-- 1 weyl staff 2.0G May 6 12:06 blockchain_v1_mainnet.sqlite -rw-r--r-- 1 weyl staff 64K May 6 11:17 blockchain_v1_mainnet.sqlite-shm -rw-r--r-- 1 weyl staff 20M May 6 12:10 blockchain_v1_mainnet.sqlite-wal -rw-r--r-- 1 weyl staff 1.8M May 6 11:46 peer_table_node.sqlite -rw-r--r-- 1 weyl staff 32K May 5 17:30 peer_table_node.sqlite-shm -rw-r--r-- 1 weyl staff 5.4M May 6 11:46 peer_table_node.sqlite-wal ~/.chia/mainnet/wallet/db ❯ ll -h total 3055848 -rw-r--r-- 1 weyl staff 1.4G May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite -rw-r--r-- 1 weyl staff 32K May 7 15:24 blockchain_wallet_v1_mainnet_903996200.sqlite-shm -rw-r--r-- 1 weyl staff 4.0M May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite-wal -rw-r--r-- 1 weyl staff 16K May 7 15:24 wallet_peers.sqlite 然后，我们可以先用 SQLite Browser，一个 SQlite 数据库（文件）的浏览器来看看它。 SQlite 浏览器的官网是 https://sqlitebrowser.org/ 。在下载，安装之后，我们可以通过点击 Open Database/打开数据库 选择浏览上边列出来的两个 .sqlite 扩展名的数据库文件。 打开数据库之后，我们可以选择第一个标签 Database Schema 来看看表的结构。 我们还能像类似于 Excel 一样去看表的数据，还可以 Filter/过滤、Sort/排序任意列。 下一部分，我们来简单看看表里的数据。 Tips: 这里边，~/.chia/mainnet/wallet 和裸目录 ~/.chia/mainnet 下边的 db 里分别都有表文件，他们的信息是有重复的，大家可以分别打开看看哦，即使是相同的表的名字，比如 block_record 内里的信息也略有差别，如果大家知道为什么有这样的差别，欢迎浏览告诉大家哈，可能要仔细研究一下客户端、钱包等代码才行，幸运的是，它们相对比较好阅读，是 Python 写的： https://github.com/Chia-Network/chia-blockchain 。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#运行"},{"categories":["Nebula Graph"],"content":" 1.2 如何连接Chia?我们可以通过 Chia Network 的客户端来访问它，这个客户端是 Electron + Python 的程序，天然跨平台，既有 GUI 又有 CLI 的方式。 1.2.1 安装只需要按照官方的 Guide 来下载安装就好， https://github.com/Chia-Network/chia-blockchain/wiki/INSTALL，我在 M1 Mac 下安装的时候脚本出了点小问题，大概是因为拉取二进制 wheel 文件网络出问题走到了编译 wheel的逻辑，而那里是依赖 cargo的，如果大家遇到了这个问题，可以提前手动安装一下 rust，或者 cherry-pick 我的这个 PR 。 1.2.2 运行 按照官方 guide，比如 macOS 来说，最后一步执行npm run electron \u0026 就是运行它的GUI客户端。 如果大家像我一样喜欢 CLI，直接在执行完 . ./activate 之后就可以 chia --help了哈☺，里边有只启动部分服务的方式（相比 GUI 启动所有来说)。 在运行之后，如果你的网络不是多层 NAT 的那种，理论上您可以连到 mainnet 并且自动和主链同步数据了，如果您是第二次运行，连接主链，一开始可能有一阵子同步的block 数是不变的，也没有 peer 连过来，不必惊慌，等一下就好了。 Tips: 第一次连到 Chia Network 的同学们，客户端会自动生成一个钱包，及的保存那一串词，它们就是你的私钥哦。 万一，如果真的连不上的话，可能需要在路由上配置，UPnP，防火墙要允许 8444。 1.2.3 访问 Chia 的数据Chia 的客户端把数据存在了几个 SQLite 数据库里，它们的路径是我们安装客户端的用户的家目录：~/.chia/mainnet 下边就是运行起来 Chia 之后生成的主要的两个数据库的二进制文件： ~/.chia/mainnet/db ❯ ll -h total 4350416 -rw-r--r-- 1 weyl staff 2.0G May 6 12:06 blockchain_v1_mainnet.sqlite -rw-r--r-- 1 weyl staff 64K May 6 11:17 blockchain_v1_mainnet.sqlite-shm -rw-r--r-- 1 weyl staff 20M May 6 12:10 blockchain_v1_mainnet.sqlite-wal -rw-r--r-- 1 weyl staff 1.8M May 6 11:46 peer_table_node.sqlite -rw-r--r-- 1 weyl staff 32K May 5 17:30 peer_table_node.sqlite-shm -rw-r--r-- 1 weyl staff 5.4M May 6 11:46 peer_table_node.sqlite-wal ~/.chia/mainnet/wallet/db ❯ ll -h total 3055848 -rw-r--r-- 1 weyl staff 1.4G May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite -rw-r--r-- 1 weyl staff 32K May 7 15:24 blockchain_wallet_v1_mainnet_903996200.sqlite-shm -rw-r--r-- 1 weyl staff 4.0M May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite-wal -rw-r--r-- 1 weyl staff 16K May 7 15:24 wallet_peers.sqlite 然后，我们可以先用 SQLite Browser，一个 SQlite 数据库（文件）的浏览器来看看它。 SQlite 浏览器的官网是 https://sqlitebrowser.org/ 。在下载，安装之后，我们可以通过点击 Open Database/打开数据库 选择浏览上边列出来的两个 .sqlite 扩展名的数据库文件。 打开数据库之后，我们可以选择第一个标签 Database Schema 来看看表的结构。 我们还能像类似于 Excel 一样去看表的数据，还可以 Filter/过滤、Sort/排序任意列。 下一部分，我们来简单看看表里的数据。 Tips: 这里边，~/.chia/mainnet/wallet 和裸目录 ~/.chia/mainnet 下边的 db 里分别都有表文件，他们的信息是有重复的，大家可以分别打开看看哦，即使是相同的表的名字，比如 block_record 内里的信息也略有差别，如果大家知道为什么有这样的差别，欢迎浏览告诉大家哈，可能要仔细研究一下客户端、钱包等代码才行，幸运的是，它们相对比较好阅读，是 Python 写的： https://github.com/Chia-Network/chia-blockchain 。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#访问-chia-的数据"},{"categories":["Nebula Graph"],"content":" 2 分析 Chia 的数据如果大家仔细看了上边表结构定义的截图，就能注意到一些表的主要信息是嵌套二进制 KV Byte，所以只从 SQLite 并不能看到所有 Chia 的数据，所以我们需要（用一个编程语言来）读取表里的 Byte。 幸运的是，这件事儿因为 Chia 是开源的，而且是 Python 的代码，使得我们可以直接交互式的做。 我花了一点点时间在 Chia 客户端代码里找到了需要的封装类，借助它，可以比较方便的分析 Chia 客户端在本地的全链数据。 如果您不感兴趣细节，可以直接看我分析的结论。 结论之后，我也给大家演示一下是怎么读取它们的。 ","date":"2021-05-26","objectID":"/nebula-chia/:2:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#分析-chia-的数据"},{"categories":["Nebula Graph"],"content":" 2.1 TL;DR, 结论我们可以从表中读取到区块链记录（Block Record ），Chia 币记录（Coin Record）。 从区块记录中，我们可以看到关键的涉及交易的信息： 关联的 Coin ，关联的 Puzzle（地址），Coin 的值(Amount) 从币记录中，我们可以看到关键的涉及区块的信息： 生成这个 Coin 所在区块链里的索引高度（Confirmed Index） 如果这个记录是花费 Coin 的，花费它的索引高度（Spent Index） ┌──────────────────────┐ ┌────────────────────────────────────────┐ │ │ │ │ │ Coin Record │ │ Block Record │ │ │ │ │ │ Coin Name │ │ Height ◄────────────────────────────┼─┐ │ │ │ │ │ ┌─┼───► Puzzle │ │ Header │ │ │ │ │ │ │ │ ├─┼───► Coin Parent │ │ Prev Header │ │ │ │ │ │ │ │ ├─┼───► Amount │ │ Block Body │ │ │ │ │ │ farmer_puzzle_hash │ │ │ │ Time Stamp │ │ fees │ │ │ │ │ │ pool_puzzle_hash │ └─────┼─┼─┬─ Confirmed Index │ │ prev_transaction_block_hash │ │ │ │ │ │ prev_transaction_block_height │ │ │ └─ Spent Index │ │ transactions_info ───────────────┼───────┘ │ │ │ ┌─── is_transaction_block │ │ Coinbase │ │ │ sub_epoch_summary ────────────────┼───────┐ │ │ │ │ │ │ └─ ────────────────────┘ │ │ is Peak │ │ │ └──is Block │ │ ┌─────────────────────┐ │ │ │ │ │ └────────────────────────────────────────┘ └─┼─► Sub Epoch Segment │ │ │ └─────────────────────┘ ","date":"2021-05-26","objectID":"/nebula-chia/:2:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#tldr-结论"},{"categories":["Nebula Graph"],"content":" 2.2 准备因为安装客户端之后，我们本地实际上已经有了相关的 Python 环境和依赖，只需要在里边跑起来就好。 # 注意，我们要 cd 到之前安装客户端时候克隆的仓库。 cd chia-blockchain # source activate 脚本来切换到仓库安装时候创建的 Python 虚拟环境，并进到 IPython 里。 source venv/bin/activate \u0026\u0026 pip install ipython \u0026\u0026 ipython 然后试着导入客户端里边带有的 Python 的 Chia 的封装类试试看。 In [1]: import sqlite3 ...: from chia.consensus.block_record import BlockRecord # 导入成功，没有报错 In [2]: !pwd # 我的安装克隆目录 /Users/weyl/chia-blockchain 恭喜你做好了准备，我们看看 Block Record 里都有什么。 ","date":"2021-05-26","objectID":"/nebula-chia/:2:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#准备"},{"categories":["Nebula Graph"],"content":" 2.3 Chia 链的数据 2.3.1 区块记录在上一步的 IPython 窗口下。 # 注意，这里的路径的前缀是我们自己的家目录，不同操作系统，不同的用户都会有所不同。 chia_db_path = \"/Users/weyl/.chia/mainnet/db/blockchain_v1_mainnet.sqlite\" cur = con.cursor() # 这里我们取第 201645 高的区块 rows = list(cur.execute('SELECT * FROM block_records WHERE height = 201645')) # 这里 0 表示 SELECT 结果的第一行，3 表示在 BlockRecord 这个表里边，Block 的二进制 BLOB 是第四列，参考本章底部的表定义部分 block_records_201645 = BlockRecord.from_bytes(rows[0][3]) dir(block_records_201645) # 可以查看一些属性 is_transaction_block，timestamp，reward_claims_incorporated In [174]: block_records_201645.is_transaction_block Out[174]: True In [182]: from datetime import datetime In [183]: datetime.fromtimestamp(block_records_201645.timestamp) Out[183]: datetime.datetime(2021, 4, 29, 10, 8, 1) In [190]: block_records_201645.reward_claims_incorporated[0].to_json_dict() Out[190]: {'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6', 'amount': 1750000000000} # 可以快速 print 看大部分信息 print(block_records_201645) block_records_201645 的打印结果如下。 注意，这里我截断了一些数据 {'challenge_block_info_hash': '0x4a562f1ffa7a06fe76b1df74dbdd6bdcfbf63139a6f1fc3291c606d7c976abf6', 'challenge_vdf_output': {'data': '0x0200a6b38d6b58d17129d71737088772561f22a44ef302fe45a70a763b878f998abfe35946df720bcb5d78e214b667bce801d597b46c867928c4b8926c342375a961f36cd63ec698bc25e5ce48c45d9a2074eded0e42d24dd1b50a59e699f671f0900100'}, 'deficit': 16, 'farmer_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'fees': 0, 'finished_challenge_slot_hashes': ['0x2b1a7b4859a8d3597b8e6cbe3b27ab97212be8b19e6867f2a4d0eef26c36340f'], 'finished_infused_challenge_slot_hashes': ['0xd0185a6493b10d84e696c6fc55ec1920e8a96791a604dedfe77635da460f354d'], 'finished_reward_slot_hashes': ['0xe2bcbf560471131a7fb87ffe3f9ddde03166a9b0092a50f1ed1599715857c365'], 'header_hash': '0x2791729e1c914f9c3908a0ad895b5846c86fc4e207cc463820123e9a299c39f3', 'height': 201645, 'infused_challenge_vdf_output': None, 'overflow': True, 'pool_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'prev_hash': '0xf126ecf64473beb9ae5b84137788100feb9d731c604877c0744cdc6025f4cbeb', 'prev_transaction_block_hash': '0x7103fe2f1aa96998f9ccf6fc98561b64c5f7a98cf942335c4c927fb2eaa9325a', 'prev_transaction_block_height': 201643, 'required_iters': 95752, 'reward_claims_incorporated': [{'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313aa', 'puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313a8', 'puzzle_hash': '0xcf178071f6aa6cb1c92f00943424bcc8cb774449bd60058fc08e9894f49a1ca4'}], 'reward_infusion_new_challenge': '0x660886f4ab030c07755f53362ae4253dfa93ea853cbc321218f58f159c75adaa', 'signage_point_index': 63, 'sub_epoch_summary_included': None, 'sub_slot_iters': 99614720, 'timestamp': 1619662081, 'total_iters': 660123219464, 'weight': 4121254} 另外，我们取的这个表的定义如下。 CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, #\u003c---- sub_epoch_summary blob, is_peak tinyint, is_block tinyint) 2.3.2 Chia 币记录类似的，我们可以获取一个 Coin 的记录，这里边，从表的定义可以看到，唯一二进制（不能直接从数据库查询中被人读懂）的字段就是是币值，不存在嵌套的结构，所以也并不需要封装的类才能看清楚里边的信息。 CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) 这里值得注意的信息主要","date":"2021-05-26","objectID":"/nebula-chia/:2:3","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#chia-链的数据"},{"categories":["Nebula Graph"],"content":" 2.3 Chia 链的数据 2.3.1 区块记录在上一步的 IPython 窗口下。 # 注意，这里的路径的前缀是我们自己的家目录，不同操作系统，不同的用户都会有所不同。 chia_db_path = \"/Users/weyl/.chia/mainnet/db/blockchain_v1_mainnet.sqlite\" cur = con.cursor() # 这里我们取第 201645 高的区块 rows = list(cur.execute('SELECT * FROM block_records WHERE height = 201645')) # 这里 0 表示 SELECT 结果的第一行，3 表示在 BlockRecord 这个表里边，Block 的二进制 BLOB 是第四列，参考本章底部的表定义部分 block_records_201645 = BlockRecord.from_bytes(rows[0][3]) dir(block_records_201645) # 可以查看一些属性 is_transaction_block，timestamp，reward_claims_incorporated In [174]: block_records_201645.is_transaction_block Out[174]: True In [182]: from datetime import datetime In [183]: datetime.fromtimestamp(block_records_201645.timestamp) Out[183]: datetime.datetime(2021, 4, 29, 10, 8, 1) In [190]: block_records_201645.reward_claims_incorporated[0].to_json_dict() Out[190]: {'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6', 'amount': 1750000000000} # 可以快速 print 看大部分信息 print(block_records_201645) block_records_201645 的打印结果如下。 注意，这里我截断了一些数据 {'challenge_block_info_hash': '0x4a562f1ffa7a06fe76b1df74dbdd6bdcfbf63139a6f1fc3291c606d7c976abf6', 'challenge_vdf_output': {'data': '0x0200a6b38d6b58d17129d71737088772561f22a44ef302fe45a70a763b878f998abfe35946df720bcb5d78e214b667bce801d597b46c867928c4b8926c342375a961f36cd63ec698bc25e5ce48c45d9a2074eded0e42d24dd1b50a59e699f671f0900100'}, 'deficit': 16, 'farmer_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'fees': 0, 'finished_challenge_slot_hashes': ['0x2b1a7b4859a8d3597b8e6cbe3b27ab97212be8b19e6867f2a4d0eef26c36340f'], 'finished_infused_challenge_slot_hashes': ['0xd0185a6493b10d84e696c6fc55ec1920e8a96791a604dedfe77635da460f354d'], 'finished_reward_slot_hashes': ['0xe2bcbf560471131a7fb87ffe3f9ddde03166a9b0092a50f1ed1599715857c365'], 'header_hash': '0x2791729e1c914f9c3908a0ad895b5846c86fc4e207cc463820123e9a299c39f3', 'height': 201645, 'infused_challenge_vdf_output': None, 'overflow': True, 'pool_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'prev_hash': '0xf126ecf64473beb9ae5b84137788100feb9d731c604877c0744cdc6025f4cbeb', 'prev_transaction_block_hash': '0x7103fe2f1aa96998f9ccf6fc98561b64c5f7a98cf942335c4c927fb2eaa9325a', 'prev_transaction_block_height': 201643, 'required_iters': 95752, 'reward_claims_incorporated': [{'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313aa', 'puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313a8', 'puzzle_hash': '0xcf178071f6aa6cb1c92f00943424bcc8cb774449bd60058fc08e9894f49a1ca4'}], 'reward_infusion_new_challenge': '0x660886f4ab030c07755f53362ae4253dfa93ea853cbc321218f58f159c75adaa', 'signage_point_index': 63, 'sub_epoch_summary_included': None, 'sub_slot_iters': 99614720, 'timestamp': 1619662081, 'total_iters': 660123219464, 'weight': 4121254} 另外，我们取的这个表的定义如下。 CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, #\u003c---- sub_epoch_summary blob, is_peak tinyint, is_block tinyint) 2.3.2 Chia 币记录类似的，我们可以获取一个 Coin 的记录，这里边，从表的定义可以看到，唯一二进制（不能直接从数据库查询中被人读懂）的字段就是是币值，不存在嵌套的结构，所以也并不需要封装的类才能看清楚里边的信息。 CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) 这里值得注意的信息主要","date":"2021-05-26","objectID":"/nebula-chia/:2:3","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#区块记录"},{"categories":["Nebula Graph"],"content":" 2.3 Chia 链的数据 2.3.1 区块记录在上一步的 IPython 窗口下。 # 注意，这里的路径的前缀是我们自己的家目录，不同操作系统，不同的用户都会有所不同。 chia_db_path = \"/Users/weyl/.chia/mainnet/db/blockchain_v1_mainnet.sqlite\" cur = con.cursor() # 这里我们取第 201645 高的区块 rows = list(cur.execute('SELECT * FROM block_records WHERE height = 201645')) # 这里 0 表示 SELECT 结果的第一行，3 表示在 BlockRecord 这个表里边，Block 的二进制 BLOB 是第四列，参考本章底部的表定义部分 block_records_201645 = BlockRecord.from_bytes(rows[0][3]) dir(block_records_201645) # 可以查看一些属性 is_transaction_block，timestamp，reward_claims_incorporated In [174]: block_records_201645.is_transaction_block Out[174]: True In [182]: from datetime import datetime In [183]: datetime.fromtimestamp(block_records_201645.timestamp) Out[183]: datetime.datetime(2021, 4, 29, 10, 8, 1) In [190]: block_records_201645.reward_claims_incorporated[0].to_json_dict() Out[190]: {'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6', 'amount': 1750000000000} # 可以快速 print 看大部分信息 print(block_records_201645) block_records_201645 的打印结果如下。 注意，这里我截断了一些数据 {'challenge_block_info_hash': '0x4a562f1ffa7a06fe76b1df74dbdd6bdcfbf63139a6f1fc3291c606d7c976abf6', 'challenge_vdf_output': {'data': '0x0200a6b38d6b58d17129d71737088772561f22a44ef302fe45a70a763b878f998abfe35946df720bcb5d78e214b667bce801d597b46c867928c4b8926c342375a961f36cd63ec698bc25e5ce48c45d9a2074eded0e42d24dd1b50a59e699f671f0900100'}, 'deficit': 16, 'farmer_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'fees': 0, 'finished_challenge_slot_hashes': ['0x2b1a7b4859a8d3597b8e6cbe3b27ab97212be8b19e6867f2a4d0eef26c36340f'], 'finished_infused_challenge_slot_hashes': ['0xd0185a6493b10d84e696c6fc55ec1920e8a96791a604dedfe77635da460f354d'], 'finished_reward_slot_hashes': ['0xe2bcbf560471131a7fb87ffe3f9ddde03166a9b0092a50f1ed1599715857c365'], 'header_hash': '0x2791729e1c914f9c3908a0ad895b5846c86fc4e207cc463820123e9a299c39f3', 'height': 201645, 'infused_challenge_vdf_output': None, 'overflow': True, 'pool_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'prev_hash': '0xf126ecf64473beb9ae5b84137788100feb9d731c604877c0744cdc6025f4cbeb', 'prev_transaction_block_hash': '0x7103fe2f1aa96998f9ccf6fc98561b64c5f7a98cf942335c4c927fb2eaa9325a', 'prev_transaction_block_height': 201643, 'required_iters': 95752, 'reward_claims_incorporated': [{'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313aa', 'puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313a8', 'puzzle_hash': '0xcf178071f6aa6cb1c92f00943424bcc8cb774449bd60058fc08e9894f49a1ca4'}], 'reward_infusion_new_challenge': '0x660886f4ab030c07755f53362ae4253dfa93ea853cbc321218f58f159c75adaa', 'signage_point_index': 63, 'sub_epoch_summary_included': None, 'sub_slot_iters': 99614720, 'timestamp': 1619662081, 'total_iters': 660123219464, 'weight': 4121254} 另外，我们取的这个表的定义如下。 CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, #\u003c---- sub_epoch_summary blob, is_peak tinyint, is_block tinyint) 2.3.2 Chia 币记录类似的，我们可以获取一个 Coin 的记录，这里边，从表的定义可以看到，唯一二进制（不能直接从数据库查询中被人读懂）的字段就是是币值，不存在嵌套的结构，所以也并不需要封装的类才能看清楚里边的信息。 CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) 这里值得注意的信息主要","date":"2021-05-26","objectID":"/nebula-chia/:2:3","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#chia-币记录"},{"categories":["Nebula Graph"],"content":" 2.3 Chia 链的数据 2.3.1 区块记录在上一步的 IPython 窗口下。 # 注意，这里的路径的前缀是我们自己的家目录，不同操作系统，不同的用户都会有所不同。 chia_db_path = \"/Users/weyl/.chia/mainnet/db/blockchain_v1_mainnet.sqlite\" cur = con.cursor() # 这里我们取第 201645 高的区块 rows = list(cur.execute('SELECT * FROM block_records WHERE height = 201645')) # 这里 0 表示 SELECT 结果的第一行，3 表示在 BlockRecord 这个表里边，Block 的二进制 BLOB 是第四列，参考本章底部的表定义部分 block_records_201645 = BlockRecord.from_bytes(rows[0][3]) dir(block_records_201645) # 可以查看一些属性 is_transaction_block，timestamp，reward_claims_incorporated In [174]: block_records_201645.is_transaction_block Out[174]: True In [182]: from datetime import datetime In [183]: datetime.fromtimestamp(block_records_201645.timestamp) Out[183]: datetime.datetime(2021, 4, 29, 10, 8, 1) In [190]: block_records_201645.reward_claims_incorporated[0].to_json_dict() Out[190]: {'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6', 'amount': 1750000000000} # 可以快速 print 看大部分信息 print(block_records_201645) block_records_201645 的打印结果如下。 注意，这里我截断了一些数据 {'challenge_block_info_hash': '0x4a562f1ffa7a06fe76b1df74dbdd6bdcfbf63139a6f1fc3291c606d7c976abf6', 'challenge_vdf_output': {'data': '0x0200a6b38d6b58d17129d71737088772561f22a44ef302fe45a70a763b878f998abfe35946df720bcb5d78e214b667bce801d597b46c867928c4b8926c342375a961f36cd63ec698bc25e5ce48c45d9a2074eded0e42d24dd1b50a59e699f671f0900100'}, 'deficit': 16, 'farmer_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'fees': 0, 'finished_challenge_slot_hashes': ['0x2b1a7b4859a8d3597b8e6cbe3b27ab97212be8b19e6867f2a4d0eef26c36340f'], 'finished_infused_challenge_slot_hashes': ['0xd0185a6493b10d84e696c6fc55ec1920e8a96791a604dedfe77635da460f354d'], 'finished_reward_slot_hashes': ['0xe2bcbf560471131a7fb87ffe3f9ddde03166a9b0092a50f1ed1599715857c365'], 'header_hash': '0x2791729e1c914f9c3908a0ad895b5846c86fc4e207cc463820123e9a299c39f3', 'height': 201645, 'infused_challenge_vdf_output': None, 'overflow': True, 'pool_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'prev_hash': '0xf126ecf64473beb9ae5b84137788100feb9d731c604877c0744cdc6025f4cbeb', 'prev_transaction_block_hash': '0x7103fe2f1aa96998f9ccf6fc98561b64c5f7a98cf942335c4c927fb2eaa9325a', 'prev_transaction_block_height': 201643, 'required_iters': 95752, 'reward_claims_incorporated': [{'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313aa', 'puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313a8', 'puzzle_hash': '0xcf178071f6aa6cb1c92f00943424bcc8cb774449bd60058fc08e9894f49a1ca4'}], 'reward_infusion_new_challenge': '0x660886f4ab030c07755f53362ae4253dfa93ea853cbc321218f58f159c75adaa', 'signage_point_index': 63, 'sub_epoch_summary_included': None, 'sub_slot_iters': 99614720, 'timestamp': 1619662081, 'total_iters': 660123219464, 'weight': 4121254} 另外，我们取的这个表的定义如下。 CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, #\u003c---- sub_epoch_summary blob, is_peak tinyint, is_block tinyint) 2.3.2 Chia 币记录类似的，我们可以获取一个 Coin 的记录，这里边，从表的定义可以看到，唯一二进制（不能直接从数据库查询中被人读懂）的字段就是是币值，不存在嵌套的结构，所以也并不需要封装的类才能看清楚里边的信息。 CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) 这里值得注意的信息主要","date":"2021-05-26","objectID":"/nebula-chia/:2:3","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#puzzles-address地址"},{"categories":["Nebula Graph"],"content":" 3 如何探索 Chia 链随着我们之前分析的信息，自然地，我们可以把 Chia 区块链中的信息取出来，用图（Graph）来表示，这里的图并不是（Graphic）图形、图画的意思，是数学、图论中的图。 在图的语境下，最主要的两个元素就是顶点（Vertex）和边（Edge）。 顶点表示一个实体，而边表示实体之间的某种关系，这种关系可以是对等的（无方向的）也可以是有方向的。 这里我们可以把这里的信息抽象映射到如图的图模型里： Block 顶点 Coin 顶点 Puzzle 顶点 spends 边（Block 到 Coin） confirms 边 （Block 到 Coin） belongs_to 边（Coin 到 Puzzle） 这里，我们应用的图是一种叫做属性图的形式，除了点和边的关系之外。这两种实体（点、边）还有其他信息只和它们的一个实例相关，所以再定义为顶点、边就不是很适合，这些信息就作为点、边的属性（preperty）存在。 这种为了处理实体之间关联、涉及实体、关联的属性信息的，也就是\"属性图\"的存储信息的方式在计算机领域越来越流行，甚至有专门为此结构而原生开发的数据库——图数据库（Graph Database）。 这里，我们用的就是一个叫做 Nebula Graph 的图数据库，它是一个现代的、为超大规模分部署架构设计的、原生存储、查询、计算图数据的项目，更棒的是，它是产生于社区的开源产品。 Tips: 安装 Nebula Graph 一般来说，面向超大规模数据的分布式系统，天然的都是不容易轻量部署的，大家如果第一次使用的话可以试试我写的一个叫做 nebula-up 的小工具，可以一行指令部署一个用来试用、学习的 Nebula Graph 集群，地址在这里： https://github.com/wey-gu/nebula-up/ 。 ","date":"2021-05-26","objectID":"/nebula-chia/:3:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#如何探索-chia-链"},{"categories":["Nebula Graph"],"content":" 3.1 Nebula Graph 导入 Chia 数据到图数据库我们分两步走，第一步这把 Chia Network 数据转换成 CSV 文件，第二步使用 Nebula 的 Nebula-Importer 把数据导入 Nebula Graph。 3.1.1 数据转换这部分的代码我开源在这里了: https://github.com/wey-gu/nebula-chia 使用它只需要在 Chia Network 的 python venv 下安装它: python3 -m pip install nebula-chia 然后调用 ChaiBatchConvertor 就可以在当前目录下生成两个 CSV 文件。 这里边有一些可以配置的参数，具体可以参考代码 nebulachia/convertor.py from nebulachia.convertor import ChiaBatchConvertor c = ChaiBatchConvertor( block_record_limit=0, coin_record_limit=0, write_batch_size=10000) c.convert_block_record() c.convert_coin_record() 生成的文件： $ ls -lth -rw-r--r-- 1 weyl staff 173M May 19 13:01 coin_record.csv -rw-r--r-- 1 weyl staff 77M May 19 12:59 block_record.csv 这里边字段的含义和类型，可以参考代码中 block_record_row 和 coin_record_row 的 __doc__ In [466]: print(c.coin_record_row.__doc__) Parse row and return a CSV block coin row list. CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) Coin Record CSV Head: 0 1(int) 2(int) 3(bool) coin_name|confirmed_index|spent_index|spent| 4(bool) 5 6 7(int) coinbase|puzzle_hash|coin_parent|amount| 8(timestamp) timestamp| 9 10 confirmed_hash|spent_hash In [467]: print(c.block_record_row.__doc__) Parse row and return a CSV block record row list. CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, sub_epoch_summary blob, is_peak tinyint, is_block tinyint) Block Record CSV Head: 0 1 2(int) 3(bool) 4(bool) header_hash|prev_hash|height|is_peak|is_block| 5(int) deficit| 6 challenge_block_info_hash| 7 farmer_puzzle_hash| 8(int) fees| 9 prev_transaction_block_hash| 10 prev_transaction_block_height| 11 12(int) required_iters|signage_point_index| 13(timestamp) timestamp 3.1.2 数据导入有了 CSV 文件，我们可以借助 Nebula-Importer 导入数据到图数据库中。 这里，我们写好了 nebula-importer 的配置文件，其中包涵了如下信息: 在 Nebula Graph 中创建需要的数据模型 Schema，这和我们前边做的图映射的信息是等价的 描述 CSV 文件之中的 Column 的数据到图模型（点，边，点或边的属性）映射关系 # 这里，我的 csv 文件和 配置文件都放在 /home/wei.gu/chia 之下 # 我使用 docker-compose 默认配置部署的 Nebula Graph, # 它创建了叫 nebula-docker-compose_nebula-net 的 docker 网络 docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v /home/wei.gu/chia/nebula-chia.yaml:/root/nebula-chia.yaml \\ -v /home/wei.gu/chia:/root \\ vesoft/nebula-importer:v2 \\ --config /root/nebula-chia.yaml 这里我展示一个导入的结果示例，我在单机部署的 Nebula Graph 里导入了我一两周之前取的全量 Chia Network 数据的结果。 ... 2021/05/19 09:55:09 [INFO] reader.go:180: Total lines of file(/root/coin_record.csv) is: 547557, error lines: 0 2021/05/19 09:55:09 [INFO] statsmgr.go:61: Done(/root/coin_record.csv): Time(4385.88s), Finished(4512927), Failed(0), Latency AVG(1305us), Batches Req AVG(2015us), Rows AVG(1028.42/s) 2021/05/19 09:55:10 --- END OF NEBULA IMPORTER --- ","date":"2021-05-26","objectID":"/nebula-chia/:3:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#nebula-graph-导入-chia-数据到图数据库"},{"categories":["Nebula Graph"],"content":" 3.1 Nebula Graph 导入 Chia 数据到图数据库我们分两步走，第一步这把 Chia Network 数据转换成 CSV 文件，第二步使用 Nebula 的 Nebula-Importer 把数据导入 Nebula Graph。 3.1.1 数据转换这部分的代码我开源在这里了: https://github.com/wey-gu/nebula-chia 使用它只需要在 Chia Network 的 python venv 下安装它: python3 -m pip install nebula-chia 然后调用 ChaiBatchConvertor 就可以在当前目录下生成两个 CSV 文件。 这里边有一些可以配置的参数，具体可以参考代码 nebulachia/convertor.py from nebulachia.convertor import ChiaBatchConvertor c = ChaiBatchConvertor( block_record_limit=0, coin_record_limit=0, write_batch_size=10000) c.convert_block_record() c.convert_coin_record() 生成的文件： $ ls -lth -rw-r--r-- 1 weyl staff 173M May 19 13:01 coin_record.csv -rw-r--r-- 1 weyl staff 77M May 19 12:59 block_record.csv 这里边字段的含义和类型，可以参考代码中 block_record_row 和 coin_record_row 的 __doc__ In [466]: print(c.coin_record_row.__doc__) Parse row and return a CSV block coin row list. CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) Coin Record CSV Head: 0 1(int) 2(int) 3(bool) coin_name|confirmed_index|spent_index|spent| 4(bool) 5 6 7(int) coinbase|puzzle_hash|coin_parent|amount| 8(timestamp) timestamp| 9 10 confirmed_hash|spent_hash In [467]: print(c.block_record_row.__doc__) Parse row and return a CSV block record row list. CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, sub_epoch_summary blob, is_peak tinyint, is_block tinyint) Block Record CSV Head: 0 1 2(int) 3(bool) 4(bool) header_hash|prev_hash|height|is_peak|is_block| 5(int) deficit| 6 challenge_block_info_hash| 7 farmer_puzzle_hash| 8(int) fees| 9 prev_transaction_block_hash| 10 prev_transaction_block_height| 11 12(int) required_iters|signage_point_index| 13(timestamp) timestamp 3.1.2 数据导入有了 CSV 文件，我们可以借助 Nebula-Importer 导入数据到图数据库中。 这里，我们写好了 nebula-importer 的配置文件，其中包涵了如下信息: 在 Nebula Graph 中创建需要的数据模型 Schema，这和我们前边做的图映射的信息是等价的 描述 CSV 文件之中的 Column 的数据到图模型（点，边，点或边的属性）映射关系 # 这里，我的 csv 文件和 配置文件都放在 /home/wei.gu/chia 之下 # 我使用 docker-compose 默认配置部署的 Nebula Graph, # 它创建了叫 nebula-docker-compose_nebula-net 的 docker 网络 docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v /home/wei.gu/chia/nebula-chia.yaml:/root/nebula-chia.yaml \\ -v /home/wei.gu/chia:/root \\ vesoft/nebula-importer:v2 \\ --config /root/nebula-chia.yaml 这里我展示一个导入的结果示例，我在单机部署的 Nebula Graph 里导入了我一两周之前取的全量 Chia Network 数据的结果。 ... 2021/05/19 09:55:09 [INFO] reader.go:180: Total lines of file(/root/coin_record.csv) is: 547557, error lines: 0 2021/05/19 09:55:09 [INFO] statsmgr.go:61: Done(/root/coin_record.csv): Time(4385.88s), Finished(4512927), Failed(0), Latency AVG(1305us), Batches Req AVG(2015us), Rows AVG(1028.42/s) 2021/05/19 09:55:10 --- END OF NEBULA IMPORTER --- ","date":"2021-05-26","objectID":"/nebula-chia/:3:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#数据转换"},{"categories":["Nebula Graph"],"content":" 3.1 Nebula Graph 导入 Chia 数据到图数据库我们分两步走，第一步这把 Chia Network 数据转换成 CSV 文件，第二步使用 Nebula 的 Nebula-Importer 把数据导入 Nebula Graph。 3.1.1 数据转换这部分的代码我开源在这里了: https://github.com/wey-gu/nebula-chia 使用它只需要在 Chia Network 的 python venv 下安装它: python3 -m pip install nebula-chia 然后调用 ChaiBatchConvertor 就可以在当前目录下生成两个 CSV 文件。 这里边有一些可以配置的参数，具体可以参考代码 nebulachia/convertor.py from nebulachia.convertor import ChiaBatchConvertor c = ChaiBatchConvertor( block_record_limit=0, coin_record_limit=0, write_batch_size=10000) c.convert_block_record() c.convert_coin_record() 生成的文件： $ ls -lth -rw-r--r-- 1 weyl staff 173M May 19 13:01 coin_record.csv -rw-r--r-- 1 weyl staff 77M May 19 12:59 block_record.csv 这里边字段的含义和类型，可以参考代码中 block_record_row 和 coin_record_row 的 __doc__ In [466]: print(c.coin_record_row.__doc__) Parse row and return a CSV block coin row list. CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) Coin Record CSV Head: 0 1(int) 2(int) 3(bool) coin_name|confirmed_index|spent_index|spent| 4(bool) 5 6 7(int) coinbase|puzzle_hash|coin_parent|amount| 8(timestamp) timestamp| 9 10 confirmed_hash|spent_hash In [467]: print(c.block_record_row.__doc__) Parse row and return a CSV block record row list. CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, sub_epoch_summary blob, is_peak tinyint, is_block tinyint) Block Record CSV Head: 0 1 2(int) 3(bool) 4(bool) header_hash|prev_hash|height|is_peak|is_block| 5(int) deficit| 6 challenge_block_info_hash| 7 farmer_puzzle_hash| 8(int) fees| 9 prev_transaction_block_hash| 10 prev_transaction_block_height| 11 12(int) required_iters|signage_point_index| 13(timestamp) timestamp 3.1.2 数据导入有了 CSV 文件，我们可以借助 Nebula-Importer 导入数据到图数据库中。 这里，我们写好了 nebula-importer 的配置文件，其中包涵了如下信息: 在 Nebula Graph 中创建需要的数据模型 Schema，这和我们前边做的图映射的信息是等价的 描述 CSV 文件之中的 Column 的数据到图模型（点，边，点或边的属性）映射关系 # 这里，我的 csv 文件和 配置文件都放在 /home/wei.gu/chia 之下 # 我使用 docker-compose 默认配置部署的 Nebula Graph, # 它创建了叫 nebula-docker-compose_nebula-net 的 docker 网络 docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v /home/wei.gu/chia/nebula-chia.yaml:/root/nebula-chia.yaml \\ -v /home/wei.gu/chia:/root \\ vesoft/nebula-importer:v2 \\ --config /root/nebula-chia.yaml 这里我展示一个导入的结果示例，我在单机部署的 Nebula Graph 里导入了我一两周之前取的全量 Chia Network 数据的结果。 ... 2021/05/19 09:55:09 [INFO] reader.go:180: Total lines of file(/root/coin_record.csv) is: 547557, error lines: 0 2021/05/19 09:55:09 [INFO] statsmgr.go:61: Done(/root/coin_record.csv): Time(4385.88s), Finished(4512927), Failed(0), Latency AVG(1305us), Batches Req AVG(2015us), Rows AVG(1028.42/s) 2021/05/19 09:55:10 --- END OF NEBULA IMPORTER --- ","date":"2021-05-26","objectID":"/nebula-chia/:3:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#数据导入"},{"categories":["Nebula Graph"],"content":" 3.2 探索 Chia 的图数据 3.2.1 用图数据库的 Queries导入 Chia 链的网络到 Nebula Graph 之后，我们可以在里边快速查询数据之间的关联。 比如这个查询表示从区块 524aa2013781ff4cd9d2b5dc... 查起，经过三种边 farmer_puzzle, spends, confirms 双向遍历的结果。 GO 5 STEPS FROM \\ \"524aa2013781ff4cd9d2b5dce40647b670d722e2de25bd2e2b79970a8ec435ee\" \\ OVER farmer_puzzle,spends,confirms BIDIRECT ... Got 419437 rows (time spent 735120/1170946 us) Wed, 19 May 2021 10:11:28 UTC 再比如，计算一个 Puzzle 地址上的余额（所有 coin 的总价值）比如这个puzzle bbe39134ccc32c08fdeff... GO 1 STEP FROM \"bbe39134ccc32c08fdeff4d2c19d1d1f4f7e48cdaf79d37397bc3136ce9b3cb7\" \\ OVER belongs_to REVERSELY \\ YIELD CASE $$.coin.is_spent \\ WHEN true THEN $$.coin.amount \\ WHEN false THEN -$$.coin.amount \\ END AS Amount | YIELD sum($-.Amount) 3.2.2 用 Nebula Studio 可视化探索Nebula Graph 为我们提供了图形化界面，有了它，我们可以用更符合人脑的方式地查看 Chia Network 中的数据。 比如，我们还是回到上边的那个区块，从这里查询。 我们就获得了这个 block 类型的一个点/ vertex。我们可以从他开始进一步探索，先鼠标单击这个点，在拓展条件里把方向选择双向，默认的边类型是所有的边类型，这样我们就可以把所有 步数内相关联的数据一下子全都找出来。 选择好拓展条件之后，点击拓展就可以。 这里，我们选择了步数为 1，点击拓展（或者双击要拓展的点），之后，我们可以快速双击其他的点继续拓展，这是我鼠标点了几次之后看到的样子： 我们接下来再试试拓展的步数为 2，点击拓展（或者双击要拓展的点），看起来找到了有意思的信息。 我们看到了一个有很多边的黑色的点。 通过查看这个点和我们开始查看的 block 之间的边，我们知道这个点正是 farm 这个 block 的地址，这个地址下边有非常多的 coin。 这只是一个开始，有了这个导入到 Nebula Graph 图数据的基础，我们可以做很多有意思的分析和洞察，大家可以自己试试看，得到更有意思的结果分享给其他同学。 ","date":"2021-05-26","objectID":"/nebula-chia/:3:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#探索-chia-的图数据"},{"categories":["Nebula Graph"],"content":" 3.2 探索 Chia 的图数据 3.2.1 用图数据库的 Queries导入 Chia 链的网络到 Nebula Graph 之后，我们可以在里边快速查询数据之间的关联。 比如这个查询表示从区块 524aa2013781ff4cd9d2b5dc... 查起，经过三种边 farmer_puzzle, spends, confirms 双向遍历的结果。 GO 5 STEPS FROM \\ \"524aa2013781ff4cd9d2b5dce40647b670d722e2de25bd2e2b79970a8ec435ee\" \\ OVER farmer_puzzle,spends,confirms BIDIRECT ... Got 419437 rows (time spent 735120/1170946 us) Wed, 19 May 2021 10:11:28 UTC 再比如，计算一个 Puzzle 地址上的余额（所有 coin 的总价值）比如这个puzzle bbe39134ccc32c08fdeff... GO 1 STEP FROM \"bbe39134ccc32c08fdeff4d2c19d1d1f4f7e48cdaf79d37397bc3136ce9b3cb7\" \\ OVER belongs_to REVERSELY \\ YIELD CASE $$.coin.is_spent \\ WHEN true THEN $$.coin.amount \\ WHEN false THEN -$$.coin.amount \\ END AS Amount | YIELD sum($-.Amount) 3.2.2 用 Nebula Studio 可视化探索Nebula Graph 为我们提供了图形化界面，有了它，我们可以用更符合人脑的方式地查看 Chia Network 中的数据。 比如，我们还是回到上边的那个区块，从这里查询。 我们就获得了这个 block 类型的一个点/ vertex。我们可以从他开始进一步探索，先鼠标单击这个点，在拓展条件里把方向选择双向，默认的边类型是所有的边类型，这样我们就可以把所有 步数内相关联的数据一下子全都找出来。 选择好拓展条件之后，点击拓展就可以。 这里，我们选择了步数为 1，点击拓展（或者双击要拓展的点），之后，我们可以快速双击其他的点继续拓展，这是我鼠标点了几次之后看到的样子： 我们接下来再试试拓展的步数为 2，点击拓展（或者双击要拓展的点），看起来找到了有意思的信息。 我们看到了一个有很多边的黑色的点。 通过查看这个点和我们开始查看的 block 之间的边，我们知道这个点正是 farm 这个 block 的地址，这个地址下边有非常多的 coin。 这只是一个开始，有了这个导入到 Nebula Graph 图数据的基础，我们可以做很多有意思的分析和洞察，大家可以自己试试看，得到更有意思的结果分享给其他同学。 ","date":"2021-05-26","objectID":"/nebula-chia/:3:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#用图数据库的-queries"},{"categories":["Nebula Graph"],"content":" 3.2 探索 Chia 的图数据 3.2.1 用图数据库的 Queries导入 Chia 链的网络到 Nebula Graph 之后，我们可以在里边快速查询数据之间的关联。 比如这个查询表示从区块 524aa2013781ff4cd9d2b5dc... 查起，经过三种边 farmer_puzzle, spends, confirms 双向遍历的结果。 GO 5 STEPS FROM \\ \"524aa2013781ff4cd9d2b5dce40647b670d722e2de25bd2e2b79970a8ec435ee\" \\ OVER farmer_puzzle,spends,confirms BIDIRECT ... Got 419437 rows (time spent 735120/1170946 us) Wed, 19 May 2021 10:11:28 UTC 再比如，计算一个 Puzzle 地址上的余额（所有 coin 的总价值）比如这个puzzle bbe39134ccc32c08fdeff... GO 1 STEP FROM \"bbe39134ccc32c08fdeff4d2c19d1d1f4f7e48cdaf79d37397bc3136ce9b3cb7\" \\ OVER belongs_to REVERSELY \\ YIELD CASE $$.coin.is_spent \\ WHEN true THEN $$.coin.amount \\ WHEN false THEN -$$.coin.amount \\ END AS Amount | YIELD sum($-.Amount) 3.2.2 用 Nebula Studio 可视化探索Nebula Graph 为我们提供了图形化界面，有了它，我们可以用更符合人脑的方式地查看 Chia Network 中的数据。 比如，我们还是回到上边的那个区块，从这里查询。 我们就获得了这个 block 类型的一个点/ vertex。我们可以从他开始进一步探索，先鼠标单击这个点，在拓展条件里把方向选择双向，默认的边类型是所有的边类型，这样我们就可以把所有 步数内相关联的数据一下子全都找出来。 选择好拓展条件之后，点击拓展就可以。 这里，我们选择了步数为 1，点击拓展（或者双击要拓展的点），之后，我们可以快速双击其他的点继续拓展，这是我鼠标点了几次之后看到的样子： 我们接下来再试试拓展的步数为 2，点击拓展（或者双击要拓展的点），看起来找到了有意思的信息。 我们看到了一个有很多边的黑色的点。 通过查看这个点和我们开始查看的 block 之间的边，我们知道这个点正是 farm 这个 block 的地址，这个地址下边有非常多的 coin。 这只是一个开始，有了这个导入到 Nebula Graph 图数据的基础，我们可以做很多有意思的分析和洞察，大家可以自己试试看，得到更有意思的结果分享给其他同学。 ","date":"2021-05-26","objectID":"/nebula-chia/:3:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#用-nebula-studio-可视化探索"},{"categories":["Nebula Graph"],"content":" 4 总结这篇文章里，在我们简单介绍了 Chia Network 之后，我们首次的带大家一起从安装一个 Chia 终端，到分析终端同步到本地的 Chia 全网数据，借助于 Chia 终端开源的 Python 代码库，我们分析了全网数据里的重要信息。 之后，我们开源了一个小工具 Nebula-Chia，有了它，就可以把 Chia 的全网数据转换成 CSV 格式，这样，就可以借助 nebula-importer 把所有的数据导入到一个先进的图数据库（Nebula Graph）中。 Nebula Graph 的项目地址是 https://github.com/vesoft-inc/nebula-graph Nebula-Chia 我也开源在 https://github.com/wey-gu/nebula-chia 在图数据库中，我们展示了做基本 Query 的例子和借助图数据库自带的可视化工具，我们可以轻易地获取 Chia 全网数据之间关联关系，有了这个作为基础，这些数据中洞察的潜力和可以尝试的有意思事情可以比较直观和高效地进一步探索了！ 是不是很酷？ ","date":"2021-05-26","objectID":"/nebula-chia/:4:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#总结"},{"categories":["Nebula Graph"],"content":" 5 引用 https://www.chia.net/faq/ https://chialisp.com/docs/ https://www.chiaexplorer.com/chia-coins https://docs.google.com/document/d/1tmRIb7lgi4QfKkNaxuKOBHRmwbVlGL4f7EsBDr_5xZE https://github.com/sipa/bech32/tree/master/ref/python https://github.com/Chia-Network/chia-blockchain/blob/main/README.md https://www.chia.net/assets/ChiaGreenPaper.pdf https://docs.nebula-graph.com.cn 题图版权：Icons8 Team ","date":"2021-05-26","objectID":"/nebula-chia/:5:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#引用"},{"categories":null,"content":" Nebula-Corp-Rel-Graph Nebula-Corp-Rel-Graph，基于图数据库的股权穿透系统 阅读全文 Nebula-Siwi Nebula-Siwi，基于图数据库的智能问答助手 阅读全文 Nebula-Holdshare Nebula-Holdshare，图数据库应用示例：股权关系穿透 阅读全文 Nebula-KIND Nebula-Kind，无需依赖，一键安装尝鲜基于 Nebula Operator 的 K8s Nebula Graph Cluster。注： KIND 是一个 K8s 的 SIG，代表 K8s in Docker。 阅读全文 Nebula-Up Nebula-up，一键拉起一个 Nebula 测试环境，支持 mscOS，Windows 10，CentOS 和 Ubuntu。 阅读全文 VSCode-nGQL VSCode-nGQL，Nebula Graph 的 VS Code 插件，ngql 语法高亮。 阅读全文 Nebula-Chia Nebula-Chia，将 Chia Network 全链导入 Nebula Graph 中的探索分享和转换工具（一并开源出来）。 阅读全文 IPython-nGQL Nebula Graph 的 Jupyter Notebook 和 IPython 插件，方便在 Notebook 之中嵌入 nGQL 的 query 和 结果的调试。 阅读全文 nebula-insights 本文介绍我们如何用公有云 Serverless 技术：Google Cloud Scheduler，Google Cloud Functions 和 BigQuery 搭建数据管道，收集探索开源社区洞察。并将全部代码开源在 GitHub。 阅读全文 ","date":"2021-05-26","objectID":"/projects/:0:0","series":null,"tags":null,"title":"个人项目","uri":"/projects/#"},{"categories":null,"content":" Nebula Operator Explained Nebula Graph K8s Operator 介绍 阅读全文 Nebula Config Explained Nebula Graph 配置详解 阅读全文 Nebula Index Demystified Nebula Graph 原生索引解谜 阅读全文 Nebula Data Import Options Nebula Graph 提供了好多种数据导入的工具，我们应该如何选择呢？ 阅读全文 Nebula Deployment Options Nebula Graph 有很多种分发、部署方式，我们应该如何选择它们呢？ 阅读全文 Nebula Intro 新手玩转 Nebula Graph 系列开篇。 阅读全文 ","date":"2021-05-26","objectID":"/sketch-notes/:0:0","series":null,"tags":null,"title":"手绘笔记","uri":"/sketch-notes/#"},{"categories":["sketches"],"content":"Nebula Graph Core Arch.","date":"2021-05-25","objectID":"/sketches/nebula-core-arch/","series":null,"tags":["Nebula Graph","Core"],"title":"Nebula Core Arch","uri":"/sketches/nebula-core-arch/"},{"categories":["sketches"],"content":" 1 Bilibili 上 下 ","date":"2021-05-25","objectID":"/sketches/nebula-core-arch/:1:0","series":null,"tags":["Nebula Graph","Core"],"title":"Nebula Core Arch","uri":"/sketches/nebula-core-arch/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube 上 下 ","date":"2021-05-25","objectID":"/sketches/nebula-core-arch/:2:0","series":null,"tags":["Nebula Graph","Core"],"title":"Nebula Core Arch","uri":"/sketches/nebula-core-arch/#youtube"},{"categories":["Nebula Graph"],"content":"VSCode-ngql 是 Nebula Graph 的 VS Code 之中对 nGQL 语法高亮的插件。","date":"2021-05-05","objectID":"/vscode-ngql/","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/"},{"categories":["Nebula Graph"],"content":" VSCode-ngql 是 Nebula Graph 的 VS Code 之中对 nGQL 语法高亮的插件。 您可以从 这里 直接下载安装试用。 ","date":"2021-05-05","objectID":"/vscode-ngql/:0:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#"},{"categories":["Nebula Graph"],"content":" VS Code nGQL Syntax Highlight ","date":"2021-05-05","objectID":"/vscode-ngql/:0:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#vs-code-ngql-syntax-highlight"},{"categories":["Nebula Graph"],"content":" 1 DownloadSearch ngql from the market or click here. ","date":"2021-05-05","objectID":"/vscode-ngql/:1:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#download"},{"categories":["Nebula Graph"],"content":" 2 Features Highlighting all Keywords, Functions of a given .ngql file ","date":"2021-05-05","objectID":"/vscode-ngql/:2:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#features"},{"categories":["Nebula Graph"],"content":" 3 Release Notes","date":"2021-05-05","objectID":"/vscode-ngql/:3:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#release-notes"},{"categories":["Nebula Graph"],"content":" 3.1 0.0.1Initial release, only .ngql Syntax is supported. ","date":"2021-05-05","objectID":"/vscode-ngql/:3:1","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#001"},{"categories":["Nebula Graph"],"content":" 3.2 0.0.2Lower supported vscode version till ^1.50.1 ","date":"2021-05-05","objectID":"/vscode-ngql/:3:2","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#002"},{"categories":["Nebula Graph"],"content":" 4 Reference https://docs.nebula-graph.com.cn/ https://github.com/vesoft-inc/nebula-graph/blob/master/src/parser/scanner.lex ","date":"2021-05-05","objectID":"/vscode-ngql/:4:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#reference"},{"categories":["Big Data","Cloud"],"content":"本文介绍我们如何用公有云 Serverless 技术：Google Cloud Scheduler，Google Cloud Functions 和 BigQuery 搭建数据管道，收集探索开源社区洞察。并将全部代码开源在 GitHub。","date":"2021-05-03","objectID":"/nebula-insights/","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/"},{"categories":["Big Data","Cloud"],"content":" 这是我首发在 Datawhale 的文章，介绍我们如何用公有云 Serverless 技术：Google Cloud Scheduler，Google Cloud Functions 和 BigQuery 搭建数据管道，收集探索开源社区洞察。并将全部代码开源在 GitHub。 引子 我们想要收集一些帮助 Nebula Graph 社区运营的 metrics，希望能从不同来源的数据自动化周期性收集、处理、并方便地展现出来做数据驱动分析的基础设施。 Nebula Graph 是一个现代的开源分布式图数据库(Graph Database)，欢迎同学们从: 官网: https://nebula-graph.com.cn Bilibili: https://space.bilibili.com/472621355 GitHub:https://github.com/vesoft-inc/nebula-graph 了解我们哈。 ","date":"2021-05-03","objectID":"/nebula-insights/:0:0","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#"},{"categories":["Big Data","Cloud"],"content":" 1 需求 方便增加新的数据 数据收集无需人为触发（自动、周期性） 每天数据量不超过1000条 数据可以生成 dashboard，也可以支持统计分期 query 高可用，数据安全 低预算，尽可能不需要运维人力 ","date":"2021-05-03","objectID":"/nebula-insights/:1:0","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#需求"},{"categories":["Big Data","Cloud"],"content":" 1.1 需求分析我们需要搭建一个系统能实现 一个能周期性触发获取数据的事件的服务: scheduler 一个触发之后，把数据 ETL 到数据库中的服务: ETL worker 一个数据仓库 一个能够把数据库作为源，允许用户 query，展示数据的界面: Data-UI 这个需求的特点是虽然数据量很小、但是要求服务高可用、安全。因为这种情况下自建服务器还需要保证HA和数据安全会一定会消耗昂贵运维人力，所以我们应该尽量避免在自己维护的服务器中搭建 scheduler, 和数据库。 最终，我们选择了尽量使用公有云的 aaS 的方案: ┌──────────────────────────┐ │ │ │ Google Cloud Scheduler │ │ │ └────────────┬─────────────┘ │ ┌─────────────────────┐ │ │ │ ┌────────────▼─────────────┐ ┌───────────► GitHub API Server │ │ │ │ │ │ │ Google Cloud Functions ├───┤ └─────────────────────┘ │ │ │ └────────────┬─────────────┘ │ ┌─────────────────────────┐ │ │ │ │ │ ├───────────► Docker Hub API Server │ ┌─────────▼─────────┐ │ │ │ │ │ │ │ │ │ Google BigQuery │ │ └─────────────────────────┘ │ │ ├───────────► ... └─────────▲─────────┘ │ ┌──────────────────┐ │ │ │ │ │ └───────────► Aliyun OSS API │ ┌──────────┴───────────┐ │ │ │ │ └──────────────────┘ │ Google Data Studio │ │ ┌──┐ │ │ ┌──┐ │ │ ┌──┐ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──┴──┴─┴──┴─┴──┴──────┘ 因为我个人比较熟悉 Google Cloud Platform(GCP)的原因，加上GCP在大数据处理上比较领先，再加上Google提供的 free tier额度非常大方，以至于在我们这个数据量下，所有workload都会是免费的。 这个方案最后选择了全栈 Google Cloud，然而，这实际上只是一个参考，同学们完全可以在其他公有云提供商那里找到对应的服务。 这里我简单介绍一下， Google Cloud Scheduler是自解释的，不用多介绍了。 而 Google Cloud Functions是GCP的无服务器(serverless)的 Function as a Service服务，它的好处是我们可以把无状态的 event-driven 的 workload 代码放上去，它是按需付费（pay as you go)的，类似的服务还有 Google Cloud Run，后者的区别在于我们提供的是一个docker/container（这使得能支持的运行环境可以使任何能跑在容器里的东西），而 Cloud Functions是把我们的代码文件放上去。他们的效果是类似的，因为我准备用Python来做 ETL的东西，Clouf Functions已经支持了，我就直接选择它了。 在scheduler里边，我定义了每一天它发一个 pub/sub（类似于kafka，这里google可以保证至少发成功一次）消息给 Cloud Functions，然后 Cloud Functions会去做 ETL的工作。 这里，实际上我的设计里这个触发的函数调会把数据从API那里获取下来，在内存里处理好之后，存储到在对象存储里为 JSON 文件，然后再调用 Google BigQuery 的 API让 BigQuery直接从对对象存储里拉取 JSON 文件，导入记录到相应的表之中。 Google BigQuery 作为GCP 特别有竞争力的一个产品，是它数据仓库，BigQuery 可以无限扩容，支持海量数据导入，支持 SQL-like 的 query，还自带ML算法，通过SQL就能调用这些算法。它可以和很多GCP以及第三方的组件可以集成起来。 Google Data Studio 是GCP的数据 Insights产品，如果大家用过 Google Analytics 应该已经用过它了。 ","date":"2021-05-03","objectID":"/nebula-insights/:1:1","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#需求分析"},{"categories":["Big Data","Cloud"],"content":" 1.2 数据的获取，API我们第一阶段想要收集的数据来源是 GitHub 上，社区项目的统计数据、Docker Hub上，社区镜像的拉取计数，之后，会增加更多维度的数据。 Github API, ref: https://pygithub.readthedocs.io 这里我们利用了一个Github API的一个 Python 封装，下边是在 IDLE/iPython/Jupyter 里尝试的例子 # 实例化一个client g = Github(login_or_token=token, timeout=60, retry=Retry( total=10, status_forcelist=(500, 502, 504), backoff_factor=0.3)) # 配置好要获取的repo的信息 org_str = \"vesoft-inc\" org = g.get_organization(org_str) repos = org.get_repos() # 这里repos是一个迭代器，方便看到里边的东西，我们把它 list 一下可以看到所有的repo: list(repos) [Repository(full_name=\"vesoft-inc/nebula\"), Repository(full_name=\"vesoft-inc/nebula-docs\"), Repository(full_name=\"vesoft-inc/nebula-dev-docker\"), Repository(full_name=\"vesoft-inc/github-statistics\"), Repository(full_name=\"vesoft-inc/nebula-docker-compose\"), Repository(full_name=\"vesoft-inc/nebula-go\"), Repository(full_name=\"vesoft-inc/nebula-java\"), Repository(full_name=\"vesoft-inc/nebula-python\"), Repository(full_name=\"vesoft-inc/nebula-importer\"), Repository(full_name=\"vesoft-inc/nebula-third-party\"), Repository(full_name=\"vesoft-inc/nebula-storage\"), Repository(full_name=\"vesoft-inc/nebula-graph\"), Repository(full_name=\"vesoft-inc/nebula-common\"), Repository(full_name=\"vesoft-inc/nebula-stats-exporter\"), Repository(full_name=\"vesoft-inc/nebula-web-docker\"), Repository(full_name=\"vesoft-inc/nebula-bench\"), Repository(full_name=\"vesoft-inc/nebula-console\"), Repository(full_name=\"vesoft-inc/nebula-docs-cn\"), Repository(full_name=\"vesoft-inc/nebula-chaos\"), Repository(full_name=\"vesoft-inc/nebula-clients\"), Repository(full_name=\"vesoft-inc/nebula-spark-utils\"), Repository(full_name=\"vesoft-inc/nebula-node\"), Repository(full_name=\"vesoft-inc/nebula-rust\"), Repository(full_name=\"vesoft-inc/nebula-cpp\"), Repository(full_name=\"vesoft-inc/nebula-http-gateway\"), Repository(full_name=\"vesoft-inc/nebula-flink-connector\"), Repository(full_name=\"vesoft-inc/nebula-community\"), Repository(full_name=\"vesoft-inc/nebula-br\"), Repository(full_name=\"vesoft-inc/.github\")] # repo0 是 vesoft-inc/nebula 这个repo，我们可以通过 get_clones_traffic，get_views_traffic 来获取过去十几天的 clone，view 统计 In [16]: repo0.get_clones_traffic() Out[16]: {'count': 362, 'uniques': 150, 'clones': [Clones(uniques=5, timestamp=2021-04-06 00:00:00, count=16), Clones(uniques=8, timestamp=2021-04-07 00:00:00, count=23), Clones(uniques=13, timestamp=2021-04-08 00:00:00, count=30), Clones(uniques=33, timestamp=2021-04-09 00:00:00, count=45), Clones(uniques=2, timestamp=2021-04-10 00:00:00, count=13), Clones(uniques=6, timestamp=2021-04-11 00:00:00, count=19), Clones(uniques=15, timestamp=2021-04-12 00:00:00, count=28), Clones(uniques=40, timestamp=2021-04-13 00:00:00, count=54), Clones(uniques=9, timestamp=2021-04-14 00:00:00, count=21), Clones(uniques=10, timestamp=2021-04-15 00:00:00, count=34), Clones(uniques=10, timestamp=2021-04-16 00:00:00, count=23), Clones(uniques=5, timestamp=2021-04-17 00:00:00, count=17), Clones(uniques=2, timestamp=2021-04-18 00:00:00, count=13), Clones(uniques=9, timestamp=2021-04-19 00:00:00, count=23), Clones(uniques=3, timestamp=2021-04-20 00:00:00, count=3)]} In [17]: repo0.get_views_traffic() Out[17]: {'count': 6019, 'uniques': 1134, 'views': [View(uniques=52, timestamp=2021-04-06 00:00:00, count=169), View(uniques=143, timestamp=2021-04-07 00:00:00, count=569), View(uniques=152, timestamp=2021-04-08 00:00:00, count=635), View(uniques=134, timestamp=2021-04-09 00:00:00, count=648), View(uniques=81, timestamp=2021-04-10 00:00:00, count=318), View(uniques=42, timestamp=2021-04-11 00:00:00, count=197), View(uniques=127, timestamp=2021-04-12 00:00:00, count=515), View(uniques=149, timestamp=2021-04-13 00:00:00, count=580), View(uniques=134, timestamp=2021-04-14 00:00:00, count=762), View(uniques=141, timestamp=2021-04-15 00:00:00, count=385), View(uniques=113, timestamp=2021-04-16 00:00:00, count=284), View(uniques=48, timestamp=2021-04-17 00:00:00, count=168), View(uniques=35, timestamp=2021-04-18 00:00:00, count=135), View(uniques=124, timestamp=2021-04-19 00:00:00, co","date":"2021-05-03","objectID":"/nebula-insights/:1:2","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#数据的获取api"},{"categories":["Big Data","Cloud"],"content":" 2 实现","date":"2021-05-03","objectID":"/nebula-insights/:2:0","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#实现"},{"categories":["Big Data","Cloud"],"content":" 2.1 计划任务调度 with Cloud Scheduler前边提到，Scheduler --\u003e Functions 中间是通过消息队列实现的可靠事件触发，我们需要在 Google Cloud Pub/Sub里创建一个订阅消息，后边我们会把这个订阅消息从 Scheduler 定期发送，并且在 Function创建的时候定义为触发条件。 $ gcloud pubsub topics create nebula-insights-cron-topic $ gcloud pubsub subscriptions create cron-sub --topic nebula-insights-cron-topic 任务的创建非常直接，在 Scheduler Web Console 上直接图形化操作就可以了，记得要选择触发 Pub/Sub 消息为 cron-sub，消息主题为 nebula-insights-cron-topic ","date":"2021-05-03","objectID":"/nebula-insights/:2:1","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#计划任务调度-with-cloud-scheduler"},{"categories":["Big Data","Cloud"],"content":" 2.2 ETL Worker with Python + Google Functions当 Scheduler 每天定时发送消息之后，接收方就是我们要定义的 Google Functions了，它的定义如图 第一步，选择它的触发类型为 Pub/Sub，同时要定义消息的主题和名字。 第二步就是把代码放进去: ┌─────────────────────┐ │ │ ┌──────────────────────────┐ ┌───────────► GitHub API Server │ │ │ │ │ │ │ Google Cloud Functions ◄───► └─────────────────────┘ │ │ │ └────────────▲─────────────┘ │ ┌─────────────────────────┐ │ │ │ │ │ ├───────────► Docker Hub API Server │ ┌────────────▼────────────┐ │ │ │ │ │ │ │ │ │ Google Cloud Storage │ │ └─────────────────────────┘ │ │ ... └────────────┬────────────┘ │ ┌──────────────────┐ │ │ │ │ │ └───────────► Aliyun OSS API │ ┌─────────▼─────────┐ │ │ │ │ └──────────────────┘ │ Google BigQuery │ │ │ └───────────────────┘ 这部分的逻辑就是通过前边分析了的API取得信息，然后组装成需要的格式存到 Cloud Storage(对象存储），然后再导入到 BigQuery（数仓）之中，全部代码在GitHub上: https://github.com/wey-gu/nebula-insights/blob/main/functions/data-fetching-0/main.py 另外，可以参考这个官方教程 https://cloud.google.com/scheduler/docs/tut-pub-sub ","date":"2021-05-03","objectID":"/nebula-insights/:2:2","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#etl-worker-with-python--google-functions"},{"categories":["Big Data","Cloud"],"content":" 2.3 数仓表结构定义数仓的表结构比较直接，schema的图贴在下边了，值得注意的是，BigQuery支持嵌套的表结构（而不像一般关系型数据库那样需要把这样的逻辑结构用辅助表来表示），在我们这个场景下非常方便，比如release表中的 assets的三个嵌套字段。 更详细的信息可以参考GitHub上的介绍和代码: https://github.com/wey-gu/nebula-insights#data-etl-bigquery-and-gcs ","date":"2021-05-03","objectID":"/nebula-insights/:2:3","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#数仓表结构定义"},{"categories":["Big Data","Cloud"],"content":" 2.4 数据可视化到这里，我们就可以自动在BigQuery里存有每天收集的不同来源的统计数据啦，有了它，我们可以借助 Data Studio 来生成各式各样的可视化表示。 参考 https://cloud.google.com/bigquery/docs/visualize-data-studio ","date":"2021-05-03","objectID":"/nebula-insights/:2:4","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#数据可视化"},{"categories":["Big Data","Cloud"],"content":" 3 总结这样，我们实际上不需要任何认为维护的成本和投入，就搭建了一整个数据的流水线，并且只需要按照数据用量付费，在我们的数据量下，及时考虑未来增加数十个新的量度的收集，我们依然没有达到需要付费的用量，是不是很Cool？ 因为数据同时存在于对象存储与数仓里，我们可以方便随时把数据导入任意其他平台上。 BigQuery还有一些非常常用的，自带的机器学习的功能，只需要写一个SQL-Like的query就能触发然后获得预测结果，如果我们用到这些功能的话也会回到 datawhale 为同学们继续分享哈。 第一次做数据工程方面的分享，如果有错误的地方欢迎大家不吝指出哈~~ 谢谢！ ","date":"2021-05-03","objectID":"/nebula-insights/:3:0","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#总结"},{"categories":["Nebula Graph"],"content":"Nebula-up，一键拉起一个 Nebula 测试环境，包括 Nebula BR、Exchange、Algorithm、Dashboard、Studio","date":"2021-04-26","objectID":"/nebula-up/","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/"},{"categories":["Nebula Graph"],"content":" Update: the All-in-one mode is introduced! Check here and try it! Nebula-Up is PoC utility to enable developer to bootstrap an nebula-graph cluster with nebula-graph-studio(Web UI) + nebula-graph-console(Command UI) ready out of box in an oneliner run. All required packages will handled with nebula-up as well, including Docker on Linux(Ubuntu/CentOS), Docker Desktop on macOS(including both Intel and M1 chip based), and Docker Desktop Windows. Also, it’s optimized to leverage China Repo Mirrors(docker, brew, gitee, etc…) in case needed enable a smooth deployment for both Mainland China users and others. macOS and Linux with Shell: curl -fsSL nebula-up.siwei.io/install.sh | bash Note: you could specify the version of Nebula Graph like: curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v2.6 ","date":"2021-04-26","objectID":"/nebula-up/:0:0","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#"},{"categories":["Nebula Graph"],"content":" 1 All-in-one modeWith all-in-one mode, you could play with many Nebula Tools in one command, too: Supported tools: Nebula Dashboard Nebula Graph Studio Nebula Graph Console Nebula BR(backup \u0026 restore) Nebula Graph Spark utils Nebula Graph Spark Connector/PySpark Nebula Graph Algorithm Nebula Graph Exchange Nebula Graph Importer Nebula Graph Fulltext Search Nebula Bench ","date":"2021-04-26","objectID":"/nebula-up/:1:0","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#all-in-one-mode"},{"categories":["Nebula Graph"],"content":" 1.1 Install all in one # Install Nebula Core with all-in-one mode curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash ","date":"2021-04-26","objectID":"/nebula-up/:1:1","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#install-all-in-one"},{"categories":["Nebula Graph"],"content":" 1.2 Install Nebula Core and One of the coponent: # Install Core with Backup and Restore with MinIO curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 br # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark # Install Core with Dashboard curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 dashboard ","date":"2021-04-26","objectID":"/nebula-up/:1:2","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#install-nebula-core-and-one-of-the-coponent"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be \u003chost-ip\u003e:9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#how-to-play-with-all-in-one-mode"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#console-and-basketballplayer-dataset-loading"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#monitor-the-whole-cluster-with-nebula-dashboard"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#access-nebula-graph-studio"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#query-data-with-nebula-spark-connector-in-pyspark-shell"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#run-nebula-exchange"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#run-nebula-graph-algorithm"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#try-backup-and-restore-with-minio-as-storage"},{"categories":["Nebula Graph"],"content":"Nebula Graph 的 Jupyter Notebook 和 IPython 插件，方便在 Notebook 之中嵌入 nGQL 的 query 和 结果的调试。","date":"2021-03-07","objectID":"/ipython-ngql/","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/"},{"categories":["Nebula Graph"],"content":" Nebula Graph 的 Jupyter Notebook 和 IPython 插件，方便在 Notebook 之中嵌入 nGQL 的 query 和 结果的调试。 ipython-ngql is a python package to extend the ability to connect Nebula Graph from your Jupyter Notebook or iPython. It’s easier for data scientists to create, debug and share reusable and all-in-one Jupyter Notebooks with Nebula Graph interaction embedded. ipython-ngql is inspired by ipython-sql created by Catherine Devlin ","date":"2021-03-07","objectID":"/ipython-ngql/:0:0","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#"},{"categories":["Nebula Graph"],"content":" 1 Get Started","date":"2021-03-07","objectID":"/ipython-ngql/:1:0","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#get-started"},{"categories":["Nebula Graph"],"content":" 1.1 Installationipython-ngql could be installed either via pip or from this git repo itself. Install via pip pip install ipython-ngql Install inside the repo git clone git@github.com:wey-gu/ipython-ngql.git cd ipython-ngql python setup.py install ","date":"2021-03-07","objectID":"/ipython-ngql/:1:1","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#installation"},{"categories":["Nebula Graph"],"content":" 1.2 Load it in Jupyter Notebook or iPython %load_ext ngql ","date":"2021-03-07","objectID":"/ipython-ngql/:1:2","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#load-it-in-jupyter-notebook-or-ipython"},{"categories":["Nebula Graph"],"content":" 1.3 Connect to Nebula GraphArguments as below are needed to connect a Nebula Graph DB instance: Argument Description --address or -addr IP address of the Nebula Graph Instance --port or -P Port number of the Nebula Graph Instance --user or -u User name --password or -p Password Below is an exmple on connecting to 127.0.0.1:9669 with username: “user” and password: “password”. %ngql --address 127.0.0.1 --port 9669 --user user --password password ","date":"2021-03-07","objectID":"/ipython-ngql/:1:3","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#connect-to-nebula-graph"},{"categories":["Nebula Graph"],"content":" 1.4 Make QueriesNow two kind of iPtython Magics are supported: Option 1: The one line stype with %ngql: %ngql GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id; Option 2: The multiple lines stype with %%ngql %%ngql USE pokemon_club; SHOW TAGS; SHOW HOSTS; There will be other options in future, i.e. from a .ngql file. ","date":"2021-03-07","objectID":"/ipython-ngql/:1:4","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#make-queries"},{"categories":["Nebula Graph"],"content":" 1.5 Query String with Variablesipython-ngql supports taking variables from the local namespace, with the help of Jinja2 template framework, it’s supported to have queries like the below example. The actual query string should be GO FROM \"Sue\" OVER owns_pokemon ..., and \"{{ trainer }}\" was renderred as \"Sue\" by consuming the local variable trainer: In [8]: trainer = \"Sue\" In [9]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: Out[9]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey ","date":"2021-03-07","objectID":"/ipython-ngql/:1:5","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#query-string-with-variables"},{"categories":["Nebula Graph"],"content":" 1.6 Configure ngql_result_styleBy default, ipython-ngql will use pandas dataframe as output style to enable more human readable output, while it’s supported to use the raw thrift data format comes from the nebula2-python itself. This can be done ad-hoc with below one line: %config IPythonNGQL.ngql_result_style=\"raw\" After above line being executed, the output will be like: ResultSet(ExecutionResponse( error_code=0, latency_in_us=2844, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) The result are always stored in variable _ in Jupyter Notebook, thus, to tweak the result, just refer a new var to it like: In [10]: %config IPythonNGQL.ngql_result_style=\"raw\" In [11]: %%ngql USE pokemon_club; ...: GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id ...: | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[11]: ResultSet(ExecutionResponse( error_code=0, latency_in_us=3270, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) In [12]: r = _ In [13]: r.column_values(key='Trainer_Name')[0]._value.value Out[13]: b'Tom' ","date":"2021-03-07","objectID":"/ipython-ngql/:1:6","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#configure-ngql_result_style"},{"categories":["Nebula Graph"],"content":" 1.7 Get HelpDon’t remember anything or even relying on the cheatsheet here, oen takeaway for you: the help! In [7]: %ngql help Supported Configurations: ------------------------ \u003e How to config ngql_result_style in \"raw\", \"pandas\" %config IPythonNGQL.ngql_result_style=\"raw\" %config IPythonNGQL.ngql_result_style=\"pandas\" \u003e How to config ngql_verbose in True, False %config IPythonNGQL.ngql_verbose=True \u003e How to config max_connection_pool_size %config IPythonNGQL.max_connection_pool_size=10 Quick Start: ----------- \u003e Connect to Neubla Graph %ngql --address 127.0.0.1 --port 9669 --user user --password password \u003e Use Space %ngql USE nba \u003e Query %ngql SHOW TAGS; \u003e Multile Queries %%ngql SHOW TAGS; SHOW HOSTS; Reload ngql Magic %reload_ext ngql \u003e Variables in query, we are using Jinja2 here name = \"nba\" %ngql USE \"{{ name }}\" ","date":"2021-03-07","objectID":"/ipython-ngql/:1:7","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#get-help"},{"categories":["Nebula Graph"],"content":" 1.8 Examples 1.8.1 Jupyter NotebookPlease refer here:https://github.com/wey-gu/ipython-ngql/blob/main/examples/get_started.ipynb 1.8.2 iPython venv ❯ ipython In [1]: %load_ext ngql In [2]: %ngql --address 127.0.0.1 --port 9669 --user user --password password Connection Pool Created Out[2]: Name 0 pokemon_club In [3]: %ngql GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name Out[3]: Trainer_Name 0 Tom 1 Jerry 2 Sue 3 Tom 4 Wey In [4]: %%ngql ...: SHOW TAGS; ...: SHOW HOSTS; ...: ...: Out[4]: Host Port Status Leader count Leader distribution Partition distribution 0 storaged0 9779.0 ONLINE 0 No valid partition No valid partition 1 storaged1 9779.0 ONLINE 1 pokemon_club:1 pokemon_club:1 2 storaged2 9779.0 ONLINE 0 No valid partition No valid partition 3 Total NaN None 1 pokemon_club:1 pokemon_club:1 In [5]: trainer = \"Sue\" In [6]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: Out[6]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [7]: %ngql help Supported Configurations: ------------------------ \u003e How to config ngql_result_style in \"raw\", \"pandas\" %config IPythonNGQL.ngql_result_style=\"raw\" %config IPythonNGQL.ngql_result_style=\"pandas\" \u003e How to config ngql_verbose in True, False %config IPythonNGQL.ngql_verbose=True \u003e How to config max_connection_pool_size %config IPythonNGQL.max_connection_pool_size=10 Quick Start: ----------- \u003e Connect to Neubla Graph %ngql --address 127.0.0.1 --port 9669 --user user --password password \u003e Use Space %ngql USE nba \u003e Query %ngql SHOW TAGS; \u003e Multile Queries %%ngql SHOW TAGS; SHOW HOSTS; Reload ngql Magic %reload_ext ngql \u003e Variables in query, we are using Jinja2 here name = \"nba\" %ngql USE \"{{ name }}\" In [8]: trainer = \"Sue\" In [9]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[9]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [10]: %config IPythonNGQL.ngql_result_style=\"raw\" In [11]: %%ngql USE pokemon_club; ...: GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id ...: | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[11]: ResultSet(ExecutionResponse( error_code=0, latency_in_us=3270, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) In [12]: r = _ In [13]: r.column_values(key='Trainer_Name')[0]._value.value Out[13]: b'Tom' ","date":"2021-03-07","objectID":"/ipython-ngql/:1:8","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#examples"},{"categories":["Nebula Graph"],"content":" 1.8 Examples 1.8.1 Jupyter NotebookPlease refer here:https://github.com/wey-gu/ipython-ngql/blob/main/examples/get_started.ipynb 1.8.2 iPython venv ❯ ipython In [1]: %load_ext ngql In [2]: %ngql --address 127.0.0.1 --port 9669 --user user --password password Connection Pool Created Out[2]: Name 0 pokemon_club In [3]: %ngql GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name Out[3]: Trainer_Name 0 Tom 1 Jerry 2 Sue 3 Tom 4 Wey In [4]: %%ngql ...: SHOW TAGS; ...: SHOW HOSTS; ...: ...: Out[4]: Host Port Status Leader count Leader distribution Partition distribution 0 storaged0 9779.0 ONLINE 0 No valid partition No valid partition 1 storaged1 9779.0 ONLINE 1 pokemon_club:1 pokemon_club:1 2 storaged2 9779.0 ONLINE 0 No valid partition No valid partition 3 Total NaN None 1 pokemon_club:1 pokemon_club:1 In [5]: trainer = \"Sue\" In [6]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: Out[6]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [7]: %ngql help Supported Configurations: ------------------------ \u003e How to config ngql_result_style in \"raw\", \"pandas\" %config IPythonNGQL.ngql_result_style=\"raw\" %config IPythonNGQL.ngql_result_style=\"pandas\" \u003e How to config ngql_verbose in True, False %config IPythonNGQL.ngql_verbose=True \u003e How to config max_connection_pool_size %config IPythonNGQL.max_connection_pool_size=10 Quick Start: ----------- \u003e Connect to Neubla Graph %ngql --address 127.0.0.1 --port 9669 --user user --password password \u003e Use Space %ngql USE nba \u003e Query %ngql SHOW TAGS; \u003e Multile Queries %%ngql SHOW TAGS; SHOW HOSTS; Reload ngql Magic %reload_ext ngql \u003e Variables in query, we are using Jinja2 here name = \"nba\" %ngql USE \"{{ name }}\" In [8]: trainer = \"Sue\" In [9]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[9]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [10]: %config IPythonNGQL.ngql_result_style=\"raw\" In [11]: %%ngql USE pokemon_club; ...: GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id ...: | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[11]: ResultSet(ExecutionResponse( error_code=0, latency_in_us=3270, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) In [12]: r = _ In [13]: r.column_values(key='Trainer_Name')[0]._value.value Out[13]: b'Tom' ","date":"2021-03-07","objectID":"/ipython-ngql/:1:8","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#jupyter-notebook"},{"categories":["Nebula Graph"],"content":" 1.8 Examples 1.8.1 Jupyter NotebookPlease refer here:https://github.com/wey-gu/ipython-ngql/blob/main/examples/get_started.ipynb 1.8.2 iPython venv ❯ ipython In [1]: %load_ext ngql In [2]: %ngql --address 127.0.0.1 --port 9669 --user user --password password Connection Pool Created Out[2]: Name 0 pokemon_club In [3]: %ngql GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name Out[3]: Trainer_Name 0 Tom 1 Jerry 2 Sue 3 Tom 4 Wey In [4]: %%ngql ...: SHOW TAGS; ...: SHOW HOSTS; ...: ...: Out[4]: Host Port Status Leader count Leader distribution Partition distribution 0 storaged0 9779.0 ONLINE 0 No valid partition No valid partition 1 storaged1 9779.0 ONLINE 1 pokemon_club:1 pokemon_club:1 2 storaged2 9779.0 ONLINE 0 No valid partition No valid partition 3 Total NaN None 1 pokemon_club:1 pokemon_club:1 In [5]: trainer = \"Sue\" In [6]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: Out[6]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [7]: %ngql help Supported Configurations: ------------------------ \u003e How to config ngql_result_style in \"raw\", \"pandas\" %config IPythonNGQL.ngql_result_style=\"raw\" %config IPythonNGQL.ngql_result_style=\"pandas\" \u003e How to config ngql_verbose in True, False %config IPythonNGQL.ngql_verbose=True \u003e How to config max_connection_pool_size %config IPythonNGQL.max_connection_pool_size=10 Quick Start: ----------- \u003e Connect to Neubla Graph %ngql --address 127.0.0.1 --port 9669 --user user --password password \u003e Use Space %ngql USE nba \u003e Query %ngql SHOW TAGS; \u003e Multile Queries %%ngql SHOW TAGS; SHOW HOSTS; Reload ngql Magic %reload_ext ngql \u003e Variables in query, we are using Jinja2 here name = \"nba\" %ngql USE \"{{ name }}\" In [8]: trainer = \"Sue\" In [9]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[9]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [10]: %config IPythonNGQL.ngql_result_style=\"raw\" In [11]: %%ngql USE pokemon_club; ...: GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id ...: | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[11]: ResultSet(ExecutionResponse( error_code=0, latency_in_us=3270, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) In [12]: r = _ In [13]: r.column_values(key='Trainer_Name')[0]._value.value Out[13]: b'Tom' ","date":"2021-03-07","objectID":"/ipython-ngql/:1:8","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#ipython"}]
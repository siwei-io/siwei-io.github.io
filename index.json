[{"categories":["Nebula Graph"],"content":"本文是一个基于 NebulaGraph 上图算法、图数据库、机器学习、GNN 的推荐系统方法综述，大部分介绍的方法提供了 Playground 供大家学习。","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/"},{"categories":["Nebula Graph"],"content":" 1 基于图数据库的推荐系统 本文是一个基于 NebulaGraph 上图算法、图数据库、机器学习、GNN 的推荐系统方法综述，大部分介绍的方法提供了 Playground 供大家学习。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:0","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于图数据库的推荐系统"},{"categories":["Nebula Graph"],"content":" 1.1 基本概念推荐系统诞生的初衷是解决互联网时代才面临的信息量过载问题，从最初的 Amazon 图书推荐、商品推荐，到电影、音乐、视频、新闻推荐，如今大多数网站、App 中都有至少一个基于推荐系统生成的供用户选择的物品列表界面。而这些物品的推荐基本都是基于用户喜好、物品的特征、用户与物品交互历史和其他相关上下文去做的。 一个推荐系统会包含以下几个部分： 数据、特征的处理 从特征出发，生成推荐列表 过滤、排序推荐列表 这其中，过滤的核心方法主要有两种：基于内容的过滤（Content-Based Filtering）、与协同过滤（Collaborative Filtering）。 1.1.1 基于内容的过滤内容过滤方法的本质是给用户的偏好做画像，同时对所有待推荐的物品计算特征，做用户的画像与待推荐物品特征之间的距离运算，过滤得到相近的物品。 ref: https://www.ise.bgu.ac.il/faculty/liorr/recsyshb/chContent.pdf 内容过滤的方法的好处有： 清晰的可解释性，无论是对用户的画像分析，还是对物品的运算本身天然带来了排序、过滤的可解释性 用户数据输入的独立性，对给定的待推荐用户来说，只需要单独分析他们的画像和历史评分就足够了 规避新物品冷启动问题，对于新的添加的物品，即使没有任何历史的用户评价，也可以做出推荐 同时，基于内容过滤的挑战与劣势也有： 特征提取，提取待推荐物品的特征并非总是很容易地，比如照片、视频等非纯文本的物品，而且往往这些物品的特征提取依赖领域专家知识，比如电影推荐系统中需要抽离出导演、电影分类等领域知识作为特征 不擅长突破舒适圈，发掘用户的潜在新兴趣点 存在新用户冷启动问题，对少有信息作为用户画像的用户来说，缺少做进一步物品画像、特种距离运算的输入 1.1.2 基于协同过滤协同过滤方法本质是协同用户与系统之间的交互行为去给出推荐物品。 协同过滤的方法又分为基于记忆（memory-based）的与基于模型（model-based）的。 前者主要有物品与物品之间的协同过滤（ItemCF）和用户与用户之间的协同过滤（UserCF），ItemCF 简单来说是推荐和用户之前选择过的物品类似的物品：根据行为找物品之间的相似性，UserCF 则推荐与之有共同爱好的用户喜欢的物品：根据行为找用户之间的相似性； 而后者基于展现用户喜好的历史实践信息、利用统计与机器学习方法训练模型，对新的用户偏好进行推理。 协同过滤的方法的好处有： 无需对非结构化物品进行特征分析，因为协同过滤关注的是用户和物品之间的协同交互，这绕过了对物品领域知识处理的需求 对用户的个性化更强，更细，基于行为的分析使得对用户偏好的划分本质上是连续的（相比来说，对用户做画像的方法则是离散的），这样的推荐结果会更加“千人千面”，同时，也会蕴含内容过滤、有限的画像角度之下的“惊喜”推荐 而它的缺点有： 有新用户和新物件上的冷启动问题，因为它们身上都缺少历史喜好行为的信息 ref: https://coek.info/pdf-a-dynamic-collaborative-filtering-system-via-a-weighted-clustering-approach-.html 从以上两种主要的过滤方式的优劣中我们可以看到，它们之中存在互补的地方，比如新物件的冷启动上，基于内容的过滤有优势，对于个性化、惊喜推荐角度，协同过滤有优势。所以，在真实世界中，推荐系统在大多演化地比上边的归类复杂得多，而且常常是多种方法的融合。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:1","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基本概念"},{"categories":["Nebula Graph"],"content":" 1.1 基本概念推荐系统诞生的初衷是解决互联网时代才面临的信息量过载问题，从最初的 Amazon 图书推荐、商品推荐，到电影、音乐、视频、新闻推荐，如今大多数网站、App 中都有至少一个基于推荐系统生成的供用户选择的物品列表界面。而这些物品的推荐基本都是基于用户喜好、物品的特征、用户与物品交互历史和其他相关上下文去做的。 一个推荐系统会包含以下几个部分： 数据、特征的处理 从特征出发，生成推荐列表 过滤、排序推荐列表 这其中，过滤的核心方法主要有两种：基于内容的过滤（Content-Based Filtering）、与协同过滤（Collaborative Filtering）。 1.1.1 基于内容的过滤内容过滤方法的本质是给用户的偏好做画像，同时对所有待推荐的物品计算特征，做用户的画像与待推荐物品特征之间的距离运算，过滤得到相近的物品。 ref: https://www.ise.bgu.ac.il/faculty/liorr/recsyshb/chContent.pdf 内容过滤的方法的好处有： 清晰的可解释性，无论是对用户的画像分析，还是对物品的运算本身天然带来了排序、过滤的可解释性 用户数据输入的独立性，对给定的待推荐用户来说，只需要单独分析他们的画像和历史评分就足够了 规避新物品冷启动问题，对于新的添加的物品，即使没有任何历史的用户评价，也可以做出推荐 同时，基于内容过滤的挑战与劣势也有： 特征提取，提取待推荐物品的特征并非总是很容易地，比如照片、视频等非纯文本的物品，而且往往这些物品的特征提取依赖领域专家知识，比如电影推荐系统中需要抽离出导演、电影分类等领域知识作为特征 不擅长突破舒适圈，发掘用户的潜在新兴趣点 存在新用户冷启动问题，对少有信息作为用户画像的用户来说，缺少做进一步物品画像、特种距离运算的输入 1.1.2 基于协同过滤协同过滤方法本质是协同用户与系统之间的交互行为去给出推荐物品。 协同过滤的方法又分为基于记忆（memory-based）的与基于模型（model-based）的。 前者主要有物品与物品之间的协同过滤（ItemCF）和用户与用户之间的协同过滤（UserCF），ItemCF 简单来说是推荐和用户之前选择过的物品类似的物品：根据行为找物品之间的相似性，UserCF 则推荐与之有共同爱好的用户喜欢的物品：根据行为找用户之间的相似性； 而后者基于展现用户喜好的历史实践信息、利用统计与机器学习方法训练模型，对新的用户偏好进行推理。 协同过滤的方法的好处有： 无需对非结构化物品进行特征分析，因为协同过滤关注的是用户和物品之间的协同交互，这绕过了对物品领域知识处理的需求 对用户的个性化更强，更细，基于行为的分析使得对用户偏好的划分本质上是连续的（相比来说，对用户做画像的方法则是离散的），这样的推荐结果会更加“千人千面”，同时，也会蕴含内容过滤、有限的画像角度之下的“惊喜”推荐 而它的缺点有： 有新用户和新物件上的冷启动问题，因为它们身上都缺少历史喜好行为的信息 ref: https://coek.info/pdf-a-dynamic-collaborative-filtering-system-via-a-weighted-clustering-approach-.html 从以上两种主要的过滤方式的优劣中我们可以看到，它们之中存在互补的地方，比如新物件的冷启动上，基于内容的过滤有优势，对于个性化、惊喜推荐角度，协同过滤有优势。所以，在真实世界中，推荐系统在大多演化地比上边的归类复杂得多，而且常常是多种方法的融合。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:1","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于内容的过滤"},{"categories":["Nebula Graph"],"content":" 1.1 基本概念推荐系统诞生的初衷是解决互联网时代才面临的信息量过载问题，从最初的 Amazon 图书推荐、商品推荐，到电影、音乐、视频、新闻推荐，如今大多数网站、App 中都有至少一个基于推荐系统生成的供用户选择的物品列表界面。而这些物品的推荐基本都是基于用户喜好、物品的特征、用户与物品交互历史和其他相关上下文去做的。 一个推荐系统会包含以下几个部分： 数据、特征的处理 从特征出发，生成推荐列表 过滤、排序推荐列表 这其中，过滤的核心方法主要有两种：基于内容的过滤（Content-Based Filtering）、与协同过滤（Collaborative Filtering）。 1.1.1 基于内容的过滤内容过滤方法的本质是给用户的偏好做画像，同时对所有待推荐的物品计算特征，做用户的画像与待推荐物品特征之间的距离运算，过滤得到相近的物品。 ref: https://www.ise.bgu.ac.il/faculty/liorr/recsyshb/chContent.pdf 内容过滤的方法的好处有： 清晰的可解释性，无论是对用户的画像分析，还是对物品的运算本身天然带来了排序、过滤的可解释性 用户数据输入的独立性，对给定的待推荐用户来说，只需要单独分析他们的画像和历史评分就足够了 规避新物品冷启动问题，对于新的添加的物品，即使没有任何历史的用户评价，也可以做出推荐 同时，基于内容过滤的挑战与劣势也有： 特征提取，提取待推荐物品的特征并非总是很容易地，比如照片、视频等非纯文本的物品，而且往往这些物品的特征提取依赖领域专家知识，比如电影推荐系统中需要抽离出导演、电影分类等领域知识作为特征 不擅长突破舒适圈，发掘用户的潜在新兴趣点 存在新用户冷启动问题，对少有信息作为用户画像的用户来说，缺少做进一步物品画像、特种距离运算的输入 1.1.2 基于协同过滤协同过滤方法本质是协同用户与系统之间的交互行为去给出推荐物品。 协同过滤的方法又分为基于记忆（memory-based）的与基于模型（model-based）的。 前者主要有物品与物品之间的协同过滤（ItemCF）和用户与用户之间的协同过滤（UserCF），ItemCF 简单来说是推荐和用户之前选择过的物品类似的物品：根据行为找物品之间的相似性，UserCF 则推荐与之有共同爱好的用户喜欢的物品：根据行为找用户之间的相似性； 而后者基于展现用户喜好的历史实践信息、利用统计与机器学习方法训练模型，对新的用户偏好进行推理。 协同过滤的方法的好处有： 无需对非结构化物品进行特征分析，因为协同过滤关注的是用户和物品之间的协同交互，这绕过了对物品领域知识处理的需求 对用户的个性化更强，更细，基于行为的分析使得对用户偏好的划分本质上是连续的（相比来说，对用户做画像的方法则是离散的），这样的推荐结果会更加“千人千面”，同时，也会蕴含内容过滤、有限的画像角度之下的“惊喜”推荐 而它的缺点有： 有新用户和新物件上的冷启动问题，因为它们身上都缺少历史喜好行为的信息 ref: https://coek.info/pdf-a-dynamic-collaborative-filtering-system-via-a-weighted-clustering-approach-.html 从以上两种主要的过滤方式的优劣中我们可以看到，它们之中存在互补的地方，比如新物件的冷启动上，基于内容的过滤有优势，对于个性化、惊喜推荐角度，协同过滤有优势。所以，在真实世界中，推荐系统在大多演化地比上边的归类复杂得多，而且常常是多种方法的融合。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:1","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于协同过滤"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于图的个性推荐"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#建立图谱"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于内容的过滤-1"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#jaccard-index"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#cbf-方法在-nebulagraph-中的实现"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#可视化分析"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于记忆的协同过滤"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#itemcf"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#可视化分析-itemcf"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#关于高评分"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#pearson-correlation-coefficient"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#usercf"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#可视化分析-usercf"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#混合的方法"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#基于模型的方法"},{"categories":["Nebula Graph"],"content":" 1.2 基于图的个性推荐图技术、图数据库技术在推荐系统中的应用是多方面的，本章我们就从图数据库的出发点上给出多种应用的例子。 1.2.1 建立图谱在开始之前，我简单介绍一下本文使用的图数据集。 为了给出更接近实际情况的例子，我从两个公开的数据集 OMDB 和 MovieLens 中分别抽取了需要的信息，组成了一个既包含电影的卡司（导演、演员）和类型、又包含用户对电影评分记录的知识图谱。 它的 Scehma 如下： 顶点： user(user_id) movie(name) person(name, birthdate) genre(name) 边： watched(rate(double)) with_genre directed_by acted_by 这个数据的准备、ETL 过程会在另外的文章里详细介绍，在进入下一章节之前，我们可以用 Nebula-Up 一键搭起一个测试的 NebulaGraph 单机集群，然后参考数据集的 GitHub 仓库，一键导入所需数据： 注： Nebula-UP：https://github.com/wey-gu/nebula-up 数据集仓库：https://github.com/wey-gu/movie-recommendation-dataset 过程最简单的操作过程为： 用 Nebula-Up 安装 NebulaGraph 克隆 movie-recommendation-dataset 导入数据集 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash git clone https://github.com/wey-gu/movie-recommendation-dataset.git \u0026\u0026 cd movie-recommendation-dataset docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/dbt_project/to_nebulagraph/:/data \\ vesoft/nebula-importer:v3.2.0 \\ --config /root/nebula-importer.yaml 1.2.2 基于内容的过滤CBF 的思想是利用领域知识、历史记录、元数据分别对用户和物件做画像、打标签，最终根据用户的标签与待推荐物件之间的距离评分排序给出推荐。 对用户的画像不涉及其他用户的信息，但是输入的特征可能来源于元数据（生日、国籍、性别、年龄），历史记录（评论、打分、购买、浏览）等等，在这些基础之上对用户进行标签标注、分类、聚类。 对物件的画像输入的特征可能是基于语言处理（NLP、TF-IDF、LFM）、专家标注、多媒体处理（视觉到文字再NLP、音频风格处理、音频到文字再NLP）等。 有了用户画像与物件的画像特征、对用户涉及的画像进行相关画像物件中新对象的近似度计算，再评分加权，就可以获得最终的推荐排序了。这其中的近似度计算可以是常见的 KNN，余弦相似，Jaccard 相似等各种方法。 CBF 的方法中没有限定具体实现方式，如前边介绍，可能是基于机器学习、elasticsearch、图谱等不同的方法。这里为切合本章的主题，我给出一个基于图数据库、图谱上的 CBF 的例子，做一个电影推荐系统，能让读者理解这个方法的思想的同时熟悉图数据库、知识图谱的方法。 这其中用户的特征我们直接利用历史电影评价记录，而推荐物件：电影，的画像则来自于领域中的知识。这些知识有：电影风格、电影的卡斯、导演。近似度这里我们就采用图谱中基于关系的 Jaccard 相似度算法。 1.2.2.1 Jaccard IndexJaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉地取两者的交集与并集测度的比例，它的定义记为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（有共同的导演、电影类型、演员），并集理解为这几种关系下与 A 或者 B 直连的所有点，而测度就直接用数量表示。 1.2.2.2 CBF 方法在 NebulaGraph 中的实现CBF 方法分如下几步： 找出推荐用户评分过的电影 从用户评分过的电影，经由导演卡司、电影类型找到新的待推荐电影 对看过的电影与新的电影，藉由导演、卡司、电影类型的关系，在图上做 Jaccard 相似性运算，得出每一对看过的电影和待推荐新电影之间的 Jaccard 系数 把用户对看过电影的评分作为加权系数，针对其到每一个新电影之间的 Jaccard 系数加权评分，获得排序后的推荐电影列表 // 用户 u_124 看过的电影 MATCH (u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_124\" WITH collect(id(m)) AS watched_movies_id // 根据电影的标注关系找到备选推荐电影，刨除看过的，把评分、交集关联链路的数量传下去 MATCH (u:`user`)-[e:watched]-\u003e(m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection)\u003c-[:directed_by|acted_by|with_genre]-(recomm:`movie`) WHERE id(u) == \"u_124\" AND NOT id(recomm) IN watched_movies_id WITH (e.rate - 2.5)/2.5 AS rate, m, recomm, size(COLLECT(intersection)) AS intersection_size ORDER BY intersection_size DESC LIMIT 50 // 计算 Jaccard index------------------------------------------------- // 针对每一对 m 和 recomm： // 开始计算看过的电影，集合 a 的部分 MATCH (m:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, id(m) AS m_id, recomm, intersection_size, COLLECT(id(intersection)) AS set_a // 计算推荐电影，集合 b 的部分 MATCH (recomm:`movie`)-[:directed_by|acted_by|with_genre]-\u003e(intersection) WITH rate, m_id, id(recomm) AS recomm_id, set_a, intersection_size, COLLECT(id(intersection)) AS set_b // 得到并集数量 WITH rate, m_id, recomm_id, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B // 得到每一对 m 和 recomm 的 Jaccard index = A_N_B/A_U_B WITH rate, m_id, recomm_id, intersection_size/size(A_U_B) AS jaccard_index // 计算 Jaccard index------------------------------------------------- // 得到每一个被推荐的电影 recomm_id，经由不同看过电影推荐链路的相似度 = 评分 * jaccard_index WITH recomm_id, m_id, (rate * jaccard_index) AS score // 对每一个 recomm_id 按照 m_id 加权求得相似度的和，为总的推荐程度评分，降序排列 WITH recomm_id, sum(score) AS sim_score ORDER BY sim_score DESC WHERE sim_score \u003e 0 RETURN recomm_id, sim_score LIMIT 50 上边查询的执行结果截取出来是： recomm_id sim_score 1891 0.2705882352941177 1892 0.22278481012658227 1894 0.15555555555555556 808 0.144 1895 0.13999999999999999 85 0.12631578947368421 348 0.12413793103448277 18746 0.11666666666666668 628 0.11636363636363636 3005 0.10566037735849057 1.2.2.3 可视化分析我们把整个过程中的一些步骤的查询修改一下为 p=xxx 的方式，并渲染出来，会更加方便理解 用户 u_124 看过的、评分过的电影 // 用户 u_124 看过的电影 MATCH p=(u:`user`)-[:watched]-\u003e(m:`movie`) WHERE id(u) == \"u_1","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:2","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#gnn--图数据库的推荐系统"},{"categories":["Nebula Graph"],"content":" 1.3 推荐系统可解释性在结束本章之前，再举一个图数据库在推荐系统中的典型应用：推荐理由。 下图是美团、大众点评中的一个常见的搜索、推荐结果，现代推荐系统的复杂度是非常大的，一方面由很多方法自身的特性决定，另一方面最终的推荐可能是多个系统协同获得最终结果排名，这使得我们很难对推荐结果进行解释。 得益于被推荐用户和物件、以及他们的各种各样画像最终形成的知识图谱，我们只需要在图谱中对推荐结果进行“路径查找”就可以获得很有意义的解释，像是如下截图的“在北京喜欢北京菜的山东老乡都说这家店很赞”就是这样获得的解释。 图片来源：https://tech.meituan.com/2021/04/01/nebula-graph-practice-in-meituan.html 1.3.1 可解释性的例子咱们回到电影推荐的图谱上，我们在前边的算法中曾经获得过用户 u_124 的推荐电影 1891（星球大战：），那么我们可以通过这一个查询获得它的推荐解释： FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 我们可以很快获得 20 条路径： (root@nebula) [moviegraph]\u003e FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 +-----------------------------------------------------------------------------------------------------+ | p | +-----------------------------------------------------------------------------------------------------+ | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_49\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_17\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_10281\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_4\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_3\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_24342\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_2\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"832\")-[:with_genre@0 {}]-\u003e(\"g_1110\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_1110\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_13463\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_12248\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"47981\")-[:with_genre@0 {}]-\u003e(\"g_10219\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_6\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"497\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"120880\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_130\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"497\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11635\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | +-----------------------------------------------------------------------------------------------------+ Got 20 rows (time spent 267151/278139 us) Wed, 09 Nov 2022 19:05:56 CST 我们在结果可视化中可以很容易看出这个推荐的结果可以是： 曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:3","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#推荐系统可解释性"},{"categories":["Nebula Graph"],"content":" 1.3 推荐系统可解释性在结束本章之前，再举一个图数据库在推荐系统中的典型应用：推荐理由。 下图是美团、大众点评中的一个常见的搜索、推荐结果，现代推荐系统的复杂度是非常大的，一方面由很多方法自身的特性决定，另一方面最终的推荐可能是多个系统协同获得最终结果排名，这使得我们很难对推荐结果进行解释。 得益于被推荐用户和物件、以及他们的各种各样画像最终形成的知识图谱，我们只需要在图谱中对推荐结果进行“路径查找”就可以获得很有意义的解释，像是如下截图的“在北京喜欢北京菜的山东老乡都说这家店很赞”就是这样获得的解释。 图片来源：https://tech.meituan.com/2021/04/01/nebula-graph-practice-in-meituan.html 1.3.1 可解释性的例子咱们回到电影推荐的图谱上，我们在前边的算法中曾经获得过用户 u_124 的推荐电影 1891（星球大战：），那么我们可以通过这一个查询获得它的推荐解释： FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 我们可以很快获得 20 条路径： (root@nebula) [moviegraph]\u003e FIND NOLOOP PATH FROM \"u_124\" TO \"1891\" over * BIDIRECT UPTO 4 STEPS yield path as `p` | LIMIT 20 +-----------------------------------------------------------------------------------------------------+ | p | +-----------------------------------------------------------------------------------------------------+ | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_49\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_17\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_10281\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_4\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_3\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_24342\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_2\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"832\")-[:with_genre@0 {}]-\u003e(\"g_1110\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_1110\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_13463\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_12248\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"47981\")-[:with_genre@0 {}]-\u003e(\"g_10219\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_6\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"497\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"120880\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_104\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:acted_by@0 {}]-\u003e(\"p_130\")\u003c-[:acted_by@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"497\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11635\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | | \u003c(\"u_124\")-[:watched@0 {}]-\u003e(\"11\")-[:with_genre@0 {}]-\u003e(\"g_50\")\u003c-[:with_genre@0 {}]-(\"1891\")\u003e | +-----------------------------------------------------------------------------------------------------+ Got 20 rows (time spent 267151/278139 us) Wed, 09 Nov 2022 19:05:56 CST 我们在结果可视化中可以很容易看出这个推荐的结果可以是： 曾经喜欢的星战电影的大部分演职人员都也参与了这部和同样是“奥斯卡获奖”且“经典”的电影。 ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:3","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#可解释性的例子"},{"categories":["Nebula Graph"],"content":" 1.4 总结现在，我们知道图数据库作为推荐系统中信息的最终形式：知识存在，可以适用在不同类型方法上，尽管很多方法中，图库不一定是最终落地系统方案的最流行选择，图数据库所带来的可视化洞察的潜力还是非常大的。 同时，构建的综合知识图谱上的解释、推理能力与一些实时要求高的图方法中（比如 GNN的基于模型方法），能起到带来独一无二的作用。 题图版权：charlesdeluvio ","date":"2022-10-25","objectID":"/recommendation-system-with-graphdb/:1:4","series":null,"tags":["Nebula Graph","Recommendation system","GNN","推荐系统","DGL"],"title":"基于图数据库的推荐系统","uri":"/recommendation-system-with-graphdb/#总结"},{"categories":["Nebula Graph"],"content":"本文是一个快速了解为 NebulaGraph 内核贡献代码、构建、Debug 的一站式指南。","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/"},{"categories":["Nebula Graph"],"content":" 如何 build NebulaGraph？如何为 NebulaGraph 内核做贡献？从本章作为切入点就够了。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:0:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#"},{"categories":["Nebula Graph"],"content":" 1 NebulaGraph 的架构简介为了方便对 NebulaGraph 尚未了解的读者也能快速直接从贡献代码为起点了解它，我把开发、贡献内核代码入手所需要的基本架构知识也在这里以最小信息量的形式总结一下，作为前导知识，请资深的 NebulaGraph 玩家直接跳过这一章节。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#nebulagraph-的架构简介"},{"categories":["Nebula Graph"],"content":" 1.1 服务、进程NebulaGraph 的架构和 Google Spanner, TiDB 很相似，核心部分只有三种服务、进程：Graph 服务、Meta 服务和 Storage 服务。它们之间彼此通过 TCP 之上的 Thrift RPC 协议进行通信。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#服务进程"},{"categories":["Nebula Graph"],"content":" 1.2 计算层与存储层NebulaGraph 是存储与计算分离的架构，它的 Meta 服务和 Storage 服务共同组成了存储层，Graph 服务是内核提供的计算层。 这样的设计使得 NebulaGraph 的集群部署可以灵活按需分配计算、存储的资源，比如我们可以为同一个集群中创建不同配置的两组 Graph 服务实例、用来面向不同类型的业务。 同时，计算层解耦于存储层使得在 NebulaGraph 之上的构建不同的特定计算层成为可能，比如 NebulaGraph Algorithm、NebulaGraph Analytics 就是在 NebulaGraph 之上构建了异构的另一个计算层，如果需要，任何人也可以定制自己的专属计算层，从而满足统一图基础存储之上的复合、多样的计算需求。 1.2.1 Graph Service: nebula-graphdGraph 服务是对外接受图库登录、图查询请求、集群管理操作、schema 定义所直接连接的服务，他的进程名字叫 graphd，表示 nebula graph daemon。 Graph 服务的每一个进程是无状态的，这使得横向扩缩 Graph 服务的实例非常灵活、简单。 Graph 服务也叫 Query Engine，其内部和传统的数据库系统的设计非常相似，分为：解析、校验、计划、执行几部分。 1.2.2 Meta Service: nebula-metadMeta 服务顾名思义负责元数据管理，进程名字叫 metad。这些元数据包括： 所有的图空间、Schema 定义 用户鉴权、授权信息 集群服务的发现与服务的分布 图空间中的数据分布 Meta 服务的进程可以单实例部署，在非单机部署的场景下，为了数据、服务的高 SLA ，我们可以奇数多个实例的部署，通常来说 3 个 nebula-metad 就足够了，三个 nebula-metad 通过 RAFT 共识协议构成一个集群提供服务。 1.2.3 Storage Service: nebula-storagedStorage 服务存储所有的图数据，进程名字叫 storaged。storaged 分布式地存储图数据，为 Graph 内部的图查询执行期提供底层的图语义存储接口，方便 Storage 客户端通过 Thrift RPC 协议面向涉及的 storaged 示例进行图语义的读写。 当 NebulaGraph 中图空间的副本数大于 1 的时候，每一个分区都会在不同 storaged 示例上有副本，副本之间则通过 RAFT 协议协调同步与读写。 参考 文档：架构介绍，了解更多详情； 推荐阅读社区官方播客的架构系列文章：nebula-graph.com.cn/tags/架构系列。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#计算层与存储层"},{"categories":["Nebula Graph"],"content":" 1.2 计算层与存储层NebulaGraph 是存储与计算分离的架构，它的 Meta 服务和 Storage 服务共同组成了存储层，Graph 服务是内核提供的计算层。 这样的设计使得 NebulaGraph 的集群部署可以灵活按需分配计算、存储的资源，比如我们可以为同一个集群中创建不同配置的两组 Graph 服务实例、用来面向不同类型的业务。 同时，计算层解耦于存储层使得在 NebulaGraph 之上的构建不同的特定计算层成为可能，比如 NebulaGraph Algorithm、NebulaGraph Analytics 就是在 NebulaGraph 之上构建了异构的另一个计算层，如果需要，任何人也可以定制自己的专属计算层，从而满足统一图基础存储之上的复合、多样的计算需求。 1.2.1 Graph Service: nebula-graphdGraph 服务是对外接受图库登录、图查询请求、集群管理操作、schema 定义所直接连接的服务，他的进程名字叫 graphd，表示 nebula graph daemon。 Graph 服务的每一个进程是无状态的，这使得横向扩缩 Graph 服务的实例非常灵活、简单。 Graph 服务也叫 Query Engine，其内部和传统的数据库系统的设计非常相似，分为：解析、校验、计划、执行几部分。 1.2.2 Meta Service: nebula-metadMeta 服务顾名思义负责元数据管理，进程名字叫 metad。这些元数据包括： 所有的图空间、Schema 定义 用户鉴权、授权信息 集群服务的发现与服务的分布 图空间中的数据分布 Meta 服务的进程可以单实例部署，在非单机部署的场景下，为了数据、服务的高 SLA ，我们可以奇数多个实例的部署，通常来说 3 个 nebula-metad 就足够了，三个 nebula-metad 通过 RAFT 共识协议构成一个集群提供服务。 1.2.3 Storage Service: nebula-storagedStorage 服务存储所有的图数据，进程名字叫 storaged。storaged 分布式地存储图数据，为 Graph 内部的图查询执行期提供底层的图语义存储接口，方便 Storage 客户端通过 Thrift RPC 协议面向涉及的 storaged 示例进行图语义的读写。 当 NebulaGraph 中图空间的副本数大于 1 的时候，每一个分区都会在不同 storaged 示例上有副本，副本之间则通过 RAFT 协议协调同步与读写。 参考 文档：架构介绍，了解更多详情； 推荐阅读社区官方播客的架构系列文章：nebula-graph.com.cn/tags/架构系列。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#graph-service-nebula-graphd"},{"categories":["Nebula Graph"],"content":" 1.2 计算层与存储层NebulaGraph 是存储与计算分离的架构，它的 Meta 服务和 Storage 服务共同组成了存储层，Graph 服务是内核提供的计算层。 这样的设计使得 NebulaGraph 的集群部署可以灵活按需分配计算、存储的资源，比如我们可以为同一个集群中创建不同配置的两组 Graph 服务实例、用来面向不同类型的业务。 同时，计算层解耦于存储层使得在 NebulaGraph 之上的构建不同的特定计算层成为可能，比如 NebulaGraph Algorithm、NebulaGraph Analytics 就是在 NebulaGraph 之上构建了异构的另一个计算层，如果需要，任何人也可以定制自己的专属计算层，从而满足统一图基础存储之上的复合、多样的计算需求。 1.2.1 Graph Service: nebula-graphdGraph 服务是对外接受图库登录、图查询请求、集群管理操作、schema 定义所直接连接的服务，他的进程名字叫 graphd，表示 nebula graph daemon。 Graph 服务的每一个进程是无状态的，这使得横向扩缩 Graph 服务的实例非常灵活、简单。 Graph 服务也叫 Query Engine，其内部和传统的数据库系统的设计非常相似，分为：解析、校验、计划、执行几部分。 1.2.2 Meta Service: nebula-metadMeta 服务顾名思义负责元数据管理，进程名字叫 metad。这些元数据包括： 所有的图空间、Schema 定义 用户鉴权、授权信息 集群服务的发现与服务的分布 图空间中的数据分布 Meta 服务的进程可以单实例部署，在非单机部署的场景下，为了数据、服务的高 SLA ，我们可以奇数多个实例的部署，通常来说 3 个 nebula-metad 就足够了，三个 nebula-metad 通过 RAFT 共识协议构成一个集群提供服务。 1.2.3 Storage Service: nebula-storagedStorage 服务存储所有的图数据，进程名字叫 storaged。storaged 分布式地存储图数据，为 Graph 内部的图查询执行期提供底层的图语义存储接口，方便 Storage 客户端通过 Thrift RPC 协议面向涉及的 storaged 示例进行图语义的读写。 当 NebulaGraph 中图空间的副本数大于 1 的时候，每一个分区都会在不同 storaged 示例上有副本，副本之间则通过 RAFT 协议协调同步与读写。 参考 文档：架构介绍，了解更多详情； 推荐阅读社区官方播客的架构系列文章：nebula-graph.com.cn/tags/架构系列。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#meta-service-nebula-metad"},{"categories":["Nebula Graph"],"content":" 1.2 计算层与存储层NebulaGraph 是存储与计算分离的架构，它的 Meta 服务和 Storage 服务共同组成了存储层，Graph 服务是内核提供的计算层。 这样的设计使得 NebulaGraph 的集群部署可以灵活按需分配计算、存储的资源，比如我们可以为同一个集群中创建不同配置的两组 Graph 服务实例、用来面向不同类型的业务。 同时，计算层解耦于存储层使得在 NebulaGraph 之上的构建不同的特定计算层成为可能，比如 NebulaGraph Algorithm、NebulaGraph Analytics 就是在 NebulaGraph 之上构建了异构的另一个计算层，如果需要，任何人也可以定制自己的专属计算层，从而满足统一图基础存储之上的复合、多样的计算需求。 1.2.1 Graph Service: nebula-graphdGraph 服务是对外接受图库登录、图查询请求、集群管理操作、schema 定义所直接连接的服务，他的进程名字叫 graphd，表示 nebula graph daemon。 Graph 服务的每一个进程是无状态的，这使得横向扩缩 Graph 服务的实例非常灵活、简单。 Graph 服务也叫 Query Engine，其内部和传统的数据库系统的设计非常相似，分为：解析、校验、计划、执行几部分。 1.2.2 Meta Service: nebula-metadMeta 服务顾名思义负责元数据管理，进程名字叫 metad。这些元数据包括： 所有的图空间、Schema 定义 用户鉴权、授权信息 集群服务的发现与服务的分布 图空间中的数据分布 Meta 服务的进程可以单实例部署，在非单机部署的场景下，为了数据、服务的高 SLA ，我们可以奇数多个实例的部署，通常来说 3 个 nebula-metad 就足够了，三个 nebula-metad 通过 RAFT 共识协议构成一个集群提供服务。 1.2.3 Storage Service: nebula-storagedStorage 服务存储所有的图数据，进程名字叫 storaged。storaged 分布式地存储图数据，为 Graph 内部的图查询执行期提供底层的图语义存储接口，方便 Storage 客户端通过 Thrift RPC 协议面向涉及的 storaged 示例进行图语义的读写。 当 NebulaGraph 中图空间的副本数大于 1 的时候，每一个分区都会在不同 storaged 示例上有副本，副本之间则通过 RAFT 协议协调同步与读写。 参考 文档：架构介绍，了解更多详情； 推荐阅读社区官方播客的架构系列文章：nebula-graph.com.cn/tags/架构系列。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#storage-service-nebula-storaged"},{"categories":["Nebula Graph"],"content":" 1.3 进程间通信、服务发现机制graphd、metad、storaged 之间通过 Thrift 协议进行远程调用（RPC），下边给一些例子： graphd 会通过 metaclient 调用 metad 将自己报告为一个正在运行的服务，以便被发现 为用户（使用 graphclient ）登录进行 RPC 调用 当它处理 nGQL 查询时，获取图形存储分布情况 graphd 会通过 storageclient 调用 storaged 在处理 nGQL 时，在它从 metad 获得所需的元信息后，进行图形数据的读/写 storaged 会通过 metaclient调用 metad 将自己报告为一个正在运行的服务，以便被发现 当然有状态的存储引擎内部也有集群同步的流量与通信 storaged 与其他 storaged 有 RAFT 连接 metad 与其他 metad 实例有 RAFT 连接 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:1:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#进程间通信服务发现机制"},{"categories":["Nebula Graph"],"content":" 2 开发环境搭建接下来我们开始 NebulaGraph 的构建、开发环境的部分。 NebulaGraph 只支持在 GNU/Linux 分支中构建，目前来说，最方便的方式是在社区预先提供好了依赖的容器镜像的基础上在容器内部构建、调试 NebulaGraph 代码的更改和 Debug。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#开发环境搭建"},{"categories":["Nebula Graph"],"content":" 2.1 创建一个容器化的 NebulaGraph 集群为了更方便地调试代码，我习惯提前创建一个 NebulaGraph Docker 环境，我们可以使用官方的 Docker-Compose 方式部署，也可以使用我在官方 Docker-Compose 基础之上弄的一键部署工具：nebula-up.siwei.io。 以 nebula-up 为例： 在我们的 Linux 开发服务器中执行 curl -fsSL nebula-up.siwei.io/install.sh | bash 就可以了。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#创建一个容器化的-nebulagraph-集群"},{"categories":["Nebula Graph"],"content":" 2.2 代码获取NebulaGraph 的代码仓库托管在 GitHub 之上，我们可以在有互联网的地方直接克隆下来： git clone git@github.com:vesoft-inc/nebula.git cd nebula ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#代码获取"},{"categories":["Nebula Graph"],"content":" 2.3 创建开发容器有了 NebulaGraph 集群，我们可以借助 https://github.com/vesoft-inc/nebula-dev-docker/ 提供的开箱即用开发容器镜像，搭建开发环境： export TAG=ubuntu2004 docker run -ti \\ --network nebula-net \\ --security-opt seccomp=unconfined \\ -v \"$PWD\":/home/nebula \\ -w /home/nebula \\ --name nebula_dev \\ vesoft/nebula-dev:$TAG \\ bash 这其中，-v \"$PWD\" 表示当前的 NebulaGraph 代码本地的路径会被映射到开发容器内部的 /home/nebula，而启动的容器名字是 nebula_dev。 待这个容器启动之后，我们会自动进入到这个容器的 bash shell 之中，如果我们输入 exit 退出容器，它会被关闭，如果我们想再次启动容器，只需要执行： docker start nebula_dev 之后，我们的编译、Debug、测试工作都在 nebula_dev 容器内部进行，在容器是运行状态的情况下，可以随时新建一个容器内部的 bash shell 进程： docker exec -ti nebula_dev bash 注，为了保持编译环境是最新的，我们可以定期删除、拉取、重建这个开发容器，以保持环境与代码相匹配。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#创建开发容器"},{"categories":["Nebula Graph"],"content":" 2.4 编译环境在 nebula_dev 这个容器内部，我们可以进行代码编译： 进入编译容器 docker exec -ti nebula_dev bash 用 CMake 准备 makefile，第一次构建的时候，为了节省时间、内存，我关闭了测试（-DENABLE_TESTING=OFF）： mkdir build \u0026\u0026 cd build cmake -DCMAKE_CXX_COMPILER=$TOOLSET_CLANG_DIR/bin/g++ -DCMAKE_C_COMPILER=$TOOLSET_CLANG_DIR/bin/gcc -DENABLE_WERROR=OFF -DCMAKE_BUILD_TYPE=Debug -DENABLE_TESTING=OFF .. 开始编译，根据服务器的空闲 CPU 个数和内存量力而行，比如我在自己 72 核心的服务器上准备允许同时运行 64 个 job，则运行： make -j64 第一次构建的时间会慢一些，在 make 成功之后，我们也可以执行 make install 把二进制安装到像生产安装时候一样的路径： root@1827b82e88bf:/home/nebula/build# make install root@1827b82e88bf:/home/nebula/build# ls /usr/local/nebula/bin db_dump db_upgrader meta_dump nebula-graphd nebula-metad nebula-storaged root@1827b82e88bf:/home/nebula/build# ls /usr/local/nebula/ bin etc pids scripts share ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:2:4","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#编译环境"},{"categories":["Nebula Graph"],"content":" 3 调试 NebulaGraph以 GraphD 调试为例。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:3:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#调试-nebulagraph"},{"categories":["Nebula Graph"],"content":" 3.1 安装依赖安装一些后边会方便 Debug 额外用到的依赖 # 装一个 ping，测试一下 nebula-up 安装的集群可以访问 apt update \u0026\u0026 apt install iputils-ping -y # ping graphd 试试看 ping graphd -c 4 # 安装 gdb gdb-dashboard apt install gdb -y wget -P ~ https://git.io/.gdbinit pip install pygments ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:3:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#安装依赖"},{"categories":["Nebula Graph"],"content":" 3.2 准备客户端准备一个 NebulaGraph 的命令行客户端： # 新开一个 nebula_dev 的 shell docker exec -ti nebula_dev bash # 下载 nebula-console 二进制文件，并赋予可执行权限，命名为 nebula-console 并安装到 /usr/bin/ 下 wget https://github.com/vesoft-inc/nebula-console/releases/download/v3.2.0/nebula-console-linux-amd64-v3.2.0 chmod +x nebula-console* mv nebula-console* /usr/bin/nebula-console 连接到前边我们 nebula-up 准备的集群之上，加载 basketballplayer 这个测试数据： nebula-console -u root -p nebula --address=graphd --port=9669 :play basketballplayer; exit ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:3:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#准备客户端"},{"categories":["Nebula Graph"],"content":" 3.3 gdb 运行 graphd我们用 gdb 执行刚刚编译的 nebula-graphd 二进制，让他成为一个新的 graphd 服务，名字就叫 nebula_dev。 首先启动 gdb # 新开一个 nebula_dev 的 shell docker exec -ti nebula_dev bash cd /usr/local/nebula/ mkdir -p /home/nebula/build/log gdb bin/nebula-graphd 在 gdb 内部执行设置必要的参数 跟随 fork 的子进程 set follow-fork-mode child 设置待调试 graphd 的启动参数（配置）： meta_server_addrs 填已经启动的集群的所有 metad 的地址 local_ip 和 ws_ip 填本容器的域名，port 是 graphd 监听端口 log_dir 是输出日志的目录，v 和 minloglevel 是日志的输出等级 set args --flagfile=/usr/local/nebula/etc/nebula-graphd.conf.default \\ --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 \\ --port=9669 \\ --local_ip=nebula_dev \\ --ws_ip=nebula_dev \\ --ws_http_port=19669 \\ --log_dir=/home/nebula/build/log \\ --v=4 \\ --minloglevel=0 如果我们想加断点在 src/common/function/FunctionManager.cpp 2783 行，可以再执行： b /home/nebula/src/common/function/FunctionManager.cpp:2783 配置前边安装的 gdb-dashboard，一个开源的 gdb 界面插件。 # 设定在 gdb 界面上展示 代码、历史、回调栈、变量、表达几个部分，详细参考 https://github.com/cyrus-and/gdb-dashboard dashboard -layout source history stack variables expressions 最后我们让进程通过 gdb 跑起来吧： run 之后，我们就可以在这个窗口/shell 会话下调试 graphd 程序了。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:3:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#gdb-运行-graphd"},{"categories":["Nebula Graph"],"content":" 4 修改 NebulaGraph 代码这里，我以 #3513 这个 issue 为例子，快速介绍一下代码修改的过程。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#修改-nebulagraph-代码"},{"categories":["Nebula Graph"],"content":" 4.1 读代码这个 issue 表达的内容是在有一小部分用户决定把 JSON 以 String 的形式存储在 NebulaGraph 中的属性里，因为这种方式比较罕见且不被推崇，NebulaGraph 没有直接支持对 JSON String 直接解析的方法。 本来这个功能是等到很希望得到支持的同学过来亲自去实现的，而在 Issue 中，刚好有一位新手贡献者在里边回复求助如何能开始参与这个贡献。接着这个契机，我去参与讨论看了一下这个功能可以实现成什么样子，最终讨论的结果是可以做成和 MySQL 中的 JSON_EXTRACT 函数那样，但是改为只接受 JSON String，无需处理输出路径参数。 这个任务一句话来说就是为 NebulaGraph 引入一个解析 JSON String 为 Map 的函数。那么，应该大概如何实现这个功能呢？ 4.1.1 在哪里修改很自然，引入新的函数的更改肯定有很多，所以我们只需要找到之前增加新函数的 PR 就可以快速知道在哪些地方修改了。 当然我们可以自底向上去了解 NebulaGraph 整体的代码结构，然后一点点找到函数处理的位置，事实上有的时候我们也不得不这么做，这时候除了代码本身，一些面向贡献者的文章可能会帮助我们事半功倍对整体有一个了解，NebulaGraph 官方博客里就有这样的一个系列文章，推荐大家在贡献的时候也去通读一下：nebula-graph.com.cn/posts/nebula-graph-source-code-reading-00。 于是，我从 #4526 这个 PR 里了解到所有函数入口都被统一管理在 src/common/function/FunctionManager.cpp 之中，通过搜索、理解其中其他某一个函数的关键词之后可以很容易理解一个函数实体的关键词、输入输出数据类型、以及它的处理逻辑的代码在哪里实现。 同时，我注意到在同一个目录下，src/common/function/test/FunctionManagerTest.cpp 之中则是所有这些函数的单元测试代码，用同样的方式也可以知道新加的一个函数需要如何在里边实现基于 gtest 的单元测试。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#读代码"},{"categories":["Nebula Graph"],"content":" 4.1 读代码这个 issue 表达的内容是在有一小部分用户决定把 JSON 以 String 的形式存储在 NebulaGraph 中的属性里，因为这种方式比较罕见且不被推崇，NebulaGraph 没有直接支持对 JSON String 直接解析的方法。 本来这个功能是等到很希望得到支持的同学过来亲自去实现的，而在 Issue 中，刚好有一位新手贡献者在里边回复求助如何能开始参与这个贡献。接着这个契机，我去参与讨论看了一下这个功能可以实现成什么样子，最终讨论的结果是可以做成和 MySQL 中的 JSON_EXTRACT 函数那样，但是改为只接受 JSON String，无需处理输出路径参数。 这个任务一句话来说就是为 NebulaGraph 引入一个解析 JSON String 为 Map 的函数。那么，应该大概如何实现这个功能呢？ 4.1.1 在哪里修改很自然，引入新的函数的更改肯定有很多，所以我们只需要找到之前增加新函数的 PR 就可以快速知道在哪些地方修改了。 当然我们可以自底向上去了解 NebulaGraph 整体的代码结构，然后一点点找到函数处理的位置，事实上有的时候我们也不得不这么做，这时候除了代码本身，一些面向贡献者的文章可能会帮助我们事半功倍对整体有一个了解，NebulaGraph 官方博客里就有这样的一个系列文章，推荐大家在贡献的时候也去通读一下：nebula-graph.com.cn/posts/nebula-graph-source-code-reading-00。 于是，我从 #4526 这个 PR 里了解到所有函数入口都被统一管理在 src/common/function/FunctionManager.cpp 之中，通过搜索、理解其中其他某一个函数的关键词之后可以很容易理解一个函数实体的关键词、输入输出数据类型、以及它的处理逻辑的代码在哪里实现。 同时，我注意到在同一个目录下，src/common/function/test/FunctionManagerTest.cpp 之中则是所有这些函数的单元测试代码，用同样的方式也可以知道新加的一个函数需要如何在里边实现基于 gtest 的单元测试。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#在哪里修改"},{"categories":["Nebula Graph"],"content":" 4.2 开始改代码 注：在修改代码之前，请确保自己在最新的 master 分支之上创建一个单独的分支，这里的例子中，我把分支名字叫 fn_JSON_EXTRACT： git checkout master git pull git checkout -b fn_JSON_EXTRACT 通过 Google 了解与交叉验证 NebulaGraph 内部使用的 utils 库，我知道我应该用 folly::parseJson 把字符串读成 folly::dynamic 然后再 cast 成 NebulaGraph 内置的 Map() 类型，然后，借助于 StackOverflow/GitHub Copilot，我终于完成了第一个版本的代码修改。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#开始改代码"},{"categories":["Nebula Graph"],"content":" 4.3 调试代码接下来，我兴冲冲地改好了第一版的代码，信心满满地开始编译！实际上因为是 CPP 新手，即使在 Copilot 的加持下，我的代码还是花了好几次修改才通过编译。 然后，我开始用 GDB 把修改了的 GraphD 启动起来，用 console 发起 JSON_EXTRACT 的函数调用，先调通了期待中的效果，并试着跑几种异常的输入，在发现新问题、修改、编译、调试的几轮循环下让代码达到了期望的状态，这时候，我知道我要把代码提交到 GitHub 请项目的资深贡献者帮忙 review 啦！ ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:4:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#调试代码"},{"categories":["Nebula Graph"],"content":" 5 提交 PRPR（Pull Request）是 GitHub 中方便多人代码协作、代码审查中的一种方式，它通过把一个 repo 下的分支与这个审查协作的实例（PR）做映射，得到一个项目下唯一的 PR 号码之后，生成单独的网页，在这个网页下，我们可以做不同贡献者之间的交流和后续的代码更新，这个过程中代码提交者们可以一直在这个分支上不断提交代码直到代码的状态被各方同意之后，就可以合并（merge）到目的分支中。 这个过程可以分为： 创建 GitHub 上远程的个人开发分支 基于分支创建目标项目仓库中的 PR 在 PR 中协作、讨论、不断再次提交到开发分支直到多方达到合并、或者关闭的共识 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:0","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#提交-pr"},{"categories":["Nebula Graph"],"content":" 5.1 提交到个人远程分支这一步骤里，我们要把当前的本地提交的 commit，提交到自己的 GitHub 分叉之中。 5.1.1 commit 本地修改首先，我们确认一下本地的修改是否都是期待中的： # 先确定修改的文件 $ git status # 再看看修改的内容 $ git diff 然后，把它们 commit（提交在本地仓库） # 添加所有当前目录（. 这个点表示当前目录）修改过的文件为待 commit $ git add . # 然后我们可以看一下状态，这些修改的文件状态已经不同了 $ git status # 最后，提交在本地仓库，并用 -m 参数指定单行的 commit message $ git commit -m \"feat: introduce function JSON_EXTRACT\" 5.1.2 提交到自己远程的分支在提交之前，要确保自己的 GitHub 账号之下确实存在 NebulaGraph 代码仓库的分叉（fork），比如我的 GitHub 账号是 wey-gu，我访问，那么我对 https://github.com/vesoft-inc/nebula 的分叉应该就是 https://github.com/wey-gu/nebula 。 如果还没有自己的分叉，可以直接在 https://github.com/vesoft-inc/nebula 上点击右上角的 Fork，创建自己的分叉仓库。 当远程的个人分叉存在之后，我们可以把代码提交上去了 # 添加一个新的远程仓库叫 wey git remote add wey git@github.com:wey-gu/nebula.git # 提交 JSON_EXTRACT 分支到 wey 这个 remote 仓库 git push wey JSON_EXTRACT 5.1.3 在个人远程分叉分支上创建 PR这时候，我们访问这个远程分支：https://github.com/wey-gu/nebula/tree/fn_JSON_EXTRACT ，就能找到 Open PR 的入口： 然后点击 Open pull request 按钮，就进入到创建 PR 的界面了，这和在一般的论坛里提交一个帖子是很类似的： 提交之后，我们可以等待、或者邀请其他人来做代码的审查（review），往往其他的贡献者都能从他们的角度给出一些代码修改的建议和提示，我们需要经过几轮的代码修改、讨论之后使得代码达到最佳的状态。 而这些审查者中除了社区的贡献者（人类）之外，还有一些自动化的机器人，他们会在代码库中自动化的通过持续集成（CI）的方式运行一些自动化的审查工作，可能包括以下几种： CLA：Contributor License Agreement（贡献者许可协议），这是一个要 PR 作者在首次提交代码到项目时签署的协议，因为代码将被提交到公共空间，这份协议的签署意味着作者同意代码被分享、复用、修改这件事情。 lint：代码风格检查，这也是最常见的 CI 任务 test：各种层面的测试检查任务 通常来说，这些所有的自动化审查机器人所代表的任务也需要全都通过，代码的状态才能被认为是可以合并的，而不出意外，我首次提交的代码果然有测试的失败。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#提交到个人远程分支"},{"categories":["Nebula Graph"],"content":" 5.1 提交到个人远程分支这一步骤里，我们要把当前的本地提交的 commit，提交到自己的 GitHub 分叉之中。 5.1.1 commit 本地修改首先，我们确认一下本地的修改是否都是期待中的： # 先确定修改的文件 $ git status # 再看看修改的内容 $ git diff 然后，把它们 commit（提交在本地仓库） # 添加所有当前目录（. 这个点表示当前目录）修改过的文件为待 commit $ git add . # 然后我们可以看一下状态，这些修改的文件状态已经不同了 $ git status # 最后，提交在本地仓库，并用 -m 参数指定单行的 commit message $ git commit -m \"feat: introduce function JSON_EXTRACT\" 5.1.2 提交到自己远程的分支在提交之前，要确保自己的 GitHub 账号之下确实存在 NebulaGraph 代码仓库的分叉（fork），比如我的 GitHub 账号是 wey-gu，我访问，那么我对 https://github.com/vesoft-inc/nebula 的分叉应该就是 https://github.com/wey-gu/nebula 。 如果还没有自己的分叉，可以直接在 https://github.com/vesoft-inc/nebula 上点击右上角的 Fork，创建自己的分叉仓库。 当远程的个人分叉存在之后，我们可以把代码提交上去了 # 添加一个新的远程仓库叫 wey git remote add wey git@github.com:wey-gu/nebula.git # 提交 JSON_EXTRACT 分支到 wey 这个 remote 仓库 git push wey JSON_EXTRACT 5.1.3 在个人远程分叉分支上创建 PR这时候，我们访问这个远程分支：https://github.com/wey-gu/nebula/tree/fn_JSON_EXTRACT ，就能找到 Open PR 的入口： 然后点击 Open pull request 按钮，就进入到创建 PR 的界面了，这和在一般的论坛里提交一个帖子是很类似的： 提交之后，我们可以等待、或者邀请其他人来做代码的审查（review），往往其他的贡献者都能从他们的角度给出一些代码修改的建议和提示，我们需要经过几轮的代码修改、讨论之后使得代码达到最佳的状态。 而这些审查者中除了社区的贡献者（人类）之外，还有一些自动化的机器人，他们会在代码库中自动化的通过持续集成（CI）的方式运行一些自动化的审查工作，可能包括以下几种： CLA：Contributor License Agreement（贡献者许可协议），这是一个要 PR 作者在首次提交代码到项目时签署的协议，因为代码将被提交到公共空间，这份协议的签署意味着作者同意代码被分享、复用、修改这件事情。 lint：代码风格检查，这也是最常见的 CI 任务 test：各种层面的测试检查任务 通常来说，这些所有的自动化审查机器人所代表的任务也需要全都通过，代码的状态才能被认为是可以合并的，而不出意外，我首次提交的代码果然有测试的失败。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#commit-本地修改"},{"categories":["Nebula Graph"],"content":" 5.1 提交到个人远程分支这一步骤里，我们要把当前的本地提交的 commit，提交到自己的 GitHub 分叉之中。 5.1.1 commit 本地修改首先，我们确认一下本地的修改是否都是期待中的： # 先确定修改的文件 $ git status # 再看看修改的内容 $ git diff 然后，把它们 commit（提交在本地仓库） # 添加所有当前目录（. 这个点表示当前目录）修改过的文件为待 commit $ git add . # 然后我们可以看一下状态，这些修改的文件状态已经不同了 $ git status # 最后，提交在本地仓库，并用 -m 参数指定单行的 commit message $ git commit -m \"feat: introduce function JSON_EXTRACT\" 5.1.2 提交到自己远程的分支在提交之前，要确保自己的 GitHub 账号之下确实存在 NebulaGraph 代码仓库的分叉（fork），比如我的 GitHub 账号是 wey-gu，我访问，那么我对 https://github.com/vesoft-inc/nebula 的分叉应该就是 https://github.com/wey-gu/nebula 。 如果还没有自己的分叉，可以直接在 https://github.com/vesoft-inc/nebula 上点击右上角的 Fork，创建自己的分叉仓库。 当远程的个人分叉存在之后，我们可以把代码提交上去了 # 添加一个新的远程仓库叫 wey git remote add wey git@github.com:wey-gu/nebula.git # 提交 JSON_EXTRACT 分支到 wey 这个 remote 仓库 git push wey JSON_EXTRACT 5.1.3 在个人远程分叉分支上创建 PR这时候，我们访问这个远程分支：https://github.com/wey-gu/nebula/tree/fn_JSON_EXTRACT ，就能找到 Open PR 的入口： 然后点击 Open pull request 按钮，就进入到创建 PR 的界面了，这和在一般的论坛里提交一个帖子是很类似的： 提交之后，我们可以等待、或者邀请其他人来做代码的审查（review），往往其他的贡献者都能从他们的角度给出一些代码修改的建议和提示，我们需要经过几轮的代码修改、讨论之后使得代码达到最佳的状态。 而这些审查者中除了社区的贡献者（人类）之外，还有一些自动化的机器人，他们会在代码库中自动化的通过持续集成（CI）的方式运行一些自动化的审查工作，可能包括以下几种： CLA：Contributor License Agreement（贡献者许可协议），这是一个要 PR 作者在首次提交代码到项目时签署的协议，因为代码将被提交到公共空间，这份协议的签署意味着作者同意代码被分享、复用、修改这件事情。 lint：代码风格检查，这也是最常见的 CI 任务 test：各种层面的测试检查任务 通常来说，这些所有的自动化审查机器人所代表的任务也需要全都通过，代码的状态才能被认为是可以合并的，而不出意外，我首次提交的代码果然有测试的失败。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#提交到自己远程的分支"},{"categories":["Nebula Graph"],"content":" 5.1 提交到个人远程分支这一步骤里，我们要把当前的本地提交的 commit，提交到自己的 GitHub 分叉之中。 5.1.1 commit 本地修改首先，我们确认一下本地的修改是否都是期待中的： # 先确定修改的文件 $ git status # 再看看修改的内容 $ git diff 然后，把它们 commit（提交在本地仓库） # 添加所有当前目录（. 这个点表示当前目录）修改过的文件为待 commit $ git add . # 然后我们可以看一下状态，这些修改的文件状态已经不同了 $ git status # 最后，提交在本地仓库，并用 -m 参数指定单行的 commit message $ git commit -m \"feat: introduce function JSON_EXTRACT\" 5.1.2 提交到自己远程的分支在提交之前，要确保自己的 GitHub 账号之下确实存在 NebulaGraph 代码仓库的分叉（fork），比如我的 GitHub 账号是 wey-gu，我访问，那么我对 https://github.com/vesoft-inc/nebula 的分叉应该就是 https://github.com/wey-gu/nebula 。 如果还没有自己的分叉，可以直接在 https://github.com/vesoft-inc/nebula 上点击右上角的 Fork，创建自己的分叉仓库。 当远程的个人分叉存在之后，我们可以把代码提交上去了 # 添加一个新的远程仓库叫 wey git remote add wey git@github.com:wey-gu/nebula.git # 提交 JSON_EXTRACT 分支到 wey 这个 remote 仓库 git push wey JSON_EXTRACT 5.1.3 在个人远程分叉分支上创建 PR这时候，我们访问这个远程分支：https://github.com/wey-gu/nebula/tree/fn_JSON_EXTRACT ，就能找到 Open PR 的入口： 然后点击 Open pull request 按钮，就进入到创建 PR 的界面了，这和在一般的论坛里提交一个帖子是很类似的： 提交之后，我们可以等待、或者邀请其他人来做代码的审查（review），往往其他的贡献者都能从他们的角度给出一些代码修改的建议和提示，我们需要经过几轮的代码修改、讨论之后使得代码达到最佳的状态。 而这些审查者中除了社区的贡献者（人类）之外，还有一些自动化的机器人，他们会在代码库中自动化的通过持续集成（CI）的方式运行一些自动化的审查工作，可能包括以下几种： CLA：Contributor License Agreement（贡献者许可协议），这是一个要 PR 作者在首次提交代码到项目时签署的协议，因为代码将被提交到公共空间，这份协议的签署意味着作者同意代码被分享、复用、修改这件事情。 lint：代码风格检查，这也是最常见的 CI 任务 test：各种层面的测试检查任务 通常来说，这些所有的自动化审查机器人所代表的任务也需要全都通过，代码的状态才能被认为是可以合并的，而不出意外，我首次提交的代码果然有测试的失败。 ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:1","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#在个人远程分叉分支上创建-pr"},{"categories":["Nebula Graph"],"content":" 5.2 调试 CI 测试代码NebulaGraph 里所有的 CI 测试代码也都能在本地被触发，并且（显然）都有被单独触发的方式，我们需要掌握它们而不是在每次修改一个小的测试修复之后提交到服务器上等着 CI 做全量的运行（这样常常几十分钟就这么浪费掉了）。 5.2.1 CTest在这个距离的 PR 提交中，我修改的函数代码同一层级下的单元测试 CTest 就有问题，问题可能是测试代码本身造成、我们的修改破坏了原来的测试用例导致、亦或者是我们自己的测试用例发现了代码修改本身的问题。 这次，我们要根据 CTest 失败的报错进行排查和代码修改，然后编译代码，在本地运行一下这个失败的用例： # 我们需要进入到我们的编译容器内部的 build 目录下 $ docker exec -ti nebula_dev bash $ cd build # 在 -DENABLE_TESTING=ON 之中编译，如果之前的编译 job 数下内存已经跑满了的话，这次可以把 job 数调小一点，因为开启测试会占用更多内存 $ cmake -DCMAKE_CXX_COMPILER=$TOOLSET_CLANG_DIR/bin/g++ -DCMAKE_C_COMPILER=$TOOLSET_CLANG_DIR/bin/gcc -DENABLE_WERROR=OFF -DCMAKE_BUILD_TYPE=Debug -DENABLE_TESTING=ON .. $ make -j 48 # 可以看到编译成功了 CTest 的单元测试二进制可执行文件 # [100%] Linking CXX executable ../../../../bin/test/function_manager_test # [100%] Built target function_manager_test # 执行重新修改过的单元测试！ $ bin/test/function_manager_test [==========] Running 11 tests from 1 test suite. [----------] Global test environment set-up. [----------] 11 tests from FunctionManagerTest [ RUN ] FunctionManagerTest.testNull [ OK ] FunctionManagerTest.testNull (0 ms) [ RUN ] FunctionManagerTest.functionCall W20221020 23:35:18.579897 28679 Map.cpp:77] JSON_EXTRACT nested layer 1: Map can be populated only by Bool, Double, Int, String value and null, now trying to parse from: object [ OK ] FunctionManagerTest.functionCall (2 ms) [ RUN ] FunctionManagerTest.time [ OK ] FunctionManagerTest.time (0 ms) [ RUN ] FunctionManagerTest.returnType [ OK ] FunctionManagerTest.returnType (0 ms) [ RUN ] FunctionManagerTest.SchemaRelated [ OK ] FunctionManagerTest.SchemaRelated (0 ms) [ RUN ] FunctionManagerTest.ScalarFunctionTest [ OK ] FunctionManagerTest.ScalarFunctionTest (0 ms) [ RUN ] FunctionManagerTest.ListFunctionTest [ OK ] FunctionManagerTest.ListFunctionTest (0 ms) [ RUN ] FunctionManagerTest.duplicateEdgesORVerticesInPath [ OK ] FunctionManagerTest.duplicateEdgesORVerticesInPath (0 ms) [ RUN ] FunctionManagerTest.ReversePath [ OK ] FunctionManagerTest.ReversePath (0 ms) [ RUN ] FunctionManagerTest.DataSetRowCol [ OK ] FunctionManagerTest.DataSetRowCol (0 ms) [ RUN ] FunctionManagerTest.PurityTest [ OK ] FunctionManagerTest.PurityTest (0 ms) [----------] 11 tests from FunctionManagerTest (5 ms total) [----------] Global test environment tear-down [==========] 11 tests from 1 test suite ran. (5 ms total) [ PASSED ] 11 tests. 成功！ 于是，我把新的更改提交到远程分支上，在 PR 的网页中，可以看到 CI 已经在新的提交的触发下重新编译、执行了，过一会儿果然都 pass 了，于是我兴高采烈地等待着两位以上的审查者帮忙批准代码，然后合并它！ 但是，我收到了新的建议： 另一位贡献者请我添加 TCK 的测试用例。 5.2.2 TCKTCK 的全称是 The Cypher Technology Compatibility Kit，它是 NebulaGraph 从 OpenCypher 社区继承演进而来的一套测试框架，我们用 Python 做了测试用例格式兼容的实现。 它的优雅在于，我们可以像写英语一样去描述我们想实现的端到端功能测试用例，像这样！ # tests/tck/features/function/json_extract.feature Feature: json_extract Function Background: Test json_extract function Scenario: Test Positive Cases When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": \"foo\", \"b\": 0.2, \"c\": true}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: \"foo\", b: 0.2, c: true} | When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": 1, \"b\": {}, \"c\": {\"d\": true}}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: 1, b: {}, c: {d: true}} | When executing query: \"\"\" YIELD JSON_EXTRACT('{}') AS result; \"\"\" Then the result should be, in any order: | result | | {} | 在添加了自己的一个新的 tck 测试用例文本文件之后，我们只需要在测试文件中临时增加标签，并在执行的时候指定标签，就可以单独执行新增的 tck 测试用例了： # 还是在编译容器内部，进入到 tests 目录下 cd ../tests # 安装 tck 测试所需依赖 python3 -m pip install -r requirements.txt python3 -m pip install nebula3-python==3.1.0 # 运行一个单独为 tck 测试准备的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true up # 给 tests/tck/features/function/json_extract.feature 以@开头第一行加上标签，比如 @wey vi tests/tck/features/function/json_extract.feature # 执行 pytest (包含 tck 用例)，因为制定了 -m \"wey\"，只有 tests/tck/features/function/json_extract.feature 会被执行 python3 -m pytest -m \"wey\" # 关闭 pytest 所依赖的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true down 延伸阅读： 基于 BDD 理论的 Nebula 集成测试框架重构，https://nebula-graph.com.cn/posts/bdd-testing-pract","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#调试-ci-测试代码"},{"categories":["Nebula Graph"],"content":" 5.2 调试 CI 测试代码NebulaGraph 里所有的 CI 测试代码也都能在本地被触发，并且（显然）都有被单独触发的方式，我们需要掌握它们而不是在每次修改一个小的测试修复之后提交到服务器上等着 CI 做全量的运行（这样常常几十分钟就这么浪费掉了）。 5.2.1 CTest在这个距离的 PR 提交中，我修改的函数代码同一层级下的单元测试 CTest 就有问题，问题可能是测试代码本身造成、我们的修改破坏了原来的测试用例导致、亦或者是我们自己的测试用例发现了代码修改本身的问题。 这次，我们要根据 CTest 失败的报错进行排查和代码修改，然后编译代码，在本地运行一下这个失败的用例： # 我们需要进入到我们的编译容器内部的 build 目录下 $ docker exec -ti nebula_dev bash $ cd build # 在 -DENABLE_TESTING=ON 之中编译，如果之前的编译 job 数下内存已经跑满了的话，这次可以把 job 数调小一点，因为开启测试会占用更多内存 $ cmake -DCMAKE_CXX_COMPILER=$TOOLSET_CLANG_DIR/bin/g++ -DCMAKE_C_COMPILER=$TOOLSET_CLANG_DIR/bin/gcc -DENABLE_WERROR=OFF -DCMAKE_BUILD_TYPE=Debug -DENABLE_TESTING=ON .. $ make -j 48 # 可以看到编译成功了 CTest 的单元测试二进制可执行文件 # [100%] Linking CXX executable ../../../../bin/test/function_manager_test # [100%] Built target function_manager_test # 执行重新修改过的单元测试！ $ bin/test/function_manager_test [==========] Running 11 tests from 1 test suite. [----------] Global test environment set-up. [----------] 11 tests from FunctionManagerTest [ RUN ] FunctionManagerTest.testNull [ OK ] FunctionManagerTest.testNull (0 ms) [ RUN ] FunctionManagerTest.functionCall W20221020 23:35:18.579897 28679 Map.cpp:77] JSON_EXTRACT nested layer 1: Map can be populated only by Bool, Double, Int, String value and null, now trying to parse from: object [ OK ] FunctionManagerTest.functionCall (2 ms) [ RUN ] FunctionManagerTest.time [ OK ] FunctionManagerTest.time (0 ms) [ RUN ] FunctionManagerTest.returnType [ OK ] FunctionManagerTest.returnType (0 ms) [ RUN ] FunctionManagerTest.SchemaRelated [ OK ] FunctionManagerTest.SchemaRelated (0 ms) [ RUN ] FunctionManagerTest.ScalarFunctionTest [ OK ] FunctionManagerTest.ScalarFunctionTest (0 ms) [ RUN ] FunctionManagerTest.ListFunctionTest [ OK ] FunctionManagerTest.ListFunctionTest (0 ms) [ RUN ] FunctionManagerTest.duplicateEdgesORVerticesInPath [ OK ] FunctionManagerTest.duplicateEdgesORVerticesInPath (0 ms) [ RUN ] FunctionManagerTest.ReversePath [ OK ] FunctionManagerTest.ReversePath (0 ms) [ RUN ] FunctionManagerTest.DataSetRowCol [ OK ] FunctionManagerTest.DataSetRowCol (0 ms) [ RUN ] FunctionManagerTest.PurityTest [ OK ] FunctionManagerTest.PurityTest (0 ms) [----------] 11 tests from FunctionManagerTest (5 ms total) [----------] Global test environment tear-down [==========] 11 tests from 1 test suite ran. (5 ms total) [ PASSED ] 11 tests. 成功！ 于是，我把新的更改提交到远程分支上，在 PR 的网页中，可以看到 CI 已经在新的提交的触发下重新编译、执行了，过一会儿果然都 pass 了，于是我兴高采烈地等待着两位以上的审查者帮忙批准代码，然后合并它！ 但是，我收到了新的建议： 另一位贡献者请我添加 TCK 的测试用例。 5.2.2 TCKTCK 的全称是 The Cypher Technology Compatibility Kit，它是 NebulaGraph 从 OpenCypher 社区继承演进而来的一套测试框架，我们用 Python 做了测试用例格式兼容的实现。 它的优雅在于，我们可以像写英语一样去描述我们想实现的端到端功能测试用例，像这样！ # tests/tck/features/function/json_extract.feature Feature: json_extract Function Background: Test json_extract function Scenario: Test Positive Cases When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": \"foo\", \"b\": 0.2, \"c\": true}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: \"foo\", b: 0.2, c: true} | When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": 1, \"b\": {}, \"c\": {\"d\": true}}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: 1, b: {}, c: {d: true}} | When executing query: \"\"\" YIELD JSON_EXTRACT('{}') AS result; \"\"\" Then the result should be, in any order: | result | | {} | 在添加了自己的一个新的 tck 测试用例文本文件之后，我们只需要在测试文件中临时增加标签，并在执行的时候指定标签，就可以单独执行新增的 tck 测试用例了： # 还是在编译容器内部，进入到 tests 目录下 cd ../tests # 安装 tck 测试所需依赖 python3 -m pip install -r requirements.txt python3 -m pip install nebula3-python==3.1.0 # 运行一个单独为 tck 测试准备的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true up # 给 tests/tck/features/function/json_extract.feature 以@开头第一行加上标签，比如 @wey vi tests/tck/features/function/json_extract.feature # 执行 pytest (包含 tck 用例)，因为制定了 -m \"wey\"，只有 tests/tck/features/function/json_extract.feature 会被执行 python3 -m pytest -m \"wey\" # 关闭 pytest 所依赖的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true down 延伸阅读： 基于 BDD 理论的 Nebula 集成测试框架重构，https://nebula-graph.com.cn/posts/bdd-testing-pract","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#ctest"},{"categories":["Nebula Graph"],"content":" 5.2 调试 CI 测试代码NebulaGraph 里所有的 CI 测试代码也都能在本地被触发，并且（显然）都有被单独触发的方式，我们需要掌握它们而不是在每次修改一个小的测试修复之后提交到服务器上等着 CI 做全量的运行（这样常常几十分钟就这么浪费掉了）。 5.2.1 CTest在这个距离的 PR 提交中，我修改的函数代码同一层级下的单元测试 CTest 就有问题，问题可能是测试代码本身造成、我们的修改破坏了原来的测试用例导致、亦或者是我们自己的测试用例发现了代码修改本身的问题。 这次，我们要根据 CTest 失败的报错进行排查和代码修改，然后编译代码，在本地运行一下这个失败的用例： # 我们需要进入到我们的编译容器内部的 build 目录下 $ docker exec -ti nebula_dev bash $ cd build # 在 -DENABLE_TESTING=ON 之中编译，如果之前的编译 job 数下内存已经跑满了的话，这次可以把 job 数调小一点，因为开启测试会占用更多内存 $ cmake -DCMAKE_CXX_COMPILER=$TOOLSET_CLANG_DIR/bin/g++ -DCMAKE_C_COMPILER=$TOOLSET_CLANG_DIR/bin/gcc -DENABLE_WERROR=OFF -DCMAKE_BUILD_TYPE=Debug -DENABLE_TESTING=ON .. $ make -j 48 # 可以看到编译成功了 CTest 的单元测试二进制可执行文件 # [100%] Linking CXX executable ../../../../bin/test/function_manager_test # [100%] Built target function_manager_test # 执行重新修改过的单元测试！ $ bin/test/function_manager_test [==========] Running 11 tests from 1 test suite. [----------] Global test environment set-up. [----------] 11 tests from FunctionManagerTest [ RUN ] FunctionManagerTest.testNull [ OK ] FunctionManagerTest.testNull (0 ms) [ RUN ] FunctionManagerTest.functionCall W20221020 23:35:18.579897 28679 Map.cpp:77] JSON_EXTRACT nested layer 1: Map can be populated only by Bool, Double, Int, String value and null, now trying to parse from: object [ OK ] FunctionManagerTest.functionCall (2 ms) [ RUN ] FunctionManagerTest.time [ OK ] FunctionManagerTest.time (0 ms) [ RUN ] FunctionManagerTest.returnType [ OK ] FunctionManagerTest.returnType (0 ms) [ RUN ] FunctionManagerTest.SchemaRelated [ OK ] FunctionManagerTest.SchemaRelated (0 ms) [ RUN ] FunctionManagerTest.ScalarFunctionTest [ OK ] FunctionManagerTest.ScalarFunctionTest (0 ms) [ RUN ] FunctionManagerTest.ListFunctionTest [ OK ] FunctionManagerTest.ListFunctionTest (0 ms) [ RUN ] FunctionManagerTest.duplicateEdgesORVerticesInPath [ OK ] FunctionManagerTest.duplicateEdgesORVerticesInPath (0 ms) [ RUN ] FunctionManagerTest.ReversePath [ OK ] FunctionManagerTest.ReversePath (0 ms) [ RUN ] FunctionManagerTest.DataSetRowCol [ OK ] FunctionManagerTest.DataSetRowCol (0 ms) [ RUN ] FunctionManagerTest.PurityTest [ OK ] FunctionManagerTest.PurityTest (0 ms) [----------] 11 tests from FunctionManagerTest (5 ms total) [----------] Global test environment tear-down [==========] 11 tests from 1 test suite ran. (5 ms total) [ PASSED ] 11 tests. 成功！ 于是，我把新的更改提交到远程分支上，在 PR 的网页中，可以看到 CI 已经在新的提交的触发下重新编译、执行了，过一会儿果然都 pass 了，于是我兴高采烈地等待着两位以上的审查者帮忙批准代码，然后合并它！ 但是，我收到了新的建议： 另一位贡献者请我添加 TCK 的测试用例。 5.2.2 TCKTCK 的全称是 The Cypher Technology Compatibility Kit，它是 NebulaGraph 从 OpenCypher 社区继承演进而来的一套测试框架，我们用 Python 做了测试用例格式兼容的实现。 它的优雅在于，我们可以像写英语一样去描述我们想实现的端到端功能测试用例，像这样！ # tests/tck/features/function/json_extract.feature Feature: json_extract Function Background: Test json_extract function Scenario: Test Positive Cases When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": \"foo\", \"b\": 0.2, \"c\": true}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: \"foo\", b: 0.2, c: true} | When executing query: \"\"\" YIELD JSON_EXTRACT('{\"a\": 1, \"b\": {}, \"c\": {\"d\": true}}') AS result; \"\"\" Then the result should be, in any order: | result | | {a: 1, b: {}, c: {d: true}} | When executing query: \"\"\" YIELD JSON_EXTRACT('{}') AS result; \"\"\" Then the result should be, in any order: | result | | {} | 在添加了自己的一个新的 tck 测试用例文本文件之后，我们只需要在测试文件中临时增加标签，并在执行的时候指定标签，就可以单独执行新增的 tck 测试用例了： # 还是在编译容器内部，进入到 tests 目录下 cd ../tests # 安装 tck 测试所需依赖 python3 -m pip install -r requirements.txt python3 -m pip install nebula3-python==3.1.0 # 运行一个单独为 tck 测试准备的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true up # 给 tests/tck/features/function/json_extract.feature 以@开头第一行加上标签，比如 @wey vi tests/tck/features/function/json_extract.feature # 执行 pytest (包含 tck 用例)，因为制定了 -m \"wey\"，只有 tests/tck/features/function/json_extract.feature 会被执行 python3 -m pytest -m \"wey\" # 关闭 pytest 所依赖的集群 make CONTAINERIZED=true ENABLE_SSL=true CA_SIGNED=true down 延伸阅读： 基于 BDD 理论的 Nebula 集成测试框架重构，https://nebula-graph.com.cn/posts/bdd-testing-pract","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:2","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#tck"},{"categories":["Nebula Graph"],"content":" 5.3 邀请再次 review待我们把需要的测试调通、再次提交 PR 并且 CI 用例全都通过之后，我们可以再次邀请之前帮助审查代码的同学做做最后的查看，如果一切都顺利，代码就会被合并了！ 题图来自 Jon ","date":"2022-10-23","objectID":"/nebulagraph-hacking-guide/:5:3","series":null,"tags":["NebulaGraph","contributing","open-source","开发指南"],"title":"NebulaGraph 内核贡献开发指南","uri":"/nebulagraph-hacking-guide/#邀请再次-review"},{"categories":["Nebula Graph"],"content":"本文旨在帮助 NebulaGraph 新手快速了解查询语句调优，读懂查询计划。","date":"2022-09-06","objectID":"/ngql-execution-plan/","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/"},{"categories":["Nebula Graph"],"content":" 本文旨在帮助 NebulaGraph 新手快速了解查询语句调优，读懂查询计划。 很长时间以来，NebulaGraph 社区里最热门之一的话题都是“我如何表达这样的查询最好？“，”我这个查询还有优化空间吗？“这一类的。今天，我就试着介绍一下如何理解查询语句的执行与优化过程，帮助大家脚踩在地上去写自己的查询语句。 同时，这篇文章也是 nGQL 简明教程系列的第二期，通过本文了解面向性能去写查询语句之后，我们在进行图建模的过程（第三期的内容）中也能有更多支撑。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:0:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#"},{"categories":["Nebula Graph"],"content":" 1 一个查询的一生先从一个查询语句从进入 NebulaGraph 一直到返回查询结果的全过程。 在开始之前，推荐阅读如下源码解读、架构设计的文章： 参考文章 https://nebula-graph.com.cn/posts/nebula-graph-architecture-overview https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-01 https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-02 https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-03 https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-04 https://nebula-graph.com.cn/posts/nebula-graph-source-code-reading-05 https://nebula-graph.com.cn/posts/how-indexing-works-in-nebula-graph 简单来说，一个查询语句被从 GraphClient 发送给 GraphD 之后，经历了： 在 Parser 中被解析成抽象语法树(AST) 在 Validator, Planner 中被写成执行计划图，图中的每一个顶点 PlanNode 对应着一种算子 通过 Optimizer 中的优化规则（RBO）改写执行计划图 优化过的计划图被执行引擎从图的叶子节点开始执行直到根部 的过程： 举一个例子，在查年龄大于 34 岁的三跳好友的语句被查询之后 GO 3 STEPS FROM \"player100\" OVER follow WHERE $$.player.age \u003e 34 YIELD DISTINCT $$.player.name AS name, $$.player.age AS age | ORDER BY $-.age ASC, $-.name DESC; 语句经过了解析、验证、优化之后，最终的执行计划是， Start -\u003e Loop -\u003e Start -\u003e GetNeighbors -\u003e Project -\u003e Dedup -\u003e Loop -\u003e GetNeighbors -\u003e Project -\u003e GetVertices -\u003e Project -\u003e LeftJoin -\u003e Filter -\u003e Project -\u003e Dedup -\u003e Sort，或者如下图所示。 了解这个优化过程和最终执行计划意味着什么是调优查询、面向性能设计图建模的关键。 这个计划图由添加了 PROFILE FORMAT=\"DOT\" 的执行结果中的 digraph 部分，借助 graphviz 渲染而得，的https://dreampuf.github.io/GraphvizOnline 是一个方便的线上渲染的工具。 另外，值得注意的是，FORMAT=\"DOT\" 省略之后的输出结果是表格形式的，并且，有更多信息会展示出来，后边我们会解读。 (root@nebula) [basketballplayer]\u003e PROFILE FORMAT=\"DOT\" GO 3 STEPS FROM \"player100\" OVER follow WHERE $$.player.age \u003e 34 YIELD DISTINCT $$.player.name AS name, $$.player.age AS age | ORDER BY $-.age ASC, $-.name DESC; +-----------------+-----+ | name | age | +-----------------+-----+ | \"Tony Parker\" | 36 | | \"Manu Ginobili\" | 41 | | \"Tim Duncan\" | 42 | +-----------------+-----+ Got 3 rows (time spent 8885/19871 us) Execution Plan (optimize time 1391 us) ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ plan ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ digraph exec_plan { rankdir=BT; \"Sort_14\"[label=\"{Sort_14|outputVar: \\{\\\"colNames\\\":\\[\\\"name\\\",\\\"age\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Sort_14\\\"\\}|inputVar: __Dedup_13}\", shape=Mrecord]; \"Dedup_13\"-\u003e\"Sort_14\"; \"Dedup_13\"[label=\"{Dedup_13|outputVar: \\{\\\"colNames\\\":\\[\\\"name\\\",\\\"age\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Dedup_13\\\"\\}|inputVar: __Project_12}\", shape=Mrecord]; \"Project_12\"-\u003e\"Dedup_13\"; \"Project_12\"[label=\"{Project_12|outputVar: \\{\\\"colNames\\\":\\[\\\"name\\\",\\\"age\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Project_12\\\"\\}|inputVar: __Filter_11}\", shape=Mrecord]; \"Filter_11\"-\u003e\"Project_12\"; \"Filter_11\"[label=\"{Filter_11|outputVar: \\{\\\"colNames\\\":\\[\\\"JOIN_DST_VID\\\",\\\"__COL_0\\\",\\\"__COL_1\\\",\\\"DST_VID\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Filter_11\\\"\\}|inputVar: __LeftJoin_10}\", shape=Mrecord]; \"LeftJoin_10\"-\u003e\"Filter_11\"; \"LeftJoin_10\"[label=\"{LeftJoin_10|outputVar: \\{\\\"colNames\\\":\\[\\\"JOIN_DST_VID\\\",\\\"__COL_0\\\",\\\"__COL_1\\\",\\\"DST_VID\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__LeftJoin_10\\\"\\}|inputVar: \\{\\\"rightVar\\\":\\{\\\"__Project_9\\\":0\\},\\\"leftVar\\\":\\{\\\"__Project_7\\\":0\\}\\}}\", shape=Mrecord]; \"Project_9\"-\u003e\"LeftJoin_10\"; \"Project_9\"[label=\"{Project_9|outputVar: \\{\\\"colNames\\\":\\[\\\"__COL_0\\\",\\\"__COL_1\\\",\\\"DST_VID\\\"\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__Project_9\\\"\\}|inputVar: __GetVertices_8}\", shape=Mrecord]; \"GetVertices_8\"-\u003e\"Project_9\"; \"GetVertices_8\"[label=\"{GetVertices_8|outputVar: \\{\\\"colNames\\\":\\[\\],\\\"type\\\":\\\"DATASET\\\",\\\"name\\\":\\\"__GetVertices_8\\\"\\}|inputVar: __Project_7}\", shape=Mrecord]; \"Project_7\"-\u003e\"GetVertices_8\"; \"Project_7\"[label=\"{Project_7|outputVar: \\{\\\"colNames\\\":\\[\\","date":"2022-09-06","objectID":"/ngql-execution-plan/:1:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#一个查询的一生"},{"categories":["Nebula Graph"],"content":" 1.1 查询计划为了理解一个查询在整个生命周期中，如何反应到执行层面，以及它们的性能代价是多少，我们从认识它的执行计划开始入手。 以前边的图的拓展的 GO 语句为例，它的整个过程经历了如下节点 GetNeighbors 是执行计划中最重要的节点，GetNeighbors 算子会在运行期访问存储服务，拿到通过起点和指定边类型一步拓展后终点的 id 多步拓展通过 Loop 节点实现，Start 到 Loop 之间是 Loop 子计划，当满足条件时 Loop 子计划会被循环执行，最后一步拓展节点在 Loop 外实现 Project 节点用来获取当前拓展的终点 id Dedup 节点对终点 id 进行去重后作为下一步拓展的起点 GetVertices 节点负责取终点 tag 的属性 Filter 做条件过滤 LeftJoin 的作用是合并 GetNeightbors 和 GetVertices 的结果 Sort 做排序 而这些节点就是不同的算子。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:1:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#查询计划"},{"categories":["Nebula Graph"],"content":" 2 认识算子在 NebulaGraph 博客的代码解读文章中已经有很多算子被提及、解释过，这里列举其中部分常见的算子： 注：这里没有提及 GET SUBGRAPH/ FIND PATH 中的算子。 算子 介绍 GetNeighbor 根据指定的 vid ，从存储层获取起始点和边的属性 Traverse 仅用于MATCH 匹配 ()-[e:0..n]-() 模式，获取拓展过程中的起始点和边的属性 AppendVertices 仅用于MATCH ，和 Traverse 配合获取点的属性 GetEdge 获取边的属性 GetVertices 获取点的属性，FETCH PROP 或者 GO 语句中。 ScanEdge 全表扫描边，例如 MATCH ()-[e]-\u003e() RETURN e LIMIT 3 ScanVertices 全表扫描点，例如 MATCH (v) return v LIMIT 3 IndexScan MATCH 语句中找到起始点的索引查询 TagIndexPrefixScan LOOKUP 语句中前缀扫描 LOOKUP ON player where player.name == \"Steve Nash\" YIELD player.name TagIndexRangeScan LOOKUP 语句中范围扫描 LOOKUP ON player where player.name \u003e \"S\" YIELD player.name TagIndexFullScan LOOKUP 语句中全扫描 LOOKUP ON player YIELD player.name Filter 按条件过滤，例如 WHERE 语句 Project 获取上一步算子的列 Dedup 去重 LeftJoin 合并结果 LIMIT 限制输出行数 从这些算子的含义中已经可以更加具体的知道图数据库查询落到查询引擎（GraphD）内部的最小所需操作了，而性能调优的关键就在于如何规划、优化一个查询如何被拆解为算子的执行计划。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:2:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#认识算子"},{"categories":["Nebula Graph"],"content":" 3 认识优化规则对于任何给定的查询，执行计划并不是唯一确定的，相反，在最简单、直接的计划基础之上，优化器（Optimizer）会进行很多性能上的优化。 NebulaGraph 目前的优化器是完全的基于规则的优化（RBO），这些预设的规则的代码都在 src/graph/optimizer 的 rules 里边，它们都是针对执行计划模式的修改规则，之前 Shylock 在这篇文章里给过源码层面的介绍，大家可以去读一下。 值得庆幸的是，今年，大部分优化规则的代码里增加了很多好理解的 asciiart 图形注释，结合优化规则的命名本身的自解释性，我们可以很快速去大概理解优化规则的匹配规则和转换逻辑。 首先，这些规则的转换(transform)代码都在 .cpp 文件里，asciiart 图形注释在同名对应的 .h 里！ ls src/graph/optimizer/rule/*.h src/graph/optimizer/rule/CollapseProjectRule.h src/graph/optimizer/rule/PushFilterDownLeftJoinRule.h src/graph/optimizer/rule/CombineFilterRule.h src/graph/optimizer/rule/PushFilterDownNodeRule.h src/graph/optimizer/rule/EdgeIndexFullScanRule.h src/graph/optimizer/rule/PushFilterDownProjectRule.h src/graph/optimizer/rule/EliminateAppendVerticesRule.h src/graph/optimizer/rule/PushFilterDownScanVerticesRule.h src/graph/optimizer/rule/EliminateRowCollectRule.h src/graph/optimizer/rule/PushLimitDownGetNeighborsRule.h src/graph/optimizer/rule/GeoPredicateEdgeIndexScanRule.h src/graph/optimizer/rule/PushLimitDownIndexScanRule.h src/graph/optimizer/rule/GeoPredicateIndexScanBaseRule.h src/graph/optimizer/rule/PushLimitDownProjectRule.h src/graph/optimizer/rule/GeoPredicateTagIndexScanRule.h src/graph/optimizer/rule/PushLimitDownScanAppendVerticesRule.h src/graph/optimizer/rule/GetEdgesTransformAppendVerticesLimitRule.h src/graph/optimizer/rule/PushLimitDownScanEdgesAppendVerticesRule.h src/graph/optimizer/rule/GetEdgesTransformRule.h src/graph/optimizer/rule/PushLimitDownScanEdgesRule.h src/graph/optimizer/rule/GetEdgesTransformUtils.h src/graph/optimizer/rule/PushStepLimitDownGetNeighborsRule.h src/graph/optimizer/rule/IndexFullScanBaseRule.h src/graph/optimizer/rule/PushStepSampleDownGetNeighborsRule.h src/graph/optimizer/rule/IndexScanRule.h src/graph/optimizer/rule/PushTopNDownIndexScanRule.h src/graph/optimizer/rule/MergeGetNbrsAndDedupRule.h src/graph/optimizer/rule/PushVFilterDownScanVerticesRule.h src/graph/optimizer/rule/MergeGetNbrsAndProjectRule.h src/graph/optimizer/rule/RemoveNoopProjectRule.h src/graph/optimizer/rule/MergeGetVerticesAndDedupRule.h src/graph/optimizer/rule/RemoveProjectDedupBeforeGetDstBySrcRule.h src/graph/optimizer/rule/MergeGetVerticesAndProjectRule.h src/graph/optimizer/rule/TagIndexFullScanRule.h src/graph/optimizer/rule/OptimizeEdgeIndexScanByFilterRule.h src/graph/optimizer/rule/TopNRule.h src/graph/optimizer/rule/OptimizeTagIndexScanByFilterRule.h src/graph/optimizer/rule/UnionAllEdgeIndexScanRule.h src/graph/optimizer/rule/PushEFilterDownRule.h src/graph/optimizer/rule/UnionAllIndexScanBaseRule.h src/graph/optimizer/rule/PushFilterDownAggregateRule.h src/graph/optimizer/rule/UnionAllTagIndexScanRule.h src/graph/optimizer/rule/PushFilterDownGetNbrsRule.h ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#认识优化规则"},{"categories":["Nebula Graph"],"content":" 3.1 GetEdgesTransformRule我们看下这个规则名字的意思是转换 GetEdges 的规则，看起来不够明确，再看看 GetEdgesTransformRule.h // Convert [[ScanVertices]] to [[ScanEdges]] in certain cases // Required conditions: // 1. Match the pattern // Benefits: // 1. Avoid doing Traverse to optimize performance // Quey example: // 1. match ()-[e]-\u003e() return e limit 3 // // Tranformation: // Before: // +---------+---------+ // | Project | // +---------+---------+ // | // +---------+---------+ // | Limit | // +---------+---------+ // | // +---------+---------+ // | Traverse | // +---------+---------+ // | // +---------+---------+ // | ScanVertices | // +---------+---------+ // // After: // +---------+---------+ // | Project | // +---------+---------+ // | // +---------+---------+ // | Limit | // +---------+---------+ // | // +---------+---------+ // | Project | // +---------+---------+ // | // +---------+---------+ // | ScanEdges | // +---------+---------+ 结合 .cpp 中 GetEdgesTransformRule::match 和 GetEdgesTransformRule::transform 的代码，我们可以确定这个优化规则是将 MATCH ()-[e]-\u003e() RETURN e LIMIT 3 原本按照 ScanVertices 去扫描顶点的起点转变为 ScanEdges。 这个规则的背景是没有点、边索引的 LIMIT 情况下，无起点 VID/属性条件的查询是可以通过扫点边数据下推 LIMIT 的，这个扫描边的查询因为只需要返回边，所以直接扫描边是更高效的。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#getedgestransformrule"},{"categories":["Nebula Graph"],"content":" 3.2 PushLimitDownScanEdgesRule我们看看这个规则，在 PushLimitDownScanEdgesRule.h 里有注释 // Embedding limit to [[ScanEdges]] // Required conditions: // 1. Match the pattern // Benefits: // 1. Limit data early to optimize performance // // Transformation: // Before: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | ScanEdges | // +---------+---------+ // // After: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | ScanEdges | // | (limit=3) | // +---------+---------+ 这个规则很简单，当 ScanEdges 算子的下游是 Limit 算子的时候，把 Limit 的过滤条件嵌入到 ScanEdges 之中。这一步的意义是什么呢？这里涉及到一个优化规则里常见的概念，计算下推。 3.2.1 计算下推在计算存储分离的数据库系统中，涉及到读取数据的算子需要从存储层远程捞取数据再做进一步处理。而这个 RPC 的数据传输常常成为性能的瓶颈。然而，如果下一步计算要做的事情是对数据的按条件剪枝，例如 Filter、 Limit、TopN 等等，这时候，让这些剪枝条件在存储层捞数据的时候就考虑到，则可以大大减少数据传输的量。 PushLimitDownScanEdgesRule.h 的优化规则就是一个典型的 Limit 下推（Push Down）的规则。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#pushlimitdownscanedgesrule"},{"categories":["Nebula Graph"],"content":" 3.2 PushLimitDownScanEdgesRule我们看看这个规则，在 PushLimitDownScanEdgesRule.h 里有注释 // Embedding limit to [[ScanEdges]] // Required conditions: // 1. Match the pattern // Benefits: // 1. Limit data early to optimize performance // // Transformation: // Before: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | ScanEdges | // +---------+---------+ // // After: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | ScanEdges | // | (limit=3) | // +---------+---------+ 这个规则很简单，当 ScanEdges 算子的下游是 Limit 算子的时候，把 Limit 的过滤条件嵌入到 ScanEdges 之中。这一步的意义是什么呢？这里涉及到一个优化规则里常见的概念，计算下推。 3.2.1 计算下推在计算存储分离的数据库系统中，涉及到读取数据的算子需要从存储层远程捞取数据再做进一步处理。而这个 RPC 的数据传输常常成为性能的瓶颈。然而，如果下一步计算要做的事情是对数据的按条件剪枝，例如 Filter、 Limit、TopN 等等，这时候，让这些剪枝条件在存储层捞数据的时候就考虑到，则可以大大减少数据传输的量。 PushLimitDownScanEdgesRule.h 的优化规则就是一个典型的 Limit 下推（Push Down）的规则。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#计算下推"},{"categories":["Nebula Graph"],"content":" 3.3 PushLimitDownProjectRule类似的，我们看看这个规则，PushLimitDownProjectRule.h 里有这样一段注释，这个规则只是把 Project 算子 之后的 Limit 算子的顺序调换了一下，我们可以想象在这个变换之后，Limit 就和 ScanEdges 等其他可以下推 Limit 的算子相邻了，然后例如 PushLimitDownScanEdgesRule 的规则变换也可以做了。 // Push [[Limit]] down [[Project]] // Required conditions: // 1. Match the pattern // Benefits: // 1. Limit data early to optimize performance // // Tranformation: // Before: // // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ // | // +---------+---------+ // | Project | // +---------+---------+ // // After: // +---------+---------+ // | Project | // +---------+---------+ // | // +--------+--------+ // | Limit | // | (limit=3) | // +--------+--------+ ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:3","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#pushlimitdownprojectrule"},{"categories":["Nebula Graph"],"content":" 3.4 PushFilterDownGetNbrsRule再介绍一个 Filter 下推的例子，从规则注释里的转换图示可以读出，当 GetNeighbors 之后再双条件交集 Filter 的时候，取一个条件下推到 GetNeighbors，再进行另一个条件的 Filter。这个规则既减少了 GetNeighbors 数据传输的量和 Filter 输入的运算量、又少了一次集合运算。 // Embed the [[Filter]] into [[GetNeighbors]] // Required conditions: // 1. Match the pattern // 2. Filter contains subexpressions that meet pushdown conditions // Benefits: // 1. Filter data early to optimize performance // // Tranformation: // Before: // // +------------------+------------------+ // | Filter | // |($^.player.age\u003e3 and $$.player.age\u003c4)| // +------------------+------------------+ // | // +------+------+ // | GetNeighbors| // +------+------+ // // After: // // +--------+--------+ // | Filter | // |($$.player.age\u003c4)| // +--------+--------+ // | // +--------+--------+ // | GetNeighbors | // |($^.player.age\u003e3)| // +--------+--------+ 3.4.1 下一步 感兴趣的同学可以试着进一步看看所有的规则。 可以试着在多个 GraphD 的集群上，更改其中一个 GraphD 的配置，关闭 enable_optimizer，把同一个 Query 分别在开启了优化和关闭优化的 GraphD 中执行，比较执行计划的区别。 如果你发现可以更优化的规则给到大家，欢迎来论坛、github 提交优化建议、或者 PR！ 简单的介绍就到这里，接下来我们从一些实例出发来进一步实操执行计划调优吧。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#pushfilterdowngetnbrsrule"},{"categories":["Nebula Graph"],"content":" 3.4 PushFilterDownGetNbrsRule再介绍一个 Filter 下推的例子，从规则注释里的转换图示可以读出，当 GetNeighbors 之后再双条件交集 Filter 的时候，取一个条件下推到 GetNeighbors，再进行另一个条件的 Filter。这个规则既减少了 GetNeighbors 数据传输的量和 Filter 输入的运算量、又少了一次集合运算。 // Embed the [[Filter]] into [[GetNeighbors]] // Required conditions: // 1. Match the pattern // 2. Filter contains subexpressions that meet pushdown conditions // Benefits: // 1. Filter data early to optimize performance // // Tranformation: // Before: // // +------------------+------------------+ // | Filter | // |($^.player.age\u003e3 and $$.player.age\u003c4)| // +------------------+------------------+ // | // +------+------+ // | GetNeighbors| // +------+------+ // // After: // // +--------+--------+ // | Filter | // |($$.player.age\u003c4)| // +--------+--------+ // | // +--------+--------+ // | GetNeighbors | // |($^.player.age\u003e3)| // +--------+--------+ 3.4.1 下一步 感兴趣的同学可以试着进一步看看所有的规则。 可以试着在多个 GraphD 的集群上，更改其中一个 GraphD 的配置，关闭 enable_optimizer，把同一个 Query 分别在开启了优化和关闭优化的 GraphD 中执行，比较执行计划的区别。 如果你发现可以更优化的规则给到大家，欢迎来论坛、github 提交优化建议、或者 PR！ 简单的介绍就到这里，接下来我们从一些实例出发来进一步实操执行计划调优吧。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:3:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#下一步"},{"categories":["Nebula Graph"],"content":" 4 nGQL 执行计划调优解读实例希望这些具体问题能够给大家带来启发。 ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#ngql-执行计划调优解读实例"},{"categories":["Nebula Graph"],"content":" 4.1 观察基于索引与数据的扫描我在索引详解中解释过 NebulaGraph 的索引和传统数据库中索引的区别，简单来说，因为以类似于邻接表的方式存储数据，NebulaGraph 里需要明确指定额外创建索引来解决全扫描或者根据属性条件扫描点、边的类似于表结构数据库中的场景。 另外，在无过滤条件 Limit 采样扫描的场景下，NebulaGraph 从 v3.0 以后允许了无索引的查询情形（因为点边数据扫描支持了 Limit 下推，不再像之前那么昂贵），在没有索引可以被选择的情况下，planner 也会选择直接扫点或者边的数据，这个差别可以从 explain, profile 中看出来。 这里用 Basketballplayer 数据集中自带的索引来距离，注意到其中只在 player 这个 TAG 上有两个索引： (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 4.1.1 无索引查询先看一个没有索引的场景的查询： (root@nebula) [basketballplayer]\u003e PROFILE MATCH (n:team) RETURN id(n) LIMIT 1 +-----------+ | id(n) | +-----------+ | \"team206\" | +-----------+ Got 1 rows (time spent 3637/17551 us) Execution Plan (optimize time 265 us) -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 15 | Project | 16 | ver: 0, rows: 1, execTime: 28us, totalTime: 29us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"id(n)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_8\" | | | | | | } | | | | | | inputVar: __Limit_13 | | | | | | columns: [ | | | | | | \"id($-.n)\" | | | | | | ] | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 16 | Limit | 17 | ver: 0, rows: 1, execTime: 3us, totalTime: 8us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Limit_13\" | | | | | | } | | | | | | inputVar: __AppendVertices_17 | | | | | | offset: 0 | | | | | | count: 1 | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 17 | AppendVertices | 18 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 244us, totalTime: 1124us | \"colNames\": [ | | | | | \"storaged0\":9779 exec/total: 257(us)/779(us) | \"n\" | | | | | \"storaged2\":9779 exec/total: 190(us)/870(us) | ], | | | | | total_rpc: 1024(us) | \"type\": \"DATASET\", | | | | | \"storaged1\":9779 exec/total: 195(us)/879(us) | \"name\": \"__AppendVertices_17\" | | | | | } | } | | | | | | inputVar: __ScanVertices_18 | | | | | | space: 2 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: $-._vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 3 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 4 | | | | | | } | | | | | | ] | | | | | | exprs: | | | | | | vertex_filter: | | | | | | if_track_previous_path: false | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 18 | ScanVertices | 3 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 225us, totalTime: 1586us | \"colNames\": [ | | | | | \"storaged2\":9779 exec/total: 532(us)/1303(us) | \"_vid\", | | | | | \"storaged1\":9779 exec/total: 480(us)/1318(us) | \"team._tag\" | | | | | total_rpc: 1502(us) | ], | | | | | \"storaged0\":9779 exec/total: 506(us)/1382(us) | \"type\": \"DATASET\", | | | | | } | \"name\": \"__ScanVertices_18\" | | | | | | } | | | | | | inputVar: | | | | | | space: 2 | | | | | | dedup: false | | | | | | limit: 1 | | | | | | filter: (team._tag IS NOT EMPTY AND team._tag IS NOT EMPTY) | | | | | | orderBy: [] | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#观察基于索引与数据的扫描"},{"categories":["Nebula Graph"],"content":" 4.1 观察基于索引与数据的扫描我在索引详解中解释过 NebulaGraph 的索引和传统数据库中索引的区别，简单来说，因为以类似于邻接表的方式存储数据，NebulaGraph 里需要明确指定额外创建索引来解决全扫描或者根据属性条件扫描点、边的类似于表结构数据库中的场景。 另外，在无过滤条件 Limit 采样扫描的场景下，NebulaGraph 从 v3.0 以后允许了无索引的查询情形（因为点边数据扫描支持了 Limit 下推，不再像之前那么昂贵），在没有索引可以被选择的情况下，planner 也会选择直接扫点或者边的数据，这个差别可以从 explain, profile 中看出来。 这里用 Basketballplayer 数据集中自带的索引来距离，注意到其中只在 player 这个 TAG 上有两个索引： (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 4.1.1 无索引查询先看一个没有索引的场景的查询： (root@nebula) [basketballplayer]\u003e PROFILE MATCH (n:team) RETURN id(n) LIMIT 1 +-----------+ | id(n) | +-----------+ | \"team206\" | +-----------+ Got 1 rows (time spent 3637/17551 us) Execution Plan (optimize time 265 us) -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 15 | Project | 16 | ver: 0, rows: 1, execTime: 28us, totalTime: 29us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"id(n)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_8\" | | | | | | } | | | | | | inputVar: __Limit_13 | | | | | | columns: [ | | | | | | \"id($-.n)\" | | | | | | ] | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 16 | Limit | 17 | ver: 0, rows: 1, execTime: 3us, totalTime: 8us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Limit_13\" | | | | | | } | | | | | | inputVar: __AppendVertices_17 | | | | | | offset: 0 | | | | | | count: 1 | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 17 | AppendVertices | 18 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 244us, totalTime: 1124us | \"colNames\": [ | | | | | \"storaged0\":9779 exec/total: 257(us)/779(us) | \"n\" | | | | | \"storaged2\":9779 exec/total: 190(us)/870(us) | ], | | | | | total_rpc: 1024(us) | \"type\": \"DATASET\", | | | | | \"storaged1\":9779 exec/total: 195(us)/879(us) | \"name\": \"__AppendVertices_17\" | | | | | } | } | | | | | | inputVar: __ScanVertices_18 | | | | | | space: 2 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: $-._vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 3 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 4 | | | | | | } | | | | | | ] | | | | | | exprs: | | | | | | vertex_filter: | | | | | | if_track_previous_path: false | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 18 | ScanVertices | 3 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 225us, totalTime: 1586us | \"colNames\": [ | | | | | \"storaged2\":9779 exec/total: 532(us)/1303(us) | \"_vid\", | | | | | \"storaged1\":9779 exec/total: 480(us)/1318(us) | \"team._tag\" | | | | | total_rpc: 1502(us) | ], | | | | | \"storaged0\":9779 exec/total: 506(us)/1382(us) | \"type\": \"DATASET\", | | | | | } | \"name\": \"__ScanVertices_18\" | | | | | | } | | | | | | inputVar: | | | | | | space: 2 | | | | | | dedup: false | | | | | | limit: 1 | | | | | | filter: (team._tag IS NOT EMPTY AND team._tag IS NOT EMPTY) | | | | | | orderBy: [] | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#无索引查询"},{"categories":["Nebula Graph"],"content":" 4.1 观察基于索引与数据的扫描我在索引详解中解释过 NebulaGraph 的索引和传统数据库中索引的区别，简单来说，因为以类似于邻接表的方式存储数据，NebulaGraph 里需要明确指定额外创建索引来解决全扫描或者根据属性条件扫描点、边的类似于表结构数据库中的场景。 另外，在无过滤条件 Limit 采样扫描的场景下，NebulaGraph 从 v3.0 以后允许了无索引的查询情形（因为点边数据扫描支持了 Limit 下推，不再像之前那么昂贵），在没有索引可以被选择的情况下，planner 也会选择直接扫点或者边的数据，这个差别可以从 explain, profile 中看出来。 这里用 Basketballplayer 数据集中自带的索引来距离，注意到其中只在 player 这个 TAG 上有两个索引： (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 4.1.1 无索引查询先看一个没有索引的场景的查询： (root@nebula) [basketballplayer]\u003e PROFILE MATCH (n:team) RETURN id(n) LIMIT 1 +-----------+ | id(n) | +-----------+ | \"team206\" | +-----------+ Got 1 rows (time spent 3637/17551 us) Execution Plan (optimize time 265 us) -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 15 | Project | 16 | ver: 0, rows: 1, execTime: 28us, totalTime: 29us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"id(n)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_8\" | | | | | | } | | | | | | inputVar: __Limit_13 | | | | | | columns: [ | | | | | | \"id($-.n)\" | | | | | | ] | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 16 | Limit | 17 | ver: 0, rows: 1, execTime: 3us, totalTime: 8us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Limit_13\" | | | | | | } | | | | | | inputVar: __AppendVertices_17 | | | | | | offset: 0 | | | | | | count: 1 | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 17 | AppendVertices | 18 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 244us, totalTime: 1124us | \"colNames\": [ | | | | | \"storaged0\":9779 exec/total: 257(us)/779(us) | \"n\" | | | | | \"storaged2\":9779 exec/total: 190(us)/870(us) | ], | | | | | total_rpc: 1024(us) | \"type\": \"DATASET\", | | | | | \"storaged1\":9779 exec/total: 195(us)/879(us) | \"name\": \"__AppendVertices_17\" | | | | | } | } | | | | | | inputVar: __ScanVertices_18 | | | | | | space: 2 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: $-._vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 3 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 4 | | | | | | } | | | | | | ] | | | | | | exprs: | | | | | | vertex_filter: | | | | | | if_track_previous_path: false | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 18 | ScanVertices | 3 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 225us, totalTime: 1586us | \"colNames\": [ | | | | | \"storaged2\":9779 exec/total: 532(us)/1303(us) | \"_vid\", | | | | | \"storaged1\":9779 exec/total: 480(us)/1318(us) | \"team._tag\" | | | | | total_rpc: 1502(us) | ], | | | | | \"storaged0\":9779 exec/total: 506(us)/1382(us) | \"type\": \"DATASET\", | | | | | } | \"name\": \"__ScanVertices_18\" | | | | | | } | | | | | | inputVar: | | | | | | space: 2 | | | | | | dedup: false | | | | | | limit: 1 | | | | | | filter: (team._tag IS NOT EMPTY AND team._tag IS NOT EMPTY) | | | | | | orderBy: [] | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#有索引查询limit-无下推"},{"categories":["Nebula Graph"],"content":" 4.1 观察基于索引与数据的扫描我在索引详解中解释过 NebulaGraph 的索引和传统数据库中索引的区别，简单来说，因为以类似于邻接表的方式存储数据，NebulaGraph 里需要明确指定额外创建索引来解决全扫描或者根据属性条件扫描点、边的类似于表结构数据库中的场景。 另外，在无过滤条件 Limit 采样扫描的场景下，NebulaGraph 从 v3.0 以后允许了无索引的查询情形（因为点边数据扫描支持了 Limit 下推，不再像之前那么昂贵），在没有索引可以被选择的情况下，planner 也会选择直接扫点或者边的数据，这个差别可以从 explain, profile 中看出来。 这里用 Basketballplayer 数据集中自带的索引来距离，注意到其中只在 player 这个 TAG 上有两个索引： (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 4.1.1 无索引查询先看一个没有索引的场景的查询： (root@nebula) [basketballplayer]\u003e PROFILE MATCH (n:team) RETURN id(n) LIMIT 1 +-----------+ | id(n) | +-----------+ | \"team206\" | +-----------+ Got 1 rows (time spent 3637/17551 us) Execution Plan (optimize time 265 us) -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 15 | Project | 16 | ver: 0, rows: 1, execTime: 28us, totalTime: 29us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"id(n)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_8\" | | | | | | } | | | | | | inputVar: __Limit_13 | | | | | | columns: [ | | | | | | \"id($-.n)\" | | | | | | ] | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 16 | Limit | 17 | ver: 0, rows: 1, execTime: 3us, totalTime: 8us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Limit_13\" | | | | | | } | | | | | | inputVar: __AppendVertices_17 | | | | | | offset: 0 | | | | | | count: 1 | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 17 | AppendVertices | 18 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 244us, totalTime: 1124us | \"colNames\": [ | | | | | \"storaged0\":9779 exec/total: 257(us)/779(us) | \"n\" | | | | | \"storaged2\":9779 exec/total: 190(us)/870(us) | ], | | | | | total_rpc: 1024(us) | \"type\": \"DATASET\", | | | | | \"storaged1\":9779 exec/total: 195(us)/879(us) | \"name\": \"__AppendVertices_17\" | | | | | } | } | | | | | | inputVar: __ScanVertices_18 | | | | | | space: 2 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: $-._vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 3 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 4 | | | | | | } | | | | | | ] | | | | | | exprs: | | | | | | vertex_filter: | | | | | | if_track_previous_path: false | -----+----------------+--------------+-----------------------------------------------------+-------------------------------------------------------------- | 18 | ScanVertices | 3 | { | outputVar: { | | | | | ver: 0, rows: 3, execTime: 225us, totalTime: 1586us | \"colNames\": [ | | | | | \"storaged2\":9779 exec/total: 532(us)/1303(us) | \"_vid\", | | | | | \"storaged1\":9779 exec/total: 480(us)/1318(us) | \"team._tag\" | | | | | total_rpc: 1502(us) | ], | | | | | \"storaged0\":9779 exec/total: 506(us)/1382(us) | \"type\": \"DATASET\", | | | | | } | \"name\": \"__ScanVertices_18\" | | | | | | } | | | | | | inputVar: | | | | | | space: 2 | | | | | | dedup: false | | | | | | limit: 1 | | | | | | filter: (team._tag IS NOT EMPTY AND team._tag IS NOT EMPTY) | | | | | | orderBy: [] | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#有索引查询limit-下推"},{"categories":["Nebula Graph"],"content":" 4.2 观察 filter 下推我们先看看这个查询，它沿着给定起点向外图扩展的查询，根据边的属性条件过滤，返回目的点 ID： GO FROM \"player100\" OVER follow WHERE properties(edge).degree \u003e 1 YIELD follow._dst 它的执行计划是： (root@nebula) [basketballplayer]\u003e explain GO FROM \"player100\" OVER follow WHERE properties(edge).degree \u003e 1 YIELD follow._dst Execution succeeded (time spent 959/7917 us) Execution Plan (optimize time 369 us) -----+--------------+--------------+----------------+----------------------------------------- | id | name | dependencies | profiling data | operator info | -----+--------------+--------------+----------------+----------------------------------------- | 3 | Project | 2 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"follow._dst\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_3\" | | | | | | } | | | | | | inputVar: __Filter_2 | | | | | | columns: [ | | | | | | \"follow._dst\" | | | | | | ] | -----+--------------+--------------+----------------+----------------------------------------- | 2 | Filter | 1 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Filter_2\" | | | | | | } | | | | | | inputVar: __GetNeighbors_1 | | | | | | condition: (properties(EDGE).degree\u003e1) | | | | | | isStable: false | -----+--------------+--------------+----------------+----------------------------------------- | 1 | GetNeighbors | 0 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_1\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: false | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_rank\", | | | | | | \"_src\", | | | | | | \"_type\", | | | | | | \"degree\" | | | | | | ], | | | | | | \"type\": 53 | | | | | | } | | | | | | ] | | | | | | statProps: | | | | | | exprs: | | | | | | random: false | -----+--------------+--------------+----------------+----------------------------------------- | 0 | Start | | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Start_0\" | | | | | | } | -----+--------------+--------------+----------------+----------------------------------------- 可以看到，这个计划里，GetNeighboors 算子取得了所有的 player100 的出边（以及边属性），然后再通过单独 Filter 算子。 我们关注： filter: 是空的 properties(EDGE).degree\u003e1 作为 Filter 算子的条件。 这里，我们有没有可能把 Filter 下推呢？答案是可以的，只要在 WHERE 条件中提供边类型的信息，优化条件就可以把它下推到 GetNeighbors 算子： (root@nebula) [basketballplayer]\u003e explain GO FROM \"player100\" OVER follow WHERE follow.degree \u003e 1 YIELD follow._dst Execution succeeded (time spent 664/6650 us) Execution Plan (optimize time 161 us) -----+--------------+--------------+----------------+---------------------------- | id | name | dependencies | profiling data | operator info | -----+--------------+--------------+----------------+---------------------------- | 3 | Project | 4 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"follow._dst\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_3\" | | | | | | } | | | | | | inputVar: __Filter_2 | | | | | | columns: [ | | | | | | \"follow._dst\" | | | | | | ] | -----+--------------+--------------+----------------+---------------------------- | 4 | GetNeighbors | 0 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Filter_2\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: false | | | | | | limit: -1 | | | | | | filter: (follow.degree\u003e1) | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"degree\" | | | | | | ], | | | | | | \"type\": 53 | | | | | | } | | | | | | ] | | | | | | statProps:","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#观察-filter-下推"},{"categories":["Nebula Graph"],"content":" 4.3 优化原则：减少模糊，增加确定，越早越好这里我给出三对查询的比较： GO FROM \"player100\" OVER follow YIELD dst(edge) 对比 GO FROM \"player100\" OVER follow YIELD follow._dst MATCH (:player)-[e]-(:player) RETURN e 与 MATCH (:player)-[e:follow]-(:player) RETURN e 在 1. 中，两者的差异不像前文中给出的算子有不同，这次的区别在于算子传递的数据量有不同，dst(edge) 的表达里，我们一方面没有给出 edge 的类型，另一方面是针对整个 edge 做了函数 dst() 的运算，这使得 GetNeighbors 算子的 edgeProps 输出是所有的属性，反观 follow._dst 的表达使得 edgeProps 输出只有边的 _dst，这印证了在我们已知返回 follow 边的属性的情况下，提早（而不是等到语句解析到 dst(edge) 之后）而且直接用 follow._dst 表达带来了数据传输上的优化。 (root@nebula) [basketballplayer]\u003e explain GO FROM \"player100\" OVER follow YIELD dst(edge) Execution succeeded (time spent 600/7625 us) Execution Plan (optimize time 101 us) -----+--------------+--------------+----------------+------------------------------- | id | name | dependencies | profiling data | operator info | -----+--------------+--------------+----------------+------------------------------- | 2 | Project | 1 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"dst(EDGE)\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_2\" | | | | | | } | | | | | | inputVar: __GetNeighbors_1 | | | | | | columns: [ | | | | | | \"dst(EDGE)\" | | | | | | ] | -----+--------------+--------------+----------------+------------------------------- | 1 | GetNeighbors | 0 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_1\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: false | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_rank\", | | | | | | \"_src\", | | | | | | \"_type\", | | | | | | \"degree\" | | | | | | ], | | | | | | \"type\": 53 | | | | | | } | | | | | | ] | | | | | | statProps: | | | | | | exprs: | | | | | | random: false | -----+--------------+--------------+----------------+------------------------------- | 0 | Start | | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Start_0\" | | | | | | } | -----+--------------+--------------+----------------+------------------------------- Tue, 13 Sep 2022 14:27:27 CST (root@nebula) [basketballplayer]\u003e explain GO FROM \"player100\" OVER follow YIELD follow._dst Execution succeeded (time spent 549/5971 us) Execution Plan (optimize time 91 us) -----+--------------+--------------+----------------+------------------------------- | id | name | dependencies | profiling data | operator info | -----+--------------+--------------+----------------+------------------------------- | 2 | Project | 1 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"follow._dst\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_2\" | | | | | | } | | | | | | inputVar: __GetNeighbors_1 | | | | | | columns: [ | | | | | | \"follow._dst\" | | | | | | ] | -----+--------------+--------------+----------------+------------------------------- | 1 | GetNeighbors | 0 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_1\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: false | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\" | | | | | | ], | | | | | | \"type\": 53 | | | | | | } | | | | | | ] | | | | | | statProps: | | | | | | exprs: | | | | | | random: false | -----+--------------+--------------+----------------+------------------------------- | 0 | Start | | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Start_0\" | | | | | | } | -----+--------------+--------------+--------------","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:3","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#优化原则减少模糊增加确定越早越好"},{"categories":["Nebula Graph"],"content":" 4.4 小练习：等价的多种表达的代价这是一个用户提的一个问题：如何表达两点之间是否存在直连边？ 对于这么简单的表达，大家应该直接能想到应该有好多方法表达： GO FIND PATH MATCH FETCH PROP 这里，利用 FETCH PROP 表达双向边，似乎是两个查询，我们先省略掉，对于剩下的三个表达，哪一种更适合呢？我们先写出来看看 GO FROM \"player100\" over * BIDIRECT WHERE id($$) == \"player101\" YIELD edge AS e FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p MATCH (n)--(m) WHERE id(n) == \"player100\" AND id(m) == \"player101\" RETURN count(*) 4.4.1 GO/MATCH 与 FIND PATH他们都能获得我们想要的信息，感觉上，MATCH 和 GO 会比 FIND PATH 的查询更快一些，因为它们都是从单一起点拓展，而 FIND PATH 是从两端同时查询，在一跳的情况下，这其实是冗余的动作。验证一下的话，我们可以看到 explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p 中果然有两个 GetNeighbors 算子。 (root@nebula) [basketballplayer]\u003e explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p Execution succeeded (time spent 818/16537 us) Execution Plan (optimize time 229 us) -----+-----------------+--------------+----------------+------------------------------------ | id | name | dependencies | profiling data | operator info | -----+-----------------+--------------+----------------+------------------------------------ | 9 | DataCollect | 8 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"p\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_9\" | | | | | | } | | | | | | inputVar: [ | | | | | | { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | ] | | | | | | distinct: false | | | | | | kind: ALL PATHS | -----+-----------------+--------------+----------------+------------------------------------ | 8 | Loop | 7 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Loop_8\" | | | | | | } | | | | | | inputVar: __VAR_1 | | | | | | condition: (++($__VAR_2)\u003c=1) | | | | | | loopBody: 5 | -----+-----------------+--------------+----------------+------------------------------------ | 5 | ProduceAllPaths | 3,4 | | branch: true, nodeId: 8 | | | | | | | | | | | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | inputVar: { | | | | | | \"rightVar\": \"__GetNeighbors_4\", | | | | | | \"leftVar\": \"__GetNeighbors_3\" | | | | | | } | | | | | | LeftNextVidVar: \"__VAR_0\" | | | | | | RightNextVidVar: \"__VAR_1\" | | | | | | noloop : false | | | | | | steps: 1 | -----+-----------------+--------------+----------------+------------------------------------ | 3 | GetNeighbors | 2 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_3\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -52 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -53 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -67 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -68 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -69 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -70 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\"","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#小练习等价的多种表达的代价"},{"categories":["Nebula Graph"],"content":" 4.4 小练习：等价的多种表达的代价这是一个用户提的一个问题：如何表达两点之间是否存在直连边？ 对于这么简单的表达，大家应该直接能想到应该有好多方法表达： GO FIND PATH MATCH FETCH PROP 这里，利用 FETCH PROP 表达双向边，似乎是两个查询，我们先省略掉，对于剩下的三个表达，哪一种更适合呢？我们先写出来看看 GO FROM \"player100\" over * BIDIRECT WHERE id($$) == \"player101\" YIELD edge AS e FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p MATCH (n)--(m) WHERE id(n) == \"player100\" AND id(m) == \"player101\" RETURN count(*) 4.4.1 GO/MATCH 与 FIND PATH他们都能获得我们想要的信息，感觉上，MATCH 和 GO 会比 FIND PATH 的查询更快一些，因为它们都是从单一起点拓展，而 FIND PATH 是从两端同时查询，在一跳的情况下，这其实是冗余的动作。验证一下的话，我们可以看到 explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p 中果然有两个 GetNeighbors 算子。 (root@nebula) [basketballplayer]\u003e explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p Execution succeeded (time spent 818/16537 us) Execution Plan (optimize time 229 us) -----+-----------------+--------------+----------------+------------------------------------ | id | name | dependencies | profiling data | operator info | -----+-----------------+--------------+----------------+------------------------------------ | 9 | DataCollect | 8 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"p\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_9\" | | | | | | } | | | | | | inputVar: [ | | | | | | { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | ] | | | | | | distinct: false | | | | | | kind: ALL PATHS | -----+-----------------+--------------+----------------+------------------------------------ | 8 | Loop | 7 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Loop_8\" | | | | | | } | | | | | | inputVar: __VAR_1 | | | | | | condition: (++($__VAR_2)\u003c=1) | | | | | | loopBody: 5 | -----+-----------------+--------------+----------------+------------------------------------ | 5 | ProduceAllPaths | 3,4 | | branch: true, nodeId: 8 | | | | | | | | | | | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | inputVar: { | | | | | | \"rightVar\": \"__GetNeighbors_4\", | | | | | | \"leftVar\": \"__GetNeighbors_3\" | | | | | | } | | | | | | LeftNextVidVar: \"__VAR_0\" | | | | | | RightNextVidVar: \"__VAR_1\" | | | | | | noloop : false | | | | | | steps: 1 | -----+-----------------+--------------+----------------+------------------------------------ | 3 | GetNeighbors | 2 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_3\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -52 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -53 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -67 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -68 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -69 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -70 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\"","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#gomatch-与-find-path"},{"categories":["Nebula Graph"],"content":" 4.4 小练习：等价的多种表达的代价这是一个用户提的一个问题：如何表达两点之间是否存在直连边？ 对于这么简单的表达，大家应该直接能想到应该有好多方法表达： GO FIND PATH MATCH FETCH PROP 这里，利用 FETCH PROP 表达双向边，似乎是两个查询，我们先省略掉，对于剩下的三个表达，哪一种更适合呢？我们先写出来看看 GO FROM \"player100\" over * BIDIRECT WHERE id($$) == \"player101\" YIELD edge AS e FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p MATCH (n)--(m) WHERE id(n) == \"player100\" AND id(m) == \"player101\" RETURN count(*) 4.4.1 GO/MATCH 与 FIND PATH他们都能获得我们想要的信息，感觉上，MATCH 和 GO 会比 FIND PATH 的查询更快一些，因为它们都是从单一起点拓展，而 FIND PATH 是从两端同时查询，在一跳的情况下，这其实是冗余的动作。验证一下的话，我们可以看到 explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p 中果然有两个 GetNeighbors 算子。 (root@nebula) [basketballplayer]\u003e explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p Execution succeeded (time spent 818/16537 us) Execution Plan (optimize time 229 us) -----+-----------------+--------------+----------------+------------------------------------ | id | name | dependencies | profiling data | operator info | -----+-----------------+--------------+----------------+------------------------------------ | 9 | DataCollect | 8 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"p\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_9\" | | | | | | } | | | | | | inputVar: [ | | | | | | { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | ] | | | | | | distinct: false | | | | | | kind: ALL PATHS | -----+-----------------+--------------+----------------+------------------------------------ | 8 | Loop | 7 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Loop_8\" | | | | | | } | | | | | | inputVar: __VAR_1 | | | | | | condition: (++($__VAR_2)\u003c=1) | | | | | | loopBody: 5 | -----+-----------------+--------------+----------------+------------------------------------ | 5 | ProduceAllPaths | 3,4 | | branch: true, nodeId: 8 | | | | | | | | | | | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | inputVar: { | | | | | | \"rightVar\": \"__GetNeighbors_4\", | | | | | | \"leftVar\": \"__GetNeighbors_3\" | | | | | | } | | | | | | LeftNextVidVar: \"__VAR_0\" | | | | | | RightNextVidVar: \"__VAR_1\" | | | | | | noloop : false | | | | | | steps: 1 | -----+-----------------+--------------+----------------+------------------------------------ | 3 | GetNeighbors | 2 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_3\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -52 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -53 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -67 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -68 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -69 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -70 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\"","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#go-与-match"},{"categories":["Nebula Graph"],"content":" 4.4 小练习：等价的多种表达的代价这是一个用户提的一个问题：如何表达两点之间是否存在直连边？ 对于这么简单的表达，大家应该直接能想到应该有好多方法表达： GO FIND PATH MATCH FETCH PROP 这里，利用 FETCH PROP 表达双向边，似乎是两个查询，我们先省略掉，对于剩下的三个表达，哪一种更适合呢？我们先写出来看看 GO FROM \"player100\" over * BIDIRECT WHERE id($$) == \"player101\" YIELD edge AS e FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p MATCH (n)--(m) WHERE id(n) == \"player100\" AND id(m) == \"player101\" RETURN count(*) 4.4.1 GO/MATCH 与 FIND PATH他们都能获得我们想要的信息，感觉上，MATCH 和 GO 会比 FIND PATH 的查询更快一些，因为它们都是从单一起点拓展，而 FIND PATH 是从两端同时查询，在一跳的情况下，这其实是冗余的动作。验证一下的话，我们可以看到 explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p 中果然有两个 GetNeighbors 算子。 (root@nebula) [basketballplayer]\u003e explain FIND ALL PATH FROM \"player100\" TO \"player101\" OVER * BIDIRECT UPTO 1 STEPS YIELD path AS p Execution succeeded (time spent 818/16537 us) Execution Plan (optimize time 229 us) -----+-----------------+--------------+----------------+------------------------------------ | id | name | dependencies | profiling data | operator info | -----+-----------------+--------------+----------------+------------------------------------ | 9 | DataCollect | 8 | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"p\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__DataCollect_9\" | | | | | | } | | | | | | inputVar: [ | | | | | | { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | ] | | | | | | distinct: false | | | | | | kind: ALL PATHS | -----+-----------------+--------------+----------------+------------------------------------ | 8 | Loop | 7 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Loop_8\" | | | | | | } | | | | | | inputVar: __VAR_1 | | | | | | condition: (++($__VAR_2)\u003c=1) | | | | | | loopBody: 5 | -----+-----------------+--------------+----------------+------------------------------------ | 5 | ProduceAllPaths | 3,4 | | branch: true, nodeId: 8 | | | | | | | | | | | | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"_path\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__ProduceAllPaths_5\" | | | | | | } | | | | | | inputVar: { | | | | | | \"rightVar\": \"__GetNeighbors_4\", | | | | | | \"leftVar\": \"__GetNeighbors_3\" | | | | | | } | | | | | | LeftNextVidVar: \"__VAR_0\" | | | | | | RightNextVidVar: \"__VAR_1\" | | | | | | noloop : false | | | | | | steps: 1 | -----+-----------------+--------------+----------------+------------------------------------ | 3 | GetNeighbors | 2 | | outputVar: { | | | | | | \"colNames\": [], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__GetNeighbors_3\" | | | | | | } | | | | | | inputVar: __VAR_0 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: | | | | | | orderBy: [] | | | | | | src: COLUMN[0] | | | | | | edgeTypes: [] | | | | | | edgeDirection: OUT_EDGE | | | | | | vertexProps: | | | | | | edgeProps: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -52 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -53 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -67 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -68 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -69 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\", | | | | | | \"_type\", | | | | | | \"_rank\" | | | | | | ], | | | | | | \"type\": -70 | | | | | | }, | | | | | | { | | | | | | \"props\": [ | | | | | | \"_dst\"","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#更优的-go-表达"},{"categories":["Nebula Graph"],"content":" 4.5 索引的命中在本篇结束之前，我还想再给一个索引查询的例子，首先，假设环境里只存在 player() 和 player.name 上的索引，没有 player.age 上的索引。 (root@nebula) [basketballplayer]\u003e SHOW TAG INDEXES +------------------+----------+----------+ | Index Name | By Tag | Columns | +------------------+----------+----------+ | \"player_index_0\" | \"player\" | [] | | \"player_index_1\" | \"player\" | [\"name\"] | +------------------+----------+----------+ Got 2 rows (time spent 2440/19653 us) 再次强调一下，在 NebulaGraph 中，只有无 ID 条件的起点才涉及索引，而这类起点查询其实是一个典型的非图库查询。相反，点的拓展是无关 NebulaGraph 索引的。 这里的例子也是只涉及起点查询，类似于 SELECT * FROM player WHERE ... 的表达，这三个查询 MATCH (n:player) WHERE n.player.age \u003e 50 RETURN n MATCH (n:player) WHERE n.player.name \u003e \"T\" RETURN n MATCH (n:team) WHERE n.team.name \u003e \"T\" RETURN n 之中只有 1.，2. 是允许的查询，3. 因为查询涉及数据全扫描而被 NebulaGraph 禁止，因为不存在 team 之中的索引，这样的全扫描是很昂贵的： (root@nebula) [basketballplayer]\u003e match (n:team) WHERE n.team.name \u003e \"T\" RETURN n [ERROR (-1005)]: IndexNotFound: No valid index found 而 1. 与 2. 的情况又有不同，1. 中的过滤条件 n.player.age \u003e 50 涉及未被索引的字段，这个过滤是无法被下推到 IndexScan 算子的，这意味着所有的 player 都会被扫描到 GraphD 中，然后再进一步进行 Filter 算子的过滤计算。 索引设计的文章参考：https://nebula-graph.com.cn/posts/how-indexing-works-in-nebula-graph，如下是文中介绍的点索引在 RocksDB 中的数据结构。 通过两个查询的 profile 分析，我们可以很清楚地看到： IndexScan 在 1. 查询中没有 columnHints 信息，扫描的行数为 rows: 52（这是所有的 player 顶点数量） IndexScan 在 2. 查询中有 columnHints 信息，扫描的行数只有 rows: 6 所以，我们在真的需要这种从属性反查图探索起点的时候，要根据实际查询需求去斟酌索引的创建。 (root@nebula) [basketballplayer]\u003e profile MATCH (n:player) WHERE n.player.age \u003e 50 RETURN n +---+ | n | +---+ +---+ Empty set (time spent 8468/25278 us) Execution Plan (optimize time 442 us) -----+----------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------- | id | name | dependencies | profiling data | operator info | -----+----------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------- | 6 | Project | 5 | ver: 0, rows: 0, execTime: 19us, totalTime: 22us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Project_6\" | | | | | | } | | | | | | inputVar: __Filter_5 | | | | | | columns: [ | | | | | | \"$n\" | | | | | | ] | -----+----------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------- | 5 | Filter | 9 | ver: 0, rows: 0, execTime: 74us, totalTime: 75us | outputVar: { | | | | | | \"colNames\": [ | | | | | | \"n\" | | | | | | ], | | | | | | \"type\": \"DATASET\", | | | | | | \"name\": \"__Filter_5\" | | | | | | } | | | | | | inputVar: __Project_4 | | | | | | condition: (n.player.age\u003e50) | | | | | | isStable: false | -----+----------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------- | 9 | AppendVertices | 7 | { | outputVar: { | | | | | ver: 0, rows: 51, execTime: 841us, totalTime: 4481us | \"colNames\": [ | | | | | total_rpc: 4018(us) | \"n\" | | | | | \"storaged1\":9779 exec/total: 1591(us)/2868(us) | ], | | | | | \"storaged0\":9779 exec/total: 1532(us)/2672(us) | \"type\": \"DATASET\", | | | | | \"storaged2\":9779 exec/total: 2510(us)/3733(us) | \"name\": \"__Project_4\" | | | | | } | } | | | | | | inputVar: __IndexScan_1 | | | | | | space: 49 | | | | | | dedup: true | | | | | | limit: -1 | | | | | | filter: player._tag IS NOT EMPTY | | | | | | orderBy: [] | | | | | | src: $_vid | | | | | | props: [ | | | | | | { | | | | | | \"props\": [ | | | | | | \"name\", | | | | | | \"age\", | | | | | | \"_tag\" | | | | | | ], | | | | | | \"tagId\": 59 | | | | | | ","date":"2022-09-06","objectID":"/ngql-execution-plan/:4:5","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#索引的命中"},{"categories":["Nebula Graph"],"content":" 5 小结在理解了 NebulaGraph 的基本架构设计、存储格式、查询的简单调用流程和常见的优化规则之后，结合 PROFILE/EXPLAIN，我们可以一点点去设计更适合不同场景的图建模与图查询。 优化原则：减少模糊，增加确定，越早越好。 欢迎大家在本文的评论区讨论、提供更多优化查询的例子。 Feature image generated with OpenAI Dall-E, with the keyword “make potions for the nebula magic” and Outpainting. Raw image ","date":"2022-09-06","objectID":"/ngql-execution-plan/:5:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","调优","执行计划"],"title":"nGQL 简明教程，第二期 nGQL 执行计划详解与调优","uri":"/ngql-execution-plan/#小结"},{"categories":["Nebula Graph"],"content":"NebulaGraph 教程：一文入门图查询语句：nGQL。本文旨在让新手快速了解 nGQL，掌握方向，之后可以脚踩在地上借助文档写出任何心中的 NebulaGraph 图查询。","date":"2022-08-15","objectID":"/ngql-tutorial/","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/"},{"categories":["Nebula Graph"],"content":" 本文旨在让新手快速了解 nGQL，掌握方向，之后可以脚踩在地上借助文档写出任何心中的 NebulaGraph 图查询。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:0:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#"},{"categories":["Nebula Graph"],"content":" 1 系列教程 nGQL 简明教程，第一期，快速入门，本文 nGQL 简明教程，第二期，查询计划与调优 ","date":"2022-08-15","objectID":"/ngql-tutorial/:1:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#系列教程"},{"categories":["Nebula Graph"],"content":" 2 视频本教程的视频版在这里。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:2:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#视频"},{"categories":["Nebula Graph"],"content":" 3 开始之前本文假设你已经在文档看过快速入门流程，部署、连接过 NebulaGraph，并且看过了常用命令。如果您还没看过这两个文档，强烈建议先快速过一遍。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:3:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#开始之前"},{"categories":["Nebula Graph"],"content":" 3.1 教程目标本教程目的在于让新手大概知道了 NebulaGraph 的查询语句后，解决“不知道什么样的查询应该用什么语句”的问题。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:3:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#教程目标"},{"categories":["Nebula Graph"],"content":" 3.2 nGQL 是什么我们先强调一下概念：nGQL 是 NebulaGraph Graph Query Language 的缩写，它表示 NebulaGraph 的查询语言，而 nGQL 的语句可以不严谨地分为这几部分： NebulaGraph 独有 DQL 查询语句（Data Query Language） NebulaGraph OpenCypher DQL NebulaGraph DML 写语句（Data Mutation Language） NebulaGraph DDL Schema 语句（Data Definition Language) NebulaGraph Admin Queries 管理语句 这里，作为简明教程一把梭，我们只关注前两个部分，后边的内容会在 Part 2 中介绍。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:3:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#ngql-是什么"},{"categories":["Nebula Graph"],"content":" 3.3 nGQL 速查表 Cheatsheet 大家可以报错这份单页速查表，一次了解所有 nGQL 的用法。 原始文件链接 ","date":"2022-08-15","objectID":"/ngql-tutorial/:3:3","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#ngql-速查表-cheatsheet"},{"categories":["Nebula Graph"],"content":" 4 NebulaGraph 独有 DQLNebulaGraph 的独有读查询语句的设计非常简介，对初学者非常友好，结合了管道的概念，做到了只涉及了几个关键词就可以描述大多数图查询模式。 用一句话描述来说，nGQL 的独有 DQL 一共分成四类语句： 图拓展：GO 索引反查：LOOKUP 取属性：FETCH PROP 路径与子图：FIND PATH 与 GET SUBGRAPH 和几个特别的元素 管道：| 引用属性: $ 开头的几个符号，用来描述一些特定的上下文 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:0","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#nebulagraph-独有-dql"},{"categories":["Nebula Graph"],"content":" 4.1 图拓展 GOGO 的语义非常直观：从给定的起点，向外拓展，按需返回终点、起点的信息。 # 图拓展 GO 3 STEPS FROM \"player102\" OVER follow YIELD dst(edge); ───┬─── ───┬─────── ─┬──── ──┬────── │ │ │ ┌─────────┘ │ │ │ │ │ │ │ └── 返回最后一跳边的终点 │ │ │ │ │ └────── 从 follow 这个边[出方向]探索 │ │ │ └───────────────────── 起点是 \"player102\" │ └────────────────────────────────── 探索 3 步 参考 GO 语句文档，了解如何： 指定反方向拓展、双向拓展 指定可变跳数拓展 基于所有类型边拓展 返回其他信息 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:1","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#图拓展-go"},{"categories":["Nebula Graph"],"content":" 4.2 LOOKUP 基于索引反查 ID和 GO 为从已知的点出发相反，LOOKUP 是一个类似于 SQL 里 SELECT 语义的关键字，它实际的作用也类似与关系型数据库中的扫表。 LOOKUP 需要手动明确建立相应 TAG、边类型上索引才能允许相应的查询。 4.2.1 为什么 LOOKUP 需要索引？因为 NebulaGraph 中的数据默认是按照邻接表的形式存储，在分布式设计中，扫描一个类型的点、边是非常昂贵的，所以它被默认禁止了。而创建相应的索引类似于增加了类似于表结构数据库的排序数据，可以用来做类似于 SELECT 的查询。 创建索引的代价是什么（增加写入负担）？索引会加速读么（不会，它是提供了 LOOKUP 的可能性，原生图的查询不需要索引加速）？等等更详细的问题请参阅我之前的索引详解文章。 # 索引反查 LOOKUP ON player WHERE player.name == \"Tony Parker\" YIELD id(vertex); ──┬─── ──────┬────────────────────────── ──┬────── │ │ ┌───────────────────┘ │ │ │ │ │ └──────────── 返回查到点的 VID │ │ │ └─────────────────────── 过滤条件是属性 name 的值 │ └─────────────────────────────────── 根据点的类别/TAG player 查询 进一步参考 LOOKUP 语句文档，了解如何： 返回属性 根据边的类型查询边 了解 LOOKUP 查询的前提、索引，索引详解 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#lookup-基于索引反查-id"},{"categories":["Nebula Graph"],"content":" 4.2 LOOKUP 基于索引反查 ID和 GO 为从已知的点出发相反，LOOKUP 是一个类似于 SQL 里 SELECT 语义的关键字，它实际的作用也类似与关系型数据库中的扫表。 LOOKUP 需要手动明确建立相应 TAG、边类型上索引才能允许相应的查询。 4.2.1 为什么 LOOKUP 需要索引？因为 NebulaGraph 中的数据默认是按照邻接表的形式存储，在分布式设计中，扫描一个类型的点、边是非常昂贵的，所以它被默认禁止了。而创建相应的索引类似于增加了类似于表结构数据库的排序数据，可以用来做类似于 SELECT 的查询。 创建索引的代价是什么（增加写入负担）？索引会加速读么（不会，它是提供了 LOOKUP 的可能性，原生图的查询不需要索引加速）？等等更详细的问题请参阅我之前的索引详解文章。 # 索引反查 LOOKUP ON player WHERE player.name == \"Tony Parker\" YIELD id(vertex); ──┬─── ──────┬────────────────────────── ──┬────── │ │ ┌───────────────────┘ │ │ │ │ │ └──────────── 返回查到点的 VID │ │ │ └─────────────────────── 过滤条件是属性 name 的值 │ └─────────────────────────────────── 根据点的类别/TAG player 查询 进一步参考 LOOKUP 语句文档，了解如何： 返回属性 根据边的类型查询边 了解 LOOKUP 查询的前提、索引，索引详解 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:2","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#为什么-lookup-需要索引"},{"categories":["Nebula Graph"],"content":" 4.3 FETCH PROP 获取属性如字面意思，如果我们知道一个点、边的 ID，想要获取它上边的属性，这时候我们要用 FETCH PROP 而非 LOOKUP。 # 取属性 FETCH PROP ON player \"player100\" YIELD properties(vertex); ──┬─── ────┬───── ─────────┬──────── │ │ ┌───────────┘ │ │ │ │ │ └─────── 返回点的 player TAG 下所有属性 │ │ │ └───────────────── 从 \"player100\" 这个点获取 │ └─────────────────────────── 获取 player 这个 TAG 下的属性 进一步参考 FETCH PROP 语句文档，了解如何： 返回某一个属性 获取给定边的属性 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:3","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#fetch-prop-获取属性"},{"categories":["Nebula Graph"],"content":" 4.4 路径查找 FIND PATH如果我们从给定的起点、终点中，找到之间的所有路径，一定要用 FIND PATH # 起点终点间路径 FIND SHORTEST PATH FROM \"player102\" TO \"team204\" OVER * \\ ──┬───── ───────────┬─────────── ───┬─── YIELD│path AS p; ┌────────────────┘ │ │────┬──── │ ┌──────────────────────────┘ │ │ │ │ │ │ │ └───────── 经由所有类型的边出向探索 │ │ │ │ │ └─────────────── 从给定的起点、终点 VID │ │ │ └────────────────────── 返回路径为 p 列 │ └─────────────────────────── 查找最短路径 进一步参考 FIND PATH 语句文档，了解如何： 返回路径中的属性 设定拓展方向 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:4","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#路径查找-find-path"},{"categories":["Nebula Graph"],"content":" 4.5 单点子图 GET SUBGRAPH和路径查找类似，但是我们只给定一个起点和拓展部署，用 GET SUBGRAPH 可以帮我们获取同样的 BFS 出去的子图 # 单点 BFS 子图 GET SUBGRAPH 5 STEPS FROM \"player101\" \\ ───┬─── ─────┬────────── YIELD VERTICES AS nodes, EDGES AS relationships; ────┬───┼─────────┼─────────────────────── ┌────────┘ │ │ └─────── 从 \"player101\" 开始触发 │ │ └───────────────── 获取 5 步的探索 │ └────────────────────────────── 返回所有的点、边 进一步参考 GET SUBGRAPH 语句文档，了解如何： 返回带有属性的点、边 设定拓展方向 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:5","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#单点子图-get-subgraph"},{"categories":["Nebula Graph"],"content":" 4.6 利用管道和属性引用符NebulaGraph 的管道设计和 Unix-Shell 的设计很像，可以将简单的几种语句结合起来，有强大的表达力。 # 使用通道 GO FROM \"player100\" OVER follow YIELD dst(edge) AS did | \\ ─────┬──────────────────────────────────────────── ─┬─ GO FROM│$-.did OVER follow YIELD dst(edge); │ │────┬── ┌─────────────────────────────────┘ │ │ │ │ │ └──────── 管道将左边的 AS 输出作为右边语句输入 │ │ │ └──────────────── 从管道左边的 did 属性开始探索 │ └───────────────────── 第一个查询语句 进一步参考 引用属性文档、管道文档了解： 更多属性引用定义 更多例子 结合 LOOKUP, GO, FETCH 的语句 除了以上的集中表达之外，NebulaGraph 独有查询语句还有聚合的表达参考 GROUP-BY，另外在文档里还有一个 Cheatsheet 供大家查询一些复杂一点查询的例子。 ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:6","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#利用管道和属性引用符"},{"categories":["Nebula Graph"],"content":" 4.7 NebulaGraph OpenCypher DQL从 2.0 起，OpenCypher 的 MATCH 语句也被 NebulaGraph 原生支持了，虽然这里是一个方言（有一些细节差异）。 MATCH \u003cpattern\u003e [\u003cclause_1\u003e] RETURN \u003coutput\u003e [\u003cclause_2\u003e]; MATCH 的基本表达是以 (v:tag_a) 包裹的点 --\u003e 或者 \u003c-[:edge_type_1]- 表达的边组成的模式，与 RETURN 表达的输出。 如果您从 Cypher 的查询语句入门图数据库，可以从下边几个例子了解到几个 NebulaGraph 里的细节差异： 增加了 WHERE id(v) == \"foo\" 的表达 == 表达相等判断而不是 = 点的属性表达需要填写 TAG，例如 v3.player.name 而不是 v3.name MATCH (v:player{name:\"Tim Duncan\"})--\u003e(v2)\u003c--(v3) \\ RETURN v3.player.name AS Name; MATCH (v:player) \\ WHERE NOT (v)--() \\ RETURN v; MATCH (v:player)--(v2) \\ WHERE id(v2) IN [\"player101\", \"player102\"] \\ RETURN v; MATCH (m)-[]-\u003e(n) WHERE id(m)==\"player100\" \\ OPTIONAL MATCH (n)-[]-\u003e(l) WHERE id(n)==\"player125\" \\ RETURN id(m), id(n), id(l); 进一步参考 MATCH 文档了解： 更多例子 可变跳数的 MATCH 表达 多 MATCH OPTIONAL MATCH 题图版权：DALL·E Open-AI，原图 The featured image was generated with keywords: learning spells of the nebula magic, with DALL·E Open-AI. ","date":"2022-08-15","objectID":"/ngql-tutorial/:4:7","series":null,"tags":["NebulaGraph","nGQL","OpenCypher","cheatsheet","速查表"],"title":"nGQL 简明教程，第一期","uri":"/ngql-tutorial/#nebulagraph-opencypher-dql"},{"categories":["Nebula Graph"],"content":"本文是一个基于 NebulaGraph 上的图算法、图数据库、图神经网络的 ID-Mapping 方法综述，除了基本方法思想的介绍之外，我还给大家弄了可以跑的 Playground。","date":"2022-08-14","objectID":"/identity-resolution/","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/"},{"categories":["Nebula Graph"],"content":" 本文是一个基于 NebulaGraph 上的图算法、图数据库、图神经网络的 ID-Mapping 方法综述，除了基本方法思想的介绍之外，我还给大家弄了可以跑的 Playground。 本文还在撰写中，TBD 的章节还请见谅。 ","date":"2022-08-14","objectID":"/identity-resolution/:0:0","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#"},{"categories":["Nebula Graph"],"content":" 1 基于图数据库的用户 ID 识别方法用户 ID 识别，是一个很常见的图技术应用场景，在不同的语境下它可能还被叫做 Entity Correlation（实体关联）、Entity Linking（实体链接）、ID Mapping（身份映射）等等。ID 识别解决的问题是找出相同的用户在同一个系统或者不同系统中的不同账号。 由于 ID 识别天然地是一个关联关系问题，也是一个典型的图、图数据库应用场景。 ","date":"2022-08-14","objectID":"/identity-resolution/:1:0","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图数据库的用户-id-识别方法"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱 1.1.1 图建模我们从一个最简单、直接的图谱开始，如下边的图结构示意显示，我们定义了点： user Prop: [name, email, birthday, address, phone_num] phone email device ip address 在他们之间有很自然的边： used_device Prop: time logged_in_from Prop: time has_phone has_address has_email 1.1.2 数据这份数据是开源的，地址在 https://github.com/wey-gu/identity-correlation-datagen 1.1.3 写入 NebulaGraph 利用 Nebula Up，一行部署 NebulaGraph 地址：https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 图建模的 Schema 对应的 NebulaGraph DDL 是： # 创建一个叫做 entity_resolution 的图空间 CREATE SPACE entity_resolution (vid_type=FIXED_STRING(30)); USE entity_resolution; # 创建点的类型 TAG CREATE TAG `user` (`name` string NOT NULL, `email` string NOT NULL, `phone_num` string NOT NULL, `birthday` date NOT NULL, `address` string NOT NULL); CREATE TAG `address` (`address` string NOT NULL); CREATE TAG `device` (`uuid` string NOT NULL); CREATE TAG `email` (); CREATE TAG `ip` (); CREATE TAG `phone` (); # 创建边的类型 Edge Type CREATE EDGE `used_device` (`time` timestamp NOT NULL); CREATE EDGE `logged_in_from` (`time` timestamp NOT NULL); CREATE EDGE `has_phone` (); CREATE EDGE `has_address` (); CREATE EDGE `has_email` (); 对于写入数据的 DML，这里只给出 user ，email 类型点、has_email 类型边的例子 INSERT VERTEX `user` (`email`, `name`, `birthday`, `address`, `phone_num`) VALUES \"user_1\":(\"heathermoore@johnson.com\",\"Miranda Miller\",date(\"1957-08-27\"),\"Brittany Forge Apt. 718 East Eric WV 97881\",\"+1-652-450-5443x00562\"), \"user_2\":(\"holly@welch.org\",\"Holly Pollard\",date(\"1990-10-19\"),\"1 Amanda Freeway Lisaland NJ 94933\",\"600-192-2985x041\"), \"user_3\":(\"julia.h.24@gmail.com\",\"Julia Hall\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_4\":(\"franklin.b@gibson.biz\",\"Franklin Barnett\",date(\"2020-03-01\"),\"Richard Curve Kingstad AZ 05660\",\"(224)497-9312\"), \"user_5\":(\"4kelly@yahoo.com\",\"April Kelly\",date(\"1967-12-01\"),\"Schmidt Key Lake Charles AL 36174\",\"410.138.1816x98702\"), \"user_6\":(\"steven.web@johnson.com\",\"Steven Webb\",date(\"1955-04-24\"),\"5 Joanna Key Suite 704 Frankshire OK 03035\",\"3666519376\"), \"user_7\":(\"Jessica_Torres@morris.com\",\"Jessica Torres\",date(\"1958-09-03\"),\"1 Payne Circle Mitchellfort LA 73053\",\"535-357-3112x4903\"), \"user_8\":(\"brettglenn@gmail.com\",\"Brett Glenn\",date(\"1992-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660.391.3730\"), \"user_9\":(\"veronica.j@yahoo.com\",\"Veronica Jordan\",date(\"1947-06-08\"),\"2 Klein Mission New Annetteton HI 05775\",\"810-252-6218\"), \"user_10\":(\"steven@phelps-craig.info\",\"Steven Brooks\",date(\"1954-06-14\"),\"1 Vanessa Stravenue Suite 184 Baileyville NY 46381\",\"+1-665-328-8103x3448\"), \"user_11\":(\"ReginaldTheMan@hotmail.com\",\"Reginald Mccullough\",date(\"1915-04-12\"),\"John Garden Port John LA 54602\",\"030.088.4523x94511\"), \"user_12\":(\"Jennifer.f@carroll-acosta.com\",\"Jennifer Foster\",date(\"1988-04-30\"),\"11 Webb Groves Tiffanyside MN 14566\",\"(489)306-8558x98227\"), \"user_13\":(\"Philip66@yahoo.com\",\"Philip Garcia\",date(\"1955-12-01\"),\"70 Robinson Locks Suite 113 East Veronica ND 87845\",\"490-088-7610x9437\"), \"user_14\":(\"Ann@hernandez.com\",\"Ann Williams\",date(\"1947-05-28\"),\"24 Mcknight Port Apt. 028 Sarahborough MD 38195\",\"868.057.4056x4814\"), \"user_15\":(\"Jessica@turner.com\",\"Jessica Stewart\",date(\"1951-11-28\"),\"0337 Mason Corner Apt. 900 Toddmouth FL 61464\",\"(335)408-3835x883\"), \"user_16\":(\"Sandra311@hotmail.com\",\"Sandra Dougherty\",date(\"1908-06-03\"),\"7 Davis Station Apt. 691 Pittmanfort HI 29746\",\"+1-189-827-0744x27614\"), \"user_17\":(\"Sharon91@gmail.com\",\"Sharon Mccoy\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_18\":(\"Sharon91+001@gmail.com\",\"Kathryn Miller\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_19\":(\"brettglenn@googlemail.com\",\"Bretty Glenn\",date(\"1991-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660-391-3730\"), \"user_20\":(\"julia.h.24@yahoo.com\",\"Julia H.\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_21\":(\"holly@welch.org\",\"Holly\",date(\"0000-10-19\"),\"1 Ama","date":"2022-08-14","objectID":"/identity-resolution/:1:1","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#建立图谱"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱 1.1.1 图建模我们从一个最简单、直接的图谱开始，如下边的图结构示意显示，我们定义了点： user Prop: [name, email, birthday, address, phone_num] phone email device ip address 在他们之间有很自然的边： used_device Prop: time logged_in_from Prop: time has_phone has_address has_email 1.1.2 数据这份数据是开源的，地址在 https://github.com/wey-gu/identity-correlation-datagen 1.1.3 写入 NebulaGraph 利用 Nebula Up，一行部署 NebulaGraph 地址：https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 图建模的 Schema 对应的 NebulaGraph DDL 是： # 创建一个叫做 entity_resolution 的图空间 CREATE SPACE entity_resolution (vid_type=FIXED_STRING(30)); USE entity_resolution; # 创建点的类型 TAG CREATE TAG `user` (`name` string NOT NULL, `email` string NOT NULL, `phone_num` string NOT NULL, `birthday` date NOT NULL, `address` string NOT NULL); CREATE TAG `address` (`address` string NOT NULL); CREATE TAG `device` (`uuid` string NOT NULL); CREATE TAG `email` (); CREATE TAG `ip` (); CREATE TAG `phone` (); # 创建边的类型 Edge Type CREATE EDGE `used_device` (`time` timestamp NOT NULL); CREATE EDGE `logged_in_from` (`time` timestamp NOT NULL); CREATE EDGE `has_phone` (); CREATE EDGE `has_address` (); CREATE EDGE `has_email` (); 对于写入数据的 DML，这里只给出 user ，email 类型点、has_email 类型边的例子 INSERT VERTEX `user` (`email`, `name`, `birthday`, `address`, `phone_num`) VALUES \"user_1\":(\"heathermoore@johnson.com\",\"Miranda Miller\",date(\"1957-08-27\"),\"Brittany Forge Apt. 718 East Eric WV 97881\",\"+1-652-450-5443x00562\"), \"user_2\":(\"holly@welch.org\",\"Holly Pollard\",date(\"1990-10-19\"),\"1 Amanda Freeway Lisaland NJ 94933\",\"600-192-2985x041\"), \"user_3\":(\"julia.h.24@gmail.com\",\"Julia Hall\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_4\":(\"franklin.b@gibson.biz\",\"Franklin Barnett\",date(\"2020-03-01\"),\"Richard Curve Kingstad AZ 05660\",\"(224)497-9312\"), \"user_5\":(\"4kelly@yahoo.com\",\"April Kelly\",date(\"1967-12-01\"),\"Schmidt Key Lake Charles AL 36174\",\"410.138.1816x98702\"), \"user_6\":(\"steven.web@johnson.com\",\"Steven Webb\",date(\"1955-04-24\"),\"5 Joanna Key Suite 704 Frankshire OK 03035\",\"3666519376\"), \"user_7\":(\"Jessica_Torres@morris.com\",\"Jessica Torres\",date(\"1958-09-03\"),\"1 Payne Circle Mitchellfort LA 73053\",\"535-357-3112x4903\"), \"user_8\":(\"brettglenn@gmail.com\",\"Brett Glenn\",date(\"1992-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660.391.3730\"), \"user_9\":(\"veronica.j@yahoo.com\",\"Veronica Jordan\",date(\"1947-06-08\"),\"2 Klein Mission New Annetteton HI 05775\",\"810-252-6218\"), \"user_10\":(\"steven@phelps-craig.info\",\"Steven Brooks\",date(\"1954-06-14\"),\"1 Vanessa Stravenue Suite 184 Baileyville NY 46381\",\"+1-665-328-8103x3448\"), \"user_11\":(\"ReginaldTheMan@hotmail.com\",\"Reginald Mccullough\",date(\"1915-04-12\"),\"John Garden Port John LA 54602\",\"030.088.4523x94511\"), \"user_12\":(\"Jennifer.f@carroll-acosta.com\",\"Jennifer Foster\",date(\"1988-04-30\"),\"11 Webb Groves Tiffanyside MN 14566\",\"(489)306-8558x98227\"), \"user_13\":(\"Philip66@yahoo.com\",\"Philip Garcia\",date(\"1955-12-01\"),\"70 Robinson Locks Suite 113 East Veronica ND 87845\",\"490-088-7610x9437\"), \"user_14\":(\"Ann@hernandez.com\",\"Ann Williams\",date(\"1947-05-28\"),\"24 Mcknight Port Apt. 028 Sarahborough MD 38195\",\"868.057.4056x4814\"), \"user_15\":(\"Jessica@turner.com\",\"Jessica Stewart\",date(\"1951-11-28\"),\"0337 Mason Corner Apt. 900 Toddmouth FL 61464\",\"(335)408-3835x883\"), \"user_16\":(\"Sandra311@hotmail.com\",\"Sandra Dougherty\",date(\"1908-06-03\"),\"7 Davis Station Apt. 691 Pittmanfort HI 29746\",\"+1-189-827-0744x27614\"), \"user_17\":(\"Sharon91@gmail.com\",\"Sharon Mccoy\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_18\":(\"Sharon91+001@gmail.com\",\"Kathryn Miller\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_19\":(\"brettglenn@googlemail.com\",\"Bretty Glenn\",date(\"1991-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660-391-3730\"), \"user_20\":(\"julia.h.24@yahoo.com\",\"Julia H.\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_21\":(\"holly@welch.org\",\"Holly\",date(\"0000-10-19\"),\"1 Ama","date":"2022-08-14","objectID":"/identity-resolution/:1:1","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#图建模"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱 1.1.1 图建模我们从一个最简单、直接的图谱开始，如下边的图结构示意显示，我们定义了点： user Prop: [name, email, birthday, address, phone_num] phone email device ip address 在他们之间有很自然的边： used_device Prop: time logged_in_from Prop: time has_phone has_address has_email 1.1.2 数据这份数据是开源的，地址在 https://github.com/wey-gu/identity-correlation-datagen 1.1.3 写入 NebulaGraph 利用 Nebula Up，一行部署 NebulaGraph 地址：https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 图建模的 Schema 对应的 NebulaGraph DDL 是： # 创建一个叫做 entity_resolution 的图空间 CREATE SPACE entity_resolution (vid_type=FIXED_STRING(30)); USE entity_resolution; # 创建点的类型 TAG CREATE TAG `user` (`name` string NOT NULL, `email` string NOT NULL, `phone_num` string NOT NULL, `birthday` date NOT NULL, `address` string NOT NULL); CREATE TAG `address` (`address` string NOT NULL); CREATE TAG `device` (`uuid` string NOT NULL); CREATE TAG `email` (); CREATE TAG `ip` (); CREATE TAG `phone` (); # 创建边的类型 Edge Type CREATE EDGE `used_device` (`time` timestamp NOT NULL); CREATE EDGE `logged_in_from` (`time` timestamp NOT NULL); CREATE EDGE `has_phone` (); CREATE EDGE `has_address` (); CREATE EDGE `has_email` (); 对于写入数据的 DML，这里只给出 user ，email 类型点、has_email 类型边的例子 INSERT VERTEX `user` (`email`, `name`, `birthday`, `address`, `phone_num`) VALUES \"user_1\":(\"heathermoore@johnson.com\",\"Miranda Miller\",date(\"1957-08-27\"),\"Brittany Forge Apt. 718 East Eric WV 97881\",\"+1-652-450-5443x00562\"), \"user_2\":(\"holly@welch.org\",\"Holly Pollard\",date(\"1990-10-19\"),\"1 Amanda Freeway Lisaland NJ 94933\",\"600-192-2985x041\"), \"user_3\":(\"julia.h.24@gmail.com\",\"Julia Hall\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_4\":(\"franklin.b@gibson.biz\",\"Franklin Barnett\",date(\"2020-03-01\"),\"Richard Curve Kingstad AZ 05660\",\"(224)497-9312\"), \"user_5\":(\"4kelly@yahoo.com\",\"April Kelly\",date(\"1967-12-01\"),\"Schmidt Key Lake Charles AL 36174\",\"410.138.1816x98702\"), \"user_6\":(\"steven.web@johnson.com\",\"Steven Webb\",date(\"1955-04-24\"),\"5 Joanna Key Suite 704 Frankshire OK 03035\",\"3666519376\"), \"user_7\":(\"Jessica_Torres@morris.com\",\"Jessica Torres\",date(\"1958-09-03\"),\"1 Payne Circle Mitchellfort LA 73053\",\"535-357-3112x4903\"), \"user_8\":(\"brettglenn@gmail.com\",\"Brett Glenn\",date(\"1992-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660.391.3730\"), \"user_9\":(\"veronica.j@yahoo.com\",\"Veronica Jordan\",date(\"1947-06-08\"),\"2 Klein Mission New Annetteton HI 05775\",\"810-252-6218\"), \"user_10\":(\"steven@phelps-craig.info\",\"Steven Brooks\",date(\"1954-06-14\"),\"1 Vanessa Stravenue Suite 184 Baileyville NY 46381\",\"+1-665-328-8103x3448\"), \"user_11\":(\"ReginaldTheMan@hotmail.com\",\"Reginald Mccullough\",date(\"1915-04-12\"),\"John Garden Port John LA 54602\",\"030.088.4523x94511\"), \"user_12\":(\"Jennifer.f@carroll-acosta.com\",\"Jennifer Foster\",date(\"1988-04-30\"),\"11 Webb Groves Tiffanyside MN 14566\",\"(489)306-8558x98227\"), \"user_13\":(\"Philip66@yahoo.com\",\"Philip Garcia\",date(\"1955-12-01\"),\"70 Robinson Locks Suite 113 East Veronica ND 87845\",\"490-088-7610x9437\"), \"user_14\":(\"Ann@hernandez.com\",\"Ann Williams\",date(\"1947-05-28\"),\"24 Mcknight Port Apt. 028 Sarahborough MD 38195\",\"868.057.4056x4814\"), \"user_15\":(\"Jessica@turner.com\",\"Jessica Stewart\",date(\"1951-11-28\"),\"0337 Mason Corner Apt. 900 Toddmouth FL 61464\",\"(335)408-3835x883\"), \"user_16\":(\"Sandra311@hotmail.com\",\"Sandra Dougherty\",date(\"1908-06-03\"),\"7 Davis Station Apt. 691 Pittmanfort HI 29746\",\"+1-189-827-0744x27614\"), \"user_17\":(\"Sharon91@gmail.com\",\"Sharon Mccoy\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_18\":(\"Sharon91+001@gmail.com\",\"Kathryn Miller\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_19\":(\"brettglenn@googlemail.com\",\"Bretty Glenn\",date(\"1991-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660-391-3730\"), \"user_20\":(\"julia.h.24@yahoo.com\",\"Julia H.\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_21\":(\"holly@welch.org\",\"Holly\",date(\"0000-10-19\"),\"1 Ama","date":"2022-08-14","objectID":"/identity-resolution/:1:1","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#数据"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱 1.1.1 图建模我们从一个最简单、直接的图谱开始，如下边的图结构示意显示，我们定义了点： user Prop: [name, email, birthday, address, phone_num] phone email device ip address 在他们之间有很自然的边： used_device Prop: time logged_in_from Prop: time has_phone has_address has_email 1.1.2 数据这份数据是开源的，地址在 https://github.com/wey-gu/identity-correlation-datagen 1.1.3 写入 NebulaGraph 利用 Nebula Up，一行部署 NebulaGraph 地址：https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 图建模的 Schema 对应的 NebulaGraph DDL 是： # 创建一个叫做 entity_resolution 的图空间 CREATE SPACE entity_resolution (vid_type=FIXED_STRING(30)); USE entity_resolution; # 创建点的类型 TAG CREATE TAG `user` (`name` string NOT NULL, `email` string NOT NULL, `phone_num` string NOT NULL, `birthday` date NOT NULL, `address` string NOT NULL); CREATE TAG `address` (`address` string NOT NULL); CREATE TAG `device` (`uuid` string NOT NULL); CREATE TAG `email` (); CREATE TAG `ip` (); CREATE TAG `phone` (); # 创建边的类型 Edge Type CREATE EDGE `used_device` (`time` timestamp NOT NULL); CREATE EDGE `logged_in_from` (`time` timestamp NOT NULL); CREATE EDGE `has_phone` (); CREATE EDGE `has_address` (); CREATE EDGE `has_email` (); 对于写入数据的 DML，这里只给出 user ，email 类型点、has_email 类型边的例子 INSERT VERTEX `user` (`email`, `name`, `birthday`, `address`, `phone_num`) VALUES \"user_1\":(\"heathermoore@johnson.com\",\"Miranda Miller\",date(\"1957-08-27\"),\"Brittany Forge Apt. 718 East Eric WV 97881\",\"+1-652-450-5443x00562\"), \"user_2\":(\"holly@welch.org\",\"Holly Pollard\",date(\"1990-10-19\"),\"1 Amanda Freeway Lisaland NJ 94933\",\"600-192-2985x041\"), \"user_3\":(\"julia.h.24@gmail.com\",\"Julia Hall\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_4\":(\"franklin.b@gibson.biz\",\"Franklin Barnett\",date(\"2020-03-01\"),\"Richard Curve Kingstad AZ 05660\",\"(224)497-9312\"), \"user_5\":(\"4kelly@yahoo.com\",\"April Kelly\",date(\"1967-12-01\"),\"Schmidt Key Lake Charles AL 36174\",\"410.138.1816x98702\"), \"user_6\":(\"steven.web@johnson.com\",\"Steven Webb\",date(\"1955-04-24\"),\"5 Joanna Key Suite 704 Frankshire OK 03035\",\"3666519376\"), \"user_7\":(\"Jessica_Torres@morris.com\",\"Jessica Torres\",date(\"1958-09-03\"),\"1 Payne Circle Mitchellfort LA 73053\",\"535-357-3112x4903\"), \"user_8\":(\"brettglenn@gmail.com\",\"Brett Glenn\",date(\"1992-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660.391.3730\"), \"user_9\":(\"veronica.j@yahoo.com\",\"Veronica Jordan\",date(\"1947-06-08\"),\"2 Klein Mission New Annetteton HI 05775\",\"810-252-6218\"), \"user_10\":(\"steven@phelps-craig.info\",\"Steven Brooks\",date(\"1954-06-14\"),\"1 Vanessa Stravenue Suite 184 Baileyville NY 46381\",\"+1-665-328-8103x3448\"), \"user_11\":(\"ReginaldTheMan@hotmail.com\",\"Reginald Mccullough\",date(\"1915-04-12\"),\"John Garden Port John LA 54602\",\"030.088.4523x94511\"), \"user_12\":(\"Jennifer.f@carroll-acosta.com\",\"Jennifer Foster\",date(\"1988-04-30\"),\"11 Webb Groves Tiffanyside MN 14566\",\"(489)306-8558x98227\"), \"user_13\":(\"Philip66@yahoo.com\",\"Philip Garcia\",date(\"1955-12-01\"),\"70 Robinson Locks Suite 113 East Veronica ND 87845\",\"490-088-7610x9437\"), \"user_14\":(\"Ann@hernandez.com\",\"Ann Williams\",date(\"1947-05-28\"),\"24 Mcknight Port Apt. 028 Sarahborough MD 38195\",\"868.057.4056x4814\"), \"user_15\":(\"Jessica@turner.com\",\"Jessica Stewart\",date(\"1951-11-28\"),\"0337 Mason Corner Apt. 900 Toddmouth FL 61464\",\"(335)408-3835x883\"), \"user_16\":(\"Sandra311@hotmail.com\",\"Sandra Dougherty\",date(\"1908-06-03\"),\"7 Davis Station Apt. 691 Pittmanfort HI 29746\",\"+1-189-827-0744x27614\"), \"user_17\":(\"Sharon91@gmail.com\",\"Sharon Mccoy\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_18\":(\"Sharon91+001@gmail.com\",\"Kathryn Miller\",date(\"1958-09-01\"),\"1 Southport Street Apt. 098 Westport KY 85907\",\"(814)898-9079x898\"), \"user_19\":(\"brettglenn@googlemail.com\",\"Bretty Glenn\",date(\"1991-09-03\"),\"Weber Unions Eddieland MT 64619\",\"660-391-3730\"), \"user_20\":(\"julia.h.24@yahoo.com\",\"Julia H.\",date(\"1927-08-24\"),\"Rodriguez Track East Connorfort NC 63144\",\"1248361783\"), \"user_21\":(\"holly@welch.org\",\"Holly\",date(\"0000-10-19\"),\"1 Ama","date":"2022-08-14","objectID":"/identity-resolution/:1:1","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#写入-nebulagraph"},{"categories":["Nebula Graph"],"content":" 1.2 根据确定规则获取 ID 映射关系最简单、直接的方法，在特定的场景下也可能是有用的，试想像 email、IP 地址、上网设备这些有严格结构的数据，在它们成为图谱中的点的时候，简单的相等关系就足以找出这样对应关系，比如： 拥有相同的 email 使用过相同的 IP 地址 使用过相同的设备 在前边的图谱、图数据库中，拥有相同的 email 可以直接表达为如下的图模式（Graph Pattern）。 (:user)-[:has_email]-\u003e(:email)\u003c-[:has_email]-[:user] 下图为顶点： user 与边：has_email 的一个图的可视化结果，可以看到这其中有两个三个点相连的串正是符合拥有相同 email 的模式的点。 注： 这个结果的数据源在 https://github.com/wey-gu/identity-correlation-datagen/tree/main/sample/hand_crafted 如果通过线上访问本文，你可以鼠标悬停（获取点上的属性）和框选放大每一个点和子图哦。 IFrame not supported 显然，在构建 ID Mapping 系统的过程中，我们就是通过在图数据库中直接查询，可视化渲染结果来看到等效的洞察，这个查询可以写成： MATCH p=(:user)-[:has_email]-\u003e(:email)\u003c-[:has_email]-(:user) RETURN p limit 10 NebulaGraph 中的查询结果 同样，在上边交互图中可以放大看到这两对拥有相同 email 关联起来的账号： 然而，在更多真实世界中，这样的模式匹配往往不能解决更多稍微复杂一点的情形： 比如从上边的图中我们可以看到这两个匹配了的映射中，holly@welch.org 关联下的两个用户的姓名是不同的，而 veronica.j@yahoo.com 关联下的两个用户姓名是完全相同的。 user_2,holly@welch.org,Holly Pollard,1990-10-19,1 Amanda Freeway Lisaland NJ 94933,600-192-2985x041 user_21,holly@welch.org,Holly,0000-10-19,1 Amanda Freeway Lisaland NJ 94933,(600)-192-2985 再比如 Sharon91@gmail.com 和 Sharon91+001@gmail.com ，这两个人的姓名不同，但是手机和地址却是相同的。 user_17,Sharon91@gmail.com,Sharon Mccoy,1958-09-01,1 Southport Street Apt. 098 Westport KY 85907,(814)898-9079x898 user_18,Sharon91+001@gmail.com,Kathryn Miller,1958-09-01,1 Southport Street Apt. 098 Westport KY 85907,(814)898-9079x898 比较庆幸的是我们只需要增加类似于\"拥有相同邮箱\"、“拥有相同地址”、“拥有相同电话\"等其他条件就可以把这种情况考虑进来了，而随之而来的问题是： 不是所有的数据都至少存在某一个确定条件的相等（二元的是与否），所以不存在一条确定的边去连接它们，比如这两个账户中： user_5,4kelly@yahoo.com,April Kelly,1967-12-01,Schmidt Key Lake Charles AL 36174,410.138.1816x98702 user_23,4kelly@hotmail.com,Kelly April,2010-01-01,Schmidt Key Lake Charles AL 13617,410-138-1816 如何表现 4kelly@yahoo.com 与 4kelly@hotmail.com 的相似性？ 如何将多种匹配规则的信息都纳入关联系统？ ","date":"2022-08-14","objectID":"/identity-resolution/:1:2","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#根据确定规则获取-id-映射关系"},{"categories":["Nebula Graph"],"content":" 1.3 非确定规则基于复合条件量化方法前边提到了几种确定规则无法处理的情况，它们可以归结为这两点： 需要多因素（规则）进行综合考虑与判定 需要对非确定条件（属性）进行处理，挖掘隐含相等、相似的关联关系（边） 对于 1. ，很自然可以想到对多种关联条件进行量化评分（score），按照多种条件的重要程度进行加权，给出认定为关联的总分的阈值。 有了多因素评分的机制，我们只需要考虑如何在确定的多因素基础之上，增加对不确定因素的处理，从而解决 2.的情况。这里，非确定的条件可能是： a. 表现结构化数据的相似性：Sharon91@gmail.com 与 Sharon91+001@gmail.com b. 表现非结构化数据的相似性： Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 600-192-2985x041 与(600)-192-2985 对于 a. 的结构化数据中的相似性，有两个思路是可以考虑的： 直接进行两个值的相似度 直接判定子字符串 运算 Jaccard index 等类似的相似度 拆分为更细粒的多个属性 将 email foo+num@bar.com 拆分成三个子属性 email_handle: foo, email_alias: num, email_domain: bar.com 然后就可以设计详细的确定性规则：email.handle 相等、甚至再在此基础上应用其他非确定规则 有时候，比如对于 email_domain 字段，我们还知道 gmail.com 和 googlemail.com 是等价的，这里的处理也是可以考虑的（像是user_19,brettglenn@googlemail.com 与 user_8,brettglenn@gmail.com，但从邮箱判断背后就是同一个持有者) 而对于 b. 的非结构属性相似性距离，处理方式可以根据具体的 domain knowledge 千差万别： 像 Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 的地址信息，除了可以用值的相似度之外，还可以把它转换成地理类型的属性，比如一个经纬度组成的点，从而计算两个点之间的地理距离，根据给定的距离值来打分。 注，你知道吗？NebulaGraph 图数据库中原生支持地理类型的属性与索引，可以直接创建 Point 类型的地理属性，并计算两个 Point 之间的距离。 对于 600-192-2985x041 与(600)-192-2985 这种字符串形式的电话号码，则可以统一转化为\u003c国家码\u003e+\u003c区域码\u003e+\u003c本地号码\u003e+\u003c分机号\u003e这样的结构化数据，进一步按照结构化数据的方式处理。 如果账号存在图片对象 URL，可以对比其文件相似度。 另外，对于非结构属性的相似性计算我们要尽量避免两两穷举运算的方式（笛卡尔积），因为这是一个指数增长的量级，一个可行的方法是只比较建立了确定性关系（比如相同邮件前缀：email_handle，地址在相同街区，IP 在同一个网段等）的实体。 小结 总结来看，为了解决真实世界数据的复杂情形，基于复合条件的量化方法有： 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 在有限存在确定性关联的点之间（避免两两穷举），运算其他量化、非确定相似性（字符距离、地理距离等、图片文件相似度）； 为不同关系赋予加权，计算相似度总分； 1.3.1 基于复合条件量化方法实操下边，我们来给出这系列方法的实操案例。 1. 细化结构数据 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 首先，我们把 email 的点拆成前缀 email_handle 与后缀 email_domain，自然地，会产生这样的边： has_email_with_handle (user -\u003e email_handle) has_email_with_domain (user -\u003e email_domain) with_handle (email -\u003e email_handle) with_domain (email -\u003e email_domain) 然而，可以想见 email_domain 是一个潜在的超级节点，并且，它的区分度在很多情况下是很小的，比如 gmail.com 这个公共邮箱后缀没有很大的关联性意义。我们可以只留下 email.handle 作为点，而对于 email_domain，把它留在边中作为属性： has_email_with_handle (user -\u003e email_handle) Prop: email_domain with_handle (email -\u003e email_handle) Prop: email_domain 对应的新的点类型、边类型的 NebulaGraph DDL 语句： # 新的点类型 CREATE TAG `email_handle` (); # 新的边类型 CREATE EDGE `has_email_with_handle` (`email_domain` string NOT NULL); CREATE EDGE `with_handle` (`email_domain` string NOT NULL); 对应新的点、边的 DML 语句： INSERT VERTEX `email_handle` () VALUES \"4kelly\":(), \"Ann\":(), \"brettglenn\":(), \"franklin.b\":(), \"heathermoore\":(), \"holly\":(), \"Jennifer.f\":(), \"Jessica\":(), \"Jessica_Torres\":(), \"julia.h.24\":(), \"Philip66\":(), \"ReginaldTheMan\":(), \"Sandra311\":(), \"Sharon91\":(), \"steven\":(), \"steven.web\":(), \"veronica.j\":(); INSERT EDGE `has_email_with_handle` (`email_domain`) VALUES \"user_1\"-\u003e\"heathermoore\":(\"johnson.com\"), \"user_2\"-\u003e\"holly\":(\"welch.org\"), \"user_3\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"user_4\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"user_5\"-\u003e\"4kelly\":(\"yahoo.com\"), \"user_6\"-\u003e\"steven.web\":(\"johnson.com\"), \"user_7\"-\u003e\"Jessica_Torres\":(\"morris.com\"), \"user_8\"-\u003e\"brettglenn\":(\"gmail.com\"), \"user_9\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_10\"-\u003e\"steven\":(\"phelps-craig.info\"), \"user_11\"-\u003e\"ReginaldTheMan\":(\"hotmail.com\"), \"user_12\"-\u003e\"Jennifer.f\":(\"carroll-acosta.com\"), \"user_13\"-\u003e\"Philip66\":(\"yahoo.com\"), \"user_14\"-\u003e\"Ann\":(\"hernandez.com\"), \"user_15\"-\u003e\"Jessica\":(\"turner.com\"), \"user_16\"-\u003e\"Sandra311\":(\"hotmail.com\"), \"user_17\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_18\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_19\"-\u003e\"brettglenn\":(\"googlemail.com\"), \"user_20\"-\u003e\"julia.h.24\":(\"yahoo.com\"), \"user_21\"-\u003e\"holly\":(\"welch.org\"), \"user_22\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_23\"-\u003e\"4kelly\":(\"hotmail.com\"); INSERT EDGE `with_handle` (`email_domain`) VALUES \"heathermoore@johnson.com\"-\u003e\"heathermoore\":(\"johnson.com\"), \"holly@welch.org\"-\u003e\"holly\":(\"welch.org\"), \"julia.h.24@gmail.com\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"franklin.b@gibson.biz\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"4kelly@yahoo.com\"-\u003e\"4kelly\":(\"yahoo.com\"), \"steven.web@johnson.com\"-\u003e\"steven.web\":(\"johnson.com\"), \"Jessica_Torres@morris.c","date":"2022-08-14","objectID":"/identity-resolution/:1:3","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#非确定规则基于复合条件量化方法"},{"categories":["Nebula Graph"],"content":" 1.3 非确定规则基于复合条件量化方法前边提到了几种确定规则无法处理的情况，它们可以归结为这两点： 需要多因素（规则）进行综合考虑与判定 需要对非确定条件（属性）进行处理，挖掘隐含相等、相似的关联关系（边） 对于 1. ，很自然可以想到对多种关联条件进行量化评分（score），按照多种条件的重要程度进行加权，给出认定为关联的总分的阈值。 有了多因素评分的机制，我们只需要考虑如何在确定的多因素基础之上，增加对不确定因素的处理，从而解决 2.的情况。这里，非确定的条件可能是： a. 表现结构化数据的相似性：Sharon91@gmail.com 与 Sharon91+001@gmail.com b. 表现非结构化数据的相似性： Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 600-192-2985x041 与(600)-192-2985 对于 a. 的结构化数据中的相似性，有两个思路是可以考虑的： 直接进行两个值的相似度 直接判定子字符串 运算 Jaccard index 等类似的相似度 拆分为更细粒的多个属性 将 email foo+num@bar.com 拆分成三个子属性 email_handle: foo, email_alias: num, email_domain: bar.com 然后就可以设计详细的确定性规则：email.handle 相等、甚至再在此基础上应用其他非确定规则 有时候，比如对于 email_domain 字段，我们还知道 gmail.com 和 googlemail.com 是等价的，这里的处理也是可以考虑的（像是user_19,brettglenn@googlemail.com 与 user_8,brettglenn@gmail.com，但从邮箱判断背后就是同一个持有者) 而对于 b. 的非结构属性相似性距离，处理方式可以根据具体的 domain knowledge 千差万别： 像 Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 的地址信息，除了可以用值的相似度之外，还可以把它转换成地理类型的属性，比如一个经纬度组成的点，从而计算两个点之间的地理距离，根据给定的距离值来打分。 注，你知道吗？NebulaGraph 图数据库中原生支持地理类型的属性与索引，可以直接创建 Point 类型的地理属性，并计算两个 Point 之间的距离。 对于 600-192-2985x041 与(600)-192-2985 这种字符串形式的电话号码，则可以统一转化为\u003c国家码\u003e+\u003c区域码\u003e+\u003c本地号码\u003e+\u003c分机号\u003e这样的结构化数据，进一步按照结构化数据的方式处理。 如果账号存在图片对象 URL，可以对比其文件相似度。 另外，对于非结构属性的相似性计算我们要尽量避免两两穷举运算的方式（笛卡尔积），因为这是一个指数增长的量级，一个可行的方法是只比较建立了确定性关系（比如相同邮件前缀：email_handle，地址在相同街区，IP 在同一个网段等）的实体。 小结 总结来看，为了解决真实世界数据的复杂情形，基于复合条件的量化方法有： 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 在有限存在确定性关联的点之间（避免两两穷举），运算其他量化、非确定相似性（字符距离、地理距离等、图片文件相似度）； 为不同关系赋予加权，计算相似度总分； 1.3.1 基于复合条件量化方法实操下边，我们来给出这系列方法的实操案例。 1. 细化结构数据 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 首先，我们把 email 的点拆成前缀 email_handle 与后缀 email_domain，自然地，会产生这样的边： has_email_with_handle (user -\u003e email_handle) has_email_with_domain (user -\u003e email_domain) with_handle (email -\u003e email_handle) with_domain (email -\u003e email_domain) 然而，可以想见 email_domain 是一个潜在的超级节点，并且，它的区分度在很多情况下是很小的，比如 gmail.com 这个公共邮箱后缀没有很大的关联性意义。我们可以只留下 email.handle 作为点，而对于 email_domain，把它留在边中作为属性： has_email_with_handle (user -\u003e email_handle) Prop: email_domain with_handle (email -\u003e email_handle) Prop: email_domain 对应的新的点类型、边类型的 NebulaGraph DDL 语句： # 新的点类型 CREATE TAG `email_handle` (); # 新的边类型 CREATE EDGE `has_email_with_handle` (`email_domain` string NOT NULL); CREATE EDGE `with_handle` (`email_domain` string NOT NULL); 对应新的点、边的 DML 语句： INSERT VERTEX `email_handle` () VALUES \"4kelly\":(), \"Ann\":(), \"brettglenn\":(), \"franklin.b\":(), \"heathermoore\":(), \"holly\":(), \"Jennifer.f\":(), \"Jessica\":(), \"Jessica_Torres\":(), \"julia.h.24\":(), \"Philip66\":(), \"ReginaldTheMan\":(), \"Sandra311\":(), \"Sharon91\":(), \"steven\":(), \"steven.web\":(), \"veronica.j\":(); INSERT EDGE `has_email_with_handle` (`email_domain`) VALUES \"user_1\"-\u003e\"heathermoore\":(\"johnson.com\"), \"user_2\"-\u003e\"holly\":(\"welch.org\"), \"user_3\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"user_4\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"user_5\"-\u003e\"4kelly\":(\"yahoo.com\"), \"user_6\"-\u003e\"steven.web\":(\"johnson.com\"), \"user_7\"-\u003e\"Jessica_Torres\":(\"morris.com\"), \"user_8\"-\u003e\"brettglenn\":(\"gmail.com\"), \"user_9\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_10\"-\u003e\"steven\":(\"phelps-craig.info\"), \"user_11\"-\u003e\"ReginaldTheMan\":(\"hotmail.com\"), \"user_12\"-\u003e\"Jennifer.f\":(\"carroll-acosta.com\"), \"user_13\"-\u003e\"Philip66\":(\"yahoo.com\"), \"user_14\"-\u003e\"Ann\":(\"hernandez.com\"), \"user_15\"-\u003e\"Jessica\":(\"turner.com\"), \"user_16\"-\u003e\"Sandra311\":(\"hotmail.com\"), \"user_17\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_18\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_19\"-\u003e\"brettglenn\":(\"googlemail.com\"), \"user_20\"-\u003e\"julia.h.24\":(\"yahoo.com\"), \"user_21\"-\u003e\"holly\":(\"welch.org\"), \"user_22\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_23\"-\u003e\"4kelly\":(\"hotmail.com\"); INSERT EDGE `with_handle` (`email_domain`) VALUES \"heathermoore@johnson.com\"-\u003e\"heathermoore\":(\"johnson.com\"), \"holly@welch.org\"-\u003e\"holly\":(\"welch.org\"), \"julia.h.24@gmail.com\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"franklin.b@gibson.biz\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"4kelly@yahoo.com\"-\u003e\"4kelly\":(\"yahoo.com\"), \"steven.web@johnson.com\"-\u003e\"steven.web\":(\"johnson.com\"), \"Jessica_Torres@morris.c","date":"2022-08-14","objectID":"/identity-resolution/:1:3","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于复合条件量化方法实操"},{"categories":["Nebula Graph"],"content":" 1.3 非确定规则基于复合条件量化方法前边提到了几种确定规则无法处理的情况，它们可以归结为这两点： 需要多因素（规则）进行综合考虑与判定 需要对非确定条件（属性）进行处理，挖掘隐含相等、相似的关联关系（边） 对于 1. ，很自然可以想到对多种关联条件进行量化评分（score），按照多种条件的重要程度进行加权，给出认定为关联的总分的阈值。 有了多因素评分的机制，我们只需要考虑如何在确定的多因素基础之上，增加对不确定因素的处理，从而解决 2.的情况。这里，非确定的条件可能是： a. 表现结构化数据的相似性：Sharon91@gmail.com 与 Sharon91+001@gmail.com b. 表现非结构化数据的相似性： Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 600-192-2985x041 与(600)-192-2985 对于 a. 的结构化数据中的相似性，有两个思路是可以考虑的： 直接进行两个值的相似度 直接判定子字符串 运算 Jaccard index 等类似的相似度 拆分为更细粒的多个属性 将 email foo+num@bar.com 拆分成三个子属性 email_handle: foo, email_alias: num, email_domain: bar.com 然后就可以设计详细的确定性规则：email.handle 相等、甚至再在此基础上应用其他非确定规则 有时候，比如对于 email_domain 字段，我们还知道 gmail.com 和 googlemail.com 是等价的，这里的处理也是可以考虑的（像是user_19,brettglenn@googlemail.com 与 user_8,brettglenn@gmail.com，但从邮箱判断背后就是同一个持有者) 而对于 b. 的非结构属性相似性距离，处理方式可以根据具体的 domain knowledge 千差万别： 像 Schmidt Key Lake Charles AL 36174 与 Schmidt Key Lake Charles AL 13617 的地址信息，除了可以用值的相似度之外，还可以把它转换成地理类型的属性，比如一个经纬度组成的点，从而计算两个点之间的地理距离，根据给定的距离值来打分。 注，你知道吗？NebulaGraph 图数据库中原生支持地理类型的属性与索引，可以直接创建 Point 类型的地理属性，并计算两个 Point 之间的距离。 对于 600-192-2985x041 与(600)-192-2985 这种字符串形式的电话号码，则可以统一转化为\u003c国家码\u003e+\u003c区域码\u003e+\u003c本地号码\u003e+\u003c分机号\u003e这样的结构化数据，进一步按照结构化数据的方式处理。 如果账号存在图片对象 URL，可以对比其文件相似度。 另外，对于非结构属性的相似性计算我们要尽量避免两两穷举运算的方式（笛卡尔积），因为这是一个指数增长的量级，一个可行的方法是只比较建立了确定性关系（比如相同邮件前缀：email_handle，地址在相同街区，IP 在同一个网段等）的实体。 小结 总结来看，为了解决真实世界数据的复杂情形，基于复合条件的量化方法有： 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 在有限存在确定性关联的点之间（避免两两穷举），运算其他量化、非确定相似性（字符距离、地理距离等、图片文件相似度）； 为不同关系赋予加权，计算相似度总分； 1.3.1 基于复合条件量化方法实操下边，我们来给出这系列方法的实操案例。 1. 细化结构数据 通过细化结构数据（比如邮箱字段拆分为子属性或者点）、或者转变为结构化数据（处理字符串形式的电话号码）建立相似结构化数据之间的确定关联； 首先，我们把 email 的点拆成前缀 email_handle 与后缀 email_domain，自然地，会产生这样的边： has_email_with_handle (user -\u003e email_handle) has_email_with_domain (user -\u003e email_domain) with_handle (email -\u003e email_handle) with_domain (email -\u003e email_domain) 然而，可以想见 email_domain 是一个潜在的超级节点，并且，它的区分度在很多情况下是很小的，比如 gmail.com 这个公共邮箱后缀没有很大的关联性意义。我们可以只留下 email.handle 作为点，而对于 email_domain，把它留在边中作为属性： has_email_with_handle (user -\u003e email_handle) Prop: email_domain with_handle (email -\u003e email_handle) Prop: email_domain 对应的新的点类型、边类型的 NebulaGraph DDL 语句： # 新的点类型 CREATE TAG `email_handle` (); # 新的边类型 CREATE EDGE `has_email_with_handle` (`email_domain` string NOT NULL); CREATE EDGE `with_handle` (`email_domain` string NOT NULL); 对应新的点、边的 DML 语句： INSERT VERTEX `email_handle` () VALUES \"4kelly\":(), \"Ann\":(), \"brettglenn\":(), \"franklin.b\":(), \"heathermoore\":(), \"holly\":(), \"Jennifer.f\":(), \"Jessica\":(), \"Jessica_Torres\":(), \"julia.h.24\":(), \"Philip66\":(), \"ReginaldTheMan\":(), \"Sandra311\":(), \"Sharon91\":(), \"steven\":(), \"steven.web\":(), \"veronica.j\":(); INSERT EDGE `has_email_with_handle` (`email_domain`) VALUES \"user_1\"-\u003e\"heathermoore\":(\"johnson.com\"), \"user_2\"-\u003e\"holly\":(\"welch.org\"), \"user_3\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"user_4\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"user_5\"-\u003e\"4kelly\":(\"yahoo.com\"), \"user_6\"-\u003e\"steven.web\":(\"johnson.com\"), \"user_7\"-\u003e\"Jessica_Torres\":(\"morris.com\"), \"user_8\"-\u003e\"brettglenn\":(\"gmail.com\"), \"user_9\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_10\"-\u003e\"steven\":(\"phelps-craig.info\"), \"user_11\"-\u003e\"ReginaldTheMan\":(\"hotmail.com\"), \"user_12\"-\u003e\"Jennifer.f\":(\"carroll-acosta.com\"), \"user_13\"-\u003e\"Philip66\":(\"yahoo.com\"), \"user_14\"-\u003e\"Ann\":(\"hernandez.com\"), \"user_15\"-\u003e\"Jessica\":(\"turner.com\"), \"user_16\"-\u003e\"Sandra311\":(\"hotmail.com\"), \"user_17\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_18\"-\u003e\"Sharon91\":(\"gmail.com\"), \"user_19\"-\u003e\"brettglenn\":(\"googlemail.com\"), \"user_20\"-\u003e\"julia.h.24\":(\"yahoo.com\"), \"user_21\"-\u003e\"holly\":(\"welch.org\"), \"user_22\"-\u003e\"veronica.j\":(\"yahoo.com\"), \"user_23\"-\u003e\"4kelly\":(\"hotmail.com\"); INSERT EDGE `with_handle` (`email_domain`) VALUES \"heathermoore@johnson.com\"-\u003e\"heathermoore\":(\"johnson.com\"), \"holly@welch.org\"-\u003e\"holly\":(\"welch.org\"), \"julia.h.24@gmail.com\"-\u003e\"julia.h.24\":(\"gmail.com\"), \"franklin.b@gibson.biz\"-\u003e\"franklin.b\":(\"gibson.biz\"), \"4kelly@yahoo.com\"-\u003e\"4kelly\":(\"yahoo.com\"), \"steven.web@johnson.com\"-\u003e\"steven.web\":(\"johnson.com\"), \"Jessica_Torres@morris.c","date":"2022-08-14","objectID":"/identity-resolution/:1:3","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#利用-active-learning-的方法交互式学习评分权重"},{"categories":["Nebula Graph"],"content":" 1.4 利用新的边连接不同方法进一步，对于这些确定（是否二元的）或非确定（量化的）关系，利用图库与外部系统获得了关联关系之后，常常可以直接把它们定义为图谱中直连的边，写回图库，提供给其他算法、系统作为输入，做进一步迭代、计算。 1.4.1 创建单独的直连边假设之前对邮件、地址、姓名的处理之后，把结果作为用户实体之前的直连边插入图谱，这些种边叫做： shared_similar_email shared_similar_location shared_name # DDL CREATE EDGE `shared_similar_email` (); CREATE EDGE `shared_similar_location` (); CREATE EDGE `shared_name` (); # DML INSERT EDGE `shared_similar_email` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); INSERT EDGE `shared_name` () VALUES \"user_9\" -\u003e\"user_22\":(), \"user_22\"-\u003e\"user_9\" :(); INSERT EDGE `shared_similar_location` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); 1.4.2 创建复合评分之后的边比如，我们查询综合分数大于 2 的点： MATCH (v_start:user)-[:has_email_with_handle]-\u003e(:email_handle)\u003c-[:has_email_with_handle]-(v_end:user) MATCH (v_start:user)-[:has_address]-\u003e(a_start:address) MATCH (v_end:user)-[:has_address]-\u003e(a_end:address) WITH id(v_start) AS s, id(v_end) AS e, v_start.`user`.name AS s_name, v_end.`user`.name AS e_name, ST_Distance(a_start.address.geo_point, a_end.address.geo_point) AS distance WITH s, e, 1 AS shared_email_handle, CASE WHEN s_name == e_name THEN 1 ELSE 0 END AS shared_name, CASE WHEN distance \u003c 10000 THEN 1 ELSE 0 END AS shared_location WITH s, e, (shared_email_handle + shared_name + shared_location) AS score WHERE score \u003e 2 RETURN s, e, score ORDER BY score DESC 然后根据返回结果建立新的边： # DDL CREATE EDGE `is_similar_to` (score int NOT NULL); # DML INSERT EDGE `is_similar_to` (`score`) VALUES \"user_22\" -\u003e\"user_9\":(3), \"user_9\" -\u003e\"user_22\":(3); ","date":"2022-08-14","objectID":"/identity-resolution/:1:4","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#利用新的边连接不同方法"},{"categories":["Nebula Graph"],"content":" 1.4 利用新的边连接不同方法进一步，对于这些确定（是否二元的）或非确定（量化的）关系，利用图库与外部系统获得了关联关系之后，常常可以直接把它们定义为图谱中直连的边，写回图库，提供给其他算法、系统作为输入，做进一步迭代、计算。 1.4.1 创建单独的直连边假设之前对邮件、地址、姓名的处理之后，把结果作为用户实体之前的直连边插入图谱，这些种边叫做： shared_similar_email shared_similar_location shared_name # DDL CREATE EDGE `shared_similar_email` (); CREATE EDGE `shared_similar_location` (); CREATE EDGE `shared_name` (); # DML INSERT EDGE `shared_similar_email` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); INSERT EDGE `shared_name` () VALUES \"user_9\" -\u003e\"user_22\":(), \"user_22\"-\u003e\"user_9\" :(); INSERT EDGE `shared_similar_location` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); 1.4.2 创建复合评分之后的边比如，我们查询综合分数大于 2 的点： MATCH (v_start:user)-[:has_email_with_handle]-\u003e(:email_handle)\u003c-[:has_email_with_handle]-(v_end:user) MATCH (v_start:user)-[:has_address]-\u003e(a_start:address) MATCH (v_end:user)-[:has_address]-\u003e(a_end:address) WITH id(v_start) AS s, id(v_end) AS e, v_start.`user`.name AS s_name, v_end.`user`.name AS e_name, ST_Distance(a_start.address.geo_point, a_end.address.geo_point) AS distance WITH s, e, 1 AS shared_email_handle, CASE WHEN s_name == e_name THEN 1 ELSE 0 END AS shared_name, CASE WHEN distance \u003c 10000 THEN 1 ELSE 0 END AS shared_location WITH s, e, (shared_email_handle + shared_name + shared_location) AS score WHERE score \u003e 2 RETURN s, e, score ORDER BY score DESC 然后根据返回结果建立新的边： # DDL CREATE EDGE `is_similar_to` (score int NOT NULL); # DML INSERT EDGE `is_similar_to` (`score`) VALUES \"user_22\" -\u003e\"user_9\":(3), \"user_9\" -\u003e\"user_22\":(3); ","date":"2022-08-14","objectID":"/identity-resolution/:1:4","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#创建单独的直连边"},{"categories":["Nebula Graph"],"content":" 1.4 利用新的边连接不同方法进一步，对于这些确定（是否二元的）或非确定（量化的）关系，利用图库与外部系统获得了关联关系之后，常常可以直接把它们定义为图谱中直连的边，写回图库，提供给其他算法、系统作为输入，做进一步迭代、计算。 1.4.1 创建单独的直连边假设之前对邮件、地址、姓名的处理之后，把结果作为用户实体之前的直连边插入图谱，这些种边叫做： shared_similar_email shared_similar_location shared_name # DDL CREATE EDGE `shared_similar_email` (); CREATE EDGE `shared_similar_location` (); CREATE EDGE `shared_name` (); # DML INSERT EDGE `shared_similar_email` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); INSERT EDGE `shared_name` () VALUES \"user_9\" -\u003e\"user_22\":(), \"user_22\"-\u003e\"user_9\" :(); INSERT EDGE `shared_similar_location` () VALUES \"user_5\" -\u003e\"user_23\":(), \"user_9\" -\u003e\"user_22\":(), \"user_21\"-\u003e\"user_2\" :(), \"user_2\" -\u003e\"user_21\":(), \"user_22\"-\u003e\"user_9\" :(), \"user_20\"-\u003e\"user_3\" :(), \"user_3\" -\u003e\"user_20\":(), \"user_18\"-\u003e\"user_17\":(), \"user_17\"-\u003e\"user_18\":(), \"user_19\"-\u003e\"user_8\" :(), \"user_8\" -\u003e\"user_19\":(), \"user_23\"-\u003e\"user_5\" :(); 1.4.2 创建复合评分之后的边比如，我们查询综合分数大于 2 的点： MATCH (v_start:user)-[:has_email_with_handle]-\u003e(:email_handle)\u003c-[:has_email_with_handle]-(v_end:user) MATCH (v_start:user)-[:has_address]-\u003e(a_start:address) MATCH (v_end:user)-[:has_address]-\u003e(a_end:address) WITH id(v_start) AS s, id(v_end) AS e, v_start.`user`.name AS s_name, v_end.`user`.name AS e_name, ST_Distance(a_start.address.geo_point, a_end.address.geo_point) AS distance WITH s, e, 1 AS shared_email_handle, CASE WHEN s_name == e_name THEN 1 ELSE 0 END AS shared_name, CASE WHEN distance \u003c 10000 THEN 1 ELSE 0 END AS shared_location WITH s, e, (shared_email_handle + shared_name + shared_location) AS score WHERE score \u003e 2 RETURN s, e, score ORDER BY score DESC 然后根据返回结果建立新的边： # DDL CREATE EDGE `is_similar_to` (score int NOT NULL); # DML INSERT EDGE `is_similar_to` (`score`) VALUES \"user_22\" -\u003e\"user_9\":(3), \"user_9\" -\u003e\"user_22\":(3); ","date":"2022-08-14","objectID":"/identity-resolution/:1:4","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#创建复合评分之后的边"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图算法的方法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#图相似性算法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#社区发现算法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图算法的方法-1"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图查询的-jaccard-实现"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于-nebulagraph-algorithm-图计算平台的-jaccard-方法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#前面方法的局限"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#更-scale-的方法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于-nebulagraph-algorithm-图计算平台社区发现算法"},{"categories":["Nebula Graph"],"content":" 1.5 基于图算法的方法前边的方法中我们直接利用了用户的各项属性、行为事件中产生的关系，并利用各种属性、值相似度的方法建立了基于概率或者带有评分的关联关系。而在通过其他方法增加了新的边之后的图上，我们也可以利用图算法的方法来映射潜在的相同用户 ID。 1.5.1 图相似性算法利用节点相似性图算法，比如 Jaccard Index、余弦相似度等，我们可以或者 a. 利用图库之上的图计算平台全量计算相似度，或者 b. 用图查询语句实现全图/给定的点之间的相似度，最后给相似度一定的阈值来帮助建立新的（考虑了涉及边的）映射关系。 注，这里的 Jaccard index 和我们前边提到的比较两个字符串的方法本质是一样的，不过我们现在提及的是应用在图上的点之间存在相连点作为算法中的“交集”的实现。 1.5.2 社区发现算法自然地，还可以用社区发现的算法全图找出给定的基于边之下的社区划分，调试算法，使得目标划分社区内部点为估计的相同用户。 1.5.3 基于图算法的方法 1.5.3.1 基于图查询的 Jaccard 实现Jaccard Index 是一个描述两个集合距离的定义公式，非常简单、符合直觉，它的定义为： $$ J(A,B)= \\frac {|A\\cap B|}{|A\\cup B|} $$ 这里，我们把交集理解为 A 与 B 共同连接的点（设备、IP、邮箱前缀、地址），而并集理解为这几种关系下与 A 或者 B 直连的所有点，于是，我们用这样的 NebulaGraph OpenCypher 查询就可以算出至少包含一跳关系的点和它相关的点、以及 Jaccard Index 值，越大代表关联度越大。 MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components)\u003c-[:used_device|logged_in_from|has_email_with_handle|has_address]-(v_end:user) WITH v_start, v_end, count(shared_components) AS intersection_size MATCH (v_start:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH id(v_start) AS v_start, v_end, intersection_size, COLLECT(id(shared_components)) AS set_a MATCH (v_end:user)-[:used_device|logged_in_from|has_email_with_handle|has_address]-\u003e(shared_components) WITH v_start, id(v_end) AS v_end, intersection_size, set_a, COLLECT(id(shared_components)) AS set_b WITH v_start, v_end, toFloat(intersection_size) AS intersection_size, toSet(set_a + set_b) AS A_U_B RETURN v_start, v_end, intersection_size/size(A_U_B) AS jaccard_index ORDER BY jaccard_index DESC 我们可以看到结果里： +-----------+-----------+---------------------+ | v_start | v_end | jaccard_index | +-----------+-----------+---------------------+ | \"user_8\" | \"user_19\" | 1.0 | | \"user_19\" | \"user_8\" | 1.0 | | \"user_20\" | \"user_3\" | 0.6666666666666666 | | \"user_3\" | \"user_20\" | 0.6666666666666666 | | \"user_21\" | \"user_2\" | 0.6 | | \"user_18\" | \"user_17\" | 0.6 | | \"user_17\" | \"user_18\" | 0.6 | | \"user_2\" | \"user_21\" | 0.6 | | \"user_22\" | \"user_9\" | 0.5 | | \"user_9\" | \"user_22\" | 0.5 | | \"user_23\" | \"user_5\" | 0.2 | | \"user_5\" | \"user_23\" | 0.2 | | \"user_21\" | \"user_20\" | 0.16666666666666666 | | \"user_20\" | \"user_21\" | 0.16666666666666666 | +-----------+-----------+---------------------+ user_8 与 user_19 的系数是最大的的，让我们看看他们之间的连接？ FIND ALL PATH FROM \"user_8\" TO \"user_19\" OVER * BIDIRECT YIELD path AS p; 果然，他们之间的相似度很大： 1.5.3.2 基于 NebulaGraph Algorithm 图计算平台的 Jaccard 方法 1.5.3.2.1 前面方法的局限利用图数据库查询计算 Jaccard 系数的方法有两方面局限。 首先，为了防止两两运算，我们假设了所有值得被运算的点之间已经存在某种确定链接（对应 MATCH 第一行），虽然这样的假设在大部分情况下是可以粗略被接受的，但是它是一种压缩和妥协。 其次，在数据量很大的情形里，这样的查询将不具有可操作性。 1.5.3.2.2 更 Scale 的方法为了能处理更大规模，我们可以利用 Spark 等并行计算平台进行算法执行； 在全图运算时，我们可以利用局部敏感哈希 MinHash 来对两两比对降维，庆幸的是，Spark 中提供了 MinHash 的实现供我们使用！ 参考： https://aksakalli.github.io/2016/03/01/jaccard-similarity-with-minhash.html https://en.wikipedia.org/wiki/MinHash https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala MinHash 的思想： 这个方法是用概率去有损估计 Jaccard 系数，这里的降维体现在它用 bit map 去数字化每一个集合，随机定义不同的集合上的 shuffle（乱序）变换，取变换之后 hash 的最小值。这里，两个集合的随机变换后最小值 相等的概率是等于 Jaccard 系数的。所以，这样偷梁换柱，就把需要两两集合运算比较的算法变成只需要对每一个集合做常数次随机变换取最小的降维近似运算了。 在图上，对于每一个点，我们认为它的邻居就是这个点的集合，那么在 Spark 中运算 Jaccard 系数的过程就是： 获取每一个点的邻居集合 对点的邻居进行 MinHash 运算，获得 Jaccard 系数 庆幸的是，开源的 NebulaGraph Algorithm 已经提供了这个算法的实现，感兴趣的同学可以访问 nebula-algorithm/src/main/scala/com/vesoft/nebula/algorithm/lib/JaccardAlgo.scala 了解它的实现，而我们只需要调用 NebulaGraph Algorithm 就可以了，使用方法参考 NebulaGraph Algorithm 文档。 注，配置中 jaccard.tol 的意涵是 approxSimilarityJoin 中的 threshold ： def approxSimilarityJoin( datasetA: Dataset[_], datasetB: Dataset[_], threshold: Double, distCol: String): Dataset[_] = { ... // Filter the joined datasets where the distance are smaller than the threshold. joinedDatasetWithDist.filter(col(distCol) \u003c threshold) 读者到这里应该会注意到，这个方法显然是假设所有的点都是用户实体，边是他们之间的直连关系的。所以再应用这个方法之前，我们需要创建经过预处理的直连边，这个步骤正是前边章节“利用新的边连接不同方法”中的内容。 1.5.3.3 基于","date":"2022-08-14","objectID":"/identity-resolution/:1:5","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#上手基于-nebulagraph-algorithm-图计算方法"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于图神经网络的方法"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#基于-gnn-的实操"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#hdeicdm2021httpsieeexploreieeeorgdocument9679130"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#数据集"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#数据处理"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#模型训练"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#保存模型"},{"categories":["Nebula Graph"],"content":" 1.6 基于图神经网络的方法我们注意到，在讲以上不同的方法相结合的时候，会把前导方法的结果作为图上的边，进而作为后边的方法的输入，而相同用户 ID 的识别本质上就是在图上去预测用户之间链接、边。 在 GNN 的方法中，除了我们在欺诈检测中利用到的节点分类（属性预测）之外，链接预测（Link Prediction）也是另一个常见的算法目标和应用场景。自然地，可以想到用 GNN 的方法结合 1. 非 GNN 方法获得的、 2. 已经有的人为标注的链接，来学习、预测图上的 ID 映射。 值得注意的是，GNN 的方法只能利用数字型的 feature、属性，我们没办法把非数字型的属性像在分类情况里那样枚举为数值，相反，我们在真正的 GNN 之前，可以用其他的图方法去建立基于打分、或者相似度的边建立。这时候，这些前边的方法成为了 GNN 链路预测的特征工程。 1.6.1 基于 GNN 的实操和在 “基于 NebulaGraph 图数据库的欺诈检测方法与代码示例” 的欺诈检测类似，我将给出的例子也是 GNN 结合图数据库做实时预测的例子。 1.6.1.1 HDE[ICDM2021]我们利用 Heterogeneous Graph Neural Network with Distance Encoding 给出的方法来做 Inductive Learning 的异构 GNN 上的链路预测，同时，我们将用一个更方便的 GNN 工具，OpenHGNN，有了它，本例中的代码量也会大大下降。 注：OpenHGNN 是由北邮 GAMMA Lab 开发的基于 PyTorch 和 DGL 的开源异质图神经网络工具包。 1.6.1.2 数据集本利的数据集是前边方法中建立在 NebulaGraph 中的图谱，借助于 Nebula-DGL，我们可以一行代码把 NebulaGraph 中的图加载到 DGL 之中。 注： 这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 你可以直接 load 这个 .ngql 文件到 NebulaGraph。 https://github.com/wey-gu/identity-correlation-datagen/raw/main/sample/hand_crafted/entity_resolution.ngql 1.6.1.3 数据处理为了将 NebulaGraph 图谱进行工程处理，序列化成为 DGL 的图对象，我们要通过 Nebula-DGL 的 YAML 配置文件 API 描述所需的点、边类型以及关心的属性（特征）。 我们看下现在的图中有哪些点、边类型： (root@nebula) [entity_resolution]\u003e SHOW TAGS +----------------+ | Name | +----------------+ | \"address\" | | \"device\" | | \"email\" | | \"email_handle\" | | \"ip\" | | \"phone\" | | \"user\" | +----------------+ Got 7 rows (time spent 1335/7357 us) (root@nebula) [entity_resolution]\u003e SHOW EDGES +---------------------------+ | Name | +---------------------------+ | \"has_address\" | | \"has_email\" | | \"has_email_with_handle\" | | \"has_phone\" | | \"is_similar_to\" | | \"logged_in_from\" | | \"shared_name\" | | \"shared_similar_email\" | | \"shared_similar_location\" | | \"used_device\" | | \"with_handle\" | +---------------------------+ Got 11 rows (time spent 1439/30418 us) 在本例中，我们不考虑属性(特征)。 nebulagraph_entity_resolution_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: entity_resolution # str or int vertex_id_type: int vertex_tags: - name: user - name: address - name: device - name: email_handle - name: ip edge_types: - name: has_email_with_handle start_vertex_tag: user end_vertex_tag: email_handle - name: is_similar_to start_vertex_tag: user end_vertex_tag: user - name: shared_similar_location start_vertex_tag: user end_vertex_tag: user - name: has_address start_vertex_tag: user end_vertex_tag: address - name: logged_in_from start_vertex_tag: user end_vertex_tag: ip - name: used_device start_vertex_tag: user end_vertex_tag: device 然后，我们在安装好 Nebula-DGL 之后只需要这几行代码就可以将 NebulaGraph 中的这张图构造为 DGL 的 DGLHeteroGraph 图对象： from nebula_dgl import NebulaLoader nebula_config = { \"graph_hosts\": [ ('graphd', 9669), ('graphd1', 9669), ('graphd2', 9669) ], \"nebula_user\": \"root\", \"nebula_password\": \"nebula\", } # load feature_mapper from yaml file with open('nebulagraph_entity_resolution_dgl_mapper.yaml', 'r') as f: feature_mapper = yaml.safe_load(f) nebula_loader = NebulaLoader(nebula_config, feature_mapper) g = nebula_loader.load() g = g.to('cpu') device = torch.device('cpu') 1.6.1.4 模型训练参考 custom_link_prediction_dataset.py HDE_link_predict.py import torch as th from openhgnn import Experiment from openhgnn.dataset import AsLinkPredictionDataset, generate_random_hg from dgl import transforms as T from dgl import DGLHeteroGraph from dgl.data import DGLDataset from dgl.dataloading.negative_sampler import GlobalUniform meta_paths_dict = {'APA': [('user', 'has_email_with_handle', 'email_handle'), ('user', 'is_similar_to', 'user'), ('user', 'shared_similar_location', 'user'), ('user', 'has_address', 'address'), ('user', 'logged_in_from', 'ip'), ('user', 'used_device', 'device')]} target_link = [('user', 'is_similar_to', 'user')] target_link_r = [('user', 'is_similar_to', 'user')] class MyLPDataset(DGLDataset): def __init__(self, g): super().__init__(name='entity_resolution', force_reload=True) self.g = g def process(","date":"2022-08-14","objectID":"/identity-resolution/:1:6","series":null,"tags":["Nebula Graph","ID-Mapping","GNN","Entity-Linking","用户360","DGL"],"title":"基于 NebulaGraph 图数据库的 ID Resolution 方法与代码示例","uri":"/identity-resolution/#应用落地"},{"categories":["Nebula Graph"],"content":"本文是一个基于 NebulaGraph 上的图算法、图数据库、机器学习、图神经网络的 Fraud Detection 方法综述，除了基本方法思想的介绍之外，我还给大家弄了可以跑的 Playground。值得一提的是，这还我第一次给大家介绍 Nebula-DGL 这个项目 😁。","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/"},{"categories":["Nebula Graph"],"content":" 本文是一个基于 NebulaGraph 上图算法、图数据库、机器学习、GNN 的 Fraud Detection 方法综述，除了基本方法思想的介绍之外，我还给大家弄了可以跑的 Playground。 值得一提的是，这还我第一次给大家介绍 Nebula-DGL 这个项目 😁。 ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:0:0","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#"},{"categories":["Nebula Graph"],"content":" 1 基于图数据库的欺诈检测方法","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:0","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#基于图数据库的欺诈检测方法"},{"categories":["Nebula Graph"],"content":" 1.1 建立图谱首先，对现有的历史数据、标注信息面向关联关系进行属性图建模。这种原始数据是多个表结构中的银行、电子商务或者保险行业里的交易事件记录、用户数据和风控标注，而建模过程就是抽象出我们关心的实体、实体间的关联关系、和其中有意义的属性。 一般来说，自然人、公司实体、电话号码、地址、设备（比如终端设备、网络地址、终端设备所连接的 WiFi SSID 等）、订单都是实体本身，其他信息比如风险标注（是否高风险、风险描述等）、自然人和公司实体的信息（职业、收入、学历等）都作为实体的属性来建模。 下图是一个可以参考的贷款反欺诈的示例建模，它来自一份作者开源的图结构数据生成项目。 注，你可以访问 https://github.com/wey-gu/fraud-detection-datagen 获取这个开源的数据生成器代码和一份示例的数据。 ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:1","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#建立图谱"},{"categories":["Nebula Graph"],"content":" 1.2 图数据库查询识别风险有了一张囊括了人、公司、历史贷款申请记录、电话、线上申请网络设备的图谱，我们可以挖掘一些有意思的信息。 事实上，很多值得被发现、并有效阻止从而止损的骗保行为是具有群体聚集性的。比如欺诈团伙可能是一小批人（比如3到5人）有组织地收集更大规模的身份证信息（比如30张），同时发起多个金融机构大量贷款，然后在放款后选择丢弃这批留下了违约记录的身份证，再进一步选择下一批身份证信息如法炮制。 这种团伙作案的方式因为利用了大量新的身份信息，完全利用历史记录去黑名单规避风险的方式是无效的。不过，借助于关联关系的视角，这些模式是一定程度上可以被及时识别出来的。 这些可以被识别出的规律我把它分成两种： 一种是风控专家可以直接用某种模式来描述的，例如：和已经被标注为高风险的实体有直接或者间接的关联关系（新订单申请人使用了和过往高风险记录相同的网络设备），这种模式对应到图谱中，通过一个图查询就可以实时给出结果。 另一种是隐含在数据的关联关系背后，需要通过图算法挖掘得出的一些风险提示，例如：尽管给定的实体与有限的标注高风险实体没有匹配的关联，但是它在图中形成了聚集性可能提示我们这可能是一个尚未得手的进行中的团伙贷款诈骗的其中一次申请，这种情况可以通过定期在历史数据中批量执行社区发现算法得出，并在高聚集社区中利用中心性算法给出核心实体，一并提示给风险专家进行后续评估和风险标注。 1.2.1 基于图谱与专家图模式匹配的欺诈检测示例在开始之前，我们利用 Nebula-UP 来一键部署一套 NebulaGraph 图数据库： 更多请参考 https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 首先，我们把前边建模的图谱加载到 NebulaGraph 里： # 克隆数据集代码仓库 git clone https://github.com/wey-gu/fraud-detection-datagen.git cp -r data_sample_numerical_vertex_id data # 去掉表头 sed -i '1d' data/*.csv docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/data/:/data \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/nebula_graph_importer.yaml 有了这样一个图谱，风控专家可以在可视化探索工具中按需探索实体之间的关系，绘制相应的风险模式： 在这个探索截图里，我们可以明显看到一个群控设备的风险模式，这个模式可以被交给图数据库开发者，抽象成可以被风控应用定期、实时查询的语句： ## 针对一笔交易申请关联查询 MATCH (n) WHERE id(n) == \"200000010265\" OPTIONAL MATCH p_shared_d=(n)-[:used_device]-\u003e(d)\u003c-[:used_device]-(:applicant)-[:with_phone_num]-\u003e(pn:phone_num)\u003c-[e:with_phone_num]-(:applicant) RETURN p_shared_d 我们可以很容易在此模型之上，通过修改返回的关联设备计数，作为意向指标查询的判断 API： ## 群控指标 MATCH (n) WHERE id(n) == \"200000010265\" OPTIONAL MATCH p_shared_d=(n)-[:used_device]-\u003e(d)\u003c-[:used_device]-(:applicant)-[:with_phone_num]-\u003e(pn:phone_num)\u003c-[e:with_phone_num]-(:applicant) RETURN count(e) 如此，我们可以建立一个相对有效的风控系统，利用有限的标注数据和专家资源，去更高效控制团伙欺诈作案风险。 另一个利用标注风险节点的查询是找到相关联节点高风险属性的数量： MATCH p_=(p:applicant)-[*1..2]-(p2:applicant) WHERE id(p)==\"200000014810\" AND p2.applicant.is_risky == \"True\" RETURN p_ LIMIT 100 可以从这个路径查询看到 200000014810 的相连接的申请人中有不少是高风险的（也能看出聚集的 device）。 如此，我们可以定义相连高风险点数量为一个指标： MATCH (p:applicant)-[*1..2]-(p2:applicant) WHERE id(p)==\"200000014810\" AND p2.applicant.is_risky == \"True\" RETURN count(p2) 然而，在现实情况下，我们的大多数标注数据的获取还是过于昂贵，那么有没有什么方法是更有效利用有限的风险标注和图结构，来预测出风险呢？ ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:2","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#图数据库查询识别风险"},{"categories":["Nebula Graph"],"content":" 1.2 图数据库查询识别风险有了一张囊括了人、公司、历史贷款申请记录、电话、线上申请网络设备的图谱，我们可以挖掘一些有意思的信息。 事实上，很多值得被发现、并有效阻止从而止损的骗保行为是具有群体聚集性的。比如欺诈团伙可能是一小批人（比如3到5人）有组织地收集更大规模的身份证信息（比如30张），同时发起多个金融机构大量贷款，然后在放款后选择丢弃这批留下了违约记录的身份证，再进一步选择下一批身份证信息如法炮制。 这种团伙作案的方式因为利用了大量新的身份信息，完全利用历史记录去黑名单规避风险的方式是无效的。不过，借助于关联关系的视角，这些模式是一定程度上可以被及时识别出来的。 这些可以被识别出的规律我把它分成两种： 一种是风控专家可以直接用某种模式来描述的，例如：和已经被标注为高风险的实体有直接或者间接的关联关系（新订单申请人使用了和过往高风险记录相同的网络设备），这种模式对应到图谱中，通过一个图查询就可以实时给出结果。 另一种是隐含在数据的关联关系背后，需要通过图算法挖掘得出的一些风险提示，例如：尽管给定的实体与有限的标注高风险实体没有匹配的关联，但是它在图中形成了聚集性可能提示我们这可能是一个尚未得手的进行中的团伙贷款诈骗的其中一次申请，这种情况可以通过定期在历史数据中批量执行社区发现算法得出，并在高聚集社区中利用中心性算法给出核心实体，一并提示给风险专家进行后续评估和风险标注。 1.2.1 基于图谱与专家图模式匹配的欺诈检测示例在开始之前，我们利用 Nebula-UP 来一键部署一套 NebulaGraph 图数据库： 更多请参考 https://github.com/wey-gu/nebula-up/ curl -fsSL nebula-up.siwei.io/install.sh | bash 首先，我们把前边建模的图谱加载到 NebulaGraph 里： # 克隆数据集代码仓库 git clone https://github.com/wey-gu/fraud-detection-datagen.git cp -r data_sample_numerical_vertex_id data # 去掉表头 sed -i '1d' data/*.csv docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}:/root/ \\ -v ${PWD}/data/:/data \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/nebula_graph_importer.yaml 有了这样一个图谱，风控专家可以在可视化探索工具中按需探索实体之间的关系，绘制相应的风险模式： 在这个探索截图里，我们可以明显看到一个群控设备的风险模式，这个模式可以被交给图数据库开发者，抽象成可以被风控应用定期、实时查询的语句： ## 针对一笔交易申请关联查询 MATCH (n) WHERE id(n) == \"200000010265\" OPTIONAL MATCH p_shared_d=(n)-[:used_device]-\u003e(d)\u003c-[:used_device]-(:applicant)-[:with_phone_num]-\u003e(pn:phone_num)\u003c-[e:with_phone_num]-(:applicant) RETURN p_shared_d 我们可以很容易在此模型之上，通过修改返回的关联设备计数，作为意向指标查询的判断 API： ## 群控指标 MATCH (n) WHERE id(n) == \"200000010265\" OPTIONAL MATCH p_shared_d=(n)-[:used_device]-\u003e(d)\u003c-[:used_device]-(:applicant)-[:with_phone_num]-\u003e(pn:phone_num)\u003c-[e:with_phone_num]-(:applicant) RETURN count(e) 如此，我们可以建立一个相对有效的风控系统，利用有限的标注数据和专家资源，去更高效控制团伙欺诈作案风险。 另一个利用标注风险节点的查询是找到相关联节点高风险属性的数量： MATCH p_=(p:applicant)-[*1..2]-(p2:applicant) WHERE id(p)==\"200000014810\" AND p2.applicant.is_risky == \"True\" RETURN p_ LIMIT 100 可以从这个路径查询看到 200000014810 的相连接的申请人中有不少是高风险的（也能看出聚集的 device）。 如此，我们可以定义相连高风险点数量为一个指标： MATCH (p:applicant)-[*1..2]-(p2:applicant) WHERE id(p)==\"200000014810\" AND p2.applicant.is_risky == \"True\" RETURN count(p2) 然而，在现实情况下，我们的大多数标注数据的获取还是过于昂贵，那么有没有什么方法是更有效利用有限的风险标注和图结构，来预测出风险呢？ ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:2","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#基于图谱与专家图模式匹配的欺诈检测示例"},{"categories":["Nebula Graph"],"content":" 1.3 利用图扩充标注答案是肯定的， Xiaojin Z. 和 Zoubin G. 在论文：Learning from Labeled and Unlabeled Data with Label Propagation （CMU-CALD-02-107）中，利用标签传播（Label Propagation）算法来把有限的标注信息在图上通过关联关系传播到更多实体中。 这样，在我们建立的图谱中，我们可以很容易地借助有限的高风险标注，去“传播”产生更多的标注信息。这些扩展出来的标注信息一方面可以在实时的图查询中给出更多的结果，另一方面，它还能作为风控专家重要的输入信息，帮助推进反欺诈调查行动的开展。 一般来说，我们可以通过定期离线地全图扫描数据，通过图算法扩充、更新标注，再将有效的更新标注写回到图谱之中。 注，类似的方法还有 SIGNDiffusion，感兴趣的同学可以去了解一下。 1.3.1 图算法扩充欺诈风险标注的示例下面，我给出一个可以跑通的案例： 这个例子中，我用到了 Yelp 这个欺诈识别的经典数据，这份数据不只会用在这个例子中，后边 GNN 方法中的案例我也会用到它，所以大家可以耐心把数据导入 NebulaGraph。 导入数据到图库 生成导入的方法在这里，https://github.com/wey-gu/nebulagraph-yelp-frauddetection cd ~ git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection cd nebulagraph-yelp-frauddetection python3 -m pip install -r requirements.txt python3 data_download.py # 导入图库 docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 结束之后，我们可以看一下图上的统计： ~/.nebula-up/console.sh -e \"USE yelp; SHOW STATS\" 然后，我们可以看到： (root@nebula) [(none)]\u003e USE yelp; SHOW STATS +---------+---------------------------------------+---------+ | Type | Name | Count | +---------+---------------------------------------+---------+ | \"Tag\" | \"review\" | 45954 | | \"Edge\" | \"shares_restaurant_in_one_month_with\" | 1147232 | | \"Edge\" | \"shares_restaurant_rating_with\" | 6805486 | | \"Edge\" | \"shares_user_with\" | 98630 | | \"Space\" | \"vertices\" | 45954 | | \"Space\" | \"edges\" | 8051348 | +---------+---------------------------------------+---------+ Got 6 rows (time spent 1911/4488 us) 目前，市面上的 LPA 标签传播算法都是用来做社区检测的，很少有实现是用来做标签拓展的（只有 SK-Learn 中有这个实现），这里，我们参考 Thibaud M 给出来的实现。 原始的讨论参考：https://datascience.stackexchange.com/a/55720/138720 为了让这个算法跑的快一点，会从 NebulaGraph 里取一个点的子图，在这个小的子图上做标注的扩充： 首先，我们启动一个 Jupyter 的 Playground， 参考 https://github.com/wey-gu/nebula-dgl 中的 Playground 过程： git clone https://github.com/wey-gu/nebula-dgl.git cd nebula-dgl # 运行 Jupyter Notebook docker run -it --name dgl -p 8888:8888 --network nebula-net \\ -v \"$PWD\":/home/jovyan/work jupyter/datascience-notebook \\ start-notebook.sh --NotebookApp.token='nebulagraph' 访问：http://localhost:8888/lab/tree/work?token=nebulagraph 安装依赖（这些依赖在后边的 GNN 例子中也会被用到） !python3 -m pip install git+https://github.com/vesoft-inc/nebula-python.git@8c328c534413b04ccecfd42e64ce6491e09c6ca8 !python3 -m pip install . 然后，我们从图中读取一个子图，从 2048 这个点开始探索两步内的所有边。 import torch import json from torch import tensor from dgl import DGLHeteroGraph, heterograph from nebula3.gclient.net import ConnectionPool from nebula3.Config import Config config = Config() config.max_connection_pool_size = 2 connection_pool = ConnectionPool() connection_pool.init([('graphd', 9669)], config) vertex_id = 2048 client = connection_pool.get_session('root', 'nebula') r = client.execute_json( \"USE yelp;\" f\"GET SUBGRAPH WITH PROP 2 STEPS FROM {vertex_id} YIELD VERTICES AS nodes, EDGES AS relationships;\") r = json.loads(r) data = r.get('results', [{}])[0].get('data') columns = r.get('results', [{}])[0].get('columns') # create node and nodedata node_id_map = {} # key: vertex id in NebulaGraph, value: node id in dgl_graph node_idx = 0 features = [[] for _ in range(32)] + [[]] for i in range(len(data)): for index, node in enumerate(data[i]['meta'][0]): nodeid = data[i]['meta'][0][index]['id'] if nodeid not in node_id_map: node_id_map[nodeid] = node_idx node_idx += 1 for f in range(32): features[f].append(data[i]['row'][0][index][f\"review.f{f}\"]) features[32].append(data[i]['row'][0][index]['review.is_fraud']) rur_start, rur_end, rsr_start, rsr_end, rtr_start, rtr_end = [], [], [], [], [], [] for i in range(len(data)): for edge in data[i]['meta'][1]: edge = edge['id'] if edge['name'] == 'shares_user_with': rur_start.append(node_id_map[edge['src']]) rur_end.append(node_id_map[edge['dst']]) elif edge['name'] == 'shares_restaurant_rating_with': rsr_start.append(node_id_map[edge['src']]) rsr_end.append(node_id_map[edge['dst']]) elif edge['name'] == 'shar","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:3","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#利用图扩充标注"},{"categories":["Nebula Graph"],"content":" 1.3 利用图扩充标注答案是肯定的， Xiaojin Z. 和 Zoubin G. 在论文：Learning from Labeled and Unlabeled Data with Label Propagation （CMU-CALD-02-107）中，利用标签传播（Label Propagation）算法来把有限的标注信息在图上通过关联关系传播到更多实体中。 这样，在我们建立的图谱中，我们可以很容易地借助有限的高风险标注，去“传播”产生更多的标注信息。这些扩展出来的标注信息一方面可以在实时的图查询中给出更多的结果，另一方面，它还能作为风控专家重要的输入信息，帮助推进反欺诈调查行动的开展。 一般来说，我们可以通过定期离线地全图扫描数据，通过图算法扩充、更新标注，再将有效的更新标注写回到图谱之中。 注，类似的方法还有 SIGNDiffusion，感兴趣的同学可以去了解一下。 1.3.1 图算法扩充欺诈风险标注的示例下面，我给出一个可以跑通的案例： 这个例子中，我用到了 Yelp 这个欺诈识别的经典数据，这份数据不只会用在这个例子中，后边 GNN 方法中的案例我也会用到它，所以大家可以耐心把数据导入 NebulaGraph。 导入数据到图库 生成导入的方法在这里，https://github.com/wey-gu/nebulagraph-yelp-frauddetection cd ~ git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection cd nebulagraph-yelp-frauddetection python3 -m pip install -r requirements.txt python3 data_download.py # 导入图库 docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 结束之后，我们可以看一下图上的统计： ~/.nebula-up/console.sh -e \"USE yelp; SHOW STATS\" 然后，我们可以看到： (root@nebula) [(none)]\u003e USE yelp; SHOW STATS +---------+---------------------------------------+---------+ | Type | Name | Count | +---------+---------------------------------------+---------+ | \"Tag\" | \"review\" | 45954 | | \"Edge\" | \"shares_restaurant_in_one_month_with\" | 1147232 | | \"Edge\" | \"shares_restaurant_rating_with\" | 6805486 | | \"Edge\" | \"shares_user_with\" | 98630 | | \"Space\" | \"vertices\" | 45954 | | \"Space\" | \"edges\" | 8051348 | +---------+---------------------------------------+---------+ Got 6 rows (time spent 1911/4488 us) 目前，市面上的 LPA 标签传播算法都是用来做社区检测的，很少有实现是用来做标签拓展的（只有 SK-Learn 中有这个实现），这里，我们参考 Thibaud M 给出来的实现。 原始的讨论参考：https://datascience.stackexchange.com/a/55720/138720 为了让这个算法跑的快一点，会从 NebulaGraph 里取一个点的子图，在这个小的子图上做标注的扩充： 首先，我们启动一个 Jupyter 的 Playground， 参考 https://github.com/wey-gu/nebula-dgl 中的 Playground 过程： git clone https://github.com/wey-gu/nebula-dgl.git cd nebula-dgl # 运行 Jupyter Notebook docker run -it --name dgl -p 8888:8888 --network nebula-net \\ -v \"$PWD\":/home/jovyan/work jupyter/datascience-notebook \\ start-notebook.sh --NotebookApp.token='nebulagraph' 访问：http://localhost:8888/lab/tree/work?token=nebulagraph 安装依赖（这些依赖在后边的 GNN 例子中也会被用到） !python3 -m pip install git+https://github.com/vesoft-inc/nebula-python.git@8c328c534413b04ccecfd42e64ce6491e09c6ca8 !python3 -m pip install . 然后，我们从图中读取一个子图，从 2048 这个点开始探索两步内的所有边。 import torch import json from torch import tensor from dgl import DGLHeteroGraph, heterograph from nebula3.gclient.net import ConnectionPool from nebula3.Config import Config config = Config() config.max_connection_pool_size = 2 connection_pool = ConnectionPool() connection_pool.init([('graphd', 9669)], config) vertex_id = 2048 client = connection_pool.get_session('root', 'nebula') r = client.execute_json( \"USE yelp;\" f\"GET SUBGRAPH WITH PROP 2 STEPS FROM {vertex_id} YIELD VERTICES AS nodes, EDGES AS relationships;\") r = json.loads(r) data = r.get('results', [{}])[0].get('data') columns = r.get('results', [{}])[0].get('columns') # create node and nodedata node_id_map = {} # key: vertex id in NebulaGraph, value: node id in dgl_graph node_idx = 0 features = [[] for _ in range(32)] + [[]] for i in range(len(data)): for index, node in enumerate(data[i]['meta'][0]): nodeid = data[i]['meta'][0][index]['id'] if nodeid not in node_id_map: node_id_map[nodeid] = node_idx node_idx += 1 for f in range(32): features[f].append(data[i]['row'][0][index][f\"review.f{f}\"]) features[32].append(data[i]['row'][0][index]['review.is_fraud']) rur_start, rur_end, rsr_start, rsr_end, rtr_start, rtr_end = [], [], [], [], [], [] for i in range(len(data)): for edge in data[i]['meta'][1]: edge = edge['id'] if edge['name'] == 'shares_user_with': rur_start.append(node_id_map[edge['src']]) rur_end.append(node_id_map[edge['dst']]) elif edge['name'] == 'shares_restaurant_rating_with': rsr_start.append(node_id_map[edge['src']]) rsr_end.append(node_id_map[edge['dst']]) elif edge['name'] == 'shar","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:3","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#图算法扩充欺诈风险标注的示例"},{"categories":["Nebula Graph"],"content":" 1.4 带有图特征的机器学习在风控领域开始利用图的思想和能力之前，已经有很多利用机器学习的分类算法基于历史数据预测高风险行为的方法了，这些方法把记录中领域专家认为有关的信息（例如：年龄、学历、收入）作为特征，历史标注信息作为标签去训练风险预测模型。 那么读到的这里，我们是否会想到在这些方法的基础之上，如果把基于图结构的属性也考虑进来，作为特征去训练的模型可能更有效呢？答案也是肯定的，已经有很多论文和工程实践揭示这样的模型比未考虑图特征的算法更加有效：这些被尝试有效的图结构特征可能是实体的 PageRank 值、Degree 值或者是某一个社区发现算法得出的社区 id。 在生产上，我们可以定期从图谱中获得实时的全图信息，在图计算平台中分析运算获得所需特征，经过预定的数据管道，导入机器学习模型中周期获得新的风险提示，并将部分结果写回图谱方便其他系统和专家抽取、参考。 1.4.1 带有图特征的机器学习欺诈检测示例这里，机器学习的方法我就不演示了，就是常见的分类方法，在此之上，我们可以在数据中通过图算法获得一些新的属性，这些属性再处理一下作为新的特征。我只演示一个社区发现的方法，我们可以对全图跑一个 Louvain，得出不同节点的社区归属，然后把社区的值当做一个分类处理成为数值的特征。 这个例子里我们还用 https://github.com/wey-gu/fraud-detection-datagen 这个数据，在此基础上，这个例子我用到了 Nebula-Algorithm 这个项目，它是一个 Spark 应用，可以在 NebulaGraph 图库上运行很多常用的图算法。 首先，我们部署 Spark 和 Nebula Algorithm，还是利用 Nebula-UP，一键部署： curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 集群起来之后，因为需要的配置文件我已经放在了 Nebula-UP 内部，我们只需要一行就可以运行算法啦！ cd ~/.nebula-up/nebula-up/spark \u0026\u0026 ls -l docker exec -it sparkmaster /spark/bin/spark-submit \\ --master \"local\" --conf spark.rpc.askTimeout=6000s \\ --class com.vesoft.nebula.algorithm.Main \\ --driver-memory 4g /root/download/nebula-algo.jar \\ -p /root/louvain.conf 而最终的结果就在 sparkmaster 容器内的 /output 里： # docker exec -it sparkmaster bash ls -l /output 之后，我们可以对这个 Louvain 的图特征做一些处理，并开始传统的模型训练了。 ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:4","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#带有图特征的机器学习"},{"categories":["Nebula Graph"],"content":" 1.4 带有图特征的机器学习在风控领域开始利用图的思想和能力之前，已经有很多利用机器学习的分类算法基于历史数据预测高风险行为的方法了，这些方法把记录中领域专家认为有关的信息（例如：年龄、学历、收入）作为特征，历史标注信息作为标签去训练风险预测模型。 那么读到的这里，我们是否会想到在这些方法的基础之上，如果把基于图结构的属性也考虑进来，作为特征去训练的模型可能更有效呢？答案也是肯定的，已经有很多论文和工程实践揭示这样的模型比未考虑图特征的算法更加有效：这些被尝试有效的图结构特征可能是实体的 PageRank 值、Degree 值或者是某一个社区发现算法得出的社区 id。 在生产上，我们可以定期从图谱中获得实时的全图信息，在图计算平台中分析运算获得所需特征，经过预定的数据管道，导入机器学习模型中周期获得新的风险提示，并将部分结果写回图谱方便其他系统和专家抽取、参考。 1.4.1 带有图特征的机器学习欺诈检测示例这里，机器学习的方法我就不演示了，就是常见的分类方法，在此之上，我们可以在数据中通过图算法获得一些新的属性，这些属性再处理一下作为新的特征。我只演示一个社区发现的方法，我们可以对全图跑一个 Louvain，得出不同节点的社区归属，然后把社区的值当做一个分类处理成为数值的特征。 这个例子里我们还用 https://github.com/wey-gu/fraud-detection-datagen 这个数据，在此基础上，这个例子我用到了 Nebula-Algorithm 这个项目，它是一个 Spark 应用，可以在 NebulaGraph 图库上运行很多常用的图算法。 首先，我们部署 Spark 和 Nebula Algorithm，还是利用 Nebula-UP，一键部署： curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 集群起来之后，因为需要的配置文件我已经放在了 Nebula-UP 内部，我们只需要一行就可以运行算法啦！ cd ~/.nebula-up/nebula-up/spark \u0026\u0026 ls -l docker exec -it sparkmaster /spark/bin/spark-submit \\ --master \"local\" --conf spark.rpc.askTimeout=6000s \\ --class com.vesoft.nebula.algorithm.Main \\ --driver-memory 4g /root/download/nebula-algo.jar \\ -p /root/louvain.conf 而最终的结果就在 sparkmaster 容器内的 /output 里： # docker exec -it sparkmaster bash ls -l /output 之后，我们可以对这个 Louvain 的图特征做一些处理，并开始传统的模型训练了。 ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:4","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#带有图特征的机器学习欺诈检测示例"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#图神经网络的方法"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#基于图表示的图神经网络欺诈检测系统示例"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#数据集"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#数据处理"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#模型训练"},{"categories":["Nebula Graph"],"content":" 1.5 图神经网络的方法然而，这些图特征的方法的问题在于： 图特征并不能把关联关系，数据的局部性充分反映到我们的模型、方法里； 图的特征工程是很昂贵、繁琐的。 在最近几年的成果中，基于 GNN 的方法通过将图结构与属性信息进行嵌入表示，使得我们能在不进行图特征抽取、特征工程、专家与工程方法的数据标注的情况下，得到相比于基于传统图特征的机器学习更好的效果。有意思的是，现在正是这些方法快速被发现、演进的时期，基于图的深度学习是之前几年最热门的机器学习研究方向之一。 同时，图深度学习的一些方法可以做到 Inductive Learning——模型可以在新的点、边上进行推理，这样，配合图数据库上线上的子图查询能力，在线实时的风险预测也变得很简单可行了。 1.5.1 基于图表示的图神经网络欺诈检测系统示例利用 GNN 的方法中，图数据库并不是必须的，数据的存储可以在其他几种常见的介质之中，但是图库能够最大化助益模型训练、模型更新、线上结果的更新。当我们把图数据库作为数据的单一数据来源（single source of truth）的时候，所有的基于线上、离线、图谱的方法可以很容易被集成起来，从而组合所有方法的优势与结果，做出更有效的欺诈检测复合系统。 在这个示例中我们一样分为：数据处理、模型训练、构建检测系统这几部分。 注，这里，我们使用的的工具为 Deep Graph library（DGL），NebulaGraph 图数据库和他们之间的桥梁，Nebula-DGL。 DGL: https://www.dgl.ai/ Nebula-DGL: https://github.com/wey-gu/nebula-dgl 我也是这个库的作者 😁 1.5.1.1 数据集本例中，我们使用的数据集是 Yelp-Fraud，他直接来自于论文 Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters。 这个图中有一种点，三种关系： 顶点：来自 Yelp 中的餐厅、酒店的评价，有两类属性： 每一个评价中有被标注了的是否是虚假、欺诈评价的标签 32 个已经被处理过的数字型属性 边：三类评价之间的关联关系 R-U-R：两个评价由同一个用户发出 shares_user_with R-S-R：两个评价是同餐厅同评分（评分可以是1到5） shares_restaurant_rating_with R-T-R：两个评价是同餐厅同提交月份 shares_restaurant_in_one_month_with 在开始之前，我们假设这个图已经在我们的 NebulaGraph 里边了。 注，我已经帮大家提前做好了将这张图导入 NebulaGraph 的工作，长话短说就是： # 部署 NebulaGraph curl -fsSL nebula-up.siwei.io/install.sh | bash # 拉取这个数据的 Repo git clone https://github.com/wey-gu/nebulagraph-yelp-frauddetection \u0026\u0026 cd nebulagraph-yelp-frauddetection # 安装依赖，执行数据下载生成 python3 -m pip install -r requirements.txt python3 data_download.py # 导入到 NebulaGraph docker run --rm -ti \\ --network=nebula-net \\ -v ${PWD}/yelp_nebulagraph_importer.yaml:/root/importer.yaml \\ -v ${PWD}/data:/root \\ vesoft/nebula-importer:v3.1.0 \\ --config /root/importer.yaml 详情参考：https://github.com/wey-gu/nebulagraph-yelp-frauddetection 1.5.1.2 数据处理这部分的任务是将图谱中和风险相关子图的拓扑结构表示和其中有关的特征（属性）进行工程处理，序列化成为 DGL 的图对象。 DGL 本身支持从点、边列表（edgelist）形式 CSV 文件，或者从 NetworkX 和 SciPy 的序列化稀疏的邻接矩阵（adjacency matrix）的数据来构造它的图对象，我们可以把原始的图数据或者图库中的数据全量导出为这些形式，不过在真实的例子中图库中的数据是实时变化的，能够直接在 NebulaGraph 中的子图上做 GNN 训练一般来说是更理想。得益于 Nebula-DGL 这个库，做这件事儿是很自然的。 注，DGL 外部数据员导入文档：https://docs.dgl.ai/guide/graph-external.html 现在我们开始这个数据的导入，在这之前，我先介绍一下 Nebula-DGL。 Nebula-DGL 可以根据给定的映射和转换规则（YAML 格式），将 NebulaGraph 中的顶点、边，和它们的属性按照规则处理成为点、边、和其中的标注（Label）与特征（Feature），从而构造为 DGL 的图对象。这其中，值得一提的是属性到特征的转换。我们知道，特征可能是某一个属性的值、一个或者多个属性的值做一定的数学变换、亦或是字符型的属性按照枚举规则输出为数字。相应的，Nebula-DGL 在规则中，我们都可以针对这几种情况利用 filter 进行表达： 特征直接选取属性的值： 这个例子里，NebulaGraph 图中 follow 这个边将被抽取，边上的属性 degree 的值将直接被作为名为 degree 的特征。 edge_types: - name: follow start_vertex_tag: player end_vertex_tag: player features: - name: degree properties: - name: degree type: int nullable: False filter: type: value 特征从属性中经过数学变换 这个例子中，我们把 serve 边之中的两个属性进行 (end_year - start_year) / 30 的处理，变为 service_time 这样的一个特征。 edge_types: - name: serve start_vertex_tag: player end_vertex_tag: team features: - name: service_time properties: - name: start_year type: int nullable: False - name: end_year type: int nullable: False # The variable was mapped by order of properties filter: type: function function: \"lambda start_year, end_year: (end_year - start_year) / 30\" 枚举属性值为数字特征 这个例子中，我们把 team 顶点中的 name 属性进行枚举，根据这个对于是西岸还是东岸： vertex_tags: - name: team features: - name: coast properties: - name: name type: str nullable: False filter: # 0 stand for the east coast, 1 stand for the west coast type: enumeration enumeration: Celtics: 0 Nets: 0 Nuggets: 1 Timberwolves: 1 Thunder: 1 # ... not showing all teams here 可以看到这个转换规则非常简单直接，大家也可以参考 Nebula-DGL 的完整例子了解全部细节 https://github.com/wey-gu/nebula-dgl/tree/main/example。而有上边数据处理规则的了解之后，我们可以开始处理这个 Yelp 图数据了。 首先，定义如下规则，这里，我们把顶点 review 和三种边都对应过来了，同时，review 上的属性也按照原本的值对应了过来： nebulagraph_yelp_dgl_mapper.yaml --- # If vertex id is string-typed, remap_vertex_id must be true. remap_vertex_id: True space: yelp # str or int vertex_id_type: int vertex_tags: - name: review label: name: is_fraud properties: - name: is_fraud type: int nullable: False filter: type: value features: - name: f0 properties: - name: f0 type: float nullable: False filter: type: value - na","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:5","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#推理接口"},{"categories":["Nebula Graph"],"content":" 1.6 总结总结起来，欺诈检测的方法有： 在一个交易历史、风控的图谱上，通过图模式查询直接获得风险提示 定期利用图算法扩充风险标注，写回图库 定期计算图谱中的图特征，和其他特征一起用传统机器学习方法离线预测风险 将图谱中的属性处理成为点、边特征，用图神经网络方法离线预测风险，部分可以 Inductive Learning 的方法结合图库可以实现在线风险预测 Feature Image credit goes to https://unsplash.com/photos/BW0vK-FA3eg ","date":"2022-08-01","objectID":"/fraud-detection-with-nebulagraph/:1:6","series":null,"tags":["Nebula Graph","Fraud Detection","GNN","欺诈检测","金融风控","DGL","PyTorch"],"title":"基于 NebulaGraph 图数据库的欺诈检测方法与代码示例","uri":"/fraud-detection-with-nebulagraph/#总结"},{"categories":["Nebula Graph"],"content":"Nebula Graph 生态中有哪些 Spark 项目？ 本文为大家介绍 Spark-connector（包括 PySpark）， Nebula Algorithm 和 Nebula Exchange。","date":"2022-06-06","objectID":"/spark-on-nebula-graph/","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/"},{"categories":["Nebula Graph"],"content":" Nebula Graph 生态中有哪些 Spark 项目？ 本文为大家介绍 Spark-connector（包括 PySpark）， Nebula Algorithm 和 Nebula Exchange。 最近我试着搭建了方便大家一键试玩的 Nebula Graph 中的 Spark 相关的项目，今天就把它们整理成文分享给大家。而且，我趟出来了 PySpark 下的 Nebula Spark Connector 的使用方式，后边也会一并贡献到文档里。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:0:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#"},{"categories":["Nebula Graph"],"content":" 1 Nebula Graph 的三个 Spark 子项目我曾经围绕 Nebula Graph 的所有数据导入方法画过一个草图，其中已经包含了 Spark Connector，Nebula Exchange 的简单介绍。在这篇文章中我将它们和另外的 Nebula Algorithm 进行稍微深入的探讨。 TL;DR Nebula Spark Connector 是一个 Spark Lib，它能让 Spark 应用程序能够以 dataframe 的形式从 Nebula Graph 中读取和写入图数据。 Nebula Exchange 建立在 Nebula Spark Connector 之上，作为一个 Spark Lib 同时可以直接被 Spark 提交 JAR 包执行的应用程序，它的设计目标是和 Nebula Graph 交换不同的数据源（对于开源版本，它是单向的：写入，而对于企业版本，它是双向的）。Nebula Exchange 支持的很多不同类型的数据源如：MySQL、Neo4j、PostgreSQL、ClickHouse、Hive 等。除了直接写入 Nebula Graph，它还可以选择生成 SST 文件，并将其注入 Nebula Graph，以便使用 Nebula Graph 集群之外算力帮助排序底层。 Nebula Algorithm，建立在 Nebula Spark Connector 和 GraphX 之上，也是一个Spark Lib 和 Spark 上的应用程序，它用来在 Nebula Graph 的图上运行常用的图算法（pagerank，LPA等）。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:1:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-graph-的三个-spark-子项目"},{"categories":["Nebula Graph"],"content":" 2 Nebula Spark Connector 代码：https://github.com/vesoft-inc/nebula-spark-connector 文档：https://docs.nebula-graph.io/3.1.0/nebula-spark-connector/ JAR 包：https://repo1.maven.org/maven2/com/vesoft/nebula-spark-connector/ 代码例子：example ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-spark-connector"},{"categories":["Nebula Graph"],"content":" 2.1 Nebula Graph Spark Reader为了从 Nebula Graph 中读取数据，比如读 vertex，Nebula Spark Connector 将扫描所有带有给定 TAG 的 Nebula StorageD，比如这样表示扫描 player 这个 TAG ：withLabel(\"player\")，我们还可以指定 vertex 的属性：withReturnCols(List(\"name\", \"age\"))。 指定好所有的读 TAG 相关的配置之后，调用 spark.read.nebula.loadVerticesToDF 返回得到的就是扫描 Nebula Graph 之后转换为 Dataframe 的图数据，像这样： def readVertex(spark: SparkSession): Unit = { LOG.info(\"start to read nebula vertices\") val config = NebulaConnectionConfig .builder() .withMetaAddress(\"metad0:9559,metad1:9559,metad2:9559\") .withConenctionRetry(2) .build() val nebulaReadVertexConfig: ReadNebulaConfig = ReadNebulaConfig .builder() .withSpace(\"basketballplayer\") .withLabel(\"player\") .withNoColumn(false) .withReturnCols(List(\"name\", \"age\")) .withLimit(10) .withPartitionNum(10) .build() val vertex = spark.read.nebula(config, nebulaReadVertexConfig).loadVerticesToDF() vertex.printSchema() vertex.show(20) println(\"vertex count: \" + vertex.count()) } 写入的例子我这里不列出，不过，前边给出的代码示例的链接里是有更详细的例子，这里值得一提的是，Spark Connector 读数据为了满足图分析、图计算的大量数据场景，和大部分其他客户端非常不同，它直接绕过了 GraphD，通过扫描 MetaD 和 StorageD 获得数据，但是写入的情况则是通过 GraphD 发起 nGQL DML 语句写入的。 接下来我们来做一个上手练习吧。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-graph-spark-reader"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#上手-nebula-spark-connector"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#拉起环境"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#进入-spark-环境"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#跑-spark-connector-的例子"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#选项-1推荐通过-pyspark"},{"categories":["Nebula Graph"],"content":" 2.2 上手 Nebula Spark Connector先决条件：假设下面的程序是在一台有互联网连接的 Linux 机器上运行的，最好是预装了 Docker 和 Docker-Compose。 2.2.1 拉起环境首先，让我们用 Nebula-Up 部署基于容器的 Nebula Graph Core v3、Nebula Studio、Nebula Console 和 Spark、Hadoop 环境，如果还没安装好它也会尝试为我们安装 Docker 和 Docker-Compose。 # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark 你知道吗 Nebula-UP 可以一键装更多东西，如果你的环境配置大一点（比如 8 GB RAM）curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash 可以装更多东西，但是请注意 Nebula-UP 不是为生产环境准备的。 上述边脚本执行后，让我们用 Nebula-Console（Nebula Graph 的命令行客户端）来连接它。 # Connect to nebula with console ~/.nebula-up/console.sh # Execute any queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" 加载一份数据进去，并执行一个图查询： # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # 等一分钟左右 # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 2.2.2 进入 Spark 环境执行下面这一行，我们就可以进入到 Spark 环境： docker exec -it sparkmaster bash 如果我们想执行编译，可以在里边安装 mvn： docker exec -it sparkmaster bash # in the container shell export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 2.2.3 跑 Spark Connector 的例子 2.2.3.1 选项 1（推荐）：通过 PySpark 进入 PySpark Shell ~/.nebula-up/nebula-pyspark.sh 调用 Nebula Spark Reader # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit of 2 df.show(n=2) 返回结果例子 ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 2.2.3.2 选项 2：编译、提交示例 JAR 包 先克隆 Spark Connector 和它示例代码的代码仓库，然后编译： 注意，我们使用了 master 分支，因为当下 master 分支是兼容 3.x 的，一定要保证 spark connector 和数据库内核版本是匹配的，版本对应关系参考代码仓库的 README.md 。 cd ~/.nebula-up/nebula-up/spark git clone https://github.com/vesoft-inc/nebula-spark-connector.git docker exec -it sparkmaster bash cd /root/nebula-spark-connector 替换示例项目的代码 echo \u003e example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala vi example/src/main/scala/com/vesoft/nebula/examples/connector/NebulaSparkReaderExample.scala 把如下的代码粘贴进去，这里边我们对前边加载的图： basketballplayer 上做了顶点和边的读操作：分别调用 readVertex 和 readEdges。 package com.vesoft.nebula.examples.connector import com.facebook.thrift.protocol.TCompactProtocol import com.vesoft.nebula.connector.connector.NebulaDataFrameReader import com.vesoft.nebula.connector.{NebulaConnectionConfig, ReadNebulaConfig} import org.apache.spark.SparkConf import org.apache.spark.sql.SparkSession import org.slf4j.LoggerFactory object NebulaSparkReaderExample { private val LOG = LoggerFactory.getLogger(this.getClass) def main(args: Array[String]): Unit = { val sparkConf = new SparkConf sparkConf .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") .registerKryoClasses(Array[Class[_]](classOf[TCompactProt","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:2:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#选项-2编译提交示例-jar-包"},{"categories":["Nebula Graph"],"content":" 3 Nebula Exchange 代码：https://github.com/vesoft-inc/nebula-exchange/ 文档：https://docs.nebula-graph.com.cn/3.1.0/nebula-exchange/about-exchange/ex-ug-what-is-exchange/ JAR 包：https://github.com/vesoft-inc/nebula-exchange/releases 配置例子： exchange-common/src/test/resources/application.conf Nebula Exchange 是一个 Spark Lib，也是一个可以直接提交执行的 Spark 应用，它被用来从多个数据源读取数据写入 Nebula Graph 或者输出 Nebula Graph SST 文件。 通过 spark-submit 的方式使用 Nebula Exchange 的方法很直接： 首先创建配置文件，让 Exchange 知道应该如何获取和写入数据 然后用指定的配置文件调用 Exchange 包 现在，让我们用上一章中创建的相同环境做一个实际测试。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:3:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-exchange"},{"categories":["Nebula Graph"],"content":" 3.1 一键试玩 Exchange 3.1.1 先跑起来看看吧 请参考前边拉起环境这一章节，先一键装好环境。 一键执行： ~/.nebula-up/nebula-exchange-example.sh 恭喜你，已经第一次执行成功一个 Exchange 的数据导入任务啦！ 3.1.2 再看看一些细节这个例子里，我们实际上是用 Exchange 从 CSV 文件这一其中支持的数据源中读取数据写入 Nebula Graph 集群的。这个 CSV 文件中第一列是顶点 ID，第二和第三列是 “姓名 “和 “年龄 “的属性： player800,\"Foo Bar\",23 player801,\"Another Name\",21 咱们可以进到 Spark 环境里看看 docker exec -it sparkmaster bash cd /root 可以看到我们提交 Exchange 任务时候指定的配置文件 exchange.conf 它是一个 HOCON 格式的文件： 在 .nebula 中描述了 Nebula Graph 集群的相关信息 在 .tags 中描述了如何将必填字段对应到我们的数据源（这里是 CSV 文件）等有关 Vertecies 的信息。 { # Spark relation config spark: { app: { name: Nebula Exchange } master:local driver: { cores: 1 maxResultSize: 1G } executor: { memory: 1G } cores:{ max: 16 } } # Nebula Graph relation config nebula: { address:{ graph:[\"graphd:9669\"] meta:[\"metad0:9559\", \"metad1:9559\", \"metad2:9559\"] } user: root pswd: nebula space: basketballplayer # parameters for SST import, not required path:{ local:\"/tmp\" remote:\"/sst\" hdfs.namenode: \"hdfs://localhost:9000\" } # nebula client connection parameters connection { # socket connect \u0026 execute timeout, unit: millisecond timeout: 30000 } error: { # max number of failures, if the number of failures is bigger than max, then exit the application. max: 32 # failed import job will be recorded in output path output: /tmp/errors } # use google's RateLimiter to limit the requests send to NebulaGraph rate: { # the stable throughput of RateLimiter limit: 1024 # Acquires a permit from RateLimiter, unit: MILLISECONDS # if it can't be obtained within the specified timeout, then give up the request. timeout: 1000 } } # Processing tags # There are tag config examples for different dataSources. tags: [ # HDFS csv # Import mode is client, just change type.sink to sst if you want to use client import mode. { name: player type: { source: csv sink: client } path: \"file:///root/player.csv\" # if your csv file has no header, then use _c0,_c1,_c2,.. to indicate fields fields: [_c1, _c2] nebula.fields: [name, age] vertex: { field:_c0 } separator: \",\" header: false batch: 256 partition: 32 } ] } 我们应该能看到那个 CSV 数据源和这个配置文件都在同一个目录下了： bash-5.0# ls -l total 24 drwxrwxr-x 2 1000 1000 4096 Jun 1 04:26 download -rw-rw-r-- 1 1000 1000 1908 Jun 1 04:23 exchange.conf -rw-rw-r-- 1 1000 1000 2593 Jun 1 04:23 hadoop.env drwxrwxr-x 7 1000 1000 4096 Jun 6 03:27 nebula-spark-connector -rw-rw-r-- 1 1000 1000 51 Jun 1 04:23 player.csv 然后，实际上我们可以手动再次提交一下这个 Exchange 任务 /spark/bin/spark-submit --master local \\ --class com.vesoft.nebula.exchange.Exchange download/nebula-exchange.jar \\ -c exchange.conf 部分返回结果 22/06/06 03:56:26 INFO Exchange$: Processing Tag player 22/06/06 03:56:26 INFO Exchange$: field keys: _c1, _c2 22/06/06 03:56:26 INFO Exchange$: nebula keys: name, age 22/06/06 03:56:26 INFO Exchange$: Loading CSV files from file:///root/player.csv ... 22/06/06 03:56:41 INFO Exchange$: import for tag player cost time: 3.35 s 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchSuccess.player: 2 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchFailure.player: 0 ... 更多的数据源，请参考文档和配置的例子。 关于 Exchange 输出 SST 文件的实践，你可以参考文档和我的旧文 Nebula Exchange SST 2.x实践指南。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:3:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#一键试玩-exchange"},{"categories":["Nebula Graph"],"content":" 3.1 一键试玩 Exchange 3.1.1 先跑起来看看吧 请参考前边拉起环境这一章节，先一键装好环境。 一键执行： ~/.nebula-up/nebula-exchange-example.sh 恭喜你，已经第一次执行成功一个 Exchange 的数据导入任务啦！ 3.1.2 再看看一些细节这个例子里，我们实际上是用 Exchange 从 CSV 文件这一其中支持的数据源中读取数据写入 Nebula Graph 集群的。这个 CSV 文件中第一列是顶点 ID，第二和第三列是 “姓名 “和 “年龄 “的属性： player800,\"Foo Bar\",23 player801,\"Another Name\",21 咱们可以进到 Spark 环境里看看 docker exec -it sparkmaster bash cd /root 可以看到我们提交 Exchange 任务时候指定的配置文件 exchange.conf 它是一个 HOCON 格式的文件： 在 .nebula 中描述了 Nebula Graph 集群的相关信息 在 .tags 中描述了如何将必填字段对应到我们的数据源（这里是 CSV 文件）等有关 Vertecies 的信息。 { # Spark relation config spark: { app: { name: Nebula Exchange } master:local driver: { cores: 1 maxResultSize: 1G } executor: { memory: 1G } cores:{ max: 16 } } # Nebula Graph relation config nebula: { address:{ graph:[\"graphd:9669\"] meta:[\"metad0:9559\", \"metad1:9559\", \"metad2:9559\"] } user: root pswd: nebula space: basketballplayer # parameters for SST import, not required path:{ local:\"/tmp\" remote:\"/sst\" hdfs.namenode: \"hdfs://localhost:9000\" } # nebula client connection parameters connection { # socket connect \u0026 execute timeout, unit: millisecond timeout: 30000 } error: { # max number of failures, if the number of failures is bigger than max, then exit the application. max: 32 # failed import job will be recorded in output path output: /tmp/errors } # use google's RateLimiter to limit the requests send to NebulaGraph rate: { # the stable throughput of RateLimiter limit: 1024 # Acquires a permit from RateLimiter, unit: MILLISECONDS # if it can't be obtained within the specified timeout, then give up the request. timeout: 1000 } } # Processing tags # There are tag config examples for different dataSources. tags: [ # HDFS csv # Import mode is client, just change type.sink to sst if you want to use client import mode. { name: player type: { source: csv sink: client } path: \"file:///root/player.csv\" # if your csv file has no header, then use _c0,_c1,_c2,.. to indicate fields fields: [_c1, _c2] nebula.fields: [name, age] vertex: { field:_c0 } separator: \",\" header: false batch: 256 partition: 32 } ] } 我们应该能看到那个 CSV 数据源和这个配置文件都在同一个目录下了： bash-5.0# ls -l total 24 drwxrwxr-x 2 1000 1000 4096 Jun 1 04:26 download -rw-rw-r-- 1 1000 1000 1908 Jun 1 04:23 exchange.conf -rw-rw-r-- 1 1000 1000 2593 Jun 1 04:23 hadoop.env drwxrwxr-x 7 1000 1000 4096 Jun 6 03:27 nebula-spark-connector -rw-rw-r-- 1 1000 1000 51 Jun 1 04:23 player.csv 然后，实际上我们可以手动再次提交一下这个 Exchange 任务 /spark/bin/spark-submit --master local \\ --class com.vesoft.nebula.exchange.Exchange download/nebula-exchange.jar \\ -c exchange.conf 部分返回结果 22/06/06 03:56:26 INFO Exchange$: Processing Tag player 22/06/06 03:56:26 INFO Exchange$: field keys: _c1, _c2 22/06/06 03:56:26 INFO Exchange$: nebula keys: name, age 22/06/06 03:56:26 INFO Exchange$: Loading CSV files from file:///root/player.csv ... 22/06/06 03:56:41 INFO Exchange$: import for tag player cost time: 3.35 s 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchSuccess.player: 2 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchFailure.player: 0 ... 更多的数据源，请参考文档和配置的例子。 关于 Exchange 输出 SST 文件的实践，你可以参考文档和我的旧文 Nebula Exchange SST 2.x实践指南。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:3:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#先跑起来看看吧"},{"categories":["Nebula Graph"],"content":" 3.1 一键试玩 Exchange 3.1.1 先跑起来看看吧 请参考前边拉起环境这一章节，先一键装好环境。 一键执行： ~/.nebula-up/nebula-exchange-example.sh 恭喜你，已经第一次执行成功一个 Exchange 的数据导入任务啦！ 3.1.2 再看看一些细节这个例子里，我们实际上是用 Exchange 从 CSV 文件这一其中支持的数据源中读取数据写入 Nebula Graph 集群的。这个 CSV 文件中第一列是顶点 ID，第二和第三列是 “姓名 “和 “年龄 “的属性： player800,\"Foo Bar\",23 player801,\"Another Name\",21 咱们可以进到 Spark 环境里看看 docker exec -it sparkmaster bash cd /root 可以看到我们提交 Exchange 任务时候指定的配置文件 exchange.conf 它是一个 HOCON 格式的文件： 在 .nebula 中描述了 Nebula Graph 集群的相关信息 在 .tags 中描述了如何将必填字段对应到我们的数据源（这里是 CSV 文件）等有关 Vertecies 的信息。 { # Spark relation config spark: { app: { name: Nebula Exchange } master:local driver: { cores: 1 maxResultSize: 1G } executor: { memory: 1G } cores:{ max: 16 } } # Nebula Graph relation config nebula: { address:{ graph:[\"graphd:9669\"] meta:[\"metad0:9559\", \"metad1:9559\", \"metad2:9559\"] } user: root pswd: nebula space: basketballplayer # parameters for SST import, not required path:{ local:\"/tmp\" remote:\"/sst\" hdfs.namenode: \"hdfs://localhost:9000\" } # nebula client connection parameters connection { # socket connect \u0026 execute timeout, unit: millisecond timeout: 30000 } error: { # max number of failures, if the number of failures is bigger than max, then exit the application. max: 32 # failed import job will be recorded in output path output: /tmp/errors } # use google's RateLimiter to limit the requests send to NebulaGraph rate: { # the stable throughput of RateLimiter limit: 1024 # Acquires a permit from RateLimiter, unit: MILLISECONDS # if it can't be obtained within the specified timeout, then give up the request. timeout: 1000 } } # Processing tags # There are tag config examples for different dataSources. tags: [ # HDFS csv # Import mode is client, just change type.sink to sst if you want to use client import mode. { name: player type: { source: csv sink: client } path: \"file:///root/player.csv\" # if your csv file has no header, then use _c0,_c1,_c2,.. to indicate fields fields: [_c1, _c2] nebula.fields: [name, age] vertex: { field:_c0 } separator: \",\" header: false batch: 256 partition: 32 } ] } 我们应该能看到那个 CSV 数据源和这个配置文件都在同一个目录下了： bash-5.0# ls -l total 24 drwxrwxr-x 2 1000 1000 4096 Jun 1 04:26 download -rw-rw-r-- 1 1000 1000 1908 Jun 1 04:23 exchange.conf -rw-rw-r-- 1 1000 1000 2593 Jun 1 04:23 hadoop.env drwxrwxr-x 7 1000 1000 4096 Jun 6 03:27 nebula-spark-connector -rw-rw-r-- 1 1000 1000 51 Jun 1 04:23 player.csv 然后，实际上我们可以手动再次提交一下这个 Exchange 任务 /spark/bin/spark-submit --master local \\ --class com.vesoft.nebula.exchange.Exchange download/nebula-exchange.jar \\ -c exchange.conf 部分返回结果 22/06/06 03:56:26 INFO Exchange$: Processing Tag player 22/06/06 03:56:26 INFO Exchange$: field keys: _c1, _c2 22/06/06 03:56:26 INFO Exchange$: nebula keys: name, age 22/06/06 03:56:26 INFO Exchange$: Loading CSV files from file:///root/player.csv ... 22/06/06 03:56:41 INFO Exchange$: import for tag player cost time: 3.35 s 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchSuccess.player: 2 22/06/06 03:56:41 INFO Exchange$: Client-Import: batchFailure.player: 0 ... 更多的数据源，请参考文档和配置的例子。 关于 Exchange 输出 SST 文件的实践，你可以参考文档和我的旧文 Nebula Exchange SST 2.x实践指南。 ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:3:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#再看看一些细节"},{"categories":["Nebula Graph"],"content":" 4 Nebula Algorithm 代码仓库： https://github.com/vesoft-inc/nebula-algorithm 文档：https://docs.nebula-graph.com.cn/3.1.0/nebula-algorithm/ JAR 包：https://repo1.maven.org/maven2/com/vesoft/nebula-algorithm/ 示例代码：example/src/main/scala/com/vesoft/nebula/algorithm ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:4:0","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#nebula-algorithm"},{"categories":["Nebula Graph"],"content":" 4.1 通过 spark-submit 提交任务 我在这个代码仓库里给出了例子，今天我们借助 Nebula-UP 可以更方便体验它。 参考前边拉起环境这一章节，先一键装好环境。 在如上通过 Nebula-UP 的 Spark 模式部署了需要的依赖之后 加载 LiveJournal 数据集 ~/.nebula-up/load-LiveJournal-dataset.sh 在 LiveJournal 数据集上执行一个 PageRank 算法，结果输出到 CSV 文件中 ~/.nebula-up/nebula-algo-pagerank-example.sh 检查输出结果： docker exec -it sparkmaster bash head /output/part*000.csv _id,pagerank 637100,0.9268620883822242 108150,1.1855749056722755 957460,0.923720299211093 257320,0.9967932799358413 4.1.1 配置文件解读完整文件在这里，这里，我们介绍一下主要的字段： .data 指定了源是 Nebula，表示从集群获取图数据，输出sink是 csv，表示写到本地文件里。 data: { # data source. optional of nebula,csv,json source: nebula # data sink, means the algorithm result will be write into this sink. optional of nebula,csv,text sink: csv # if your algorithm needs weight hasWeight: false } .nebula.read 规定了读 Nebula Graph 集群的对应关系，这里是读取所有 edge type: follow 的边数据为一整张图 nebula: { # algo's data source from Nebula. If data.source is nebula, then this nebula.read config can be valid. read: { # Nebula metad server address, multiple addresses are split by English comma metaAddress: \"metad0:9559\" # Nebula space space: livejournal # Nebula edge types, multiple labels means that data from multiple edges will union together labels: [\"follow\"] # Nebula edge property name for each edge type, this property will be as weight col for algorithm. # Make sure the weightCols are corresponding to labels. weightCols: [] } .algorithm 里配置了我们要调用的算法，和算法的配置 algorithm: { executeAlgo: pagerank # PageRank parameter pagerank: { maxIter: 10 resetProb: 0.15 # default 0.15 } ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:4:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#通过-spark-submit-提交任务"},{"categories":["Nebula Graph"],"content":" 4.1 通过 spark-submit 提交任务 我在这个代码仓库里给出了例子，今天我们借助 Nebula-UP 可以更方便体验它。 参考前边拉起环境这一章节，先一键装好环境。 在如上通过 Nebula-UP 的 Spark 模式部署了需要的依赖之后 加载 LiveJournal 数据集 ~/.nebula-up/load-LiveJournal-dataset.sh 在 LiveJournal 数据集上执行一个 PageRank 算法，结果输出到 CSV 文件中 ~/.nebula-up/nebula-algo-pagerank-example.sh 检查输出结果： docker exec -it sparkmaster bash head /output/part*000.csv _id,pagerank 637100,0.9268620883822242 108150,1.1855749056722755 957460,0.923720299211093 257320,0.9967932799358413 4.1.1 配置文件解读完整文件在这里，这里，我们介绍一下主要的字段： .data 指定了源是 Nebula，表示从集群获取图数据，输出sink是 csv，表示写到本地文件里。 data: { # data source. optional of nebula,csv,json source: nebula # data sink, means the algorithm result will be write into this sink. optional of nebula,csv,text sink: csv # if your algorithm needs weight hasWeight: false } .nebula.read 规定了读 Nebula Graph 集群的对应关系，这里是读取所有 edge type: follow 的边数据为一整张图 nebula: { # algo's data source from Nebula. If data.source is nebula, then this nebula.read config can be valid. read: { # Nebula metad server address, multiple addresses are split by English comma metaAddress: \"metad0:9559\" # Nebula space space: livejournal # Nebula edge types, multiple labels means that data from multiple edges will union together labels: [\"follow\"] # Nebula edge property name for each edge type, this property will be as weight col for algorithm. # Make sure the weightCols are corresponding to labels. weightCols: [] } .algorithm 里配置了我们要调用的算法，和算法的配置 algorithm: { executeAlgo: pagerank # PageRank parameter pagerank: { maxIter: 10 resetProb: 0.15 # default 0.15 } ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:4:1","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#配置文件解读"},{"categories":["Nebula Graph"],"content":" 4.2 作为一个库在 Spark 中调用 Nebula Algoritm请注意另一方面，我们可以将 Nebula Algoritm 作为一个库调用，它的好处在于： 对算法的输出格式有更多的控制/定制功能 可以对非数字 ID 的情况进行转换，见这里 这里我先不给出例子了，如果大家感兴趣可以给 Nebula-UP 提需求，我也会增加相应的例子。 题图来源： Sander ","date":"2022-06-06","objectID":"/spark-on-nebula-graph/:4:2","series":null,"tags":["Nebula Graph","Spark","PySpark"],"title":"一文了解 Nebula Graph 上的 Spark 项目","uri":"/spark-on-nebula-graph/#作为一个库在-spark-中调用-nebula-algoritm"},{"categories":["Nebula Graph"],"content":"得益于 Nebula 的原生 ARM64v8 的支持，在树莓派等 ARM 单板上跑 Nebula Graph 也非常容易。","date":"2022-03-23","objectID":"/nebula-graph-on-pi/","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/"},{"categories":["Nebula Graph"],"content":" 得益于 Nebula 的原生 ARM64v8 的支持，在树莓派等 ARM 单板上跑 Nebula Graph 非常容易。 ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:0:0","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#"},{"categories":["Nebula Graph"],"content":" 1 背景最近，在 Nebula Graph 社区 Yee 老师的（再）一次修复了 Nebula Graph 的构建依赖的 ARM 支持问题（nebula-third-party#37）之后，我们又可以愉快地在 M1 Mac 上玩这个分布式开源图数据库了。 苦于树莓派的价格，一直没找机会把 Nebula 跑在小板子上玩玩。至于为什么要跑在树莓派上我的回答当然是 Because I can 在非常非常边缘计算的场景下（这里挖个坑，我一定要找一个这样的场景分享出来）。 终于，一周多之前在 @laixintao 和 @andelf 的一个讨论下我决定找一个树莓派的 alternative，最后下单了 Rock Pi 3A，在因为深圳疫情影响下拖到了这个礼拜才终于发货了！ 它看起来真的很棒！ ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:1:0","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#背景"},{"categories":["Nebula Graph"],"content":" 2 在 ARM64 板子上装 Nebula Graph 图数据库 实际上 Nebula Graph 在 3.0 之后提供了一个单机版，这使得 Nebula 在边缘计算情况下有了更小的 footprint，不过这次我还没有使用这个版本，下次试试再给大家分享。 我在附录列出了安装 Ubuntu Server 的步骤，这里假设大家已经在树莓派或者其他单板 ARM 电脑里拉起来了 64 位的 Linux Server。 ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:2:0","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#在-arm64-板子上装-nebula-graph-图数据库"},{"categories":["Nebula Graph"],"content":" 2.1 第 0 步，安装 Docker 和 Docker-Compose这里，我假设是 Debian/Ubuntu，其他分发版直接参考这里就好。 sudo apt-get update sudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release echo \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io # follow https://docs.docker.com/engine/install/linux-postinstall/ sudo groupadd docker sudo usermod -aG docker $USER exit # login again newgrp docker 安装好了 Docker 之后，安装 Compose，它 Docker 官方的步骤是有问题的，因为它其实是一个 Python 的包，我们通过 PIP 去装就好了。 sudo apt-get install -y python3 python3-pip sudo pip3 install docker-compose ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:2:1","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#第-0-步安装-docker-和-docker-compose"},{"categories":["Nebula Graph"],"content":" 2.2 第 1 步，拉起 Nebula Graph首先，我们克隆 Nebula Docker Compose 这个 Repo，在 Master Branch，用 Compose 把服务拉起来。 git clone https://github.com/vesoft-inc/nebula-docker-compose.git \u0026\u0026 cd nebula-docker-compose docker-compose up -d 然后，我们下载 Console，连上 GraphD 服务。 wget https://github.com/vesoft-inc/nebula-console/releases/download/v3.0.0/nebula-console-linux-arm64-v3.0.0 chmod +x nebula-console-linux-arm64-v3.0.0 ./nebula-console-linux-arm64-v3.0.0 -addr localhost -port 9669 -u root -p nebula 并激活 Storage 服务。 ADD HOSTS \"storaged0\":9779,\"storaged1\":9779,\"storaged2\":9779; SHOW HOSTS; ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:2:2","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#第-1-步拉起-nebula-graph"},{"categories":["Nebula Graph"],"content":" 2.3 第 2 步，玩转 Nebula Graph on Pi这时候，透过 SHOW HOSTS 看到三个 StorageD 服务都是 ONLINE 之后，我们可以给 Nebula 里加载进去测试数据集。 $:play basketballplayer; 差不多一分钟之后，数据库加载成功，我们进入这个图空间，玩一下吧！ USE basketballplayer; GO FROM \"player100\" OVER follow YIELD dst(edge); Check this out and… Happy Graphing! ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:2:3","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#第-2-步玩转-nebula-graph-on-pi"},{"categories":["Nebula Graph"],"content":" 3 附录：安装 Ubuntu Server 在 Rock Pi 3A 上 准备一个 micro SD card，在 https://wiki.radxa.com/Rock3/downloads 下载镜像，解压为 .img 文件 把镜像写进 SD card，比如用 etcher 插入电源（5V，3A）启动！ feature image credit: @_louisreed ","date":"2022-03-23","objectID":"/nebula-graph-on-pi/:3:0","series":null,"tags":["Nebula Graph","ARM","Respberry Pi"],"title":"Nebula Graph on Pi","uri":"/nebula-graph-on-pi/#附录安装-ubuntu-server-在-rock-pi-3a-上"},{"categories":["Nebula Graph"],"content":"我发现用 Nebula Graph 的图查询解 Antfu 的汉兜特别有意思！","date":"2022-02-28","objectID":"/resolve-wordle/","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/"},{"categories":["Nebula Graph"],"content":" 我发现用 Nebula Graph 的图查询解 Antfu 的汉兜（最好的中文成语版 wordle 👉🏻 handle.antfu.me）特别有意思，很适合每天写图库语句的体操练习，本文揭示如何用知识图谱作弊解汉兜😁 ","date":"2022-02-28","objectID":"/resolve-wordle/:0:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#"},{"categories":["Nebula Graph"],"content":" 1 什么是汉兜？汉兜（https://handle.antfu.me）是由 Vue/Vite 核心团队的 Antfu 的又一个非常酷的作品，一个非常精致的汉字版的 Wordle，他是是一个每日挑战的填字游戏的中文成语版。 每天，汉兜会发起一个猜成语挑战，人们要在十次内才对它才能获胜，每一步之后都会收到相应的文字、声母、韵母、声调的匹配情况的提示，其中：绿色表示这个因素存在并且位置匹配、橘色表示这个元素存在但是位置不对，详细的规则可见如下的网页截图： 汉兜的乐趣就我们在于在有限的尝试过程中，在大脑中搜寻可能的答案，不断去逼近真理，任何试图作弊、讨巧去泄漏结果的行为都是很无趣、倒胃口的（比如从开源的汉兜代码里窃取信息），这个过程就像在做大脑的体操。 说到大脑的成语词汇量体操，我突然想到，为什么我们不能在大脑之外造一个汉语成语知识图谱，然后基于这个图谱去做图数据库查询语法体操呢？ ","date":"2022-02-28","objectID":"/resolve-wordle/:1:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#什么是汉兜"},{"categories":["Nebula Graph"],"content":" 2 构造解决汉兜的成语知识图谱","date":"2022-02-28","objectID":"/resolve-wordle/:2:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#构造解决汉兜的成语知识图谱"},{"categories":["Nebula Graph"],"content":" 2.1 什么是知识图谱？简单来说，知识图谱是一个连接实体之间关联关系的网络，它最初由 Google 提出并用来满足搜索引擎中基于知识推理才可获得（而不是网页倒排索引）的搜索问题，比如：”姚明妻子的年龄？“、”火箭队得过几次总冠军？“ 这里边，我们关注的条件。到 2022 年的现在，知识图谱已经被广泛应用在推荐系统、问答系统、安全风控等等更多搜索之外的领域。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:1","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#什么是知识图谱"},{"categories":["Nebula Graph"],"content":" 2.2 为什么需要用知识图谱解决汉兜？原因就是：because I can 实际上，我们在大脑中解决字谜游戏的过程像极了图谱网络中的信息搜寻的过程，汉兜的解谜反馈提示条件天然适合被用图谱的语义来进行表达。在本文后边，你们会发现解谜条件翻译成图语义是非常非常自然的，这个问题就像是一个天然的为图谱而存在的练习一样，我相信这和知识图谱的结构和人脑中的知识结构非常接近有很大的关系。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:2","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#为什么需要用知识图谱解决汉兜"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#如何构建面向汉兜解谜的知识图谱"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#图建模"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#最初的想法"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#最终的版本"},{"categories":["Nebula Graph"],"content":" 2.3 如何构建面向汉兜解谜的知识图谱？知识图谱是由实体（顶点）和关系（边）组成的，用图数据库管理系统（Graph Database MS）可以很方便进行知识的入库、更改、查询、甚至可视化探索。 在本文里，我将利用开源的分布式图数据库 Nebula Graph 开实践这个过程，具体图谱系统的搭建我都会放在文末。 在本章，我们只讨论图谱的建模：如何面向汉兜的解谜去设计“实体”与“关系”。 2.3.1 图建模 2.3.1.1 最初的想法首先，一定存在的实体是： 成语 汉字 成语-[包含]-\u003e汉字，每个汉字-[读作]-\u003e读音。 其次，因为解谜过程中涉及到了声母、韵母以及声调的条件，考虑到图谱本身的量级非常小（千级别），而且字的读音是一对多的关系，我把读音和声母（包涵声母-initial和韵母-final）也作为实体，他们之间的关系则是顺理成章了： 2.3.1.2 最终的版本然而，我在后边基于图谱进行查询的时候发现最初的建模会使得(成语)–\u003e(字)–\u003e(读音)查询过程中丢失了这个字特定的读法的条件，所以我最终的建模是： 这样，纯文字的条件只涉及了(成语)--\u003e(字) 这一跳，而读音、声母、声调的条件则是另一条关系路径，既没有最初版本条件的冗余，又可以在一个路径模式匹配里带上两种条件（后边的例子里会涉及这样的表达）。 2.3.2 构建成语知识图谱有了建模、这么简单的图谱的构建就剩下了数据的收集、清洗和入库。 对于所有成语数据和他们的读音，我一方面直接抽取了汉兜代码内部的数据、另一方面利用 PyPinyin 这个开源的 Python 库将汉兜数据中没有读音的数据获得读音，同时，我也用到了 PyPinyin 里的很多方便的函数比如获取一个拼音的声母、韵母。 构建工具的代码在这里：https://github.com/wey-gu/chinese-graph 更多信息我也放在文末的附录之中。 ","date":"2022-02-28","objectID":"/resolve-wordle/:2:3","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#构建成语知识图谱"},{"categories":["Nebula Graph"],"content":" 3 开始知识图谱查询体操至此，我假设咱们都已经有了我帮大家搭建的成语作弊知识图谱了，开始我们的图谱查询体操吧！ 首先，打开汉兜 👉🏻 https://handle.antfu.me/ 假设我们想从一个成语开始，如果你没有想法的话可以试试这个： // 匹配成语中的一个结果 MATCH (x:idiom) RETURN x LIMIT 1 // 返回结果 (\"爱憎分明\" :idiom{pinyin: \"['ai4', 'zeng1', 'fen1', 'ming2']\"}) 然后我们把它填到汉兜之中，获得第一次尝试的提示条件： 我们运气不错，得到了三个位置上的条件！ 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱（爱） 有一个一声的字，不在第二个位置（憎） 有一个字韵母是 ing，不在第四个位置（明） 第四个字是二声（明） 下面，我们开始图数据库语句体操！ // 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱 MATCH (char0:character)\u003c-[with_char_0:with_character]-(x:idiom)-[with_pinyin_0:with_pinyin]-\u003e(pinyin_0:character_pinyin)-[:with_pinyin_part]-\u003e(final_part_0:pinyin_part{part_type: \"final\"}) WHERE id(final_part_0) == \"ai\" AND pinyin_0.character_pinyin.tone == 4 AND with_pinyin_0.position != 0 AND with_char_0.position != 0 AND id(char0) != \"爱\" // 有一个一声的字，不在第二个位置 MATCH (x:idiom) -[with_pinyin_1:with_pinyin]-\u003e(pinyin_1:character_pinyin) WHERE pinyin_1.character_pinyin.tone == 1 AND with_pinyin_1.position != 1 // 有一个字韵母是 ing，不在第四个位置 MATCH (x:idiom) -[with_pinyin_2:with_pinyin]-\u003e(:character_pinyin)-[:with_pinyin_part]-\u003e(final_part_2:pinyin_part{part_type: \"final\"}) WHERE id(final_part_2) == \"ing\" AND with_pinyin_2.position != 3 // 第四个字是二声 MATCH (x:idiom) -[with_pinyin_3:with_pinyin]-\u003e(pinyin_3:character_pinyin) WHERE pinyin_3.character_pinyin.tone == 2 AND with_pinyin_3.position == 3 RETURN x, count(x) as c ORDER BY c DESC 在图数据库之中运行，得到了 7 个答案： (\"惊愚骇俗\" :idiom{pinyin: \"['jing1', 'yu2', 'hai4', 'su2']\"}) (\"惊世骇俗\" :idiom{pinyin: \"['jing1', 'shi4', 'hai4', 'su2']\"}) (\"惊见骇闻\" :idiom{pinyin: \"['jing1', 'jian4', 'hai4', 'wen2']\"}) (\"沽名卖直\" :idiom{pinyin: \"['gu1', 'ming2', 'mai4', 'zhi2']\"}) (\"惊心骇神\" :idiom{pinyin: \"['jing1', 'xin1', 'hai4', 'shen2']\"}) (\"荆棘载途\" :idiom{pinyin: \"['jing1', 'ji2', 'zai4', 'tu2']\"}) (\"出卖灵魂\" :idiom{pinyin: \"['chu1', 'mai4', 'ling2', 'hun2']\"}) 看起来 惊世骇俗 比较主流，试试！ 我们很幸运，借助于成语作弊知识图谱，居然一次就找到了答案，当然这实际上得益于第一次随机选取的词带来的限制条件的个数，不过在大部分情况下，两次尝试获得最终答案的可能性还是非常大的！ 注，这中间很长的253分钟是因为我在查询中发现之前代码里构造的图谱有点 bug，是“披枷带锁”这个词引起的读音图谱的错误数据，还好后来被修复了。 大家知道“披枷带锁”的正确读音么？😭 接下来，我给大家详细解释一下这个语句的意思。 ","date":"2022-02-28","objectID":"/resolve-wordle/:3:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#开始知识图谱查询体操"},{"categories":["Nebula Graph"],"content":" 3.1 语句的含义我们从第一个字的条件开始，这是一个既有声音、又有字形信息的条件。 声音信息：存在一个韵母为 ai4 的发音，位置不在第一个字 文字信息：这个韵母为 ai4 的字，不是爱字 对于声音信息条件，转换为图模式匹配为：(成语)-一个字发音-(拼音) -包含声母-(韵母) WHERE 拼音韵母为 ai4 AND 位置不是第一个。 因为建模的时候，属性名称我用的是英文（其实中文也是支持的），实际上的语句为： // 有一个非第一个位置的字，拼音是 4 声，韵母是 ai MATCH (x:idiom)-[with_pinyin_0:with_pinyin]-\u003e(pinyin_0:character_pinyin)-[:with_pinyin_part]-\u003e(final_part_0:pinyin_part{part_type: \"final\"}) WHERE id(final_part_0) == \"ai\" AND pinyin_0.character_pinyin.tone == 4 AND with_pinyin_0.position != 0 // ... RETURN x 类似的，表示非第一个位置的字，不是爱 的表达是： # 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱 MATCH (char0:character)\u003c-[with_char_0:with_character]-(x:idiom) WHERE with_char_0.position != 0 AND id(char0) != \"爱\" # ... RETURN x, count(x) as c ORDER BY c DESC 而因为这两个条件最终描述的是同一个字，所以它们是可以被写在一个路径下的： # 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱 MATCH (char0:character)\u003c-[with_char_0:with_character]-(x:idiom)-[with_pinyin_0:with_pinyin]-\u003e(pinyin_0:character_pinyin)-[:with_pinyin_part]-\u003e(final_part_0:pinyin_part{part_type: \"final\"}) WHERE id(final_part_0) == \"ai\" AND pinyin_0.character_pinyin.tone == 4 AND with_pinyin_0.position != 0 AND with_char_0.position != 0 AND id(char0) != \"爱\" # ... RETURN x 更多的 MATCH 语法和例子细节，请大家参考文档： MATCH https://docs.nebula-graph.com.cn/3.0.0/3.ngql-guide/7.general-query-statements/2.match/ 图模式 https://docs.nebula-graph.com.cn/3.0.0/3.ngql-guide/1.nGQL-overview/3.graph-patterns/ nGQL 命令 cheatsheet https://docs.nebula-graph.com.cn/3.0.0/2.quick-start/6.cheatsheet-for-ngql-command/ ","date":"2022-02-28","objectID":"/resolve-wordle/:3:1","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#语句的含义"},{"categories":["Nebula Graph"],"content":" 4 可视化展示线索我们把每一个条件的匹配路径作为输出，利用 Nebula Graph 的可视化能力，可以得到： # 有一个非第一个位置的字，拼音是 4 声，韵母是 ai，但不是爱 MATCH p0=(char0:character)\u003c-[with_char_0:with_character]-(x:idiom)-[with_pinyin_0:with_pinyin]-\u003e(pinyin_0:character_pinyin)-[:with_pinyin_part]-\u003e(final_part_0:pinyin_part{part_type: \"final\"}) WHERE id(final_part_0) == \"ai\" AND pinyin_0.character_pinyin.tone == 4 AND with_pinyin_0.position != 0 AND with_char_0.position != 0 AND id(char0) != \"爱\" # 有一个一声的字，不在第二个位置 MATCH p1=(x:idiom) -[with_pinyin_1:with_pinyin]-\u003e(pinyin_1:character_pinyin) WHERE pinyin_1.character_pinyin.tone == 1 AND with_pinyin_1.position != 1 # 有一个字韵母是 ing，不在第四个位置 MATCH p2=(x:idiom) -[with_pinyin_2:with_pinyin]-\u003e(:character_pinyin)-[:with_pinyin_part]-\u003e(final_part_2:pinyin_part{part_type: \"final\"}) WHERE id(final_part_2) == \"ing\" AND with_pinyin_2.position != 3 # 第四个字是二声 MATCH p3=(x:idiom) -[with_pinyin_3:with_pinyin]-\u003e(pinyin_3:character_pinyin) WHERE pinyin_3.character_pinyin.tone == 2 AND with_pinyin_3.position == 3 RETURN p0,p1,p2,p3 在可视化工具的 Console 控制台里执行上边的语句之后，选择导入图探索，就可以看到 ","date":"2022-02-28","objectID":"/resolve-wordle/:4:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#可视化展示线索"},{"categories":["Nebula Graph"],"content":" 5 下一步如果大家是从本文第一次了解到 Nebula Graph 图数据库，那么大家可以下一步从 Nebula Graph 项目和 Nebula Graph 社区的官方 Bilibili 站点 👉🏻 https://space.bilibili.com/472621355 了解更多有意思的入门知识。 另外，这里是 Nebula Graph 的官方线上试玩环境，大家可以照着文档，利用试玩环境尝鲜。 后边，Nebula Graph 会开展每天的汉兜 nGQL 体操活动，敬请关注哈！ Happy Graphing! ","date":"2022-02-28","objectID":"/resolve-wordle/:5:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#下一步"},{"categories":["Nebula Graph"],"content":" 6 附录：搭建成语知识图谱","date":"2022-02-28","objectID":"/resolve-wordle/:6:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#附录搭建成语知识图谱"},{"categories":["Nebula Graph"],"content":" 6.1 收集、生成图谱数据 $ python3 graph_data_generator.py ","date":"2022-02-28","objectID":"/resolve-wordle/:6:1","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#收集生成图谱数据"},{"categories":["Nebula Graph"],"content":" 6.2 导入数据到 Nebula Graph 图数据库 6.2.1 部署图数据库 借助于 Nebula-Up https://github.com/wey-gu/nebula-up/ ，一行就可以了。 $ curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v3.0.0 部署成功的话，会看到这样的结果： ┌────────────────────────────────────────┐ │ 🌌 Nebula-Graph Playground is Up now! │ ├────────────────────────────────────────┤ │ │ │ 🎉 Congrats! Your Nebula is Up now! │ │ $ cd ~/.nebula-up │ │ │ │ 🌏 You can access it from browser: │ │ http://127.0.0.1:7001 │ │ http://\u003cother_interface\u003e:7001 │ │ │ │ 🔥 Or access via Nebula Console: │ │ $ ~/.nebula-up/console.sh │ │ │ │ To remove the playground: │ │ $ ~/.nebula-up/uninstall.sh │ │ │ │ 🚀 Have Fun! │ │ │ └────────────────────────────────────────┘ 6.2.2 图谱入库 借助于 Nebula-Importer https://github.com/vesoft-inc/nebula-importer/ ，一行就可以了。 $ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v ${PWD}/importer_conf.yaml:/root/importer_conf.yaml \\ -v ${PWD}/output:/root \\ vesoft/nebula-importer:v3.0.0 \\ --config /root/importer_conf.yaml 大概一两分钟数据就导入成功了，命令也会正常退出。 连到图数据库的 console 进入 Console 的容器执行下边的命令： $ ~/.nebula-up/console.sh # nebula-console -addr graphd -port 9669 -user root -p nebula 检查一下导入的数据： (root@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"chinese_idiom\" | +--------------------+ (root@nebula) [(none)]\u003e use chinese_idiom Execution succeeded (time spent 1510/2329 us) Fri, 25 Feb 2022 08:53:11 UTC (root@nebula) [chinese_idiom]\u003e match p=(成语:idiom) return p limit 2 +------------------------------------------------------------------+ | p | +------------------------------------------------------------------+ | \u003c(\"一丁不识\" :idiom{pinyin: \"['yi1', 'ding1', 'bu4', 'shi2']\"})\u003e | | \u003c(\"一丝不挂\" :idiom{pinyin: \"['yi1', 'si1', 'bu4', 'gua4']\"})\u003e | +------------------------------------------------------------------+ (root@nebula) [chinese_idiom]\u003e SUBMIT JOB STATS +------------+ | New Job Id | +------------+ | 11 | +------------+ (root@nebula) [chinese_idiom]\u003e SHOW STATS +---------+--------------------+--------+ | Type | Name | Count | +---------+--------------------+--------+ | \"Tag\" | \"character\" | 4847 | | \"Tag\" | \"character_pinyin\" | 1336 | | \"Tag\" | \"idiom\" | 29503 | | \"Tag\" | \"pinyin_part\" | 57 | | \"Edge\" | \"with_character\" | 116090 | | \"Edge\" | \"with_pinyin\" | 5943 | | \"Edge\" | \"with_pinyin_part\" | 3290 | | \"Space\" | \"vertices\" | 35739 | | \"Space\" | \"edges\" | 125323 | +---------+--------------------+--------+ ","date":"2022-02-28","objectID":"/resolve-wordle/:6:2","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#导入数据到-nebula-graph-图数据库"},{"categories":["Nebula Graph"],"content":" 6.2 导入数据到 Nebula Graph 图数据库 6.2.1 部署图数据库 借助于 Nebula-Up https://github.com/wey-gu/nebula-up/ ，一行就可以了。 $ curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v3.0.0 部署成功的话，会看到这样的结果： ┌────────────────────────────────────────┐ │ 🌌 Nebula-Graph Playground is Up now! │ ├────────────────────────────────────────┤ │ │ │ 🎉 Congrats! Your Nebula is Up now! │ │ $ cd ~/.nebula-up │ │ │ │ 🌏 You can access it from browser: │ │ http://127.0.0.1:7001 │ │ http://:7001 │ │ │ │ 🔥 Or access via Nebula Console: │ │ $ ~/.nebula-up/console.sh │ │ │ │ To remove the playground: │ │ $ ~/.nebula-up/uninstall.sh │ │ │ │ 🚀 Have Fun! │ │ │ └────────────────────────────────────────┘ 6.2.2 图谱入库 借助于 Nebula-Importer https://github.com/vesoft-inc/nebula-importer/ ，一行就可以了。 $ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v ${PWD}/importer_conf.yaml:/root/importer_conf.yaml \\ -v ${PWD}/output:/root \\ vesoft/nebula-importer:v3.0.0 \\ --config /root/importer_conf.yaml 大概一两分钟数据就导入成功了，命令也会正常退出。 连到图数据库的 console 进入 Console 的容器执行下边的命令： $ ~/.nebula-up/console.sh # nebula-console -addr graphd -port 9669 -user root -p nebula 检查一下导入的数据： (root@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"chinese_idiom\" | +--------------------+ (root@nebula) [(none)]\u003e use chinese_idiom Execution succeeded (time spent 1510/2329 us) Fri, 25 Feb 2022 08:53:11 UTC (root@nebula) [chinese_idiom]\u003e match p=(成语:idiom) return p limit 2 +------------------------------------------------------------------+ | p | +------------------------------------------------------------------+ | \u003c(\"一丁不识\" :idiom{pinyin: \"['yi1', 'ding1', 'bu4', 'shi2']\"})\u003e | | \u003c(\"一丝不挂\" :idiom{pinyin: \"['yi1', 'si1', 'bu4', 'gua4']\"})\u003e | +------------------------------------------------------------------+ (root@nebula) [chinese_idiom]\u003e SUBMIT JOB STATS +------------+ | New Job Id | +------------+ | 11 | +------------+ (root@nebula) [chinese_idiom]\u003e SHOW STATS +---------+--------------------+--------+ | Type | Name | Count | +---------+--------------------+--------+ | \"Tag\" | \"character\" | 4847 | | \"Tag\" | \"character_pinyin\" | 1336 | | \"Tag\" | \"idiom\" | 29503 | | \"Tag\" | \"pinyin_part\" | 57 | | \"Edge\" | \"with_character\" | 116090 | | \"Edge\" | \"with_pinyin\" | 5943 | | \"Edge\" | \"with_pinyin_part\" | 3290 | | \"Space\" | \"vertices\" | 35739 | | \"Space\" | \"edges\" | 125323 | +---------+--------------------+--------+ ","date":"2022-02-28","objectID":"/resolve-wordle/:6:2","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#部署图数据库"},{"categories":["Nebula Graph"],"content":" 6.2 导入数据到 Nebula Graph 图数据库 6.2.1 部署图数据库 借助于 Nebula-Up https://github.com/wey-gu/nebula-up/ ，一行就可以了。 $ curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v3.0.0 部署成功的话，会看到这样的结果： ┌────────────────────────────────────────┐ │ 🌌 Nebula-Graph Playground is Up now! │ ├────────────────────────────────────────┤ │ │ │ 🎉 Congrats! Your Nebula is Up now! │ │ $ cd ~/.nebula-up │ │ │ │ 🌏 You can access it from browser: │ │ http://127.0.0.1:7001 │ │ http://:7001 │ │ │ │ 🔥 Or access via Nebula Console: │ │ $ ~/.nebula-up/console.sh │ │ │ │ To remove the playground: │ │ $ ~/.nebula-up/uninstall.sh │ │ │ │ 🚀 Have Fun! │ │ │ └────────────────────────────────────────┘ 6.2.2 图谱入库 借助于 Nebula-Importer https://github.com/vesoft-inc/nebula-importer/ ，一行就可以了。 $ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v ${PWD}/importer_conf.yaml:/root/importer_conf.yaml \\ -v ${PWD}/output:/root \\ vesoft/nebula-importer:v3.0.0 \\ --config /root/importer_conf.yaml 大概一两分钟数据就导入成功了，命令也会正常退出。 连到图数据库的 console 进入 Console 的容器执行下边的命令： $ ~/.nebula-up/console.sh # nebula-console -addr graphd -port 9669 -user root -p nebula 检查一下导入的数据： (root@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"chinese_idiom\" | +--------------------+ (root@nebula) [(none)]\u003e use chinese_idiom Execution succeeded (time spent 1510/2329 us) Fri, 25 Feb 2022 08:53:11 UTC (root@nebula) [chinese_idiom]\u003e match p=(成语:idiom) return p limit 2 +------------------------------------------------------------------+ | p | +------------------------------------------------------------------+ | \u003c(\"一丁不识\" :idiom{pinyin: \"['yi1', 'ding1', 'bu4', 'shi2']\"})\u003e | | \u003c(\"一丝不挂\" :idiom{pinyin: \"['yi1', 'si1', 'bu4', 'gua4']\"})\u003e | +------------------------------------------------------------------+ (root@nebula) [chinese_idiom]\u003e SUBMIT JOB STATS +------------+ | New Job Id | +------------+ | 11 | +------------+ (root@nebula) [chinese_idiom]\u003e SHOW STATS +---------+--------------------+--------+ | Type | Name | Count | +---------+--------------------+--------+ | \"Tag\" | \"character\" | 4847 | | \"Tag\" | \"character_pinyin\" | 1336 | | \"Tag\" | \"idiom\" | 29503 | | \"Tag\" | \"pinyin_part\" | 57 | | \"Edge\" | \"with_character\" | 116090 | | \"Edge\" | \"with_pinyin\" | 5943 | | \"Edge\" | \"with_pinyin_part\" | 3290 | | \"Space\" | \"vertices\" | 35739 | | \"Space\" | \"edges\" | 125323 | +---------+--------------------+--------+ ","date":"2022-02-28","objectID":"/resolve-wordle/:6:2","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#图谱入库"},{"categories":["Nebula Graph"],"content":" 7 附录：图建模的 Schema nGQL CREATE SPACE IF NOT EXISTS chinese_idiom(partition_num=5, replica_factor=1, vid_type=FIXED_STRING(24)); USE chinese_idiom; # 创建点的类型 CREATE TAG idiom(pinyin string); #成语 CREATE TAG character(); #汉字 CREATE TAG character_pinyin(tone int); #单字的拼音 CREATE TAG pinyin_part(part_type string); #拼音的声部 # 创建边的类型 CREATE EDGE with_character(position int); #包含汉字 CREATE EDGE with_pinyin(position int); #读作 CREATE EDGE with_pinyin_part(part_type string); #包含声部 ","date":"2022-02-28","objectID":"/resolve-wordle/:7:0","series":null,"tags":["Nebula Graph","图数据库","知识图谱","wordle","汉兜"],"title":"图数据库体操：用 Nebula Graph 搭成语图谱解汉兜","uri":"/resolve-wordle/#附录图建模的-schema-ngql"},{"categories":["Nebula Graph"],"content":"找不到索引？为什么我要创建 Nebula Graph 索引？什么时候要用到 Nebula Graph 原生索引，一文把这些搞清楚。","date":"2022-02-20","objectID":"/nebula-index-explained/","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/"},{"categories":["Nebula Graph"],"content":" index not found？找不到索引？为什么我要创建 Nebula Graph 索引？什么时候要用到 Nebula Graph 原生索引，一文把这些搞清楚。 Nebula Graph 的索引其实和传统的关系型数据库中的索引很像，但是又有一些容易让人疑惑的区别。刚开始了解 Nebula 的同学会疑惑于： 不清楚 Nebula Graph 图数据库中的索引到的是什么概念 我应该什么时候使用 Nebula Graph 索引 Nebula Graph 索引怎么影响到写入性能 这篇文章里，我们就把这些问题回答好。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:0:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#"},{"categories":["Nebula Graph"],"content":" 1 到底 Nebula Graph 索引是什么简而言之，Nebula Graph 索引是用来，且只用来针对纯属性条件出发查询场景的 图游走（walk）查询中的属性条件过滤不需要它 纯属性条件出发查询（注：非采样情况）必须创建索引 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#到底-nebula-graph-索引是什么"},{"categories":["Nebula Graph"],"content":" 1.1 纯属性条件出发查询我们知道在传统关系型数据库中，索引是对表数据的一个或多个针对特定列重排序的副本，它用来加速特定列过滤条件的读查询并带来了额外的数据写入（加速而非这样查询的必须前提）。 在 Nebula Graph 图数据库里，索引则是对点、边特定属性数据重排序的副本，用来提供纯属性条件出发查询（如下边的查询：从只给定了点边属性条件，而非点的 ID 出发去获取图数据） #### 必须 Nebula Graph 索引存在的查询 # query 0 纯属性条件出发查询 LOOKUP ON tag1 WHERE col1 \u003e 1 AND col2 == \"foo\" \\ YIELD tag1.col1 as col1, tag1.col3 as col3; # query 1 纯属性条件出发查询 MATCH (v:player { name: 'Tim Duncan' })--\u003e(v2:player) \\ RETURN v2.player.name AS Name; 上边这两个纯属性条件出发查询就是字面意思的”根据给定的属性条件获取点或者边本身“ ，反面的例子则是给定了点的 ID： #### 不基于索引的查询 # query 2, 从给定的点做的游走查询 vertex VID: \"player100\" GO FROM \"player100\" OVER follow REVERSELY \\ YIELD src(edge) AS id | \\ GO FROM $-.id OVER serve \\ WHERE properties($^).age \u003e 20 \\ YIELD properties($^).name AS FriendOf, properties($$).name AS Team; # query 3, 从给定的点做的游走查询 vertex VID: \"player101\" 或者 \"player102\" MATCH (v:player { name: 'Tim Duncan' })--(v2) \\ WHERE id(v2) IN [\"player101\", \"player102\"] \\ RETURN v2.player.name AS Name; 我们仔细看前边的 query 1 和 query 3，尽管语句中条件都有针对 tag 为 player 的过滤： { name: 'Tim Duncan' } ： query 3之中不需要索引，因为它可以： 更直接的从已知的 v2 顶点： [\"player101\", \"player102\"] 向外扩展、游走（GetNeighbors() 获得边的另一端的点，然后GetVertices() 得到下一跳的 v），根据 v.player.name 过滤掉不要的数据 query 1 则不同，它因为没有任何给定的顶点 ID： 只能从属性条件入手，{ name: 'Tim Duncan' }，在按照 name 排序了的索引数据中先找到符合的点：IndexScan() 得到 v 然后再从 v 做 GetNeighbors() 获得边的另一端 的 v2 ，在通过 GetVertices() 去获得下一跳 v2 中的数据 其实，这里的关键就是在于是查询是否存在给定的顶点 ID（Vertex ID），下边两个查询的执行计划里更清晰地比较了他们的区别： query 1, 需要基于索引，纯属性条件出发查询 query 3, 从已知 VID，不需要索引 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:1","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#纯属性条件出发查询"},{"categories":["Nebula Graph"],"content":" 1.2 为什么纯属性条件出发查询里必须要索引呢？因为 Nebula Graph 在存储数据的时候，它的结构是面向分布式与关联关系设计的，类似表结构数据库中无索引的全扫描条件搜索实际上更加昂贵，所以设计上被有意禁止了。 注: 如果不追求全部数据，只要采样一部分，3.0 里之后是支持不强制索引 LIMIT 的情况的，如下查询（有 LIMIT）不需要索引： # sample vertex MATCH (v:team) RETURN v LIMIT 3 # or sample edge MATCH ()-[e:follow]-\u003e() RETURN e LIMIT 3 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:2","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#为什么纯属性条件出发查询里必须要索引呢"},{"categories":["Nebula Graph"],"content":" 1.3 为什么只有纯属性条件出发查询我们比较一下正常的图查询 graph-queries 和纯属性条件出发查询 pure-prop-condition queries： graph-queries： 如 query 2 、 query 3是沿着边一路找到特定路径条件的扩展游走 pure-prop-condition queries：如 query 0 and query 1 是只通过一定属性条件（或者是无限制条件）找到满足的点、边 而在 Nebula Graph 里，graph-queries 在扩展的时候，图的原始数据已经按照 VID（点和边都是）排序过了（或者说在数据里已经索引过了），这个排序带来连续存储（物理上临接）使得扩展游走本身就是优化、很快的。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:3","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#为什么只有纯属性条件出发查询"},{"categories":["Nebula Graph"],"content":" 1.4 总结：索引是什么，索引不是什么？索引是什么？ Nebula Graph 索引是为了从给定属性条件查点、边的一份属性数据的排序，它用写入的代价是的这种读查询模式成为可能。 索引不是什么？ Nebula Graph 索引不是用来加速一般图查询的：从一个点开始向外拓展的查询（即使是过滤属性条件的）不会依赖原生索引，因为 Nebula 数据自身的存储就是面向这种查询优化、排序的。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:1:4","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#总结索引是什么索引不是什么"},{"categories":["Nebula Graph"],"content":" 2 一些 Nebula Graph 索引的设计细节为了更好理解索引的限制、代价、能力，咱们来解释更多他的细节 Nebula Graph 索引是在本地（不是分开、中心化）和点数据被一起存储、分片的。 它只支持左匹配 因为底层是 RocksDB Prefix Scan 性能代价: 写入时候的路径：不只是多一分数据，为了保证一致性，还有昂贵的读操作 读路径：基于规则的优化选择索引，Fan Out 到所有 StorageD 这些信息也在我的手绘图和视频里可以看到： 因为左匹配的设计，在有更复杂的针对纯属性条件出发查询里涉及到通配、REGEXP这样的全文搜索情况，Nebula Graph 提供了全文索引的功能，它是利用 Raft Listener 去异步将数据写到外部 Elasticsearch 集群之中，并在查询的时候去查 ES 去做到的，见文档。 在这个手绘图中，我们还可以看出 Write path 写入索引数据是同步操作的 Read path 这部分画了一个 RBO 的例子，查询里的规则假设 col2 相等匹配排在左边的情况下，性能优于 col1 的大小比较匹配，所以选择了第二个索引 选好了索引之后，扫描索引的请求被 fan out 到存储节点上，这其中有些过滤条件比如 top n 是可以下推的 结论： 因为写入的代价，只有必须用索引的时候采用，如果采样查询能满足读的要求，可以不创建索引而用 LIMIT 。 索引有左匹配的限制 符合查询的顺序要仔细设计 有时候需要使用全文索引 full-text index。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:2:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#一些-nebula-graph-索引的设计细节"},{"categories":["Nebula Graph"],"content":" 3 索引的使用具体要参考索引文档一些要点是： 在 tag 或者 edge type 上针对想要被条件反查点边的属性创建索引 CREATE INDEX 创建索引之后的索引部分数据会同步写入，但是如果创建索引之前已经有的点边数据对应的索引是需要明确指定去创建的，这是一个异步的 job： REBUILD INDEX 触发了异步的 REBUILD INDEX 之后，可以查询状态： SHOW INDEX STATUS 利用到索引的查询可以是 LOOKUP，并且常常可以借助管道符在此之上做拓展查询（Graph Query）： LOOKUP ON player \\ WHERE player.name == \"Kobe Bryant\"\\ YIELD id(vertex) AS VertexID, properties(vertex).name AS name |\\ GO FROM $-.VertexID OVER serve \\ YIELD $-.name, properties(edge).start_year, properties(edge).end_year, properties($$).name; 也可以是 MATCH ，这里边 v 是通过索引得到的，而 v2 则是在数据（非索引）部分拓展查询获得的。 MATCH (v:player{name:\"Tim Duncan\"})--(v2:player) \\ RETURN v2.player.name AS Name; 复合索引的能力与限制 理解原生索引的匹配是左匹配能让我们知道对于超过一个属性的索引：复合索引，并且能帮助我们理解它的能力有限制，这里说几个结论： 我们创建针对多个属性的复合索引是顺序有关的 比如，我们创建一个双属性复合索引 index_a: (isRisky: bool, age: int)，和 index_b: (age: int, isRisky: bool) 在根据 WHERE n.user.isRisky == true AND n.user.age \u003e 18 这个条件查询时候，index_a 因为左匹配一个相等的短字段，显然效率更高。 只有复合左匹配的被复合索引的属性真子集的过滤条件才能被只支持 比如，index_a: (isRisky: bool, age: int)，和 index_b: (age: int, isRisky: bool) 在查询 WHERE n.user.age \u003e 18 这个语句的时候, 只有 index_b 复合最左匹配，能满足这个查询。 针对一些从属性作为查询的起点，找点、边的情况，原生索引是不能满足全文搜索的匹配场景的，这时候，我们应该考虑使用 Nebula 全文索引，它是 Nebula 社区支持的开箱即用的外置 Elastic Search，通过配置，创建了全文索引的数据会通过 Raft listener 异步更新到 Elastic 集群中，他的查询入口也是 LOOKUP，详细的信息请参考文档。 ","date":"2022-02-20","objectID":"/nebula-index-explained/:3:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#索引的使用"},{"categories":["Nebula Graph"],"content":" 4 回顾 Nebula Graph 索引在只提供属性条件情况下通过对属性的排序副本扫描查点、边 Nebula Graph 索引不是用来图拓展查询的 Nebula Graph 索引是左匹配，不是用来做模糊全文搜索的 Nebula Graph 索引在写入时候有性能代价 记得如果创建 Nebula Graph 索引之前已经有相应点边上的数据，要重建索引 Happy Graphing! Feture image credit to Alina ","date":"2022-02-20","objectID":"/nebula-index-explained/:4:0","series":null,"tags":["Nebula Graph","索引","全文搜索","图数据库"],"title":"Nebula Graph 索引详解","uri":"/nebula-index-explained/#回顾"},{"categories":["Nebula Graph"],"content":"一文了解 K8s 部署的 Nebula Graph 集群的 Nebula-Algorithm 使用方法。","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/"},{"categories":["Nebula Graph"],"content":" 一文了解 K8s 部署的 Nebula Graph 集群的 Nebula-Algorithm 使用方法。 ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:0:0","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#"},{"categories":["Nebula Graph"],"content":" 1 步骤最方便的方法是将 Nebula Algorithm/ Spark 运行在与 Nebula-Operator 相同的网络命名空间里，将 show hosts meta 的 MetaD 域名:端口 格式的地址填进配置里就可以了。 注：需要 2.6.2 或者更新的版本，Spark-Connector/Algorithm 才支持域名形式的 MetaD 地址。 获取 MetaD 地址 (root@nebula) [(none)]\u003e show hosts meta +------------------------------------------------------------------+------+----------+--------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +------------------------------------------------------------------+------+----------+--------+--------------+---------+ | \"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local\" | 9559 | \"ONLINE\" | \"META\" | \"d113f4a\" | \"2.6.2\" | +------------------------------------------------------------------+------+----------+--------+--------------+---------+ Got 1 rows (time spent 1378/2598 us) Mon, 14 Feb 2022 08:22:33 UTC 填写 Algorithm 的配置文件 Ref: https://github.com/vesoft-inc/nebula-algorithm/blob/master/nebula-algorithm/src/main/resources/application.conf # ... nebula: { # algo's data source from Nebula. If data.source is nebula, then this nebula.read config can be valid. read: { # Nebula metad server address, multiple addresses are split by English comma metaAddress: \"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local:9559\" #... 或者是调用 spark-connector 的代码 Ref: https://github.com/vesoft-inc/nebula-spark-connector val config = NebulaConnectionConfig .builder() .withMetaAddress(\"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local:9559\") .withConenctionRetry(2) .build() val nebulaReadVertexConfig: ReadNebulaConfig = ReadNebulaConfig .builder() .withSpace(\"foo_bar_space\") .withLabel(\"person\") .withNoColumn(false) .withReturnCols(List(\"birthday\")) .withLimit(10) .withPartitionNum(10) .build() val vertex = spark.read.nebula(config, nebulaReadVertexConfig).loadVerticesToDF() 看起来非常简单，那么，为什么这么简单的过程却值得一篇文章呢？ ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:1:0","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#步骤"},{"categories":["Nebula Graph"],"content":" 1.1 容易忽略的问题这里的问题在于： a. 它隐含地需要保证 StorageD 的地址能被 spark 环境访问； b. 但是这些 StorageD 地址是从 MetaD 获取的； c. Nebula K8s Operator 里，MetaD 中存储的 StorageD 地址（服务发现）的来源是 StorageD 的配置文件，而它是 k8s 的内部地址。 ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:1:1","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#容易忽略的问题"},{"categories":["Nebula Graph"],"content":" 1.2 背景知识a. 的理由比较直接，和 nebula 的架构有关：图的数据都存在 Storage Service 之中，通常用语句的查询是透过 Graph Service 来透传，只需要 GraphD 的连接就足够，而 Spark-Connector 使用 Nebula Graph 的场景是扫描全图或者子图，这时候计算存储分离的设计使得我们可以绕过查询、计算层直接高效读取图数据。 那么问题来了，为什么需要、且只需要 MetaD 的地址呢？ 这也是和架构有关，Meta Service 里包含了全图的分布数据与分布式的 Storage Service 的各个分片和实例的分布，所以一方面因为只有 Meta 才有全图的信息（需要），另一方面因为从 Meta 可以获得这部分信息（只需要）。到这里 b. 的答案也有了。 详细的 Nebula Graph 架构信息可以参考博客系列文章：nebula-graph.com.cn/tags/架构设计 另外请确保您已经读了架构介绍的文档哦：Nebula 架构总览 下面我们看看 c. c. Nebula K8s Operator 里，MetaD 中存储的 StorageD 地址（服务发现）的来源是 StorageD 的配置文件，而它是 k8s 的内部地址。 这和 Nebula Graph 里的服务发现机制有关：在 Nebula Graph 集群中，Graph Service 和 Storage Service 都是通过心跳将自己的信息上报给 Meta Service 的，而这其中服务自身的地址的来源则来自于他们相应的配置文件中的网络配置。 关于服务自身的地址配置请参考文档：Storage networking 配置 关于服务发现详细的信息请参考四王的文章：图数据库 Nebula Graph 集群通信：从心跳说起。 最后，我们知道 Nebula Operator 是一个在 K8s 集群中按照配置，自动创建、维护、扩缩容 Nebula 集群的 K8s 控制面的应用，它需要抽象一部分内部资源相关的配置，这就包括了 GraphD 和 StorageD 实例的实际地址，他们是被配置的地址实际上是 headless service 地址。 而这些地址（如下）默认是没法被 k8s 外部网络访问的，所以针对 GraphD、MetaD 我们可以方便创建服务将其暴露出来。 (root@nebula) [(none)]\u003e show hosts meta +------------------------------------------------------------------+------+----------+--------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +------------------------------------------------------------------+------+----------+--------+--------------+---------+ | \"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local\" | 9559 | \"ONLINE\" | \"META\" | \"d113f4a\" | \"2.6.2\" | +------------------------------------------------------------------+------+----------+--------+--------------+---------+ Got 1 rows (time spent 1378/2598 us) Mon, 14 Feb 2022 09:22:33 UTC (root@nebula) [(none)]\u003e show hosts graph +---------------------------------------------------------------+------+----------+---------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +---------------------------------------------------------------+------+----------+---------+--------------+---------+ | \"nebula-graphd-0.nebula-graphd-svc.default.svc.cluster.local\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"d113f4a\" | \"2.6.2\" | +---------------------------------------------------------------+------+----------+---------+--------------+---------+ Got 1 rows (time spent 2072/3403 us) Mon, 14 Feb 2022 10:03:58 UTC (root@nebula) [(none)]\u003e show hosts storage +------------------------------------------------------------------------+------+----------+-----------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +------------------------------------------------------------------------+------+----------+-----------+--------------+---------+ | \"nebula-storaged-0.nebula-storaged-headless.default.svc.cluster.local\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"d113f4a\" | \"2.6.2\" | | \"nebula-storaged-1.nebula-storaged-headless.default.svc.cluster.local\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"d113f4a\" | \"2.6.2\" | | \"nebula-storaged-2.nebula-storaged-headless.default.svc.cluster.local\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"d113f4a\" | \"2.6.2\" | +------------------------------------------------------------------------+------+----------+-----------+--------------+---------+ Got 3 rows (time spent 1603/2979 us) Mon, 14 Feb 2022 10:05:24 UTC 然而，因为前边提到的 Spark-Connector 通过 Meta Service 去获取 StorageD 的地址，且这个地址是服务发现而得，所以 Spark-Connector 实际上获取的 StorageD 地址就是上边的这种 headless 的服务地址，没法直接从外部访问。 所以，我们在有条件的情况下，只需要让 Spark 运行在和 Nebula Cluster 相同的 K8s 网络里，一切就迎刃而解了，否则，我们需要： 将 MetaD 和 StorageD 的地址利用 Ingress 等方式将其 L4（TCP）暴露出来。 可以参考 Nebula Operator 的文档：doc/user/client_service.md 通过反向代理和DNS让这些 headless 服务能被解析到相应的 StorageD。 参考：TBD 那么，有没有更方便的方式？ 非常抱歉的是，目前最方便的方式依然是如文章最开头所介绍：让 Spark 运行在 Nebula Cluster 内部。实际上，我在努力推进 Nebula Spark 社区去支持可以配置的 StorageAddresses 选项，有了它之后，前边提到的 2. 就是不必要的了。 ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:1:2","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#背景知识"},{"categories":["Nebula Graph"],"content":" 2 Bonus：一键体验 nebula-algorithm + nebula-operator为了方便在 k8s 上尝鲜 nebula-graph nebula-algorithm 的同学，这里我要再次安利一下我写的一个小工具 Neubla-Operator-KinD，它是一个一键在 Docker 环境内部单独部署一个 k8s 集群并在其中部署 Nebula Operator 以及所有依赖（包括 storage provider）并部署一个小 Nebula Cluster 的工具。有点绕，不过可以看下边的步骤哈： 第一步，部署 K8s+Nebula-Operator+Nebula Cluster： curl -sL nebula-kind.siwei.io/install.sh | bash 第二步，照着工具文档里的 what’s next a. 用 console 连接集群，并加载示例数据集 b. 在这个 k8s 里跑一个图算法 创建一个 Spark 环境 kubectl create -f http://nebula-kind.siwei.io/deployment/spark.yaml kubectl wait pod --timeout=-1s --for=condition=Ready -l '!job-name' 等上边的 wait 都 ready 之后，进入 spark 的 pod。 kubectl exec -it deploy/spark-deployment -- bash 下载 nebula-algorithm 比如 2.6.2 这个版本，更多版本请参考 https://github.com/vesoft-inc/nebula-algorithm/。 注意： 官方发布的版本在这里可以获取：https://repo1.maven.org/maven2/com/vesoft/nebula-algorithm/ 因为这个问题 https://github.com/vesoft-inc/nebula-algorithm/issues/42 只有 2.6.2 或者更新的版本才支持域名访问 MetaD。 # 下载 nebula-algorithm-2.6.2.jar wget https://repo1.maven.org/maven2/com/vesoft/nebula-algorithm/2.6.2/nebula-algorithm-2.6.2.jar # 下载 nebula-algorthm 配置文件 wget https://github.com/vesoft-inc/nebula-algorithm/raw/v2.6/nebula-algorithm/src/main/resources/application.conf 修改Then we could change the config file of nebula-algorithm on meta and graph addresses: sed -i '/^ metaAddress/c\\ metaAddress: \\\"nebula-metad-0.nebula-metad-headless.default.svc.cluster.local:9559\\\"' application.conf sed -i '/^ graphAddress/c\\ graphAddress: \\\"nebula-graphd-0.nebula-graphd-svc.default.svc.cluster.local:9669\\\"' application.conf ##### change space sed -i '/^ space/c\\ space: basketballplayer' application.conf ##### read data from nebula graph sed -i '/^ source/c\\ source: nebula' application.conf ##### execute algorithm: labelpropagation sed -i '/^ executeAlgo/c\\ executeAlgo: labelpropagation' application.conf 执行 LPA 算法在 basketballplayer 图空间 /spark/bin/spark-submit --master \"local\" --conf spark.rpc.askTimeout=6000s \\ --class com.vesoft.nebula.algorithm.Main \\ nebula-algorithm-2.6.2.jar \\ -p application.conf 结果如下： bash-5.0# ls /tmp/count/ _SUCCESS part-00000-5475f9f4-66b9-426b-b0c2-704f946e54d3-c000.csv bash-5.0# head /tmp/count/part-00000-5475f9f4-66b9-426b-b0c2-704f946e54d3-c000.csv _id,lpa 1100,1104 2200,2200 2201,2201 1101,1104 2202,2202 Happy Graphing! Picture Credit: Timelab Pro ","date":"2022-02-14","objectID":"/nebula-algo-spark-k8s/:2:0","series":null,"tags":["Nebula Graph","图数据库","Spark-Connector","Nebula-Algorithm","k8s","nebula-operator"],"title":"为什么我的 Nebula-Spark-Connector、Nebula-Algorithm 连不上 K8s 部署的 Nebula Graph 集群？","uri":"/nebula-algo-spark-k8s/#bonus一键体验-nebula-algorithm--nebula-operator"},{"categories":["Nebula Graph","Mini Project"],"content":"如何利用图数据库从0-1构建一个特定领域问答助手？本文手把手带你构建一个简易版的篮球领域智能问答机器人。","date":"2021-12-30","objectID":"/siwi/","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/"},{"categories":["Nebula Graph","Mini Project"],"content":" 如何利用图数据库从0-1构建一个特定领域问答助手？本文手把手带你构建一个简易版的篮球领域智能问答机器人。 ","date":"2021-12-30","objectID":"/siwi/:0:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#"},{"categories":["Nebula Graph","Mini Project"],"content":" 1 前言「问答机器人」在我们日常生活中并不少见到 ：比如在一些电商客服、智能问诊、技术支持等人工输入与沟通界面的场景下，机器人“智能”问答系统一定程度上可以在无需人力、不需要耗费终端用户心智去做知识库、商品搜索、科室选择等等的情况下实时给出问题答案。 问答机器人系统背后的技术有多重可能： 基于检索，全文搜索接近的问题 基于机器学习阅读理解 基于知识图谱（Knowledge-Based Question Answering system: KBQA） 其他 基于知识图谱构建问答系统在以下三个情况下很有优势： 对于领域类型是结构化数据场景：电商、医药、系统运维（微服务、服务器、事件）、产品支持系统等，其中作为问答系统的参考对象已经是结构化数据； 问题的解答过程涉及多跳查询，比如“姚明的妻子今年是本命年吗？”，“你们家的产品 A 和 A+ 的区别是什么？”； 为了解决其他需求（风控、推荐、管理），已经构建了图结构数据、知识图谱的情况。 为了方便读者最快速了解如何构建 KBQA 系统，我写了非常简陋的小 KBQA 项目，在本文中，我会带领大家从头到尾把它搭起来。 💡：这个小项目叫做 Siwi，它的代码就在 GitHub 上：github.com/wey-gu/nebula-siwi Siwi 的发音是：/ˈsɪwi/ 或者叫：思二为 ，它是一个能解答 NBA 相关问题的机器人。 我们开始吧。 ","date":"2021-12-30","objectID":"/siwi/:1:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#前言"},{"categories":["Nebula Graph","Mini Project"],"content":" 2 鸟瞰 TL;DRKBQA 用一句话说就是把问题解析、转换成在知识图谱中的查询，查询得到结果之后进行筛选、翻译成结果（句子、卡片或者任何方便人理解的答案格式）。 💡：知识图谱的构建实际上是非常重要的过程，在本文中，我们专注在串起来 KBQA 系统的骨架，我们假设需求是基于一个已经有的图谱之上，为其增加一个 QA 系统。 「问题到图谱查询的转换」有不同的方法可以实现。 可以是对语义进行分析：理解问题的意图，针对不同意图匹配最可能的问题类型，从而构建这个类型问题的图谱查询，查得结果； 也可以是基于信息的抽取：从问题中抽取主要的实体，在图谱中获取实体的所有知识、关系条目（子图），再对结果根据问题中的约束条件匹配、排序选择结果。 💡：美团技术团队在这篇文章里分享了他们的真实世界实践，下图是美团结合了机器学习和 NLP 的方案。 而在 Siwi 里，我们一切从简，单独选择了语义分析这条路，它的特点是需要人为去标注或者编码一些问题类型的查询方式，但实际上在大多数场景下，尤其单一领域图谱的场景下反而是轻量却效果不差的方案，也是一个便于新手理解 KBQA 的合适的入门方式。 除了核心的问答部分，我还为 Siwi 增加了语音识别和语音回答（感谢浏览器接口标准的发展）的功能，于是，这个项目的结构和问答调用流程就是这样的了：一个语音问题自上而下分别经过三个部分： 基于网页的 Siwi Frontend 语音、文字问答界面 Python Flask 实现的 Siwi Backend/API 系统 Nebula Graph 开源分布式高性能图数据库之上的知识图谱 ┌────────────────┬──────────────────────────────────────┐ │ │ │ │ │ Speech │ │ ┌──────────▼──────────┐ │ │ │ Frontend │ Siwi, /ˈsɪwi/ │ │ │ Web_Speech_API │ A PoC of │ │ │ │ Dialog System │ │ │ Vue.JS │ With Graph Database │ │ │ │ Backed Knowledge Graph │ │ └──────────┬──────────┘ │ │ │ Sentence │ │ ┌────────────┼──────────────────────────────┐ │ │ │ │ Backend │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ Web API, Flask │ ./app/ │ │ │ │ └──────────┬──────────┘ │ │ │ │ │ Sentence ./bot/ │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ Intent matching, │ ./bot/classifier│ │ │ │ │ Symentic Processing │ │ │ │ │ └──────────┬──────────┘ │ │ │ │ │ Intent, Entities │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ Intent Actor │ ./bot/actions │ │ │ └─┴──────────┬──────────┴───────────────────┘ │ │ │ Graph Query │ │ ┌──────────▼──────────┐ │ │ │ Graph Database │ Nebula Graph │ │ └─────────────────────┘ │ └───────────────────────────────────────────────────────┘ 💡：图数据库相比于其他知识图谱存储系统来说，因为其设计专注于数据内的数据关系，非常擅长实时获取海量数据下实体之间的复杂关联关系。 Nebula Graph 的原生分布式设计和 share-nothing 架构使得它擅长于巨大数据量和高并发读写的场景，加上它的开源社区特别活跃，已经被国内很多团队用于支撑生产上的各种业务，这里有一些他们分享的选型、落地实践。 ","date":"2021-12-30","objectID":"/siwi/:2:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#鸟瞰-tldr"},{"categories":["Nebula Graph","Mini Project"],"content":" 3 知识图谱Siwi 构建于一个篮球相关的知识图谱之上，它其实是 Siwi 采用的开源分布式图数据库 Nebula Graph 社区的官方文档里的示例数据集。 在这个非常简单的图谱之中，只有两种点： player，球员 team，球队 两种关系： serve 服役于（比如：姚明 -服役于-\u003e 休斯顿火箭） follow 关注 （比如：姚明 -关注-\u003e 奥尼尔） 💡：这个数据集在 Nebula 社区上有一个 在线体验 环境，任何人都无需登录，通过Nebula Graph Studio 可视化探索篮球图谱。 下图就是这个图谱的可视化探索截图，可以看到左边的中心节点勇士队（Warriors）有杜兰特（Durant）还有其他几个队员在其中服役（serve）；除了服役之外，还可以看到队员和队员之中也有关注（follow）的关系存在。 有了这个知识图谱，咱们接下来就在它之上搭一个简单的基于语法解析的 QA 系统吧😁。 ","date":"2021-12-30","objectID":"/siwi/:3:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#知识图谱"},{"categories":["Nebula Graph","Mini Project"],"content":" 4 Siwi-backend ┌────────────┼──────────────────────────────┐ │ │ Backend │ │ ┌──────────▼──────────┐ │ │ │ Web API, Flask │ ./app/ │ │ └──────────┬──────────┘ │ │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ │ Graph Query ┌──────────▼──────────┐ │ Graph Database │ Nebula Graph └─────────────────────┘ 如上图的设计流程，Siwi 的后端部分需要接收问句，处理之后访问知识图谱（图数据库），然后将处理结果返回给用户。 ","date":"2021-12-30","objectID":"/siwi/:4:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#siwi-backend"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.1 接收 HTTP 请求(app)对于请求，就简单地用 Flask 作为 web server 来接收 HTTP 的 POST 请求： 💡：还不熟悉 Flask 的同学，可以在 freeCodeCamp 上搜索一下，有一些不错的课程哈。 下边的代码就是告诉 Flask ： 如果用户发过来 http://\u003cserver\u003e/query 的 POST 请求，提的问题就在请求的 body 里的 question 的 Key 之下。 取得问题之后，调用把请求传给 siwi_bot 的 query()，得到 answer 。 代码段：src/siwi/app/__init__.py #... from siwi.bot import bot #... @app.route(\"/query\", methods=[\"POST\"]) def query(): request_data = request.get_json() question = request_data.get(\"question\", \"\") # \u003c----- 1. if question: answer = siwi_bot.query( request_data.get(\"question\", \"\")) # \u003c----- 2. else: answer = \"Sorry, what did you say?\" return jsonify({\"answer\": answer}) 接下来我们来实现 siwi_bot，真正处理提问的逻辑。 ","date":"2021-12-30","objectID":"/siwi/:4:1","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#接收-http-请求app"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#处理请求bot"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#语义解析classifier"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#意图识别intent"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#实体识别entity"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.2 处理请求(bot) │ │ Sentence ./bot/ │ │ ┌──────────▼──────────┐ │ │ │ Intent matching, │ ./bot/classifier│ │ │ Symentic Processing │ │ │ └──────────┬──────────┘ │ │ │ Intent, Entities │ │ ┌──────────▼──────────┐ │ │ │ Intent Actor │ ./bot/actions │ └─┴──────────┬──────────┴───────────────────┘ 前边提到过，KBQA 基本上是 a. 把问题解析、转换成在知识图谱中的查询 b. 查询得到结果之后进行筛选、翻译成结果 这里，我们把 a. 的逻辑放在 classifier 里，b. 的逻辑放在 actions(actor) 里。 a. HTTP 请求的问题句子 sentence 传过来，用 classifier 解析它的意图和句子实体 b. 用意图和句子实体构造 action，并链接图数据库执行，获取结果。 代码段：src/siwi/bot/bot/__init__.py from siwi.bot.actions import SiwiActions from siwi.bot.classifier import SiwiClassifier class SiwiBot(): def __init__(self, connection_pool) -\u003e None: self.classifier = SiwiClassifier() self.actions = SiwiActions() self.connection_pool = connection_pool def query(self, sentence): intent = self.classifier.get(sentence) # \u003c--- a. action = self.actions.get(intent) # \u003c--- b. return action.execute(self.connection_pool) 首先咱们来进一步实现一下 SiwiClassifier 吧。 4.2.1 语义解析(classifier)classifier 需要在 get(sentence) 方法里将句子中的实体和句子的意图解析、分类出来。通常来说，这里是需要借助机器学习、NLP去分词、分类实现的，这里只是为了展示这个过程实际上只是各种 if/ else。 我们这里实现了三类意图的问题： 关系（A，B）：获得 A 和 B 在图谱中的关系路径，比如姚明和湖人队的关系是？ 服役情况：比如乔纳森在哪里服役？ 关注情况：比如邓肯关注了谁？ ❓ 开放问题： 如果看教程的你觉得这几个问题太没意思了，这里留一个开放问题，你可以在 Siwi 里帮我们实现：「共同好友（A，B）获得 A 和 B 的一度共同好友」这个意图（或者更酷的其他句子）么？欢迎来 Github：github.com/wey-gu/nebula-siwi/ 提 PR 哦，看看谁先实现。 代码片段：src/siwi/bot/classfier/__init__.py class SiwiClassifier(): def get(self, sentence: str) -\u003e dict: \"\"\" Classify Sentences and Fill Slots. This should be done by NLP, here we fake one to demostrate the intent Actor --\u003e Graph DB work flow. sentense: relation: - What is the relationship between Yao Ming and Lakers? - How does Tracy McGrady and Lakers connected? serving: - Which team had Jonathon Simmons served? friendship: - Whom does Tim Duncan follow? - Who are Tracy McGrady's friends? returns: { \"entities\": entities, \"intents\": intents } \"\"\" entities = self.get_matched_entities(sentence) intents = self.get_matched_intents(sentence) return { \"entities\": entities, \"intents\": intents } 这里，我把匹配的规则（等价于 if else…）写在了 src/siwi/bot/test/data 之下的 YAML 文件里，这样增加 classifier 之中新的规则只需要更新这个文件就可以了： 4.2.1.1 意图识别(intent) def load_entity_data(self) -\u003e None: # load data from yaml files module_path = f\"{ siwi.__path__[0] }/bot/test/data\" #... with open(f\"{ module_path }/intents.yaml\", \"r\") as file: self.intents = yaml.safe_load(file)[\"intents\"] 对于每一个意图来说： intents.\u003c名字\u003e 代表名字 名字之后的 action 代表后边在要实现的相应的 xxxAction 的类 比如 RelationshipAction 将是用来处理查询关系（A，B）这样的问题的 Action 类 keywords 代表在句子之中匹配的关键词 比如问句里出现 serve，served，serving 的字眼的时候，将会匹配服役的问题 💡：写 if else 条件来对应意图是不容易的，因为不同意图不可能没有关键词相交的情况，我们的实现只是一个非常简陋、不严谨的方式。在实际场景下，训练模型去做匹配效果会更好，有意思的是，那些做的比较好的模型的输入和我们的 YAML 的格式是很类似的。 --- intents: fallback: action: FallbackAction keywords: [] relationship: action: RelationshipAction keywords: - between - relation - relationship - related - connect - correlate serve: action: ServeAction keywords: - serve - served - serving friend: action: FollowAction keywords: - follows - followed - follow - friend - friends 4.2.1.2 实体识别(entity)类似的，实体识别的部分本质上也是 if else，只不过这里利用到了**Aho–Corasick算法**来帮助搜索实体，在生产（非玩具）的情况下，应该用 NLP 里的分词的方法来做。 💡：大家可以去了解一下这个 AC自动机算法 def setup_entity_tree(self) -\u003e None: self.entity_type_map.update({ key: \"player\" for key in self.players.keys() }) self.entity_type_map.update({ key: \"team\" for key in self.teams.keys() }) self.entity_tree = ahocorasick.Automaton() for index, entity in enumerate(self.entity_type_map.keys()): self.entity_tree.add_word(entity, (index, entity)) self.entity_tree.make_automaton() #... def get_matched_entities(self, sentence: str) -\u003e dict: \"\"\" Consume a sentence to be matched with ahocorasick Returns a dict: {entity: entity_type} \"\"\" _matched = [] for item in self.entity_tree.iter(sentence): entities_matched.append(item[1][1]) return { entity: self.entity_type_map[entity] for entity in _matched } 至此，我们的 SiwiClassifier.get(sentence) 已经能返回解析、分类出来的意图和实体了，这时候，它们会被传给 Actions 来让 siwi bot 知道如何去执行知识图谱的查询啦！ 4.2.2 构造图谱查询","date":"2021-12-30","objectID":"/siwi/:4:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#构造图谱查询action"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.3 测试一下 4.3.1 启动图数据库我们在 Nebula Graph 里建立（导入数据）一个篮球的知识图谱。 💡：在导入数据之前，请先部署一个 Nebula Graph 集群。最简便的部署方式是使用 Nebula-UP 这个小工具，只需要一行命令就能在 Linux 机器上同时启动一个 Nebula Graph 核心和可视化图探索工具 Nebula Graph Studio。如果你更愿意用 Docker 部署，请参考这个文档。 本文假设我们使用 Nebula-UP 来部署一个 Nebula Graph： curl -fsSL nebula-up.siwei.io/install.sh | bash 之后，我们会看到这样的提示： 按照提示，我们可以通过这个命令进入到有 Nebula Console 的容器里： 💡：Nebula Console 是命令行访问 Nebula Graph 图数据库的客户端，支持 Linux，Windows 和 macOS，下载地址：这里 ~/.nebula-up/console.sh 然后，在 # 的提示符下就表示我们进来了，我们在里边可以执行： nebula-console -addr graphd -port 9669 -user root -p nebula 这样就表示我们连接上了 Nebula Graph 图数据库： / # nebula-console -addr graphd -port 9669 -user root -p nebula Welcome to Nebula Graph! (root@nebula) [(none)]\u003e 在这里，我们就可以通过 nGQL 去操作 Nebula Graph，不过我们先退出来，执行 exit： (root@nebula) [(none)]\u003e exit Bye root! Fri, 31 Dec 2021 04:11:28 UTC 我们在这个容器内把基于 nGQL 语句的数据下载下来： / # wget https://docs.nebula-graph.io/2.0/basketballplayer-2.X.ngql 然后通过 Nebula Console 的 -f \u003cfile_path\u003e 把数据导入进去： nebula-console -addr graphd -port 9669 -user root -p nebula -f basketballplayer-2.X.ngql 至此，我们就启动了一个 Nebula Graph 图数据库，还在里边加载了篮球的知识图谱！ 💡：还记得前边我们提到的 在线体验 环境么？现在，我们可以在这个利用 Nebula-UP 部署了 Nebula 的环境里启动自己的 Nebula Studio 啦，按照上边 Nebula-UP 的提示：http://\u003c本机IP\u003e:7001 就是它的地址，然后大家可以参考文档和在线体验介绍去了解更多。 4.3.2 启动 Siwi-backend大家可以直接 clone 我的代码：git clone https://github.com/wey-gu/nebula-siwi/ 然后安装、启动 Siwi Backend： cd nebula-siwi # Install dependencies python3 -m pip install -r src/requirements.txt # Install siwi backend python3 -m build # Configure Nebula Graph Endpoint export NG_ENDPOINTS=127.0.0.1:9669 # Run Backend API server gunicorn --bind :5000 wsgi --workers 1 --threads 1 --timeout 60 启动之后，我们可以另外开窗口，通过 cURL 去发起问题给 backend，更多细节大家可以参考 GitHub 上的 README： 至此，我们已经写好了 QA 系统的重要的代码啦，大家是不是对一个 KBQA 的构成有了更清晰的概念了呢？ 接下来，我们为它增加一个界面！ ","date":"2021-12-30","objectID":"/siwi/:4:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#测试一下"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.3 测试一下 4.3.1 启动图数据库我们在 Nebula Graph 里建立（导入数据）一个篮球的知识图谱。 💡：在导入数据之前，请先部署一个 Nebula Graph 集群。最简便的部署方式是使用 Nebula-UP 这个小工具，只需要一行命令就能在 Linux 机器上同时启动一个 Nebula Graph 核心和可视化图探索工具 Nebula Graph Studio。如果你更愿意用 Docker 部署，请参考这个文档。 本文假设我们使用 Nebula-UP 来部署一个 Nebula Graph： curl -fsSL nebula-up.siwei.io/install.sh | bash 之后，我们会看到这样的提示： 按照提示，我们可以通过这个命令进入到有 Nebula Console 的容器里： 💡：Nebula Console 是命令行访问 Nebula Graph 图数据库的客户端，支持 Linux，Windows 和 macOS，下载地址：这里 ~/.nebula-up/console.sh 然后，在 # 的提示符下就表示我们进来了，我们在里边可以执行： nebula-console -addr graphd -port 9669 -user root -p nebula 这样就表示我们连接上了 Nebula Graph 图数据库： / # nebula-console -addr graphd -port 9669 -user root -p nebula Welcome to Nebula Graph! (root@nebula) [(none)]\u003e 在这里，我们就可以通过 nGQL 去操作 Nebula Graph，不过我们先退出来，执行 exit： (root@nebula) [(none)]\u003e exit Bye root! Fri, 31 Dec 2021 04:11:28 UTC 我们在这个容器内把基于 nGQL 语句的数据下载下来： / # wget https://docs.nebula-graph.io/2.0/basketballplayer-2.X.ngql 然后通过 Nebula Console 的 -f 把数据导入进去： nebula-console -addr graphd -port 9669 -user root -p nebula -f basketballplayer-2.X.ngql 至此，我们就启动了一个 Nebula Graph 图数据库，还在里边加载了篮球的知识图谱！ 💡：还记得前边我们提到的 在线体验 环境么？现在，我们可以在这个利用 Nebula-UP 部署了 Nebula 的环境里启动自己的 Nebula Studio 啦，按照上边 Nebula-UP 的提示：http://\u003c本机IP\u003e:7001 就是它的地址，然后大家可以参考文档和在线体验介绍去了解更多。 4.3.2 启动 Siwi-backend大家可以直接 clone 我的代码：git clone https://github.com/wey-gu/nebula-siwi/ 然后安装、启动 Siwi Backend： cd nebula-siwi # Install dependencies python3 -m pip install -r src/requirements.txt # Install siwi backend python3 -m build # Configure Nebula Graph Endpoint export NG_ENDPOINTS=127.0.0.1:9669 # Run Backend API server gunicorn --bind :5000 wsgi --workers 1 --threads 1 --timeout 60 启动之后，我们可以另外开窗口，通过 cURL 去发起问题给 backend，更多细节大家可以参考 GitHub 上的 README： 至此，我们已经写好了 QA 系统的重要的代码啦，大家是不是对一个 KBQA 的构成有了更清晰的概念了呢？ 接下来，我们为它增加一个界面！ ","date":"2021-12-30","objectID":"/siwi/:4:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#启动图数据库"},{"categories":["Nebula Graph","Mini Project"],"content":" 4.3 测试一下 4.3.1 启动图数据库我们在 Nebula Graph 里建立（导入数据）一个篮球的知识图谱。 💡：在导入数据之前，请先部署一个 Nebula Graph 集群。最简便的部署方式是使用 Nebula-UP 这个小工具，只需要一行命令就能在 Linux 机器上同时启动一个 Nebula Graph 核心和可视化图探索工具 Nebula Graph Studio。如果你更愿意用 Docker 部署，请参考这个文档。 本文假设我们使用 Nebula-UP 来部署一个 Nebula Graph： curl -fsSL nebula-up.siwei.io/install.sh | bash 之后，我们会看到这样的提示： 按照提示，我们可以通过这个命令进入到有 Nebula Console 的容器里： 💡：Nebula Console 是命令行访问 Nebula Graph 图数据库的客户端，支持 Linux，Windows 和 macOS，下载地址：这里 ~/.nebula-up/console.sh 然后，在 # 的提示符下就表示我们进来了，我们在里边可以执行： nebula-console -addr graphd -port 9669 -user root -p nebula 这样就表示我们连接上了 Nebula Graph 图数据库： / # nebula-console -addr graphd -port 9669 -user root -p nebula Welcome to Nebula Graph! (root@nebula) [(none)]\u003e 在这里，我们就可以通过 nGQL 去操作 Nebula Graph，不过我们先退出来，执行 exit： (root@nebula) [(none)]\u003e exit Bye root! Fri, 31 Dec 2021 04:11:28 UTC 我们在这个容器内把基于 nGQL 语句的数据下载下来： / # wget https://docs.nebula-graph.io/2.0/basketballplayer-2.X.ngql 然后通过 Nebula Console 的 -f 把数据导入进去： nebula-console -addr graphd -port 9669 -user root -p nebula -f basketballplayer-2.X.ngql 至此，我们就启动了一个 Nebula Graph 图数据库，还在里边加载了篮球的知识图谱！ 💡：还记得前边我们提到的 在线体验 环境么？现在，我们可以在这个利用 Nebula-UP 部署了 Nebula 的环境里启动自己的 Nebula Studio 啦，按照上边 Nebula-UP 的提示：http://\u003c本机IP\u003e:7001 就是它的地址，然后大家可以参考文档和在线体验介绍去了解更多。 4.3.2 启动 Siwi-backend大家可以直接 clone 我的代码：git clone https://github.com/wey-gu/nebula-siwi/ 然后安装、启动 Siwi Backend： cd nebula-siwi # Install dependencies python3 -m pip install -r src/requirements.txt # Install siwi backend python3 -m build # Configure Nebula Graph Endpoint export NG_ENDPOINTS=127.0.0.1:9669 # Run Backend API server gunicorn --bind :5000 wsgi --workers 1 --threads 1 --timeout 60 启动之后，我们可以另外开窗口，通过 cURL 去发起问题给 backend，更多细节大家可以参考 GitHub 上的 README： 至此，我们已经写好了 QA 系统的重要的代码啦，大家是不是对一个 KBQA 的构成有了更清晰的概念了呢？ 接下来，我们为它增加一个界面！ ","date":"2021-12-30","objectID":"/siwi/:4:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#启动-siwi-backend"},{"categories":["Nebula Graph","Mini Project"],"content":" 5 Siwi-frontend","date":"2021-12-30","objectID":"/siwi/:5:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#siwi-frontend"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.1 聊天界面我们利用 Vue Bot UI 这个可爱的机器人界面的 Vue 实现可以很容易构造一个 代码段：src/siwi/frontend/src/App.vue \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cVueBotUI :messages=\"msg\" :options=\"botOptions\" :bot-typing=\"locking\" :input-disable=\"locking\" @msg-send=\"msgSender\" /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import { VueBotUI } from 'vue-bot-ui' 注意到那个小飞机按钮了吧，它是发出问题请求的按键，我们要在按下它的时候对后端做出请求。 ","date":"2021-12-30","objectID":"/siwi/:5:1","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#聊天界面"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.2 访问后端这部分用到了Axios，它是浏览器里访问其他地址的 HTTP 客户端。 在按下的时候，@msg-send=\"msgSender\" 会触发 msgSender() msgSender()去构造axios.post(this.apiEndpoint, { \"question\": data.text }) 的请求给 Siwi 的后端 后端的结果被 push() 到界面的聊天消息里，渲染出来 this.msg.push() 代码段：src/siwi/frontend/src/App.vue \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cVueBotUI :messages=\"msg\" :options=\"botOptions\" :bot-typing=\"locking\" :input-disable=\"locking\" @msg-send=\"msgSender\" ---------------- 1. /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import { VueBotUI } from 'vue-bot-ui' import axios from \"axios\"; export default { name: 'App', components: { VueBotUI, }, methods: { msgSender(data) { this.msg.push({ agent: \"user\", type: \"text\", text: data.text, }); this.locking = true; axios.post(this.apiEndpoint, { \"question\": data.text }).then((response) =\u003e { console.log(response); ----------------- 2. this.msg.push({ ----------------- 3. agent: \"bot\", type: \"text\", text: response.data.answer, }); this.synthText = response.data.answer; this.agentSpeak = true; this.locking = false; }); }, } } 现在，我们已经有了一个图形界面的机器人啦，不过，更进一步，我们可以利用现代浏览器的接口，实现语音识别和机器人说话！ ","date":"2021-12-30","objectID":"/siwi/:5:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#访问后端"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.3 语音识别我们借助于 Vue Web Speech, 这个语音 API 的 VueJS 的绑定，可以很容易在按下 🎙️ 的时候接收人的语音，并把语音转换成文字发出去，在回答被返回之后，它（还是他/她😁？）也会把回答的句子读出来给用户。 record 在 🎙️ 被按下之后，变成 👂 触发 onResults() 监听 把返回结果发给 this.synthText 合成器，准备读出 \u003cvue-web-speech-synth\u003e 把语音读出 代码段：src/siwi/frontend/src/App.vue \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cbutton id=\"mic_btn\" @click=\"record = !record\"\u003e {{record?'👂':'🎙️'}} --------------------------\u003e 1. \u003c/button\u003e \u003cvue-web-speech v-model=\"record\" @results=\"onResults\" --------------------------\u003e 1. @unrecognized=\"unrecognized\" \u003e \u003c/vue-web-speech\u003e ... \u003cvue-web-speech-synth v-model=\"agentSpeak\" :voice=\"synthVoice\" :text=\"synthText\" @list-voices=\"listVoices\" --------------------------\u003e 4. /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import { VueBotUI } from 'vue-bot-ui' import axios from \"axios\"; export default { name: 'App', components: { VueBotUI, }, onResults (data) { -------------------------\u003e 2. this.results = data; this.locking = true; this.msg.push({ agent: \"user\", type: \"text\", text: data[0], }); this.locking = true; console.log(data[0]); axios.post(this.apiEndpoint, { \"question\": data[0] }).then((response) =\u003e { console.log(response.data); this.msg.push({ agent: \"bot\", type: \"text\", text: response.data.answer, }); this.synthText = response.data.answer; ----------\u003e 3. this.agentSpeak = true; }); this.locking = false; }, } } \u003c/script\u003e ","date":"2021-12-30","objectID":"/siwi/:5:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#语音识别"},{"categories":["Nebula Graph","Mini Project"],"content":" 6 总结至此，我们已经学会了搭建自己的第一个 KBQA：知识图谱驱动的问答系统。 回顾下它的代码结构： src/siwi 对应后端 App 是 Flask API 处理的部分 Bot 是处理请求、访问 Nebula Graph 的部分 src/siwi_frontend 是前端 希望大家在这个简陋的基础之上，多多探索，做出来更加成熟的聊天机器人，欢迎你来给我邮件、留言告诉我呀，这里：https://siwei.io/about 有我的联系方式。 . ├── README.md ├── src │ ├── siwi # Siwi-API Backend │ │ ├── app # Web Server, take HTTP requests and calls Bot API │ │ └── bot # Bot API │ │ ├── actions # Take Intent, Slots, Query Knowledge Graph here │ │ ├── bot # Entrypoint of the Bot API │ │ ├── classifier # Symentic Parsing, Intent Matching, Slot Filling │ │ └── test # Example Data Source as equivalent/mocked module │ └── siwi_frontend # Browser End │ ├── README.md │ ├── package.json │ └── src │ ├── App.vue # Listening to user and pass Questions to Siwi-API │ └── main.js └── wsgi.py 如果你很喜欢这样的小项目，欢迎来看看我之前的分享： 「从0-1：如何构建一个企业股权图谱系统？」哦。 💡：你知道吗，我其实借助于 Katacoda 已经为大家搭建了一个交互式体验 Siwi + Nebula 的部署的环境，如果您的网络条件够快（Katacoda服务器在国外），可以在这里点点鼠标就交互式体验它。 视频介绍 ","date":"2021-12-30","objectID":"/siwi/:6:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#总结"},{"categories":["Nebula Graph","Mini Project"],"content":" 7 感谢用到的开源项目 ❤️这个小项目里我们用到了好多开源的项目，非常感谢这些贡献者们的慷慨与无私，开源是不是很酷呢？ ","date":"2021-12-30","objectID":"/siwi/:7:0","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#感谢用到的开源项目-"},{"categories":["Nebula Graph","Mini Project"],"content":" 7.1 Backend KGQA on MedicalKG by Huanyong Liu Flask pyahocorasick created by Wojciech Muła PyYaml ","date":"2021-12-30","objectID":"/siwi/:7:1","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#backend"},{"categories":["Nebula Graph","Mini Project"],"content":" 7.2 Frontend VueJS for frontend framework Vue Bot UI, as a lovely bot UI in vue Vue Web Speech, for speech API vue wrapper Axios for browser http client Solarized for color scheme Vitesome for landing page design ","date":"2021-12-30","objectID":"/siwi/:7:2","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#frontend"},{"categories":["Nebula Graph","Mini Project"],"content":" 7.3 Graph Database Nebula Graph 高性能、云原生的开源分布式图数据库 ","date":"2021-12-30","objectID":"/siwi/:7:3","series":null,"tags":["Nebula Graph","图数据库","智能问答","语音助手","KBQA"],"title":"从零到一：如何构建一个基于知识图谱的智能问答助手？","uri":"/siwi/#graph-database"},{"categories":["Nebula Graph"],"content":"Docker 部署情况下使用 Python Storage Client 指南","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/"},{"categories":["Nebula Graph"],"content":" Python Storage Client 连不上第一次安装的 Nebula Graph？ Docker 部署情况下使用 Python Storage Client 指南 ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:0:0","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#"},{"categories":["Nebula Graph"],"content":" 1 前置条件 注意：一个重要的前置条件是我们真的需要 Storage Client，如果我们只需要在 Python Client 里通过 nGQL 来请求数据，那么 GraphClient 才是你需要的，可以跳过本文。 对于刚接触 Nebula 的同学，部署集群最快速的方式是用 Docker Compose，安装部署可以参考文档：deploy-nebula-graph-with-docker-compose。 在 docker compose up -d 之后，我们的 nebula 集群就起来了，我们可以用 docker ps 看看运行着的容器： ❯ docker ps --format \"table {{.Names}}\\t{{.Ports}}\" NAMES PORTS nebula-docker-compose-graphd1-1 0.0.0.0:61852-\u003e9669/tcp, 0.0.0.0:61850-\u003e19669/tcp, 0.0.0.0:61851-\u003e19670/tcp nebula-docker-compose-graphd-1 0.0.0.0:9669-\u003e9669/tcp, 0.0.0.0:61858-\u003e19669/tcp, 0.0.0.0:61859-\u003e19670/tcp nebula-docker-compose-graphd2-1 0.0.0.0:61855-\u003e9669/tcp, 0.0.0.0:61853-\u003e19669/tcp, 0.0.0.0:61854-\u003e19670/tcp nebula-docker-compose-storaged2-1 9777-9778/tcp, 9780/tcp, 0.0.0.0:61868-\u003e9779/tcp, 0.0.0.0:61869-\u003e19779/tcp, 0.0.0.0:61870-\u003e19780/tcp nebula-docker-compose-storaged1-1 9777-9778/tcp, 9780/tcp, 0.0.0.0:61865-\u003e9779/tcp, 0.0.0.0:61866-\u003e19779/tcp, 0.0.0.0:61864-\u003e19780/tcp nebula-docker-compose-storaged0-1 9777-9778/tcp, 9780/tcp, 0.0.0.0:61845-\u003e9779/tcp, 0.0.0.0:61843-\u003e19779/tcp, 0.0.0.0:61844-\u003e19780/tcp nebula-docker-compose-metad1-1 9560/tcp, 0.0.0.0:61705-\u003e9559/tcp, 0.0.0.0:61706-\u003e19559/tcp, 0.0.0.0:61707-\u003e19560/tcp nebula-docker-compose-metad2-1 9560/tcp, 0.0.0.0:61699-\u003e9559/tcp, 0.0.0.0:61700-\u003e19559/tcp, 0.0.0.0:61701-\u003e19560/tcp nebula-docker-compose-metad0-1 9560/tcp, 0.0.0.0:61704-\u003e9559/tcp, 0.0.0.0:61702-\u003e19559/tcp, 0.0.0.0:61703-\u003e19560/tcp 这里边有三种容器 ： GrpahD，查询引擎，也是我们用户进行登录、连接、发 Query 请求直接访问的唯一一种服务、接口。 MetaD，元数据服务，它一般不会暴露给外部，只有 GraphD 、StorageD 会直接访问它。 StorageD，存储引擎，它一般不会暴露给外部，只有 GraphD、StorageD 会直接访问它。 我们可以从 Stuido Console，或者 Nebula Console （连接到 GraphD 之后）里通过 SHOW HOSTS \u003cType\u003e，来获取每种服务的信息，其中第一列的信息就是他们的 IP 或者 Host，下边的例子是 Docker Compose 默认配置下的情况。 (root@nebula) [(none)]\u003e SHOW HOSTS GRAPH +-----------+------+----------+---------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +-----------+------+----------+---------+--------------+---------+ | \"graphd\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\" | \"2.6.0\" | +-----------+------+----------+---------+--------------+---------+ | \"graphd1\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\" | \"2.6.0\" | +-----------+------+----------+---------+--------------+---------+ | \"graphd2\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\" | \"2.6.0\" | +-----------+------+----------+---------+--------------+---------+ (root@nebula) [(none)]\u003e SHOW HOSTS META +----------+------+----------+--------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +----------+------+----------+--------+--------------+---------+ | \"metad1\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\" | \"2.6.0\" | +----------+------+----------+--------+--------------+---------+ | \"metad0\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\" | \"2.6.0\" | +----------+------+----------+--------+--------------+---------+ | \"metad2\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\" | \"2.6.0\" | +----------+------+----------+--------+--------------+---------+ (root@nebula) [(none)]\u003e SHOW HOSTS STORAGE +-------------+------+----------+-----------+--------------+---------+ | Host | Port | Status | Role | Git Info Sha | Version | +-------------+------+----------+-----------+--------------+---------+ | \"storaged0\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\" | \"2.6.0\" | +-------------+------+----------+-----------+--------------+---------+ | \"storaged1\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\" | \"2.6.0\" | +-------------+------+----------+-----------+--------------+---------+ | \"storaged2\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\" | \"2.6.0\" | +-------------+------+----------+-----------+--------------+---------+ 在默认的 nebula-docker-compose 的配置下各个服务为graphd, metad1, storaged0 这种域名的 Host 格式，这其实是假设了我们使用 Docker 启动的服务一般是作为单机测试之用，除了其中的 graphd之外，其他的服务都没有指定固定的外部映射端口（见前边的 docker ps 的结果里，它暴露在0.0.0.0:9669)。 这意味着，如果客户端不是运行在本机，访问其他服务的端口都是动态的，这会让很多第一次想用 Python Storage Client 连接服务的同学卡住。 所以我这里给大家分享一个快速用 Python 去调试 Storage Client 的方法： 本质上我们可以通过修改 Compose 的配置文件、通过其他部署或者配置的方式安装 Nebula 来保证 Python Client 能够","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:0","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#前置条件"},{"categories":["Nebula Graph"],"content":" 1.1 第一步，把 Python 容器在 nebula-docker-compose_nebula-net 这个容器网络启动一个 Jupyter 的容器。 这里采用了 https://github.com/jupyter/docker-stacks 维护的 Docker Image。 docker run \\ -p 8888:8888 \\ --network nebula-docker-compose_nebula-net \\ jupyter/scipy-notebook:33add21fab64 可以看到容器了，并且在监听端口：8888。 [I 07:06:31.060 NotebookApp] Jupyter Notebook 6.3.0 is running at: [I 07:06:31.060 NotebookApp] http://e170a5eb4858:8888/?token=5beafb26fc6995b081c611d5d2cc96d557897b74bfdaac53 [I 07:06:31.060 NotebookApp] or http://127.0.0.1:8888/?token=5beafb26fc6995b081c611d5d2cc96d557897b74bfdaac53 这时候我们可在浏览器打开 http://127.0.0.1:8888/?token=5beafb26fc6995b081c611d5d2cc96d557897b74bfdaac53. 在里边新建一个 Notebook。 ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:1","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#第一步把-python-容器"},{"categories":["Nebula Graph"],"content":" 1.2 第二步，安装 Nebula Python SDK我们只需要在 Jupyter 里执行 !pip install nebula2-python==2.6.0 就可以了，具体的版本要根据 Nebula Python 的 README 里的版本对应关系来给定。 ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:2","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#第二步安装-nebula-python-sdk"},{"categories":["Nebula Graph"],"content":" 1.3 第三步，实例化 MetaCache 和 GraphStorageClient from nebula2.mclient import MetaCache, HostAddr from nebula2.sclient.GraphStorageClient import GraphStorageClient # Docker Compose 下默认 meta 的地址是 metad1 metad0 metad2 meta_cache = MetaCache([('metad1',9559),('metad0',9559),('metad2',9559)]) graph_storage_client = GraphStorageClient(meta_cache) ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:3","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#第三步实例化-metacache-和-graphstorageclient"},{"categories":["Nebula Graph"],"content":" 1.4 第四步，扫数据 按空间、点类型扫点 resp = graph_storage_client.scan_vertex( space_name='basketballplayer', tag_name='player') while resp.has_next(): result = resp.next() for vertex_data in result: print(vertex_data) 按空间、边类型扫边 resp = graph_storage_client.scan_edge( space_name='basketballplayer', edge_name='follow') while resp.has_next(): result = resp.next() for edge_data in result: print(edge_data) Jupyter 的过程我也记录在这个 notebook 里方便大家参考。 Happy Graphing! Picture Credit：Borderpolar Photographer ","date":"2021-12-10","objectID":"/nebula-python-storage-docker-guide/:1:4","series":null,"tags":["Nebula Graph","图数据库","python"],"title":"快速搭建调试 Nebula Graph Python Storage 客户端的环境","uri":"/nebula-python-storage-docker-guide/#第四步扫数据"},{"categories":["Nebula Graph"],"content":"如何快速、即时、符合直觉地去处理 Nebula Java Client 中的数据解析？","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/"},{"categories":["Nebula Graph"],"content":" 如何快速、即时、符合直觉地去处理 Nebula Java Client 中的数据解析？读这一篇就够了。 更新: 2022-Aug-10, adapted to nebulagraph 3.x ","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:0:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#"},{"categories":["Nebula Graph"],"content":" 1 关键步骤：几行准备一个干净的交互式 Nebula Java REPL 环境多亏了 Java-REPL 我们可以很方便地（像 iPython 那样）去实时交互地调试、分析 Nebula Java 客户端，我们用它的 Docker 镜像可以很干净的去搞定： docker pull albertlatacz/java-repl docker run --rm -it \\ --network=nebula-net \\ -v ~:/root \\ albertlatacz/java-repl \\ bash apt update -y \u0026\u0026 apt install ca-certificates -y wget https://dlcdn.apache.org/maven/maven-3/3.8.6/binaries/apache-maven-3.8.6-bin.tar.gz --no-check-certificate tar xzvf apache-maven-3.8.6-bin.tar.gz wget https://github.com/vesoft-inc/nebula-java/archive/refs/tags/v3.0.0.tar.gz tar xzvf v3.0.0.tar.gz cd nebula-java-3.0.0/ ../apache-maven-3.8.6/bin/mvn dependency:copy-dependencies ../apache-maven-3.8.6/bin/mvn -B package -Dmaven.test.skip=true java -jar ../javarepl/javarepl.jar 这时候，在执行完 java -jar ../javarepl/javarepl.jar 之后，我们就进入了交互式的 Java Shell（REPL），我们可以无需做编译，执行，print 这样的慢反馈来调试和研究我们的代码了，是不是很方便？ root@a2e26ba62bb6:/javarepl/nebula-java-3.0.0# java -jar ../javarepl/javarepl.jar Welcome to JavaREPL version 428 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_111) Type expression to evaluate, :help for more options or press tab to auto-complete. Connected to local instance at http://localhost:43707 java\u003e System.out.println(\"Hello, World!\"); Hello, World! java\u003e 首先我们在 java\u003e 提示符下，这些来把必须的类路径和导入： :cp /javarepl/nebula-java-3.0.0/client/target/client-3.0.0.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/fastjson-1.2.78.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/slf4j-api-1.7.25.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/slf4j-log4j12-1.7.25.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/commons-pool2-2.2.jar :cp /javarepl/nebula-java-3.0.0/client/target/dependency/log4j-1.2.17.jar import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONObject; import com.vesoft.nebula.ErrorCode; import com.vesoft.nebula.client.graph.NebulaPoolConfig; import com.vesoft.nebula.client.graph.data.CASignedSSLParam; import com.vesoft.nebula.client.graph.data.HostAddress; import com.vesoft.nebula.client.graph.data.ResultSet; import com.vesoft.nebula.client.graph.data.SelfSignedSSLParam; import com.vesoft.nebula.client.graph.data.ValueWrapper; import com.vesoft.nebula.client.graph.net.NebulaPool; import com.vesoft.nebula.client.graph.net.Session; import java.io.UnsupportedEncodingException; import java.util.Arrays; import java.util.List; import java.util.concurrent.TimeUnit; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.lang.reflect.*; 我们可以从这 Java 环境连接到 Nebula Graph 里，下边的例子里我用了自己的 GraphD 的 IP 和端口作为例子： NebulaPoolConfig nebulaPoolConfig = new NebulaPoolConfig(); nebulaPoolConfig.setMaxConnSize(10); List\u003cHostAddress\u003e addresses = Arrays.asList(new HostAddress(\"192.168.8.127\", 9669)); NebulaPool pool = new NebulaPool(); pool.init(addresses, nebulaPoolConfig); Session session = pool.getSession(\"root\", \"nebula\", false); ","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:1:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#关键步骤几行准备一个干净的交互式-nebula-java-repl-环境"},{"categories":["Nebula Graph"],"content":" 2 通过调用 execute 方法获得不太容易懂的 ResultSet 对象刚接触这里的大家一定对这个 ResultSet 对象有些愁，借助我们的环境，咱们来十分钟把它搞通吧，这里我们执行一个简单的返回 Vertex 顶点的结果看看： ResultSet resp = session.execute(\"USE basketballplayer;MATCH (n:player) WHERE n.name==\\\"Tim Duncan\\\" RETURN n\"); 这里我们可以参考 ResultSet 的代码： Reference: client/graph/data/ResultSet.java 好吧，其实可以先不看，跟着我的教程往下走吧，我们知道结果都是二维的表，ResultSet 提供了常见的针对行、列的一些方法，通常，我们是获取每一行，然后解析它，而关键的问题是每一个值要怎么处理，对吧。 java\u003e resp.isSucceeded() java.lang.Boolean res9 = true java\u003e resp.rowsSize() java.lang.Integer res16 = 1 java\u003e rows = resp.getRows() java.util.ArrayList rows = [Row ( values : [ \u003cValue vVal:Vertex ( vid : \u003cValue sVal:70 6c 61 79 65 72 31 30 30\u003e, tags : [ Tag ( name : 70 6C 61 79 65 72, props : { [B@5264a468 : \u003cValue iVal:42\u003e [B@496b8e10 : \u003cValue sVal:54 69 6d 20 44 75 6e 63 61 6e\u003e } ) ] )\u003e ] )] java\u003e row0 = resp.rowValues(0) java.lang.Iterable\u003ccom.vesoft.nebula.client.graph.data.ValueWrapper\u003e res10 = ColumnName: [n], Values: [(\"player100\" :player {name: \"Tim Duncan\", age: 42})] 我们其实回到这次的 query ，其实是返回一个 vertex：顶点： (root@nebula) [basketballplayer]\u003e match (n:player) WHERE n.name == \"Tim Duncan\" return n +----------------------------------------------------+ | n | +----------------------------------------------------+ | (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) | +----------------------------------------------------+ Got 1 rows (time spent 2116/44373 us) 通过上边的几个方法，我们其实能够获得这个顶点的值： v = Class.forName(\"com.vesoft.nebula.Value\") v.getDeclaredMethods() 然而，我们可以看出来这个 com.vesoft.nebula.Value 的值的类提供的方法特别特别原始，这也是让大家犯愁的原因，在这个教程里最重要的一个带走的经验（除了利用 REPL之外）就是：除非必要，不要去取这个原始的类，我们应该去取得 ValueWrapper 封装之后的值！！！ 注意：其实我们有更轻松地方法，就是用 executeJson 直接获得 JSON string，别担心，会在后边提到，不过这个方法要 2.6 之后才支持。 那么问题来了，如何使用 ValueWrapper 封装呢？其实答案已经在上边了，大家可以回去看看，resp.rowValues(0) 的类型正是 ValueWrapper 的可迭代对象！ 所以，正确打开方式是迭它！迭它！迭它！其实这个就是代码库里的 GraphClientExample 的一部分例子了，我们把它迭代取出来，放到 wrappedValueList 里慢慢把玩： import java.util.ArrayList; import java.util.List; List\u003cValueWrapper\u003e wrappedValueList = new ArrayList\u003c\u003e(); for (int i = 0; i \u003c resp.rowsSize(); i++) { ResultSet.Record record = resp.rowValues(i); for (ValueWrapper value : record.values()) { wrappedValueList.add(value); if (value.isLong()) { System.out.printf(\"%15s |\", value.asLong()); } if (value.isBoolean()) { System.out.printf(\"%15s |\", value.asBoolean()); } if (value.isDouble()) { System.out.printf(\"%15s |\", value.asDouble()); } if (value.isString()) { System.out.printf(\"%15s |\", value.asString()); } if (value.isTime()) { System.out.printf(\"%15s |\", value.asTime()); } if (value.isDate()) { System.out.printf(\"%15s |\", value.asDate()); } if (value.isDateTime()) { System.out.printf(\"%15s |\", value.asDateTime()); } if (value.isVertex()) { System.out.printf(\"%15s |\", value.asNode()); } if (value.isEdge()) { System.out.printf(\"%15s |\", value.asRelationship()); } if (value.isPath()) { System.out.printf(\"%15s |\", value.asPath()); } if (value.isList()) { System.out.printf(\"%15s |\", value.asList()); } if (value.isSet()) { System.out.printf(\"%15s |\", value.asSet()); } if (value.isMap()) { System.out.printf(\"%15s |\", value.asMap()); } } System.out.println(); } 上边这些很丑的 if 就是关键了，我们知道 query 的返回值可能是多种类型的，他们分为： 图语义的：点、边、路径 数据类型：String，日期，列表，集合 等等等 这里的关键是，我们要使用 ValueWrapper 为我们准备好的 asXxx 方法，如果这个值是一个顶点，么这个 Xxx 就是 Node，同理如果是边的话，这个 Xxx 就是 Relationship。 所以，我给大家看看咱们这个返回点结果的情况下的 asNode() 方法： java\u003e v = wrappedValueList.get(0) com.vesoft.nebula.client.graph.data.ValueWrapper v = (\"player100\" :player {name: \"Tim Duncan\", age: 42}) java\u003e v.asNode() com.vesoft.nebula.client.graph.data.Node res16 = (\"player100\" :player {name: \"Tim Duncan\", age: 42}) java\u003e node = v.asNode() com.vesoft.nebula.client.graph.data.Node node = (\"player100\" :player {name: \"Tim Duncan\", age: 42}) 顺便说一下，借助于 Java 的 reflection ，我们可以在这个交互程序里做类似于 Python 里 dir() 的事情，实时地去获取一个类支持的方法，像这样，省去了查代码。 java\u003e rClass=Class.forName(\"com.vesoft.nebula.client.graph.data.ResultSet\") java.lang.Class r = class com.vesoft.nebula.client.graph.data.ResultSet java\u003e rClass.getDeclaredMethods() java.lang.reflect.","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:2:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#通过调用-execute-方法获得不太容易懂的-resultset-对象"},{"categories":["Nebula Graph"],"content":" 3 直接返回 JSON 的 executeJson 方法最后，好消息是，从 2.6 开始，nebula 可以直接返回 JSON 的 String 了，我们上边的纠结也都不是必要的了： java\u003e String resp_json = session.executeJson(\"USE basketballplayer;MATCH (n:player) WHERE n.name==\\\"Tim Duncan\\\" RETURN n\"); java.lang.String resp_json = \" { \"errors\":[ { \"code\":0 } ], \"results\":[ { \"spaceName\":\"basketballplayer\", \"data\":[ { \"meta\":[ { \"type\":\"vertex\", \"id\":\"player100\" } ], \"row\":[ { \"player.age\":42, \"player.name\":\"Tim Duncan\" } ] } ], \"columns\":[ \"n\" ], \"errors\":{ \"code\":0 }, \"latencyInUs\":4761 } ] } \" 我相信大家肯定比我更擅长处理 JSON 的结果了哈~~ ","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:3:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#直接返回-json-的-executejson-方法"},{"categories":["Nebula Graph"],"content":" 4 结论 如果我们有条件（2.6以后）用 JSON，情况会很容易，可能大家不太需要本文的方法（不过有交互环境还是很方便吧？） 如果我们不得不和 resultSet 打交道，记得用 ValueWrapper ，因为我们可以用 asNode()，asRelationship() 和 asPath() ，封装之后的值比原始的值可爱太多了！ 通过 REPL 工具，结合 Java 的 reflection 加上 源代码本身，分析数据的处理将变得异常顺滑 Happy Graphing! Picture Credit：leunesmedia ","date":"2021-11-25","objectID":"/nebula-java-happy-parsing-guide/:4:0","series":null,"tags":["Nebula Graph","图数据库","java"],"title":"Nebula Graph 的 Java 数据解析实践与指导","uri":"/nebula-java-happy-parsing-guide/#结论"},{"categories":["Nebula Graph","Mini Project"],"content":"如何利用图数据库从零到一构建一个具有股权分析的图谱与线上系统呢？本文手把手带你构建一个简易版的股权穿透图谱系统。","date":"2021-11-24","objectID":"/corp-rel-graph/","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/"},{"categories":["Nebula Graph","Mini Project"],"content":" 如何构建一个具有股权分析的图谱与线上系统呢？本文里，我将利用图数据库从零到一带你构建一个简易版的股权穿透图谱系统。 我们知道无论是监管部门、企业还是个人，都有需求去针对一个企业、法人做一些背景调查，这些调查可以是法律诉讼、公开持股、企业任职等等多种多样的信息。这些背景信息可以辅助我们做商业上的重要决策，规避风险：比如根据公司的股权关系，了解是否存在利益冲突比如是否选择与一家公司进行商业往来。 在满足这样的关系分析需求的时候，我们往往面临一些挑战，比如： 如何将这些数据的关联关系体现在系统之中？使得它们可以被挖掘、利用 多种异构数据、数据源之间的关系可能随着业务的发展引申出更多的变化，在结构数据库中，这意味着 Schema 变更 分析系统需要尽可能实时获取需要的查询结果，这通常涉及到多跳关系查询 领域专家能否快速灵活、可视化获取分享信息 那么如何构建这样一个系统解决以上挑战呢？ ","date":"2021-11-24","objectID":"/corp-rel-graph/:0:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#"},{"categories":["Nebula Graph","Mini Project"],"content":" 1 数据存在哪里？ 前提：数据集准备，为了更好的给大家演示解决这个问题，我写了一个轮子能随机生成股权结构相关的数据，生成的数据的例子在这里。 这里，我们有法人、公司的数据，更有公司与子公司之间的关系，公司持有公司股份，法人任职公司，法人持有公司股份和法人之间亲密度的关系数据。 数据存在哪里？这是一个关键的问题，这里我们剧透一下，答案是：图数据库。然后我们再简单解释一下为什么这样一个股权图谱系统跑在图数据库上是更好的。 在这样一个简单的数据模型之下，我们可以很直接的在关系型数据库中这么建模： 而这么建模的问题在于：这种逻辑关联的方式使得无论数据的关联关系查询表达、存储、还是引入新的关联关系都不是很高效。 查询表达不高效是因为关系型数据库是面向表结构设计的，这决定了关系查询要写嵌套的 JOIN。 这就是前边提到的挑战 1：能够表达，但是比较勉强，遇到稍微复杂的情况就变得很难。 存储不高效是因为表结构被设计的模式是面向数据记录，而非数据之间的关系：我们虽然习惯了将数据中实体（比如法人）和实体关联（比如持有股权 hold_sharing_relationship）以另外一个表中的记录来表达、存储起来，这逻辑上完全行得通，但是到了多跳、大量需要请求数据关系跳转的情况下，这样跨表 JOIN 的代价就成为了瓶颈。 这就是前边提到的挑战 3：无法应对多条查询的性能需要。 引入新的关联关系代价大，还是前边提到的，表结构下，用新的表来表达持有股权 hold_sharing_relationship这个关联关系是可行的，但是这非常不灵活、而且昂贵，它意味着我们在引入这个关系的时候限定了起点终点的类型，比如股权持有的关系可能是法人-\u003e公司，也可能是公司-\u003e公司，随着业务的演进，我们可能还需要引入政府-\u003e公司的新关系，而这些变化都需要做有不小代价的工作：改动 Schema。 这就是前边提到的挑战 2：无法应对业务上对数据关系上灵活多变的要求。 当一个通用系统无法满足不可忽视的具体需求的时候，一个新的系统就会诞生，这就是图数据库，针对这样的场景，图数据库很自然地特别针对关联关系场景去设计整个数据库： 面向关联关系表达的语义。（挑战 1） 如下表，我列举了一个等价的一跳查询在表结构数据库与图数据库中，查询语句的区别。大家应该可以看出“找到所有持有和 p_100 共同持有公司股份的人”这样的查询表达可以在图数据库如何自然表达，这仅仅是一条查询的区别，如果是多跳的话，他们的复杂度区分还会更明显一些。 表结构数据库 图数据库（属性图） 将关联关系存储为物理连接，从而使得跳转查询代价最小。（挑战 3、2） 图数据之中，从点拓展（找到一个或者多个关系的另一头）出去的代价是非常小的，这因为图数据库是一个专有的系统，得益于它主要关心“图”结构的设计，查找确定的实体（比如和一个法人 A ）所有关联（可能是任职、亲戚、持有、等等关系）其他所有实体（公司、法人）这个查找的代价是 O(1) 的，因为它们在图数据库的数据机构里是真的链接在一起的。 大家可以从下表的定量参考数据一窥图数据库在这种查询下的优势，这种优势在多跳高并发情况下的区别是“能”与”不能“作为线上系统的区别，是“实时”与“离线”的区别。 在面向关联关系的数据建模和数据结构之下，引入新的实体、关联关系的代价要小很多，还是前边提到的例子： 在 Nebula Graph 图数据中引入一个新的“政府机构”类型的实体，并增加政府机构-\u003e公司的“持有股份”的关联关系相比于在非图模型的数据库中的代价小很多。 表结构数据库 图数据库（属性图） 4 跳查询时延 1544 秒 4 跳查询时延 1.36 秒 建模符合直觉；图数据库有面向数据连接的数据可视化能力（挑战 4） 大家在下表第二列中可以对比我们本文中进行的股权分析数据在两种数据库之中的建模的区别，尤其是在关心关联关系的场景下，我们可以感受到属性图的模型建立是很符合人类大脑直觉的，而这和大脑之中神经元的结构可能也有一些关系。 图数据库中内置的可视化工具提供了一般用户便捷理解数据关系的能力，也给领域专家用户提供了表达请求复杂数据关系的直观接口。 表结构数据库 图数据库（属性图） 表结构数据库与图数据库的总体比较： 表结构数据库 图数据库（属性图） 查询 建模 性能 4 跳查询时延 1544 秒 4 跳查询时延 1.36 秒 综上，在本教程里，我们将利用图数据库来进行数据存储。 ","date":"2021-11-24","objectID":"/corp-rel-graph/:1:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#数据存在哪里"},{"categories":["Nebula Graph","Mini Project"],"content":" 2 图数据建模前面在讨论数据存在哪里的时候，我们已经揭示了在图数据库中建模的方式：本质上，在这张图中，将会有两种实体： 人 公司 四种关系： 人 –作为亲人–\u003e人 人 –作为角色–\u003e 公司 人 或者 公司 –持有股份–\u003e 公司 公司 –作为子机构–\u003e 公司 这里面，实体与关系本身都可以包含更多的信息，这些信息在图数据库里就是实体、关系自身的属性。如下图表示： 人的属性包括 name，age 公司的属性包括 name，location 持有股份 这个关系有属性 share(份额) 任职这个关系有属性 role，level ","date":"2021-11-24","objectID":"/corp-rel-graph/:2:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#图数据建模"},{"categories":["Nebula Graph","Mini Project"],"content":" 3 数据入库本教程中，我们使用的图数据库叫做 Nebula Graph（星云图数据库），它是一个以 Apache 2.0 许可证开源的分布式图数据库。 Nebula Graph in Github: https://github.com/vesoft-inc/nebula 在向 Nebula Graph 导入数据的时候，关于如何选择工具，请参考这篇文档和这个视频。 这里，由于数据格式是 csv 文件并且利用单机的客户端资源就足够了，我们可以选择使用 nebula-importer 来完成这个工作。 提示：在导入数据之前，请先部署一个 Nebula Graph 集群，最简便的部署方式是使用 nebula-up 这个小工具，只需要一行命令就能在 Linux 机器上同时启动一个 Nebula Graph 核心和可视化图探索工具 Nebula Graph Studio。如果你更愿意用 Docker 部署，请参考这个文档。 本文假设我们使用 Nebula-UP 来部署： curl -fsSL nebula-up.siwei.io/install.sh | bash 这里的数据是生成器生成的，你可以按需生成任意规模随机数据集，或者选择一份生成好了的数据在这里 有了这些数据，我们可以开始导入了。 $ pip install Faker==2.0.5 pydbgen==1.0.5 $ python3 data_generator.py $ ls -l data total 1688 -rw-r--r-- 1 weyl staff 23941 Jul 14 13:28 corp.csv -rw-r--r-- 1 weyl staff 1277 Jul 14 13:26 corp_rel.csv -rw-r--r-- 1 weyl staff 3048 Jul 14 13:26 corp_share.csv -rw-r--r-- 1 weyl staff 211661 Jul 14 13:26 person.csv -rw-r--r-- 1 weyl staff 179770 Jul 14 13:26 person_corp_role.csv -rw-r--r-- 1 weyl staff 322965 Jul 14 13:26 person_corp_share.csv -rw-r--r-- 1 weyl staff 17689 Jul 14 13:26 person_rel.csv 导入工具 nebula-importer 是一个 golang 的二进制文件，使用方式就是将导入的 Nebula Graph 连接信息、数据源中字段的含义的信息写进 YAML 格式的配置文件里，然后通过命令行调用它。可以参考文档或者它的 GitHub 仓库里的例子。 这里我已经写好了准备好了一份 nebula-importer 的配置文件，在数据生成器同一个 repo 之下的这里。 最后，只需要执行如下命令就可以开始数据导入了： 注意，在写本文的时候，nebula 的新版本是 2.6.1，这里对应的 nebula-importer 是 v2.6.0，如果您出现导入错误可能是版本不匹配，可以相应调整下边命令中的版本号。 git clone https://github.com/wey-gu/nebula-shareholding-example cp -r data_sample /tmp/data cp nebula-importer.yaml /tmp/data/ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v /tmp/data:/root \\ vesoft/nebula-importer:v2.6.0 \\ --config /root/nebula-importer.yaml 你知道吗？TL;DR 实际上，这份 importer 的配置里帮我们做了 Nebula Graph 之中的图建模的操作，它们的指令在下边，我们不需要手动去执行了。 CREATE SPACE IF NOT EXISTS shareholding(partition_num=5, replica_factor=1, vid_type=FIXED_STRING(10)); USE shareholding; CREATE TAG person(name string); CREATE TAG corp(name string); CREATE TAG INDEX person_name on person(name(20)); CREATE TAG INDEX corp_name on corp(name(20)); CREATE EDGE role_as(role string); CREATE EDGE is_branch_of(); CREATE EDGE hold_share(share float); CREATE EDGE reletive_with(degree int); ","date":"2021-11-24","objectID":"/corp-rel-graph/:3:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#数据入库"},{"categories":["Nebula Graph","Mini Project"],"content":" 4 图库中查询数据 Tips: 你知道吗，你也可以无需部署安装，通过 Nebula-Playground 之中，找到股权穿透来在线访问同一份数据集。 我们可以借助 Nebula Graph Studio 来访问数据，访问我们部署 Nebula-UP 的服务器地址的 7001 端口就可以了： 假设服务器地址为 192.168.8.127，则有： Nebula Studio 地址：192.168.8.127:7001 Nebula Graph 地址：192.168.8.127:9669 默认用户名：root 默认密码：nebula 访问 Nebula Studio： 选择图空间: Shareholding 之后，我们就可以在里边探索比如一个公司的三跳以内的股权穿透，具体的操作可以参考：股权穿透在线 Playground 的介绍： ","date":"2021-11-24","objectID":"/corp-rel-graph/:4:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#图库中查询数据"},{"categories":["Nebula Graph","Mini Project"],"content":" 5 构建一个图谱系统 这部分的代码开源在 GitHub 上： https://github.com/wey-gu/nebula-corp-rel-search 本项目的 Demo 也在 PyCon China 2021 上的演讲中有过展示：视频地址 在此基础之上，我们可以构建一个提供给终端用户来使用的股权查询系统了，我们已经有了图数据库作为这个图谱的存储引擎，理论上，如果业务允许，我们可以直接使用或者封装 Nebula Graph Studio 来提供服务，这完全是可行也是合规的，不过，有一些情况下，我们需要自己去实现界面、或者我们需要封装出一个 API 给上游（多端）提供图谱查询的功能。 为此，我为大家写了一个简单的实例项目，提供这样的服务，他的架构也很直接： 前端接受用户要查询的穿透法人、公司，按需发请求给后端，并用 D3.js 将返回结果渲染为关系图 后端接受前端的 API 请求，将请求转换为 Graph DB 的查询，并返回前端期待的结果 ┌───────────────┬───────────────┐ │ │ Frontend │ │ │ │ │ ┌──────────▼──────────┐ │ │ │ Vue.JS │ │ │ │ D3.JS │ │ │ └──────────┬──────────┘ │ │ │ Backend │ │ ┌──────────┴──────────┐ │ │ │ Flask │ │ │ │ Nebula-Python │ │ │ └──────────┬──────────┘ │ │ │ Graph Query │ │ ┌──────────▼──────────┐ │ │ │ Graph Database │ │ │ └─────────────────────┘ │ │ │ └───────────────────────────────┘ ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#构建一个图谱系统"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.1 后端服务–\u003e图数据库 详细的数据格式分析大家可以参考这里 5.1.1 查询语句我们假设用户请求的实体是 c_132 ，那么请求 1 到 3 步的关系穿透的语法是： MATCH p=(v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) \\ WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 这里边 ()包裹的是图之中的点，而[] 包裹的则是点之间的关系：边，所以： (v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) 之中的： (v)-[xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]-(v2)应该比较好理解，意思是从 v 到v2 做拓展。 现在我们介绍中间[]包裹的部分，这里，它的语义是：经由四种类型的边（:之后的是边的类型，|代表或者）通过可变的跳数：*1..3 （一跳到三跳）。 所以，简单来说整理看开，我们的拓展的路径是：从点 v 开始，经由四种关系一到三跳拓展到点v2，返回整个拓展路径 p，限制 100 个路径结果，其中 v 是 c_132。 5.1.2 Nebula Python Client/ SDK我们已经知道了查询语句的语法，那么就只需要在后端程序里根据请求、通过图数据库的客户端来发出查询请求，并处理返回结构就好了。在今天的例子中，我选择使用 Python 来实现后端的逻辑，所以我用了 Nebula-python 这个库，它是 Nebula 的 Python Client。 你知道么？截至到现在，Nebula 在 GitHub 上有 Java，GO，Python，C++，Spark，Flink，Rust（未GA），NodeJS（未GA） 的客户端支持，更多的语言的客户端也会慢慢被发布哦。 下边是一个 Python Client 执行一个查询并返回结果的例子，值得注意的是，在我实现这个代码的时候，Nebula Python 尚未支持返回 JSON （通过session.execute_json()）结果，如果你要实现自己的代码，我非常推荐试试 JSON 哈，就可以不用从对象中一点点取数据了，不过借助 iPython/IDLE 这种 REPL，快速了解返回对象的结构也没有那么麻烦。 $ python3 -m pip install nebula2-python==2.5.0 # 注意这里我引用旧的记录，它是 2.5.0， $ ipython In [1]: from nebula2.gclient.net import ConnectionPool In [2]: from nebula2.Config import Config In [3]: config = Config() ...: config.max_connection_pool_size = 10 ...: # init connection pool ...: connection_pool = ConnectionPool() ...: # if the given servers are ok, return true, else return false ...: ok = connection_pool.init([('192.168.8.137', 9669)], config) ...: session = connection_pool.get_session('root', 'nebula') [2021-10-13 13:44:24,242]:Get connection to ('192.168.8.137', 9669) In [4]: resp = session.execute(\"use shareholding\") In [5]: query = ''' ...: MATCH p=(v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) \\ ...: WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 ...: ''' In [6]: resp = session.execute(query) # Note: after nebula graph 2.6.0, we could use execute_json as well In [7]: resp.col_size() Out[7]: 1 In [9]: resp.row_size() Out[10]: 100 我们往下分析看看，我们知道这个请求本质上结果是路径，它有一个 .nodes() 方法和 .relationships()方法来获得路径上的点和边： In [11]: p=resp.row_values(22)[0].as_path() In [12]: p.nodes() Out[12]: [(\"c_132\" :corp{name: \"Chambers LLC\"}), (\"p_4000\" :person{name: \"Colton Bailey\"})] In [13]: p.relationships() Out[13]: [(\"p_4000\")-[:role_as@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\")] 对于边来说有这些方法 .edge_name(), .properties(), .start_vertex_id(), .end_vertex_id()，这里 edge_name 是获得边的类型。 In [14]: rel=p.relationships()[0] In [15]: rel Out[15]: (\"p_4000\")-[:role_as@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\") In [16]: rel.edge_name() Out[16]: 'role_as' In [17]: rel.properties() Out[17]: {'role': \"Editorial assistant\"} In [18]: rel.start_vertex_id() Out[18]: \"p_4000\" In [19]: rel.end_vertex_id() Out[19]: \"c_132\" 对于点来说，可以用到这些方法 .tags(), properties, get_id()，这里边 tags 是获得点的类型，它在 Nebula 里叫标签tag。 这些概念可以在文档里获得更详细的解释。 In [20]: node=p.nodes()[0] In [21]: node.tags() Out[21]: ['corp'] In [22]: node.properties('corp') Out[22]: {'name': \"Chambers LLC\"} In [23]: node.get_id() Out[23]: \"c_132\" ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:1","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#后端服务--图数据库"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.1 后端服务–\u003e图数据库 详细的数据格式分析大家可以参考这里 5.1.1 查询语句我们假设用户请求的实体是 c_132 ，那么请求 1 到 3 步的关系穿透的语法是： MATCH p=(v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) \\ WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 这里边 ()包裹的是图之中的点，而[] 包裹的则是点之间的关系：边，所以： (v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) 之中的： (v)-[xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]-(v2)应该比较好理解，意思是从 v 到v2 做拓展。 现在我们介绍中间[]包裹的部分，这里，它的语义是：经由四种类型的边（:之后的是边的类型，|代表或者）通过可变的跳数：*1..3 （一跳到三跳）。 所以，简单来说整理看开，我们的拓展的路径是：从点 v 开始，经由四种关系一到三跳拓展到点v2，返回整个拓展路径 p，限制 100 个路径结果，其中 v 是 c_132。 5.1.2 Nebula Python Client/ SDK我们已经知道了查询语句的语法，那么就只需要在后端程序里根据请求、通过图数据库的客户端来发出查询请求，并处理返回结构就好了。在今天的例子中，我选择使用 Python 来实现后端的逻辑，所以我用了 Nebula-python 这个库，它是 Nebula 的 Python Client。 你知道么？截至到现在，Nebula 在 GitHub 上有 Java，GO，Python，C++，Spark，Flink，Rust（未GA），NodeJS（未GA） 的客户端支持，更多的语言的客户端也会慢慢被发布哦。 下边是一个 Python Client 执行一个查询并返回结果的例子，值得注意的是，在我实现这个代码的时候，Nebula Python 尚未支持返回 JSON （通过session.execute_json()）结果，如果你要实现自己的代码，我非常推荐试试 JSON 哈，就可以不用从对象中一点点取数据了，不过借助 iPython/IDLE 这种 REPL，快速了解返回对象的结构也没有那么麻烦。 $ python3 -m pip install nebula2-python==2.5.0 # 注意这里我引用旧的记录，它是 2.5.0， $ ipython In [1]: from nebula2.gclient.net import ConnectionPool In [2]: from nebula2.Config import Config In [3]: config = Config() ...: config.max_connection_pool_size = 10 ...: # init connection pool ...: connection_pool = ConnectionPool() ...: # if the given servers are ok, return true, else return false ...: ok = connection_pool.init([('192.168.8.137', 9669)], config) ...: session = connection_pool.get_session('root', 'nebula') [2021-10-13 13:44:24,242]:Get connection to ('192.168.8.137', 9669) In [4]: resp = session.execute(\"use shareholding\") In [5]: query = ''' ...: MATCH p=(v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) \\ ...: WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 ...: ''' In [6]: resp = session.execute(query) # Note: after nebula graph 2.6.0, we could use execute_json as well In [7]: resp.col_size() Out[7]: 1 In [9]: resp.row_size() Out[10]: 100 我们往下分析看看，我们知道这个请求本质上结果是路径，它有一个 .nodes() 方法和 .relationships()方法来获得路径上的点和边： In [11]: p=resp.row_values(22)[0].as_path() In [12]: p.nodes() Out[12]: [(\"c_132\" :corp{name: \"Chambers LLC\"}), (\"p_4000\" :person{name: \"Colton Bailey\"})] In [13]: p.relationships() Out[13]: [(\"p_4000\")-[:role_as@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\")] 对于边来说有这些方法 .edge_name(), .properties(), .start_vertex_id(), .end_vertex_id()，这里 edge_name 是获得边的类型。 In [14]: rel=p.relationships()[0] In [15]: rel Out[15]: (\"p_4000\")-[:role_as@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\") In [16]: rel.edge_name() Out[16]: 'role_as' In [17]: rel.properties() Out[17]: {'role': \"Editorial assistant\"} In [18]: rel.start_vertex_id() Out[18]: \"p_4000\" In [19]: rel.end_vertex_id() Out[19]: \"c_132\" 对于点来说，可以用到这些方法 .tags(), properties, get_id()，这里边 tags 是获得点的类型，它在 Nebula 里叫标签tag。 这些概念可以在文档里获得更详细的解释。 In [20]: node=p.nodes()[0] In [21]: node.tags() Out[21]: ['corp'] In [22]: node.properties('corp') Out[22]: {'name': \"Chambers LLC\"} In [23]: node.get_id() Out[23]: \"c_132\" ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:1","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#查询语句"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.1 后端服务–\u003e图数据库 详细的数据格式分析大家可以参考这里 5.1.1 查询语句我们假设用户请求的实体是 c_132 ，那么请求 1 到 3 步的关系穿透的语法是： MATCH p=(v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) \\ WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 这里边 ()包裹的是图之中的点，而[] 包裹的则是点之间的关系：边，所以： (v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) 之中的： (v)-[xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]-(v2)应该比较好理解，意思是从 v 到v2 做拓展。 现在我们介绍中间[]包裹的部分，这里，它的语义是：经由四种类型的边（:之后的是边的类型，|代表或者）通过可变的跳数：*1..3 （一跳到三跳）。 所以，简单来说整理看开，我们的拓展的路径是：从点 v 开始，经由四种关系一到三跳拓展到点v2，返回整个拓展路径 p，限制 100 个路径结果，其中 v 是 c_132。 5.1.2 Nebula Python Client/ SDK我们已经知道了查询语句的语法，那么就只需要在后端程序里根据请求、通过图数据库的客户端来发出查询请求，并处理返回结构就好了。在今天的例子中，我选择使用 Python 来实现后端的逻辑，所以我用了 Nebula-python 这个库，它是 Nebula 的 Python Client。 你知道么？截至到现在，Nebula 在 GitHub 上有 Java，GO，Python，C++，Spark，Flink，Rust（未GA），NodeJS（未GA） 的客户端支持，更多的语言的客户端也会慢慢被发布哦。 下边是一个 Python Client 执行一个查询并返回结果的例子，值得注意的是，在我实现这个代码的时候，Nebula Python 尚未支持返回 JSON （通过session.execute_json()）结果，如果你要实现自己的代码，我非常推荐试试 JSON 哈，就可以不用从对象中一点点取数据了，不过借助 iPython/IDLE 这种 REPL，快速了解返回对象的结构也没有那么麻烦。 $ python3 -m pip install nebula2-python==2.5.0 # 注意这里我引用旧的记录，它是 2.5.0， $ ipython In [1]: from nebula2.gclient.net import ConnectionPool In [2]: from nebula2.Config import Config In [3]: config = Config() ...: config.max_connection_pool_size = 10 ...: # init connection pool ...: connection_pool = ConnectionPool() ...: # if the given servers are ok, return true, else return false ...: ok = connection_pool.init([('192.168.8.137', 9669)], config) ...: session = connection_pool.get_session('root', 'nebula') [2021-10-13 13:44:24,242]:Get connection to ('192.168.8.137', 9669) In [4]: resp = session.execute(\"use shareholding\") In [5]: query = ''' ...: MATCH p=(v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) \\ ...: WHERE id(v) IN [\"c_132\"] RETURN p LIMIT 100 ...: ''' In [6]: resp = session.execute(query) # Note: after nebula graph 2.6.0, we could use execute_json as well In [7]: resp.col_size() Out[7]: 1 In [9]: resp.row_size() Out[10]: 100 我们往下分析看看，我们知道这个请求本质上结果是路径，它有一个 .nodes() 方法和 .relationships()方法来获得路径上的点和边： In [11]: p=resp.row_values(22)[0].as_path() In [12]: p.nodes() Out[12]: [(\"c_132\" :corp{name: \"Chambers LLC\"}), (\"p_4000\" :person{name: \"Colton Bailey\"})] In [13]: p.relationships() Out[13]: [(\"p_4000\")-[:role_as@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\")] 对于边来说有这些方法 .edge_name(), .properties(), .start_vertex_id(), .end_vertex_id()，这里 edge_name 是获得边的类型。 In [14]: rel=p.relationships()[0] In [15]: rel Out[15]: (\"p_4000\")-[:role_as@0{role: \"Editorial assistant\"}]-\u003e(\"c_132\") In [16]: rel.edge_name() Out[16]: 'role_as' In [17]: rel.properties() Out[17]: {'role': \"Editorial assistant\"} In [18]: rel.start_vertex_id() Out[18]: \"p_4000\" In [19]: rel.end_vertex_id() Out[19]: \"c_132\" 对于点来说，可以用到这些方法 .tags(), properties, get_id()，这里边 tags 是获得点的类型，它在 Nebula 里叫标签tag。 这些概念可以在文档里获得更详细的解释。 In [20]: node=p.nodes()[0] In [21]: node.tags() Out[21]: ['corp'] In [22]: node.properties('corp') Out[22]: {'name': \"Chambers LLC\"} In [23]: node.get_id() Out[23]: \"c_132\" ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:1","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#nebula-python-client-sdk"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.2 前端渲染点边为图 详细的分析大家也可以参考这里 为了方便实现，我们采用了 Vue.js 和 vue-network-d3（D3 的 Vue Binding）。 通过 vue-network-d3 的抽象，能看出来喂给他这样的数据，就可以把点边信息渲染成很好看的图 nodes: [ {\"id\": \"c_132\", \"name\": \"Chambers LLC\", \"tag\": \"corp\"}, {\"id\": \"p_4000\", \"name\": \"Colton Bailey\", \"tag\": \"person\"}], relationships: [ {\"source\": \"p_4000\", \"target\": \"c_132\", \"properties\": { \"role\": \"Editorial assistant\" }, \"edge\": \"role_as\"}] ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:2","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#前端渲染点边为图"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.3 前端\u003c–后端 详细信息可以参考这里 我们从 D3 的初步研究上可以知道，后端只需要返回如下的 JSON 格式数据就好了 Nodes: [{\"id\": \"c_132\", \"name\": \"Chambers LLC\", \"tag\": \"corp\"}, {\"id\": \"p_4000\", \"name\": \"Colton Bailey\", \"tag\": \"person\"}] Relationships: [{\"source\": \"p_4000\", \"target\": \"c_132\", \"properties\": { \"role\": \"Editorial assistant\" }, \"edge\": \"role_as\"}, {\"source\": \"p_1039\", \"target\": \"c_132\", \"properties\": { \"share\": \"3.0\" }, \"edge\": \"hold_share\"}] 于是，，结合前边我们用 iPython 分析 Python 返回结果看，这个逻辑大概是： def make_graph_response(resp) -\u003e dict: nodes, relationships = list(), list() for row_index in range(resp.row_size()): path = resp.row_values(row_index)[0].as_path() _nodes = [ { \"id\": node.get_id(), \"tag\": node.tags()[0], \"name\": node.properties(node.tags()[0]).get(\"name\", \"\") } for node in path.nodes() ] nodes.extend(_nodes) _relationships = [ { \"source\": rel.start_vertex_id(), \"target\": rel.end_vertex_id(), \"properties\": rel.properties(), \"edge\": rel.edge_name() } for rel in path.relationships() ] relationships.extend(_relationships) return {\"nodes\": nodes, \"relationships\": relationships} 前端到后端的通信是 HTTP ，所以我们可以借助 Flask，把这个函数封装成一个 RESTful API： 前端程序通过 HTTP POST 到 /api 参考这里 from flask import Flask, jsonify, request app = Flask(__name__) @app.route(\"/\") def root(): return \"Hey There?\" @app.route(\"/api\", methods=[\"POST\"]) def api(): request_data = request.get_json() entity = request_data.get(\"entity\", \"\") if entity: resp = query_shareholding(entity) data = make_graph_response(resp) else: data = dict() # tbd return jsonify(data) def parse_nebula_graphd_endpoint(): ng_endpoints_str = os.environ.get( 'NG_ENDPOINTS', '127.0.0.1:9669,').split(\",\") ng_endpoints = [] for endpoint in ng_endpoints_str: if endpoint: parts = endpoint.split(\":\") # we dont consider IPv6 now ng_endpoints.append((parts[0], int(parts[1]))) return ng_endpoints def query_shareholding(entity): query_string = ( f\"USE shareholding; \" f\"MATCH p=(v)-[e:hold_share|:is_branch_of|:reletive_with|:role_as*1..3]-(v2) \" f\"WHERE id(v) IN ['{ entity }'] RETURN p LIMIT 100\" ) session = connection_pool.get_session('root', 'nebula') resp = session.execute(query_string) return resp 这个请求的结果则是前边前端期待的 JSON，像这样： curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{\"entity\": \"c_132\"}' \\ http://192.168.10.14:5000/api | jq { \"nodes\": [ { \"id\": \"c_132\", \"name\": \"\\\"Chambers LLC\\\"\", \"tag\": \"corp\" }, { \"id\": \"c_245\", \"name\": \"\\\"Thompson-King\\\"\", \"tag\": \"corp\" }, { \"id\": \"c_132\", \"name\": \"\\\"Chambers LLC\\\"\", \"tag\": \"corp\" }, ... } ], \"relationships\": [ { \"edge\": \"hold_share\", \"properties\": \"{'share': 0.0}\", \"source\": \"c_245\", \"target\": \"c_132\" { \"edge\": \"hold_share\", \"properties\": \"{'share': 9.0}\", \"source\": \"p_1767\", \"target\": \"c_132\" }, { \"edge\": \"hold_share\", \"properties\": \"{'share': 11.0}\", \"source\": \"p_1997\", \"target\": \"c_132\" }, ... }, { \"edge\": \"reletive_with\", \"properties\": \"{'degree': 51}\", \"source\": \"p_7283\", \"target\": \"p_4723\" } ] } ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:3","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#前端--后端"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.4 放到一起项目的代码都在 GitHub 上，最后其实只有一两百行的代码，把所有东西拼起来之后的代码是： ├── README.md # You could find Design Logs here ├── corp-rel-backend │ └── app.py # Flask App to handle Requst and calls GDB ├── corp-rel-frontend │ └── src │ ├── App.vue │ └── main.js # Vue App to call Flask App and Renders Graph └── requirements.txt ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:4","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#放到一起"},{"categories":["Nebula Graph","Mini Project"],"content":" 5.5 最终效果我们做出来了一个简陋但是足够具有参考性的小系统，它接受一个用户输入的实体的 ID，再回车之后： 前端程序把请求发给后端 后端拼接 Nebula Graph 的查询语句，通过 Nebula Python 客户端请求 Nebula Graph Nebula Graph 接受请求做出穿透查询，返回结构给后端 后端将结果构建成前端 D3 接受的格式，传给前端 前端接收到图结构的数据，渲染股权穿透的数据如下： ","date":"2021-11-24","objectID":"/corp-rel-graph/:5:5","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#最终效果"},{"categories":["Nebula Graph","Mini Project"],"content":" 6 总结现在，我们知道得益于图数据库的设计，在它上边构建一个方便的股权分析系统非常自然、高效，我们或者利用图数据库的图探索可视化能力、或者自己搭建，可以为用户提供非常高效、直观的多跳股权穿透分析。 如果你想了解更多关于分布式图数据库的知识，欢迎关注 Nebula Graph 这个开源项目，它已经被国内很多团队、公司认可选为图时代数据技术存储层的利器，大家可以访问这里，或者这里，了解更多相关的分享和文章。 未来，我会给大家分享更多图数据库相关的文章、视频和开源示例项目思路分享和教程，欢迎大家关注我的网站: siwei.io。 题图版权：fabioha ","date":"2021-11-24","objectID":"/corp-rel-graph/:6:0","series":null,"tags":["Nebula Graph","图数据库","股权穿透","知识图谱"],"title":"从零到一：如何构建一个企业股权图谱系统？","uri":"/corp-rel-graph/#总结"},{"categories":["Nebula Graph"],"content":"Dialog System With Graph Database Backed Knowledge Graph. 基于图数据库的智能问答助手","date":"2021-09-18","objectID":"/nebula-siwi/","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/"},{"categories":["Nebula Graph"],"content":" 一个基于图数据库的智能问答助手项目。 GitHub Repo: https://github.com/wey-gu/nebula-siwi/ 这个项目我也做成了互动教程，可以按照这里的步骤搭建起来 👉🏻 https://siwei.io/cources/ update: 写了一篇完整介绍 Siwi 设计的文章 👉🏻 https://siwei.io/siwi 您也可以在 Nebula Playground 上直接玩这个数据集啦：https://nebula-graph.com.cn/demo/ ","date":"2021-09-18","objectID":"/nebula-siwi/:0:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#"},{"categories":["Nebula Graph"],"content":" Siwi the voice assistantSiwi (/ˈsɪwi/) is a PoC of Dialog System With Graph Database Backed Knowledge Graph. For now, it’s a demo for task-driven(not general purpose) dialog bots with KG(Knowledge Graph) leveraging Nebula Graph with the minimal/sample dataset from Nebula Graph Manual/ NG中文手册. Tips: Now you can play with the graph online without installing yourself! Nebula Playground | Nebula Playground - China Mainland Supported queries: relation: What is the relationship between Yao Ming and Lakers? How does Yao Ming and Lakers connected? serving: Which team had Yao Ming served? friendship: Whom does Tim Duncan follow? Who are Yao Ming’s friends? ","date":"2021-09-18","objectID":"/nebula-siwi/:0:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#siwi-the-voice-assistant"},{"categories":["Nebula Graph"],"content":" 1 Deploy and TryTBD (leveraging docker and nebula-up) ","date":"2021-09-18","objectID":"/nebula-siwi/:1:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#deploy-and-try"},{"categories":["Nebula Graph"],"content":" 2 How does it work?This is one of the most naive pipeline for a specific domain/ single purpose chat bot built on a Knowledge Graph. ","date":"2021-09-18","objectID":"/nebula-siwi/:2:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#how-does-it-work"},{"categories":["Nebula Graph"],"content":" 2.1 Backend The Backend(Siwi API) is a Flask based API server: Flask API server takes questions in HTTP POST, and calls the bot API. In bot API part there are classfier(Symentic Parsing, Intent Matching, Slot Filling), and question actors(Call corresponding actions to query Knowledge Graph with intents and slots). Knowledge Graph is built on an Open-Source Graph Database: Nebula Graph ","date":"2021-09-18","objectID":"/nebula-siwi/:2:1","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#backend"},{"categories":["Nebula Graph"],"content":" 2.2 Frontend The Frontend is a VueJS Single Page Applicaiton(SPA): I reused a Vue Bot UI to showcase a chat window in this human-agent interaction, typing is supported. In addtion, leverating Chrome’s Web Speech API, a button to listen to human voice is introduced ","date":"2021-09-18","objectID":"/nebula-siwi/:2:2","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#frontend"},{"categories":["Nebula Graph"],"content":" 2.3 A Query Flow ┌────────────────┬──────────────────────────────────────┐ │ │ │ │ │ Speech │ │ ┌──────────▼──────────┐ │ │ │ Frontend │ Siwi, /ˈsɪwi/ │ │ │ Web_Speech_API │ A PoC of │ │ │ │ Dialog System │ │ │ Vue.JS │ With Graph Database │ │ │ │ Backed Knowledge Graph │ │ └──────────┬──────────┘ │ │ │ Sentence │ │ │ │ │ ┌────────────┼──────────────────────────────┐ │ │ │ │ │ │ │ │ │ Backend │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ Web API, Flask │ ./app/ │ │ │ │ └──────────┬──────────┘ │ │ │ │ │ Sentence ./bot/ │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ │ │ │ │ │ │ Intent matching, │ ./bot/classifier│ │ │ │ │ Symentic Processing │ │ │ │ │ │ │ │ │ │ │ └──────────┬──────────┘ │ │ │ │ │ Intent, Entities │ │ │ │ ┌──────────▼──────────┐ │ │ │ │ │ │ │ │ │ │ │ Intent Actor │ ./bot/actions │ │ │ │ │ │ │ │ │ └─┴──────────┬──────────┴───────────────────┘ │ │ │ Graph Query │ │ ┌──────────▼──────────┐ │ │ │ │ │ │ │ Graph Database │ Nebula Graph │ │ │ │ │ │ └─────────────────────┘ │ │ │ │ │ │ │ └───────────────────────────────────────────────────────┘ ","date":"2021-09-18","objectID":"/nebula-siwi/:2:3","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#a-query-flow"},{"categories":["Nebula Graph"],"content":" 2.4 Source Code Tree . ├── README.md ├── src │ ├── siwi # Siwi-API Backend │ │ ├── app # Web Server, take HTTP requests and calls Bot API │ │ └── bot # Bot API │ │ ├── actions # Take Intent, Slots, Query Knowledge Graph here │ │ ├── bot # Entrypoint of the Bot API │ │ ├── classifier # Symentic Parsing, Intent Matching, Slot Filling │ │ └── test # Example Data Source as equivalent/mocked module │ └── siwi_frontend # Browser End │ ├── README.md │ ├── package.json │ └── src │ ├── App.vue # Listening to user and pass Questions to Siwi-API │ └── main.js └── wsgi.py ","date":"2021-09-18","objectID":"/nebula-siwi/:2:4","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#source-code-tree"},{"categories":["Nebula Graph"],"content":" 3 Manually Run Components","date":"2021-09-18","objectID":"/nebula-siwi/:3:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#manually-run-components"},{"categories":["Nebula Graph"],"content":" 3.1 BackendInstall and run. # Install siwi backend python3 -m build # Configure Nebula Graph Endpoint export NG_ENDPOINTS=127.0.0.1:9669 # Run Backend API server gunicorn --bind :5000 wsgi --workers 1 --threads 1 --timeout 60 For OpenFunction/ KNative docker build -t weygu/siwi-api . docker run --rm --name siwi-api \\ --env=PORT=5000 \\ --env=NG_ENDPOINTS=127.0.0.1:9669 \\ --net=host \\ weygu/siwi-api Try it out Web API: $ curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{\"question\": \"What is the relationship between Yao Ming and Lakers?\"}' \\ http://192.168.8.128:5000/query | jq { \"answer\": \"There are at least 23 relations between Yao Ming and Lakers, one relation path is: Yao Ming follows Shaquille O'Neal serves Lakers.\" } Call Bot Python API: from nebula2.gclient.net import ConnectionPool from nebula2.Config import Config # define a config config = Config() config.max_connection_pool_size = 10 # init connection pool connection_pool = ConnectionPool() # if the given servers are ok, return true, else return false ok = connection_pool.init([('127.0.0.1', 9669)], config) # import siwi bot from siwi.bot import bot # instantiate a bot b = bot.SiwiBot(connection_pool) # make the question query b.query(\"Which team had Jonathon Simmons served?\") Then a response will be like this: In [4]: b.query(\"Which team had Jonathon Simmons serv ...: ed?\") [DEBUG] ServeAction intent: {'entities': {'Jonathon Simmons': 'player'}, 'intents': ('serve',)} [DEBUG] query for RelationshipAction: USE basketballplayer; MATCH p=(v)-[e:serve*1]-\u003e(v1) WHERE id(v) == \"player112\" RETURN p LIMIT 100; [2021-07-02 02:59:36,392]:Get connection to ('127.0.0.1', 9669) Out[4]: 'Jonathon Simmons had served 3 teams. Spurs from 2015 to 2015; 76ers from 2019 to 2019; Magic from 2017 to 2017; ' ","date":"2021-09-18","objectID":"/nebula-siwi/:3:1","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#backend-1"},{"categories":["Nebula Graph"],"content":" 3.2 FrontendReferring to siwi_frontend ","date":"2021-09-18","objectID":"/nebula-siwi/:3:2","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#frontend-1"},{"categories":["Nebula Graph"],"content":" 4 Further work Use NBA-API to fallback undefined pattern questions Wrap and manage sessions instead of get and release session per request, this is somehow costly actually. Use NLP methods to implement proper Symentic Parsing, Intent Matching, Slot Filling Build Graph to help with Intent Matching, especially for a general purpose bot Use larger Dataset i.e. from wyattowalsh/basketball ","date":"2021-09-18","objectID":"/nebula-siwi/:4:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#further-work"},{"categories":["Nebula Graph"],"content":" 5 Thanks to Upstream Projects ❤️","date":"2021-09-18","objectID":"/nebula-siwi/:5:0","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#thanks-to-upstream-projects-"},{"categories":["Nebula Graph"],"content":" 5.1 Backend I learnt a lot from the KGQA on MedicalKG created by Huanyong Liu Flask pyahocorasick created by Wojciech Muła PyYaml ","date":"2021-09-18","objectID":"/nebula-siwi/:5:1","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#backend-2"},{"categories":["Nebula Graph"],"content":" 5.2 Frontend VueJS for frontend framework Vue Bot UI, as a lovely bot UI in vue Vue Web Speech, for speech API vue wrapper Axios for browser http client Solarized for color scheme Vitesome for landing page design Image credit goes to https://unsplash.com/photos/0E_vhMVqL9g ","date":"2021-09-18","objectID":"/nebula-siwi/:5:2","series":null,"tags":["Nebula Graph","Know How","Intelligent assistant","图数据库应用","智能助手"],"title":"Nebula Siwi，基于图数据库的智能问答助手","uri":"/nebula-siwi/#frontend-2"},{"categories":["Nebula Graph"],"content":"Setup Nebula Graph Dev Env with CLion and Docker 搭建基于 Docker 的 Nebula Graph CLion 开发环境","date":"2021-09-18","objectID":"/nebula-clion/","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/"},{"categories":["Nebula Graph"],"content":" 之前卡比同学向我咨询搭建 CLion 环境，开发 Nebula 的一些问题，我做了一些工作方便利用 Docker 在本地搭建这样一个环境，相关的东西放在：https://github.com/wey-gu/nebula-dev-CLion 。 Related GitHub Repo: https://github.com/wey-gu/nebula-dev-CLion ","date":"2021-09-18","objectID":"/nebula-clion/:0:0","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#"},{"categories":["Nebula Graph"],"content":" 1 Run Docker Env for Nebula-Graph with CLionBuild Docker Image git clone https://github.com/wey-gu/nebula-dev-CLion.git cd nebula-dev-CLion docker build -t wey/nebula-dev-clion:v2.0 . Run Docker Container for Nebula-Dev with CLion Integration Readiness(actually mostly Rsync \u0026 SSH). cd \u003cnebula-graph-repo-you-worked-on\u003e export DOCKER_DEFAULT_PLATFORM=linux/amd64 docker run --rm -d \\ --name nebula-dev \\ --security-opt seccomp=unconfined \\ -p 2222:22 -p 2873:873 --cap-add=ALL \\ -v $PWD:/home/nebula \\ -w /home/nebula \\ wey/nebula-dev-clion:v2.0 Verify cmake with SSH. The default password is password ssh -o StrictHostKeyChecking=no root@localhost -p 2222 # in docker cd /home/nebula mkdir build \u0026\u0026 cd build cmake -DENABLE_TESTING=OFF -DCMAKE_BUILD_TYPE=Release .. Access container w/o SSH. docker exec -it nebula-dev bash mkdir -p build \u0026\u0026 cd build cmake -DENABLE_TESTING=OFF -DCMAKE_BUILD_TYPE=Release .. ","date":"2021-09-18","objectID":"/nebula-clion/:1:0","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#run-docker-env-for-nebula-graph-with-clion"},{"categories":["Nebula Graph"],"content":" 2 Configurations in CLion Ref: https://www.jetbrains.com/help/clion/clion-toolchains-in-docker.html#build-and-run Toolchains Add a remote host root@localhost:2222 password Put /opt/vesoft/toolset/cmake/bin/cmake as CMake CMake Toochain: Select the one created in last step Build directory: /home/nebula/build ","date":"2021-09-18","objectID":"/nebula-clion/:2:0","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#configurations-in-clion"},{"categories":["Nebula Graph"],"content":" 3 The appendix","date":"2021-09-18","objectID":"/nebula-clion/:3:0","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#the-appendix"},{"categories":["Nebula Graph"],"content":" 3.1 References of CMake output: [root@4c98e3f77ce8 build]# cmake -DENABLE_TESTING=OFF -DCMAKE_BUILD_TYPE=Release .. \u003e\u003e\u003e\u003e Options of Nebula Graph \u003c\u003c\u003c\u003c -- ENABLE_ASAN : OFF (Build with AddressSanitizer) -- ENABLE_BUILD_STORAGE : OFF (Whether to build storage) -- ENABLE_CCACHE : ON (Use ccache to speed up compiling) -- ENABLE_CLANG_TIDY : OFF (Enable clang-tidy if present) -- ENABLE_COMPRESSED_DEBUG_INFO : ON (Compress debug info to reduce binary size) -- ENABLE_COVERAGE : OFF (Build with coverage report) -- ENABLE_FRAME_POINTER : OFF (Build with frame pointer) -- ENABLE_FUZZY_TESTING : OFF (Enable Fuzzy tests) -- ENABLE_GDB_SCRIPT_SECTION : OFF (Add .debug_gdb_scripts section) -- ENABLE_JEMALLOC : ON (Use jemalloc as memory allocator) -- ENABLE_MODULE_FORCE_CHECKOUT : ON (Whether checkout branch of module to same as graph.) -- ENABLE_MODULE_UPDATE : OFF (Automatically update module) -- ENABLE_PACK_ONE : ON (Whether to package into one) -- ENABLE_PIC : OFF (Build with -fPIC) -- ENABLE_STATIC_ASAN : OFF (Statically link against libasan) -- ENABLE_STATIC_UBSAN : OFF (Statically link against libubsan) -- ENABLE_STRICT_ALIASING : OFF (Build with -fstrict-aliasing) -- ENABLE_TESTING : OFF (Build unit tests) -- ENABLE_TSAN : OFF (Build with ThreadSanitizer) -- ENABLE_UBSAN : OFF (Build with UndefinedBehaviourSanitizer) -- ENABLE_VERBOSE_BISON : OFF (Enable Bison to report state) -- ENABLE_WERROR : ON (Regard warnings as errors) -- CMAKE_BUILD_TYPE : Release (Choose the type of build, options are: None Debug Release RelWithDebInfo MinSizeRel ...) -- CMAKE_INSTALL_PREFIX : /usr/local/nebula (Install path prefix, prepended onto install directories.) -- CMAKE_CXX_STANDARD : 17 -- CMAKE_CXX_COMPILER : /opt/vesoft/toolset/clang/9.0.0/bin/c++ (CXX compiler) -- CMAKE_CXX_COMPILER_ID : GNU -- NEBULA_USE_LINKER : bfd -- CCACHE_DIR : /root/.ccache \u003e\u003e\u003e\u003e Configuring third party for 'Nebula Graph' \u003c\u003c\u003c\u003c -- NEBULA_THIRDPARTY_ROOT : /opt/vesoft/third-party/2.0 -- Build info of nebula third party: Package : Nebula Third Party Version : 2.0 Date : Mon Jun 28 15:07:38 UTC 2021 glibc : 2.17 Arch : x86_64 Compiler : GCC 9.2.0 C++ ABI : 11 Vendor : VEsoft Inc. -- CMAKE_INCLUDE_PATH : /opt/vesoft/third-party/2.0/include -- CMAKE_LIBRARY_PATH : /opt/vesoft/third-party/2.0/lib64;/opt/vesoft/third-party/2.0/lib -- CMAKE_PROGRAM_PATH : /opt/vesoft/third-party/2.0/bin -- GLIBC_VERSION : 2.17 -- found krb5-config here /opt/vesoft/third-party/2.0/bin/krb5-config -- Found kerberos 5 headers: /opt/vesoft/third-party/2.0/include -- Found kerberos 5 libs: /opt/vesoft/third-party/2.0/lib/libgssapi_krb5.a;/opt/vesoft/third-party/2.0/lib/libkrb5.a;/opt/vesoft/third-party/2.0/lib/libk5crypto.a;/opt/vesoft/third-party/2.0/lib/libcom_err.a;/opt/vesoft/third-party/2.0/lib/libkrb5support.a \u003e\u003e\u003e\u003e Configuring third party for 'Nebula Graph' done \u003c\u003c\u003c\u003c -- Create the pre-commit hook -- Creating pre-commit hook done \u003e\u003e\u003e\u003e Configuring Nebula Common \u003c\u003c\u003c\u003c \u003e\u003e\u003e\u003e Options of Nebula Common \u003c\u003c\u003c\u003c -- ENABLE_ASAN : OFF (Build with AddressSanitizer) -- ENABLE_CCACHE : ON (Use ccache to speed up compiling) -- ENABLE_CLANG_TIDY : OFF (Enable clang-tidy if present) -- ENABLE_COMPRESSED_DEBUG_INFO : ON (Compress debug info to reduce binary size) -- ENABLE_COVERAGE : OFF (Build with coverage report) -- ENABLE_FRAME_POINTER : OFF (Build with frame pointer) -- ENABLE_FUZZY_TESTING : OFF (Enable Fuzzy tests) -- ENABLE_GDB_SCRIPT_SECTION : OFF (Add .debug_gdb_scripts section) -- ENABLE_JEMALLOC : ON (Use jemalloc as memory allocator) -- ENABLE_PIC : OFF (Build with -fPIC) -- ENABLE_STATIC_ASAN : OFF (Statically link against libasan) -- ENABLE_STATIC_UBSAN : OFF (Statically link against libubsan) -- ENABLE_STRICT_ALIASING : OFF (Build with -fstrict-aliasing) -- ENABLE_TESTING : OFF (Build unit tests) -- ENABLE_TSAN : OFF (Build with ThreadSanitizer) -- ENABLE_UBSAN : OFF (Build with UndefinedBehaviourSanitizer) -- ENABLE_WERROR : ON (Regard warnings as errors) -- Set D_GLIBCXX_USE_CXX11_ABI to 1 -- CMAKE_BUI","date":"2021-09-18","objectID":"/nebula-clion/:3:1","series":null,"tags":["Nebula Graph","Dev Guide"],"title":"Nebula CLion，搭建基于 Docker 的 Nebula Graph CLion 开发环境","uri":"/nebula-clion/#references-of-cmake-output"},{"categories":["courses"],"content":"Hands-on Course: Breakdown multistage relationship of Persons and Corporations leverating the Nebula Graph Database.","date":"2021-09-04","objectID":"/learn/nebula-101-shareholding/","series":null,"tags":["Nebula Graph","katacoda","shareholding","Nebula Solution","Knowledge Graph"],"title":"上手实战图数据库股权关系穿透","uri":"/learn/nebula-101-shareholding/"},{"categories":["courses"],"content":"Walk you through in actions to do below sections exercises! Bootstrap a Nebula Graph Cluster and Studio Web App Import a graph of dataset about shareholding Exploring the shareholding data with Nebula Importer Visually Exploring the shareholding data with Nebula Studio Run Graph Algorithm on Nebula Cluster Graph Data The dataset comes from https://github.com/wey-gu/nebula-shareholding-example/tree/main/data_sample 课程开源在 https://github.com/wey-gu/katacoda-scenarios ，欢迎来反馈，贡献 ","date":"2021-09-04","objectID":"/learn/nebula-101-shareholding/:0:0","series":null,"tags":["Nebula Graph","katacoda","shareholding","Nebula Solution","Knowledge Graph"],"title":"上手实战图数据库股权关系穿透","uri":"/learn/nebula-101-shareholding/#"},{"categories":null,"content":" 您可以通过这个导图开始了解、入门图数据库和 Nebula Graph，上边的区域是入门的部分，下边还有进阶的部分，我们会持续更新、维护这个导图的~ Tips: 加载成功之后，点击 [See the board] 可以开始浏览，双击放大缩小。 或者点导图区域右上角的箭头在新的窗口打开，可以更方面浏览器中内容。 ","date":"2021-09-04","objectID":"/path/:0:0","series":null,"tags":null,"title":"图数据库学习路径","uri":"/path/#"},{"categories":["courses"],"content":"Hands-on Course: Setup a KGQA system from scratch with Nebula Graph, VueJS, Flask on K8s.","date":"2021-09-03","objectID":"/learn/nebula-101-siwi-kgqa/","series":null,"tags":["Nebula Graph","katacoda","Dialog System","Nebula Solution"],"title":"上手实战从0制作一个基于图谱的语音智能助手","uri":"/learn/nebula-101-siwi-kgqa/"},{"categories":["courses"],"content":"A full solution walkthrough for a Knowledge Graph Dialog System. Boostrap a Nebula Cluster in K8s Scale out the Nebula Cluster in K8s way Import the basketballplayer Dataset Siwi, the Knowledge Graph Dialog System with Nebula Graph Siwi (/ˈsɪwi/) is a PoC of Dialog System With Graph Database Backed Knowledge Graph. The code of Siwi is here: https://github.com/wey-gu/nebula-siwi. 课程开源在 https://github.com/wey-gu/katacoda-scenarios ，欢迎来反馈，贡献 ","date":"2021-09-03","objectID":"/learn/nebula-101-siwi-kgqa/:0:0","series":null,"tags":["Nebula Graph","katacoda","Dialog System","Nebula Solution"],"title":"上手实战从0制作一个基于图谱的语音智能助手","uri":"/learn/nebula-101-siwi-kgqa/#"},{"categories":["Nebula Graph"],"content":"A demo of Shareholding Breakthrough with Distributed open-source Graph Database: Nebula Graph. 图数据库应用示例：股权关系穿透","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/"},{"categories":["Nebula Graph"],"content":" A demo of Shareholding Breakthrough with Distributed open-source Graph Database: Nebula Graph. 图数据库应用示例：股权关系穿透 Related GitHub Repo: https://github.com/wey-gu/nebula-shareholding-example 更新：在这个数据集生成的工作基础上，我又做了一个全栈示例项目 👉🏻 https://siwei.io/corp-rel-graph/ 这个项目我也做成了互动教程，可以按照这里的步骤搭建起来 👉🏻 https://siwei.io/cources/ I created the Katacoda Interactive Env for this project 👉🏻 https://siwei.io/cources/ 您也可以在 Nebula Playground 上直接玩这个数据集啦：https://nebula-graph.com.cn/demo/ Now you can play with the data on Nebula Playground: https://nebula-graph.io/demo/ This is a demo of Shareholding Relationship Analysis with Distributed open-source Graph Database: Nebula Graph. ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:0:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#"},{"categories":["Nebula Graph"],"content":" 1 Data","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:1:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#data"},{"categories":["Nebula Graph"],"content":" 1.1 Data Modeling There are various kinds of relationships when we checking companies’ shareholding breakthrough, here let’s simplify it with only two kind of entities: person and corp, and with following relationship types. person can hold a corp in {share} % person can be relative with another person corp can hold another corp in {share} % corp can be a branch of another corp person can be as a role of a corp Below is the lines to reflect this graph modele in Nebula Graph, it’s quite straightforward, right? CREATE TAG person(name string); CREATE TAG corp(name string); CREATE EDGE role_as(role string); CREATE EDGE is_branch_of(); CREATE EDGE hold_share(share float); CREATE EDGE reletive_with(degree int); ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:1:1","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#data-modeling"},{"categories":["Nebula Graph"],"content":" 1.2 Data GenerationWe just randomly generate some data to help with this demo, you can call data_generator.py directly to generate or reuse what’s already done under data_sample folder. The generated data are records to be fit in above data model from below .csv files. $ pip install Faker==2.0.5 pydbgen==1.0.5 $ python3 data_generator.py $ ls -l data total 1688 -rw-r--r-- 1 weyl staff 23941 Jul 14 13:28 corp.csv -rw-r--r-- 1 weyl staff 1277 Jul 14 13:26 corp_rel.csv -rw-r--r-- 1 weyl staff 3048 Jul 14 13:26 corp_share.csv -rw-r--r-- 1 weyl staff 211661 Jul 14 13:26 person.csv -rw-r--r-- 1 weyl staff 179770 Jul 14 13:26 person_corp_role.csv -rw-r--r-- 1 weyl staff 322965 Jul 14 13:26 person_corp_share.csv -rw-r--r-- 1 weyl staff 17689 Jul 14 13:26 person_rel.csv ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:1:2","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#data-generation"},{"categories":["Nebula Graph"],"content":" 1.3 Data ImportWith those data in .csv files, we can easily import them into a Nebula Graph Cluster with the help of Nebula-Importer. nebula-importer.yaml in this repo describes rules and configurations on how this import will be done by the importer. For Nebula Graph Database, plesae refer to Doc , Doc-CN to deploy on any Linux Servers, for study and test, you can run it via Docker following the Quick Start Chapter of the documentation. For Nebula-Importer, if you already have Docker env, you can run it as the following without installing anything. Or, if you prefer to install it, it’s quite easy as it’s written in Golang and you can run its single file binary quite easily, go check both Documentation and Nebula-Importer Repo: https://github.com/vesoft-inc/nebula-importer. Let’s start! Below is the commands I used to import our data into a Nebula Graph Database. # put generated data \u0026 nebula-importor.yaml to nebula-importer server $ scp -r data nebula_graph_host:~ $ scp nebula-importer.yaml data nebula_graph_host:~/data $ ssh nebula_graph_host $ ls -l ${HOME}/data total 756 -rw-r--r--. 1 wei.gu wei.gu 23941 Jul 14 05:44 corp.csv -rw-r--r--. 1 wei.gu wei.gu 1277 Jul 14 05:44 corp_rel.csv -rw-r--r--. 1 wei.gu wei.gu 3048 Jul 14 05:44 corp_share.csv -rw-r--r--. 1 wei.gu wei.gu 3893 Jul 14 05:44 nebula-importer.yaml -rw-r--r--. 1 wei.gu wei.gu 211661 Jul 14 05:44 person.csv -rw-r--r--. 1 wei.gu wei.gu 179770 Jul 14 05:44 person_corp_role.csv -rw-r--r--. 1 wei.gu wei.gu 322965 Jul 14 05:44 person_corp_share.csv -rw-r--r--. 1 wei.gu wei.gu 17689 Jul 14 05:44 person_rel.csv # import data into our nebula graph database $ docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v ${HOME}/data/nebula-importer.yaml:/root/nebula-importer.yaml \\ -v ${HOME}/data:/root \\ vesoft/nebula-importer:v2 \\ --config /root/nebula-importer.yaml 2021/07/14 05:49:32 --- START OF NEBULA IMPORTER --- 2021/07/14 05:49:32 [WARN] config.go:491: Not set files[0].schema.vertex.vid.Type, reset to default value `string' ... 2021/07/14 05:49:43 [INFO] reader.go:180: Total lines of file(/root/person_corp_role.csv) is: 5000, error lines: 1287 2021/07/14 05:49:43 [INFO] statsmgr.go:61: Done(/root/person_corp_role.csv): Time(11.39s), Finished(12523), Failed(0), Latency AVG(1514us), Batches Req AVG(1824us), Rows AVG(1099.43/s) 2021/07/14 05:49:47 [INFO] statsmgr.go:61: Tick: Time(15.00s), Finished(25807), Failed(0), Latency AVG(1500us), Batches Req AVG(1805us), Rows AVG(1720.46/s) 2021/07/14 05:49:48 [INFO] reader.go:180: Total lines of file(/root/person.csv) is: 10000, error lines: 0 2021/07/14 05:49:48 [INFO] statsmgr.go:61: Done(/root/person.csv): Time(16.10s), Finished(29731), Failed(0), Latency AVG(1505us), Batches Req AVG(1810us), Rows AVG(1847.17/s) 2021/07/14 05:49:50 [INFO] reader.go:180: Total lines of file(/root/person_corp_share.csv) is: 20000, error lines: 0 2021/07/14 05:49:50 [INFO] statsmgr.go:61: Done(/root/person_corp_share.csv): Time(17.74s), Finished(36013), Failed(0), Latency AVG(1531us), Batches Req AVG(1844us), Rows AVG(2030.29/s) 2021/07/14 05:49:50 Finish import data, consume time: 18.25s 2021/07/14 05:49:51 --- END OF NEBULA IMPORTER --- ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:1:3","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#data-import"},{"categories":["Nebula Graph"],"content":" 2 Corporation sharehold relationship breakthrough 2.0.1 Query in nGQLWe can query from corp: c_132 over *(all relationships) in BIDIRECT: GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT Below are lines I call this query in nebula-console: / # nebula-console -addr 192.168.8.128 -port 9669 -user user -password password 2021/07/14 07:07:41 [INFO] connection pool is initialized successfully Welcome to Nebula Graph! (user@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"basketballplayer\" | +--------------------+ | \"shareholding\" | +--------------------+ Got 2 rows (time spent 3851/4595 us) Wed, 14 Jul 2021 07:07:57 UTC (user@nebula) [(none)]\u003e use shareholding Execution succeeded (time spent 1822/2342 us) Wed, 14 Jul 2021 07:08:02 UTC (user@nebula) [shareholding]\u003e GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT +--------------+-------------------+-----------------+--------------------+ | role_as._dst | is_branch_of._dst | hold_share._dst | reletive_with._dst | +--------------+-------------------+-----------------+--------------------+ | \"p_2024\" | | | | +--------------+-------------------+-----------------+--------------------+ | \"p_4000\" | | | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1039\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1399\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1767\" | | ... +--------------+-------------------+-----------------+--------------------+ | | | \"c_132\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_25\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_649\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_753\" | | +--------------+-------------------+-----------------+--------------------+ Got 1519 rows (time spent 12190/14702 us) Wed, 14 Jul 2021 07:08:06 UTC 2.0.2 In a Visual WayOf course, we can also be done in a visual way: Step 1, login from Nebula Graph Studio, explore with one VID: c_132: Step2, click this explored vertex dot, then you can explore from select vertices by selecting: Edge Type Direction Steps Query Limit(Optional) note, you can click the 👁️ icon to add options to show fields of the graph, Step3, after click Expand, you will see all quried relations with c_132 the Chambers LLC. ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:2:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#corporation-sharehold-relationship-breakthrough"},{"categories":["Nebula Graph"],"content":" 2 Corporation sharehold relationship breakthrough 2.0.1 Query in nGQLWe can query from corp: c_132 over *(all relationships) in BIDIRECT: GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT Below are lines I call this query in nebula-console: / # nebula-console -addr 192.168.8.128 -port 9669 -user user -password password 2021/07/14 07:07:41 [INFO] connection pool is initialized successfully Welcome to Nebula Graph! (user@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"basketballplayer\" | +--------------------+ | \"shareholding\" | +--------------------+ Got 2 rows (time spent 3851/4595 us) Wed, 14 Jul 2021 07:07:57 UTC (user@nebula) [(none)]\u003e use shareholding Execution succeeded (time spent 1822/2342 us) Wed, 14 Jul 2021 07:08:02 UTC (user@nebula) [shareholding]\u003e GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT +--------------+-------------------+-----------------+--------------------+ | role_as._dst | is_branch_of._dst | hold_share._dst | reletive_with._dst | +--------------+-------------------+-----------------+--------------------+ | \"p_2024\" | | | | +--------------+-------------------+-----------------+--------------------+ | \"p_4000\" | | | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1039\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1399\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1767\" | | ... +--------------+-------------------+-----------------+--------------------+ | | | \"c_132\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_25\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_649\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_753\" | | +--------------+-------------------+-----------------+--------------------+ Got 1519 rows (time spent 12190/14702 us) Wed, 14 Jul 2021 07:08:06 UTC 2.0.2 In a Visual WayOf course, we can also be done in a visual way: Step 1, login from Nebula Graph Studio, explore with one VID: c_132: Step2, click this explored vertex dot, then you can explore from select vertices by selecting: Edge Type Direction Steps Query Limit(Optional) note, you can click the 👁️ icon to add options to show fields of the graph, Step3, after click Expand, you will see all quried relations with c_132 the Chambers LLC. ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:2:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#query-in-ngql"},{"categories":["Nebula Graph"],"content":" 2 Corporation sharehold relationship breakthrough 2.0.1 Query in nGQLWe can query from corp: c_132 over *(all relationships) in BIDIRECT: GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT Below are lines I call this query in nebula-console: / # nebula-console -addr 192.168.8.128 -port 9669 -user user -password password 2021/07/14 07:07:41 [INFO] connection pool is initialized successfully Welcome to Nebula Graph! (user@nebula) [(none)]\u003e show spaces +--------------------+ | Name | +--------------------+ | \"basketballplayer\" | +--------------------+ | \"shareholding\" | +--------------------+ Got 2 rows (time spent 3851/4595 us) Wed, 14 Jul 2021 07:07:57 UTC (user@nebula) [(none)]\u003e use shareholding Execution succeeded (time spent 1822/2342 us) Wed, 14 Jul 2021 07:08:02 UTC (user@nebula) [shareholding]\u003e GO 1 TO 3 STEPS FROM \"c_132\" over * BIDIRECT +--------------+-------------------+-----------------+--------------------+ | role_as._dst | is_branch_of._dst | hold_share._dst | reletive_with._dst | +--------------+-------------------+-----------------+--------------------+ | \"p_2024\" | | | | +--------------+-------------------+-----------------+--------------------+ | \"p_4000\" | | | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1039\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1399\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"p_1767\" | | ... +--------------+-------------------+-----------------+--------------------+ | | | \"c_132\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_245\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_25\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_649\" | | +--------------+-------------------+-----------------+--------------------+ | | | \"c_753\" | | +--------------+-------------------+-----------------+--------------------+ Got 1519 rows (time spent 12190/14702 us) Wed, 14 Jul 2021 07:08:06 UTC 2.0.2 In a Visual WayOf course, we can also be done in a visual way: Step 1, login from Nebula Graph Studio, explore with one VID: c_132: Step2, click this explored vertex dot, then you can explore from select vertices by selecting: Edge Type Direction Steps Query Limit(Optional) note, you can click the 👁️ icon to add options to show fields of the graph, Step3, after click Expand, you will see all quried relations with c_132 the Chambers LLC. ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:2:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#in-a-visual-way"},{"categories":["Nebula Graph"],"content":" 3 Thanks to Upstream Projects ❤️ Python Faker https://github.com/joke2k/faker/ pydbgen https://github.com/tirthajyoti/pydbgen Nebula Graph https://github.com/vesoft-inc/nebula-graph ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:3:0","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#thanks-to-upstream-projects-"},{"categories":["Nebula Graph"],"content":" 3.1 Tips: You can deploy nebula graph in one line with: Nebula-UP, it helps install a nebula graph with Docker Nebula-operator-KIND , it helps setup all dependencies of Nebula-K8s-Operator including a K8s in Docker, PV Provider and then install a Nebula Graph with Nebula-Operator in K8s. Image Credit goes to https://unsplash.com/photos/3fPXt37X6UQ ","date":"2021-08-28","objectID":"/nebula-holdshare-dataset/:3:1","series":null,"tags":["Nebula Graph","Know How","Shareholding Relationship Analysis","图数据库应用","股权穿透"],"title":"Nebula Holdshare Dataset，图数据库的股权穿透","uri":"/nebula-holdshare-dataset/#tips"},{"categories":null,"content":" 股权穿透教程 1. 上手实战图数据库股权关系穿透 2. 体验 Nebula-Up 一键部署 Nebula Core + Studio 阅读全文 Siwi 1. 上手实战从 0 制作一个基于图谱的语音智能助手 2. 体验 Nebula-Kind-Operator 一键部署 K8s + Nebula Operator 阅读全文 ","date":"2021-08-26","objectID":"/cources/:0:0","series":null,"tags":null,"title":"上手课程","uri":"/cources/#"},{"categories":null,"content":" 掘金春招活动 那些我希望过去的自己可以知道的事实 阅读全文 DoK Talks #116 Nebula Graph: Open Source Distributed GraphDB 阅读全文 Data on K8s Community 2021 GraphDB on Kubesphere 阅读全文 K8s Community Day 2021 Openfunction + GraphDB 阅读全文 COScon 2021 我的开源之路 阅读全文 PyCon China 2021 图数据库解谜与 Python 的图库应用实践 阅读全文 K8s 上的图数据库 Nebula K8s Operator 的实现解析，图数据库应用在 K8s + OpenFunction 上的落地演示 阅读全文 nMeetup: Nebula 应用上手实操 从头实操 Nebula 的部署，股权穿透，图算法运算，语音智能助手。 阅读全文 How to Train your Dragon 如何成为开源开发者（布道师）。 阅读全文 ","date":"2021-08-26","objectID":"/talk/:0:0","series":null,"tags":null,"title":"我的演讲","uri":"/talk/#"},{"categories":["Nebula Graph"],"content":"Import LiveJournal Dataset into Nebula Graph and Run Nebula Algorithm 导入 Livejournal 数据集到 Nebula 并运行 Nebula Algorithm 图算法","date":"2021-08-24","objectID":"/nebula-livejournal/","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/"},{"categories":["Nebula Graph"],"content":" 一个导入 Livejournal 数据集到 Nebula Graph 图数据库，并执行 Nebula Algorithm 图算法的过程分享。 Related GitHub Repo: https://github.com/wey-gu/nebula-LiveJournal ","date":"2021-08-24","objectID":"/nebula-livejournal/:0:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#"},{"categories":["Nebula Graph"],"content":" nebula-LiveJournalLiveJournal Dataset is a Social Network Dataset in one file with two columns(FromNodeId, ToNodeId). $ head soc-LiveJournal1.txt # Directed graph (each unordered pair of nodes is saved once): soc-LiveJournal1.txt # Directed LiveJournal friednship social network # Nodes: 4847571 Edges: 68993773 # FromNodeId ToNodeId 0 1 0 2 0 3 0 4 0 5 0 6 It could be accessed in https://snap.stanford.edu/data/soc-LiveJournal1.html. Dataset statistics Nodes 4847571 Edges 68993773 Nodes in largest WCC 4843953 (0.999) Edges in largest WCC 68983820 (1.000) Nodes in largest SCC 3828682 (0.790) Edges in largest SCC 65825429 (0.954) Average clustering coefficient 0.2742 Number of triangles 285730264 Fraction of closed triangles 0.04266 Diameter (longest shortest path) 16 90-percentile effective diameter 6.5 ","date":"2021-08-24","objectID":"/nebula-livejournal/:0:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#nebula-livejournal"},{"categories":["Nebula Graph"],"content":" 1 Dataset Download and Preprocessing","date":"2021-08-24","objectID":"/nebula-livejournal/:1:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#dataset-download-and-preprocessing"},{"categories":["Nebula Graph"],"content":" 1.1 DownloadIt is accesissiable from the official web page: $ cd nebula-livejournal/data $ wget https://snap.stanford.edu/data/soc-LiveJournal1.txt.gz Comments in data file should be removed to make the data import tool happy. ","date":"2021-08-24","objectID":"/nebula-livejournal/:1:1","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#download"},{"categories":["Nebula Graph"],"content":" 1.2 Preprocessing $ gzip -d soc-LiveJournal1.txt.gz $ sed -i '1,4d' soc-LiveJournal1.txt ","date":"2021-08-24","objectID":"/nebula-livejournal/:1:2","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#preprocessing"},{"categories":["Nebula Graph"],"content":" 2 Import dataset to Nebula Graph","date":"2021-08-24","objectID":"/nebula-livejournal/:2:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#import-dataset-to-nebula-graph"},{"categories":["Nebula Graph"],"content":" 2.1 With Nebula ImporterNebula-Importer is a Golang Headless import tool for Nebula Graph. You may need to edit the config file under nebula-importer/importer.yaml on Nebula Graph’s address and credential。 Then, Nebula-Importer could be called in Docker as follow: $ cd nebula-livejournal $ docker run --rm -ti \\ --network=nebula-net \\ -v nebula-importer/importer.yaml:/root/importer.yaml \\ -v data/:/root \\ vesoft/nebula-importer:v2 \\ --config /root/importer.yaml Or if you have the binary nebula-importer locally: $ cd data $ \u003cpath_to_nebula-importer_binary\u003e --config ../nebula-importer/importer.yaml ","date":"2021-08-24","objectID":"/nebula-livejournal/:2:1","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#with-nebula-importer"},{"categories":["Nebula Graph"],"content":" 2.2 With Nebula ExchangeNebula-Exchange is a Spark Application to enable batch and streaming data import from multiple data sources to Nebula Graph. To be done. (You can refer to https://siwei.io/nebula-exchange-sst-2.x/) ","date":"2021-08-24","objectID":"/nebula-livejournal/:2:2","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#with-nebula-exchange"},{"categories":["Nebula Graph"],"content":" 3 Run Algorithms with Nebula GraphNebula-Algorithm is a Spark/GraphX Application to run Graph Algorithms with data consumed from files or a Nebula Graph Cluster. Supported Algorithms for now: Name Use Case PageRank page ranking, important node digging Louvain community digging, hierarchical clustering KCore community detection, financial risk control LabelPropagation community detection, consultation propagation, advertising recommendation ConnectedComponent community detection, isolated island detection StronglyConnectedComponent community detection ShortestPath path plan, network plan TriangleCount network structure analysis BetweennessCentrality important node digging, node influence calculation DegreeStatic graph structure analysis ","date":"2021-08-24","objectID":"/nebula-livejournal/:3:0","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#run-algorithms-with-nebula-graph"},{"categories":["Nebula Graph"],"content":" 3.1 Ad-hoc Spark Env setupHere I assume the Nebula Graph was bootstraped with Nebula-Up, thus nebula is running in a Docker Network named nebula-docker-compose_nebula-net. Then let’s start a single server spark: docker run --name spark-master --network nebula-docker-compose_nebula-net \\ -h spark-master -e ENABLE_INIT_DAEMON=false -d \\ -v nebula-algorithm/:/root \\ bde2020/spark-master:2.4.5-hadoop2.7 Thus we could make spark application submt inside this container: docker exec -it spark-master bash cd /root/ # download Nebula-Algorithm Jar Packagem, 2.0.0 for example, for other versions, refer to nebula-algorithm github repo and documentations. wget https://repo1.maven.org/maven2/com/vesoft/nebula-algorithm/2.0.0/nebula-algorithm-2.0.0.jar ","date":"2021-08-24","objectID":"/nebula-livejournal/:3:1","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#ad-hoc-spark-env-setup"},{"categories":["Nebula Graph"],"content":" 3.2 Run AlgorithmsThere are many altorithms supported by Nebula-Algorithm, here some of their configuration files were put under nebula-algorithm as an example. Before using them, please first edit and change Nebula Graph Cluster Addresses and credentials. vim nebula-altorithm/algo-pagerank.conf Then we could enter the spark container and call corresponding algorithms as follow. Please adjust your --driver-memeory accordingly, i.e. pagerank altorithm: /spark/bin/spark-submit --master \"local\" --conf spark.rpc.askTimeout=6000s \\ --class com.vesoft.nebula.algorithm.Main \\ --driver-memory 16g nebula-algorithm-2.0.0.jar \\ -p pagerank.conf After the algorithm finished, the output will be under the path insdie the container defined in conf file: write:{ resultPath:/output/ } 题图版权：@sigmund ","date":"2021-08-24","objectID":"/nebula-livejournal/:3:2","series":null,"tags":["Nebula Graph","LiveJournal","Nebula Algorithm","PageRank","Graph Algorithm"],"title":"Nebula LiveJournal，上手 LiveJournal 数据集导入 Nebula Graph 与图算法执行","uri":"/nebula-livejournal/#run-algorithms"},{"categories":["Nebula Graph"],"content":"这篇文章带大家以最小方式，快速趟一下 Nebula Exchange 中 SST 写入方式的步骤。","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/"},{"categories":["Nebula Graph"],"content":"这篇文章带大家以最小方式，快速趟一下 Nebula Exchange 中 SST 写入方式的步骤。 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:0:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#"},{"categories":["Nebula Graph"],"content":" 1 什么是 Nebula Exchange ?之前我在 Nebula Data Import Options 之中介绍过，Nebula Exchange 是一个 Nebula Graph 社区开源的 Spark Applicaiton，它专门用来支持批量或者流式地把数据导入 Nebula Graph Database 之中。 Nebula Exchange 支持多种多样的数据源（从 Apache Parquet, ORC, JSON, CSV, HBase, Hive MaxCompute 到 Neo4j, MySQL, ClickHouse, 再有 Kafka, Pulsar，更多的数据源也在不断增加之中）。 如上图所示，在 Exchange 内部，从除了不同 Reader 可以读取不同数据源之外，在数据经过 Processor 处理之后通过 Writer写入（sink） Nebula Graph 图数据库的时候，除了走正常的 ServerBaseWriter 的写入流程之外，它还可以绕过整个写入流程，利用 Spark 的计算能力并行生成底层 RocksDB 的 SST 文件，从而实现超高性能的数据导入，这个 SST 文件导入的场景就是本文带大家上手熟悉的部分。 详细信息请参阅：Nebula Graph 手册:什么是 Nebula Exchange Nebula Graph 官方博客也有更多 Nebula Exchange 的实践文章 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:1:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#什么是-nebula-exchange-"},{"categories":["Nebula Graph"],"content":" 2 步骤概观 实验环境 配置 Exchange 生成 SST 文件 写入 SST 文件到 Nebula Graph ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:2:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#步骤概观"},{"categories":["Nebula Graph"],"content":" 3 实验环境准备为了最小化使用 Nebula Exchange 的 SST 功能，我们需要： 搭建一个 Nebula Graph 集群，创建导入数据的 Schema，我们选择使用 Docker-Compose 方式、利用 Nebula-Up 快速部署，并简单修改其网络，以方便同样容器化的 Exchange 程序对其访问。 搭建容器化的 Spark 运行环境 搭建容器化的 HDFS ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:3:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#实验环境准备"},{"categories":["Nebula Graph"],"content":" 3.1 1. 搭建 Nebula Graph 集群借助于 Nebula-Up 我们可以在 Linux 环境下一键部署一套 Nebula Graph 集群： curl -fsSL nebula-up.siwei.io/install.sh | bash 待部署成功之后，我们需要对环境做一些修改，这里我做的修改其实就是两点： 只保留一个 metaD 服务 起用 Docker 的外部网络 详细修改的部分参考附录一 应用 docker-compose 的修改： cd ~/.nebula-up/nebula-docker-compose vim docker-compose.yaml # 参考附录一 docker network create nebula-net # 需要创建外部网络 docker-compose up -d --remove-orphans 之后，我们来创建要测试的图空间，并创建图的 Schema，为此，我们可以利用 nebula-console ，同样，Nebula-Up 里自带了容器化的 nebula-console。 进入 Nebula-Console 所在的容器 ~/.nebula-up/console.sh / # 在 console 容器里发起链接到图数据库，其中 192.168.x.y 是我所在的 Linux VM 的第一个网卡地址，请换成您的 / # nebula-console -addr 192.168.x.y -port 9669 -user root -p password [INFO] connection pool is initialized successfully Welcome to Nebula Graph! 创建图空间（我们起名字叫 sst ），以及 schema create space sst(partition_num=5,replica_factor=1,vid_type=fixed_string(32)); :sleep 20 use sst create tag player(name string, age int); 示例输出 (root@nebula) [(none)]\u003e create space sst(partition_num=5,replica_factor=1,vid_type=fixed_string(32)); Execution succeeded (time spent 1468/1918 us) (root@nebula) [(none)]\u003e :sleep 20 (root@nebula) [(none)]\u003e use sst Execution succeeded (time spent 1253/1566 us) Wed, 18 Aug 2021 08:18:13 UTC (root@nebula) [sst]\u003e create tag player(name string, age int); Execution succeeded (time spent 1312/1735 us) Wed, 18 Aug 2021 08:18:23 UTC ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:3:1","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#1-搭建-nebula-graph-集群"},{"categories":["Nebula Graph"],"content":" 3.2 搭建容器化的 Spark 环境利用 big data europe 做的工作，这个过程非常容易。 值得注意的是： 现在的 Nebula Exchange 对 Spark 的版本有要求，在现在的 2021 年 8 月，我是用了 spark-2.4.5-hadoop-2.7 的版本。 为了方便，我让 Spark 运行在 Nebula Graph 相同的机器上，并且指定了运行在同一个 Docker 网络下 docker run --name spark-master --network nebula-net \\ -h spark-master -e ENABLE_INIT_DAEMON=false -d \\ bde2020/spark-master:2.4.5-hadoop2.7 然后，我们就可以进入到环境中了： docker exec -it spark-master bash 进到 Spark 容器中之后，可以像这样安装 maven: export MAVEN_VERSION=3.5.4 export MAVEN_HOME=/usr/lib/mvn export PATH=$MAVEN_HOME/bin:$PATH wget http://archive.apache.org/dist/maven/maven-3/$MAVEN_VERSION/binaries/apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ tar -zxvf apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ rm apache-maven-$MAVEN_VERSION-bin.tar.gz \u0026\u0026 \\ mv apache-maven-$MAVEN_VERSION /usr/lib/mvn 还可以这样在容器里下载 nebula-exchange 的 jar 包： cd ~ wget https://repo1.maven.org/maven2/com/vesoft/nebula-exchange/2.1.0/nebula-exchange-2.1.0.jar ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:3:2","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#搭建容器化的-spark-环境"},{"categories":["Nebula Graph"],"content":" 3.3 搭建容器化的 HDFS同样借助 big-data-euroupe 的工作，这非常简单，不过我们要做一点修改，让它的 docker-compose.yml 文件里使用 nebula-net 这个之前创建的 Docker 网络。 详细修改的部分参考附录二 git clone https://github.com/big-data-europe/docker-hadoop.git cd docker-hadoop vim docker-compose.yml docker-compose up -d ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:3:3","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#搭建容器化的-hdfs"},{"categories":["Nebula Graph"],"content":" 4 配置Exchange这个配置主要填入的信息就是 Nebula Graph 集群本身和将要写入数据的 Space Name，以及数据源相关的配置（这里我们用 csv 作为例子），最后再配置输出（sink）为 sst Nebula Graph GraphD 地址 MetaD 地址 credential Space Name 数据源 source: csv path fields etc. ink: sst 详细的配置参考附录二 注意，这里 metaD 的地址可以这样获取，可以看到 0.0.0.0:49377-\u003e9559 表示 49377 是外部的地址。 $ docker ps | grep meta 887740c15750 vesoft/nebula-metad:v2.0.0 \"./bin/nebula-metad …\" 6 hours ago Up 6 hours (healthy) 9560/tcp, 0.0.0.0:49377-\u003e9559/tcp, :::49377-\u003e9559/tcp, 0.0.0.0:49376-\u003e19559/tcp, :::49376-\u003e19559/tcp, 0.0.0.0:49375-\u003e19560/tcp, :::49375-\u003e19560/tcp nebula-docker-compose_metad0_1 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:4:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#配置exchange"},{"categories":["Nebula Graph"],"content":" 5 生成SST文件","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:5:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#生成sst文件"},{"categories":["Nebula Graph"],"content":" 5.1 准备源文件、配置文件 docker cp exchange-sst.conf spark-master:/root/ docker cp player.csv spark-master:/root/ 其中 player.csv 的例子： 1100,Tim Duncan,42 1101,Tony Parker,36 1102,LaMarcus Aldridge,33 1103,Rudy Gay,32 1104,Marco Belinelli,32 1105,Danny Green,31 1106,Kyle Anderson,25 1107,Aron Baynes,32 1108,Boris Diaw,36 1109,Tiago Splitter,34 1110,Cory Joseph,27 1111,David West,38 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:5:1","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#准备源文件配置文件"},{"categories":["Nebula Graph"],"content":" 5.2 执行 exchange 程序进入 spark-master 容器，提交执行 exchange 应用。 docker exec -it spark-master bash cd /root/ /spark/bin/spark-submit --master local \\ --class com.vesoft.nebula.exchange.Exchange nebula-exchange-2.1.0.jar\\ -c exchange-sst.conf 检查执行结果： spark-submit 输出： 21/08/17 03:37:43 INFO TaskSetManager: Finished task 31.0 in stage 2.0 (TID 33) in 1093 ms on localhost (executor driver) (32/32) 21/08/17 03:37:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 21/08/17 03:37:43 INFO DAGScheduler: ResultStage 2 (foreachPartition at VerticesProcessor.scala:179) finished in 22.336 s 21/08/17 03:37:43 INFO DAGScheduler: Job 1 finished: foreachPartition at VerticesProcessor.scala:179, took 22.500639 s 21/08/17 03:37:43 INFO Exchange$: SST-Import: failure.player: 0 21/08/17 03:37:43 WARN Exchange$: Edge is not defined 21/08/17 03:37:43 INFO SparkUI: Stopped Spark web UI at http://spark-master:4040 21/08/17 03:37:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped! 验证 HDFS 上生成的 SST 文件： docker exec -it namenode /bin/bash root@2db58903fb53:/# hdfs dfs -ls /sst Found 10 items drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/1 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/10 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/2 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/3 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/4 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/5 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/6 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/7 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/8 drwxr-xr-x - root supergroup 0 2021-08-17 03:37 /sst/9 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:5:2","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#执行-exchange-程序"},{"categories":["Nebula Graph"],"content":" 6 写入SST到NebulaGraph这里的操作实际上都是参考文档：SST 导入，得来。其中就是从 console 之中执行了两步操作： Download Ingest 其中 Download 实际上是触发 Nebula Graph 从服务端发起 HDFS Client 的 download，获取 HDFS 上的 SST 文件，然后放到 storageD 能访问的本地路径下，这里，需要我们在服务端部署 HDFS 的依赖。因为我们是最小实践，我就偷懒手动做了这个 Download 的操作。 ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:6:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#写入sst到nebulagraph"},{"categories":["Nebula Graph"],"content":" 6.1 手动下载这里边手动下载我们就要知道 Nebula Graph 服务端下载的路径，实际上是 /data/storage/nebula/\u003cspace_id\u003e/download/，这里的 Space ID 需要手动获取一下： 这个例子里，我们的 Space Name 是 sst，而 Space ID 是 49。 (root@nebula) [sst]\u003e DESC space sst +----+-------+------------------+----------------+---------+------------+--------------------+-------------+-----------+ | ID | Name | Partition Number | Replica Factor | Charset | Collate | Vid Type | Atomic Edge | Group | +----+-------+------------------+----------------+---------+------------+--------------------+-------------+-----------+ | 49 | \"sst\" | 10 | 1 | \"utf8\" | \"utf8_bin\" | \"FIXED_STRING(32)\" | \"false\" | \"default\" | +----+-------+------------------+----------------+---------+------------+--------------------+-------------+-----------+ 于是，下边的操作就是手动把 SST 文件从 HDFS 之中 get 下来，再拷贝到 storageD 之中。 docker exec -it namenode /bin/bash $ hdfs dfs -get /sst /sst exit docker cp namenode:/sst . docker exec -it nebula-docker-compose_storaged0_1 mkdir -p /data/storage/nebula/49/download/ docker exec -it nebula-docker-compose_storaged1_1 mkdir -p /data/storage/nebula/49/download/ docker exec -it nebula-docker-compose_storaged2_1 mkdir -p /data/storage/nebula/49/download/ docker cp sst nebula-docker-compose_storaged0_1:/data/storage/nebula/49/download/ docker cp sst nebula-docker-compose_storaged1_1:/data/storage/nebula/49/download/ docker cp sst nebula-docker-compose_storaged2_1:/data/storage/nebula/49/download/ ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:6:1","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#手动下载"},{"categories":["Nebula Graph"],"content":" 6.2 SST 文件导入 进入 Nebula-Console 所在的容器 ~/.nebula-up/console.sh / # 在 console 容器里发起链接到图数据库，其中 192.168.x.y 是我所在的 Linux VM 的第一个网卡地址，请换成您的 / # nebula-console -addr 192.168.x.y -port 9669 -user root -p password [INFO] connection pool is initialized successfully Welcome to Nebula Graph! 执行 INGEST 开始让 StorageD 读取 SST 文件 (root@nebula) [(none)]\u003e use sst (root@nebula) [sst]\u003e INGEST; 我们可以用如下方法实时查看 Nebula Graph 服务端的日志 tail -f ~/.nebula-up/nebula-docker-compose/logs/*/* 成功的 INGEST 日志： I0817 08:03:28.611877 169 EventListner.h:96] Ingest external SST file: column family default, the external file path /data/storage/nebula/49/download/8/8-6.sst, the internal file path /data/storage/nebula/49/data/000023.sst, the properties of the table: # data blocks=1; # entries=1; # deletions=0; # merge operands=0; # range deletions=0; raw key size=48; raw average key size=48.000000; raw value size=40; raw average value size=40.000000; data block size=75; index block size (user-key? 0, delta-value? 0)=66; filter block size=0; (estimated) table size=141; filter policy name=N/A; prefix extractor name=nullptr; column family ID=N/A; column family name=N/A; comparator name=leveldb.BytewiseComparator; merge operator name=nullptr; property collectors names=[]; SST file compression algo=Snappy; SST file compression options=window_bits=-14; level=32767; strategy=0; max_dict_bytes=0; zstd_max_train_bytes=0; enabled=0; ; creation time=0; time stamp of earliest key=0; file creation time=0; E0817 08:03:28.611912 169 StorageHttpIngestHandler.cpp:63] SSTFile ingest successfully 题图版权：Pietro Jeng ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:6:2","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#sst-文件导入"},{"categories":["Nebula Graph"],"content":" 7 附录","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:7:0","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#附录"},{"categories":["Nebula Graph"],"content":" 7.1 附录一docker-compose.yaml diff --git a/docker-compose.yaml b/docker-compose.yaml index 48854de..cfeaedb 100644 --- a/docker-compose.yaml +++ b/docker-compose.yaml @@ -6,11 +6,13 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --local_ip=metad0 - --ws_ip=metad0 - --port=9559 - --ws_http_port=19559 + - --ws_storage_http_port=19779 - --data_path=/data/meta - --log_dir=/logs - --v=0 @@ -34,81 +36,14 @@ services: cap_add: - SYS_PTRACE - metad1: - image: vesoft/nebula-metad:v2.0.0 - environment: - USER: root - TZ: \"${TZ}\" - command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 - - --local_ip=metad1 - - --ws_ip=metad1 - - --port=9559 - - --ws_http_port=19559 - - --data_path=/data/meta - - --log_dir=/logs - - --v=0 - - --minloglevel=0 - healthcheck: - test: [\"CMD\", \"curl\", \"-sf\", \"http://metad1:19559/status\"] - interval: 30s - timeout: 10s - retries: 3 - start_period: 20s - ports: - - 9559 - - 19559 - - 19560 - volumes: - - ./data/meta1:/data/meta - - ./logs/meta1:/logs - networks: - - nebula-net - restart: on-failure - cap_add: - - SYS_PTRACE - - metad2: - image: vesoft/nebula-metad:v2.0.0 - environment: - USER: root - TZ: \"${TZ}\" - command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 - - --local_ip=metad2 - - --ws_ip=metad2 - - --port=9559 - - --ws_http_port=19559 - - --data_path=/data/meta - - --log_dir=/logs - - --v=0 - - --minloglevel=0 - healthcheck: - test: [\"CMD\", \"curl\", \"-sf\", \"http://metad2:19559/status\"] - interval: 30s - timeout: 10s - retries: 3 - start_period: 20s - ports: - - 9559 - - 19559 - - 19560 - volumes: - - ./data/meta2:/data/meta - - ./logs/meta2:/logs - networks: - - nebula-net - restart: on-failure - cap_add: - - SYS_PTRACE - storaged0: image: vesoft/nebula-storaged:v2.0.0 environment: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --local_ip=storaged0 - --ws_ip=storaged0 - --port=9779 @@ -119,8 +54,8 @@ services: - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://storaged0:19779/status\"] interval: 30s @@ -146,7 +81,7 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --local_ip=storaged1 - --ws_ip=storaged1 - --port=9779 @@ -157,8 +92,8 @@ services: - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://storaged1:19779/status\"] interval: 30s @@ -184,7 +119,7 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --local_ip=storaged2 - --ws_ip=storaged2 - --port=9779 @@ -195,8 +130,8 @@ services: - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://storaged2:19779/status\"] interval: 30s @@ -222,17 +157,19 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --port=9669 - --ws_ip=graphd - --ws_http_port=19669 + - --ws_meta_http_port=19559 - --log_dir=/logs - --v=0 - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://graphd:19669/status\"] interval: 30s @@ -257,17 +194,19 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=metad0:9559 - --port=9669 - --ws_ip=graphd1 - --ws_http_port=19669 + - --ws_meta_http_port=19559 - --log_dir=/logs - --v=0 - --minloglevel=0 depends_on: - metad0 - - metad1 - - metad2 healthcheck: test: [\"CMD\", \"curl\", \"-sf\", \"http://graphd1:19669/status\"] interval: 30s @@ -292,17 +231,21 @@ services: USER: root TZ: \"${TZ}\" command: - - --meta_server_addrs=metad0:9559,metad1:9559,metad2:9559 + - --meta_server_addrs=me","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:7:1","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#附录一"},{"categories":["Nebula Graph"],"content":" 7.2 附录二https://github.com/big-data-europe/docker-hadoop 的 docker-compose.yml diff --git a/docker-compose.yml b/docker-compose.yml index ed40dc6..66ff1f4 100644 --- a/docker-compose.yml +++ b/docker-compose.yml @@ -14,6 +14,8 @@ services: - CLUSTER_NAME=test env_file: - ./hadoop.env + networks: + - nebula-net datanode: image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8 @@ -25,6 +27,8 @@ services: SERVICE_PRECONDITION: \"namenode:9870\" env_file: - ./hadoop.env + networks: + - nebula-net resourcemanager: image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8 @@ -34,6 +38,8 @@ services: SERVICE_PRECONDITION: \"namenode:9000 namenode:9870 datanode:9864\" env_file: - ./hadoop.env + networks: + - nebula-net nodemanager1: image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8 @@ -43,6 +49,8 @@ services: SERVICE_PRECONDITION: \"namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088\" env_file: - ./hadoop.env + networks: + - nebula-net historyserver: image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8 @@ -54,8 +62,14 @@ services: - hadoop_historyserver:/hadoop/yarn/timeline env_file: - ./hadoop.env + networks: + - nebula-net volumes: hadoop_namenode: hadoop_datanode: hadoop_historyserver: + +networks: + nebula-net: + external: true ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:7:2","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#附录二"},{"categories":["Nebula Graph"],"content":" 7.3 附录三nebula-exchange-sst.conf { # Spark relation config spark: { app: { name: Nebula Exchange 2.1 } master:local driver: { cores: 1 maxResultSize: 1G } executor: { memory:1G } cores:{ max: 16 } } # Nebula Graph relation config nebula: { address:{ graph:[\"192.168.8.128:9669\"] meta:[\"192.168.8.128:49377\"] } user: root pswd: nebula space: sst # parameters for SST import, not required path:{ local:\"/tmp\" remote:\"/sst\" hdfs.namenode: \"hdfs://192.168.8.128:9000\" } # nebula client connection parameters connection { # socket connect \u0026 execute timeout, unit: millisecond timeout: 30000 } error: { # max number of failures, if the number of failures is bigger than max, then exit the application. max: 32 # failed import job will be recorded in output path output: /tmp/errors } # use google's RateLimiter to limit the requests send to NebulaGraph rate: { # the stable throughput of RateLimiter limit: 1024 # Acquires a permit from RateLimiter, unit: MILLISECONDS # if it can't be obtained within the specified timeout, then give up the request. timeout: 1000 } } # Processing tags # There are tag config examples for different dataSources. tags: [ # HDFS csv # Import mode is sst, just change type.sink to client if you want to use client import mode. { name: player type: { source: csv sink: sst } path: \"file:///root/player.csv\" # if your csv file has no header, then use _c0,_c1,_c2,.. to indicate fields fields: [_c1, _c2] nebula.fields: [name, age] vertex: { field:_c0 } separator: \",\" header: false batch: 256 partition: 32 } ] } ","date":"2021-08-18","objectID":"/nebula-exchange-sst-2.x/:7:3","series":null,"tags":["Nebula Graph","Nebula Exchange","SST"],"title":"Nebula Exchange SST 2.x Hands-on Guide","uri":"/nebula-exchange-sst-2.x/#附录三"},{"categories":["sketches"],"content":"介绍 Nebula Graph 的云原生 K8s Operator 部署","date":"2021-08-06","objectID":"/sketches/nebula-operator-explained/","series":null,"tags":["Nebula Graph","K8s"],"title":"Nebula operator Explained","uri":"/sketches/nebula-operator-explained/"},{"categories":["sketches"],"content":" Nebula Graph operator explained 这个手记里，我介绍了 Nebula Graph 的 K8s Operator: Intro 00:00 Nebula K8s Operator Explained 0:25 How do we use Nebula Operator? 02:23 What is the difference between the Operator based Nebula Graph Cluster and the binary-based one? 03:50 How about the Performance impact when it comes to K8s-Operator deployment? 04:55 What is the easiest way to try out the nebula operator? 06:04 Outra 07:30 ref: https://github.com/vesoft-inc/nebula-operator ","date":"2021-08-06","objectID":"/sketches/nebula-operator-explained/:0:0","series":null,"tags":["Nebula Graph","K8s"],"title":"Nebula operator Explained","uri":"/sketches/nebula-operator-explained/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-08-06","objectID":"/sketches/nebula-operator-explained/:1:0","series":null,"tags":["Nebula Graph","K8s"],"title":"Nebula operator Explained","uri":"/sketches/nebula-operator-explained/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-08-06","objectID":"/sketches/nebula-operator-explained/:2:0","series":null,"tags":["Nebula Graph","K8s"],"title":"Nebula operator Explained","uri":"/sketches/nebula-operator-explained/#youtube"},{"categories":["sketches"],"content":"Nebula Config Explained","date":"2021-07-26","objectID":"/sketches/nebula-config-explained/","series":null,"tags":["Nebula Graph","config"],"title":"Nebula Config Explained","uri":"/sketches/nebula-config-explained/"},{"categories":["sketches"],"content":" Nebula Graph config explained 这个手记帮助我们理解 Nebula Graph 的配置相关的知识： 介绍 Nebula Graph 三种配置方式，它们的优先级、范围、生效条件 0:16 介绍 Nebula Graph 在 Docker-Compose/Swarm 部署情况下配置的方式 03:01 介绍 Nebula Graph 在 K8s Operator 部署情况下配置的方式 03:55 我们是否应该用 Local-Config？（剧透：应该） 05:03 ","date":"2021-07-26","objectID":"/sketches/nebula-config-explained/:0:0","series":null,"tags":["Nebula Graph","config"],"title":"Nebula Config Explained","uri":"/sketches/nebula-config-explained/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-07-26","objectID":"/sketches/nebula-config-explained/:1:0","series":null,"tags":["Nebula Graph","config"],"title":"Nebula Config Explained","uri":"/sketches/nebula-config-explained/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-07-26","objectID":"/sketches/nebula-config-explained/:2:0","series":null,"tags":["Nebula Graph","config"],"title":"Nebula Config Explained","uri":"/sketches/nebula-config-explained/#youtube"},{"categories":["sketches"],"content":"Nebula Index Demystified","date":"2021-07-13","objectID":"/sketches/nebula-index-demystified/","series":null,"tags":["Nebula Graph","index"],"title":"Nebula Graph Index Demystified","uri":"/sketches/nebula-index-demystified/"},{"categories":["sketches"],"content":" Nebula Graph 原生索引解谜，帮助大家深入了解 Nebula Graph Index 原生索引，到底 Nebula Graph 的原生索引是做什么用的？为什么 Nebula Graph 索引对性能有一些影响？带有索引的写入过程是什么样的？ Index Demystified 0:33 When should we use index? 06:37 Index v.s. Fulltext Index 07:12 Index Performance Impact 08:03 ","date":"2021-07-13","objectID":"/sketches/nebula-index-demystified/:0:0","series":null,"tags":["Nebula Graph","index"],"title":"Nebula Graph Index Demystified","uri":"/sketches/nebula-index-demystified/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-07-13","objectID":"/sketches/nebula-index-demystified/:1:0","series":null,"tags":["Nebula Graph","index"],"title":"Nebula Graph Index Demystified","uri":"/sketches/nebula-index-demystified/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-07-13","objectID":"/sketches/nebula-index-demystified/:2:0","series":null,"tags":["Nebula Graph","index"],"title":"Nebula Graph Index Demystified","uri":"/sketches/nebula-index-demystified/#youtube"},{"categories":["sketches"],"content":"Nebula Graph Deployment Options","date":"2021-06-25","objectID":"/sketches/nebula-deployment-options/","series":null,"tags":["Nebula Graph","deployment"],"title":"Nebula Graph Deployment Options","uri":"/sketches/nebula-deployment-options/"},{"categories":["sketches"],"content":" Nebula Graph 有很多种分发、部署方式，我们应该如何选择它们呢？ ","date":"2021-06-25","objectID":"/sketches/nebula-deployment-options/:0:0","series":null,"tags":["Nebula Graph","deployment"],"title":"Nebula Graph Deployment Options","uri":"/sketches/nebula-deployment-options/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-06-25","objectID":"/sketches/nebula-deployment-options/:1:0","series":null,"tags":["Nebula Graph","deployment"],"title":"Nebula Graph Deployment Options","uri":"/sketches/nebula-deployment-options/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-06-25","objectID":"/sketches/nebula-deployment-options/:2:0","series":null,"tags":["Nebula Graph","deployment"],"title":"Nebula Graph Deployment Options","uri":"/sketches/nebula-deployment-options/#youtube"},{"categories":["sketches"],"content":"Nebula Graph Data Import Options","date":"2021-06-15","objectID":"/sketches/nebula-data-import-options/","series":null,"tags":["Nebula Graph","data import"],"title":"Nebula Graph Data Import Options","uri":"/sketches/nebula-data-import-options/"},{"categories":["sketches"],"content":" Nebula Graph 提供了好多种数据导入的工具，我们应该如何选择呢？这一张图帮助大家了解 Nebula Graph 所有的数据导入选项。 ","date":"2021-06-15","objectID":"/sketches/nebula-data-import-options/:0:0","series":null,"tags":["Nebula Graph","data import"],"title":"Nebula Graph Data Import Options","uri":"/sketches/nebula-data-import-options/#"},{"categories":["sketches"],"content":" 1 Bilibili ","date":"2021-06-15","objectID":"/sketches/nebula-data-import-options/:1:0","series":null,"tags":["Nebula Graph","data import"],"title":"Nebula Graph Data Import Options","uri":"/sketches/nebula-data-import-options/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube ","date":"2021-06-15","objectID":"/sketches/nebula-data-import-options/:2:0","series":null,"tags":["Nebula Graph","data import"],"title":"Nebula Graph Data Import Options","uri":"/sketches/nebula-data-import-options/#youtube"},{"categories":["Nebula Graph"],"content":"无需依赖，一键安装尝鲜基于 Nebula Operator 的 K8s Nebula Graph Cluster","date":"2021-06-09","objectID":"/nebula-operator-kind/","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/"},{"categories":["Nebula Graph"],"content":" Nebula-Kind，无需依赖，一键安装尝鲜基于 Nebula Operator 的 K8s Nebula Graph Cluster。 注： KIND 是一个 K8s 的 SIG，代表 K8s in Docker。 ","date":"2021-06-09","objectID":"/nebula-operator-kind/:0:0","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/#"},{"categories":["Nebula Graph"],"content":" 1 Nebula-Operator-Kind 是什么Nebula Graph 作为云原生的分布式开源图数据库，有开源的 K8s Operator 供大家在 K8s 上方便的通过 CRD 去维护、部署 Nebula Graph 集群。 对于手头没有方便的 K8s 环境的同学，如果想尝鲜、学习 Nebula Graph 的 K8s Operator 的话，可能需要耗费一些精力才能搭起来一整套的控制平面的依赖。 作为一个懒人，我做利用 K8s in Docker(KIND)，和之前做 Nebula-Up 的 shell 脚本架子，快速的搞了一个一键安装工具：Nebula-Operator-Kind 它能直接帮我们： 安装 Docker 安装 K8s(KIND) 安装 PV Provider 安装 Nebula-Operator 以及依赖 安装 Nebula-Console 配置 nodePort 用以一键直连 Nebula 集群 安装 kubectl 用来体验 Nebula-Operator 的 CRD 配置 ","date":"2021-06-09","objectID":"/nebula-operator-kind/:1:0","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/#nebula-operator-kind-是什么"},{"categories":["Nebula Graph"],"content":" 2 如何使用安装： curl -sL nebula-kind.siwei.io/install.sh | bash 成功之后： 用 ~/.nebula-kind/bin/console 一行连接集群： ~/.nebula-kind/bin/console -u user -p password --address=127.0.0.1 --port=30000 ","date":"2021-06-09","objectID":"/nebula-operator-kind/:2:0","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/#如何使用"},{"categories":["Nebula Graph"],"content":" 3 详细信息Repo 的地址是：https://github.com/wey-gu/nebula-operator-kind ，里边有更多的信息，欢迎大家试用、反馈、PR 哈！ Updated Sept. 2021 如果在 KubeSphere All-in-one 环境安装： curl -sL nebula-kind.siwei.io/install-ks-1.sh | bash 如果在 Minikube、其他 K8s 之中安装 curl -sL nebula-kind.siwei.io/install-on-k8s.sh | bash 题图版权：Maik Hankemann ","date":"2021-06-09","objectID":"/nebula-operator-kind/:3:0","series":null,"tags":["Nebula Graph","Nebula Operator","K8s"],"title":"Nebula Operator Kind，一键单机玩转 Nebula K8s 集群","uri":"/nebula-operator-kind/#详细信息"},{"categories":null,"content":" 您好，我是古思为。我是一个在上海的软件工程师，我在 vesoft 担任 Nebula Graph（开源的分布式图数据库）的社区开发者布道师。 我的工作是通过围绕 Nebula Graph Database 创作内容，构建工具来改善开发者的学习、开发、社区参与体验。 我在开源社区开放的工作，并（花了职业生涯中的前些年意识到）热爱用自己的思想和学到的技术帮助到别人，我认为这是一种的荣幸和宝贵的机遇。 1 ","date":"2021-06-04","objectID":"/about/:0:0","series":null,"tags":null,"title":"","uri":"/about/#您好我是古思为"},{"categories":null,"content":" 1 最近的开源项目 Nebula-Corp-Rel-Graph Nebula-Corp-Rel-Graph，基于图数据库的股权穿透系统 阅读全文 Nebula-Siwi Nebula-Siwi，基于图数据库的智能问答助手 阅读全文 Nebula-Holdshare Nebula-Holdshare，图数据库应用示例：股权关系穿透 阅读全文 Nebula-KIND Nebula-Kind，无需依赖，一键安装尝鲜基于 Nebula Operator 的 K8s Nebula Graph Cluster。注： KIND 是一个 K8s 的 SIG，代表 K8s in Docker。 阅读全文 Nebula-Up Nebula-up，一键拉起一个 Nebula 测试环境，支持 mscOS，Windows 10，CentOS 和 Ubuntu。 阅读全文 VSCode-nGQL VSCode-nGQL，Nebula Graph 的 VS Code 插件，ngql 语法高亮。 阅读全文 IPython-nGQL Nebula Graph 的 Jupyter Notebook 和 IPython 插件，方便在 Notebook 之中嵌入 nGQL 的 query 和 结果的调试。 阅读全文 nebula-insights 本文介绍我们如何用公有云 Serverless 技术：Google Cloud Scheduler，Google Cloud Functions 和 BigQuery 搭建数据管道，收集探索开源社区洞察。并将全部代码开源在 GitHub。 阅读全文 ","date":"2021-06-04","objectID":"/about/:1:0","series":null,"tags":null,"title":"","uri":"/about/#最近的开源项目"},{"categories":null,"content":" 2 我的手绘 Nebula Operator Explained Nebula Graph K8s Operator 介绍 阅读全文 Nebula Config Explained Nebula Graph 配置详解 阅读全文 Nebula Index Demystified Nebula Graph 原生索引解谜 阅读全文 Nebula Data Import Options Nebula Graph 提供了好多种数据导入的工具，我们应该如何选择呢？ 阅读全文 Nebula Deployment Options Nebula Graph 有很多种分发、部署方式，我们应该如何选择它们呢？ 阅读全文 Nebula Intro 新手玩转 Nebula Graph 系列开篇。 阅读全文 ","date":"2021-06-04","objectID":"/about/:2:0","series":null,"tags":null,"title":"","uri":"/about/#我的手绘"},{"categories":null,"content":" 3 我的上手课程 股权穿透教程 上手实战股权用图数据库关系穿透 阅读全文 Siwi 上手实战从 0 制作一个基于图谱的语音智能助手 阅读全文 ","date":"2021-06-04","objectID":"/about/:3:0","series":null,"tags":null,"title":"","uri":"/about/#我的上手课程"},{"categories":null,"content":" 4 我的演讲 掘金春招活动 那些我希望过去的自己可以知道的事实 阅读全文 DoK Talks #116 Nebula Graph: Open Source Distributed GraphDB 阅读全文 Data on K8s Community 2021 GraphDB on Kubesphere 阅读全文 K8s Community Day 2021 Openfunction + GraphDB 阅读全文 COScon 2021 我的开源之路 阅读全文 PyCon China 2021 图数据库解谜与 Python 的图库应用实践 阅读全文 K8s 上的图数据库 Nebula K8s Operator 的实现解析，图数据库应用在 K8s + OpenFunction 上的落地演示 阅读全文 nMeetup: Nebula 应用上手实操 从头实操 Nebula 的部署，股权穿透，图算法运算，语音智能助手。 阅读全文 How to Train your Dragon 如何成为开源开发者（布道师）。 阅读全文 ","date":"2021-06-04","objectID":"/about/:4:0","series":null,"tags":null,"title":"","uri":"/about/#我的演讲"},{"categories":null,"content":" 5 过往的经历我曾在爱立信工作了近十年：2011 年到 2021 年。 我是云计算产品 Cloud Execution Envrioment (CEE) 2 研发团队的系统经理 3，我大部分的工作是通过设计开发 20 多个 CEE 6.6.2 和 CEE 10 的功能与改进，涵盖计算、存储、网络、生命周期管理和安全等领域，来帮助爱立信 IaaS 产品与解决方案不断进化。 同时，我也负责 CEE 产品在中国区的布道（面向外部与内部）。 我曾在 note.siwei.info 记录一些想法和笔记，从2021年春天开始，我会把想法记录下来留在 siwei.io ","date":"2021-06-04","objectID":"/about/:5:0","series":null,"tags":null,"title":"","uri":"/about/#过往的经历"},{"categories":null,"content":" 6 联系我您最好通过 twitter，邮箱 wey.gu@vesoft.com 找到我。 如果必须，您也可以通过微信找到我，微信 ID 如下，请添加注明您的来意。 echo c2l2dmVpCg== | base64 -d 或者和我约一个 Zoom Call 我和 Ahmet Alp Balkan 的 这个推文 感同身受： Working in open source (and getting paid for it) is a privilege. It’s a career boost, makes you lots of friends across the industry, and gives you a public brand. I am one of the “lucky few” \u0026 thankful to Microsoft and Google who let me work on OSS nearly all my career. — ahmetb (@ahmetb) February 19, 2021  ↩︎ Ericsson’s Telco. Infrastructure as a Service product offerring: Cloud Execution Environment ↩︎ System Manager, PDU Cloud: 工作描述 ↩︎ ","date":"2021-06-04","objectID":"/about/:6:0","series":null,"tags":null,"title":"","uri":"/about/#联系我"},{"categories":["Nebula Graph"],"content":"本文作者分析了 Chia Network 的全链数据，并做了将全链数据导入图数据库：Nebula Graph 之中的尝试，从而可视化地探索了 Chia 图中数据之间的关联关系。","date":"2021-05-26","objectID":"/nebula-chia/","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/"},{"categories":["Nebula Graph"],"content":" 这篇文章里，我全网首次地分析了 Chia Network 的全链数据，并做了将全链数据导入图数据库：Nebula Graph 之中的尝试，从而可视化地探索了 Chia 图中数据之间的关联关系。 我把涉及的代码开源在了这里：https://github.com/wey-gu/nebula-chia ","date":"2021-05-26","objectID":"/nebula-chia/:0:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#"},{"categories":["Nebula Graph"],"content":" 1 Chia 是什么?Chia Network 是由 BitTorrent 的作者 Bram Cohen 的团队在 2017 年创建的区块链项目。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#chia-是什么"},{"categories":["Nebula Graph"],"content":" 1.1 为什么再搞一个区块链?Chia 用了全新的中本聪共识算法，这个算法通过不允许并行计算，让挖矿（Proof of Work）所需算力和能耗降到非常低，这使得超大组织、玩家没法像在其他的区块链项目那样有算力的绝对优势，也一定程度上规避了能源的浪费。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#为什么再搞一个区块链"},{"categories":["Nebula Graph"],"content":" 1.2 如何连接Chia?我们可以通过 Chia Network 的客户端来访问它，这个客户端是 Electron + Python 的程序，天然跨平台，既有 GUI 又有 CLI 的方式。 1.2.1 安装只需要按照官方的 Guide 来下载安装就好， https://github.com/Chia-Network/chia-blockchain/wiki/INSTALL，我在 M1 Mac 下安装的时候脚本出了点小问题，大概是因为拉取二进制 wheel 文件网络出问题走到了编译 wheel的逻辑，而那里是依赖 cargo的，如果大家遇到了这个问题，可以提前手动安装一下 rust，或者 cherry-pick 我的这个 PR 。 1.2.2 运行 按照官方 guide，比如 macOS 来说，最后一步执行npm run electron \u0026 就是运行它的GUI客户端。 如果大家像我一样喜欢 CLI，直接在执行完 . ./activate 之后就可以 chia --help了哈☺，里边有只启动部分服务的方式（相比 GUI 启动所有来说)。 在运行之后，如果你的网络不是多层 NAT 的那种，理论上您可以连到 mainnet 并且自动和主链同步数据了，如果您是第二次运行，连接主链，一开始可能有一阵子同步的block 数是不变的，也没有 peer 连过来，不必惊慌，等一下就好了。 Tips: 第一次连到 Chia Network 的同学们，客户端会自动生成一个钱包，及的保存那一串词，它们就是你的私钥哦。 万一，如果真的连不上的话，可能需要在路由上配置，UPnP，防火墙要允许 8444。 1.2.3 访问 Chia 的数据Chia 的客户端把数据存在了几个 SQLite 数据库里，它们的路径是我们安装客户端的用户的家目录：~/.chia/mainnet 下边就是运行起来 Chia 之后生成的主要的两个数据库的二进制文件： ~/.chia/mainnet/db ❯ ll -h total 4350416 -rw-r--r-- 1 weyl staff 2.0G May 6 12:06 blockchain_v1_mainnet.sqlite -rw-r--r-- 1 weyl staff 64K May 6 11:17 blockchain_v1_mainnet.sqlite-shm -rw-r--r-- 1 weyl staff 20M May 6 12:10 blockchain_v1_mainnet.sqlite-wal -rw-r--r-- 1 weyl staff 1.8M May 6 11:46 peer_table_node.sqlite -rw-r--r-- 1 weyl staff 32K May 5 17:30 peer_table_node.sqlite-shm -rw-r--r-- 1 weyl staff 5.4M May 6 11:46 peer_table_node.sqlite-wal ~/.chia/mainnet/wallet/db ❯ ll -h total 3055848 -rw-r--r-- 1 weyl staff 1.4G May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite -rw-r--r-- 1 weyl staff 32K May 7 15:24 blockchain_wallet_v1_mainnet_903996200.sqlite-shm -rw-r--r-- 1 weyl staff 4.0M May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite-wal -rw-r--r-- 1 weyl staff 16K May 7 15:24 wallet_peers.sqlite 然后，我们可以先用 SQLite Browser，一个 SQlite 数据库（文件）的浏览器来看看它。 SQlite 浏览器的官网是 https://sqlitebrowser.org/ 。在下载，安装之后，我们可以通过点击 Open Database/打开数据库 选择浏览上边列出来的两个 .sqlite 扩展名的数据库文件。 打开数据库之后，我们可以选择第一个标签 Database Schema 来看看表的结构。 我们还能像类似于 Excel 一样去看表的数据，还可以 Filter/过滤、Sort/排序任意列。 下一部分，我们来简单看看表里的数据。 Tips: 这里边，~/.chia/mainnet/wallet 和裸目录 ~/.chia/mainnet 下边的 db 里分别都有表文件，他们的信息是有重复的，大家可以分别打开看看哦，即使是相同的表的名字，比如 block_record 内里的信息也略有差别，如果大家知道为什么有这样的差别，欢迎浏览告诉大家哈，可能要仔细研究一下客户端、钱包等代码才行，幸运的是，它们相对比较好阅读，是 Python 写的： https://github.com/Chia-Network/chia-blockchain 。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#如何连接chia"},{"categories":["Nebula Graph"],"content":" 1.2 如何连接Chia?我们可以通过 Chia Network 的客户端来访问它，这个客户端是 Electron + Python 的程序，天然跨平台，既有 GUI 又有 CLI 的方式。 1.2.1 安装只需要按照官方的 Guide 来下载安装就好， https://github.com/Chia-Network/chia-blockchain/wiki/INSTALL，我在 M1 Mac 下安装的时候脚本出了点小问题，大概是因为拉取二进制 wheel 文件网络出问题走到了编译 wheel的逻辑，而那里是依赖 cargo的，如果大家遇到了这个问题，可以提前手动安装一下 rust，或者 cherry-pick 我的这个 PR 。 1.2.2 运行 按照官方 guide，比如 macOS 来说，最后一步执行npm run electron \u0026 就是运行它的GUI客户端。 如果大家像我一样喜欢 CLI，直接在执行完 . ./activate 之后就可以 chia --help了哈☺，里边有只启动部分服务的方式（相比 GUI 启动所有来说)。 在运行之后，如果你的网络不是多层 NAT 的那种，理论上您可以连到 mainnet 并且自动和主链同步数据了，如果您是第二次运行，连接主链，一开始可能有一阵子同步的block 数是不变的，也没有 peer 连过来，不必惊慌，等一下就好了。 Tips: 第一次连到 Chia Network 的同学们，客户端会自动生成一个钱包，及的保存那一串词，它们就是你的私钥哦。 万一，如果真的连不上的话，可能需要在路由上配置，UPnP，防火墙要允许 8444。 1.2.3 访问 Chia 的数据Chia 的客户端把数据存在了几个 SQLite 数据库里，它们的路径是我们安装客户端的用户的家目录：~/.chia/mainnet 下边就是运行起来 Chia 之后生成的主要的两个数据库的二进制文件： ~/.chia/mainnet/db ❯ ll -h total 4350416 -rw-r--r-- 1 weyl staff 2.0G May 6 12:06 blockchain_v1_mainnet.sqlite -rw-r--r-- 1 weyl staff 64K May 6 11:17 blockchain_v1_mainnet.sqlite-shm -rw-r--r-- 1 weyl staff 20M May 6 12:10 blockchain_v1_mainnet.sqlite-wal -rw-r--r-- 1 weyl staff 1.8M May 6 11:46 peer_table_node.sqlite -rw-r--r-- 1 weyl staff 32K May 5 17:30 peer_table_node.sqlite-shm -rw-r--r-- 1 weyl staff 5.4M May 6 11:46 peer_table_node.sqlite-wal ~/.chia/mainnet/wallet/db ❯ ll -h total 3055848 -rw-r--r-- 1 weyl staff 1.4G May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite -rw-r--r-- 1 weyl staff 32K May 7 15:24 blockchain_wallet_v1_mainnet_903996200.sqlite-shm -rw-r--r-- 1 weyl staff 4.0M May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite-wal -rw-r--r-- 1 weyl staff 16K May 7 15:24 wallet_peers.sqlite 然后，我们可以先用 SQLite Browser，一个 SQlite 数据库（文件）的浏览器来看看它。 SQlite 浏览器的官网是 https://sqlitebrowser.org/ 。在下载，安装之后，我们可以通过点击 Open Database/打开数据库 选择浏览上边列出来的两个 .sqlite 扩展名的数据库文件。 打开数据库之后，我们可以选择第一个标签 Database Schema 来看看表的结构。 我们还能像类似于 Excel 一样去看表的数据，还可以 Filter/过滤、Sort/排序任意列。 下一部分，我们来简单看看表里的数据。 Tips: 这里边，~/.chia/mainnet/wallet 和裸目录 ~/.chia/mainnet 下边的 db 里分别都有表文件，他们的信息是有重复的，大家可以分别打开看看哦，即使是相同的表的名字，比如 block_record 内里的信息也略有差别，如果大家知道为什么有这样的差别，欢迎浏览告诉大家哈，可能要仔细研究一下客户端、钱包等代码才行，幸运的是，它们相对比较好阅读，是 Python 写的： https://github.com/Chia-Network/chia-blockchain 。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#安装"},{"categories":["Nebula Graph"],"content":" 1.2 如何连接Chia?我们可以通过 Chia Network 的客户端来访问它，这个客户端是 Electron + Python 的程序，天然跨平台，既有 GUI 又有 CLI 的方式。 1.2.1 安装只需要按照官方的 Guide 来下载安装就好， https://github.com/Chia-Network/chia-blockchain/wiki/INSTALL，我在 M1 Mac 下安装的时候脚本出了点小问题，大概是因为拉取二进制 wheel 文件网络出问题走到了编译 wheel的逻辑，而那里是依赖 cargo的，如果大家遇到了这个问题，可以提前手动安装一下 rust，或者 cherry-pick 我的这个 PR 。 1.2.2 运行 按照官方 guide，比如 macOS 来说，最后一步执行npm run electron \u0026 就是运行它的GUI客户端。 如果大家像我一样喜欢 CLI，直接在执行完 . ./activate 之后就可以 chia --help了哈☺，里边有只启动部分服务的方式（相比 GUI 启动所有来说)。 在运行之后，如果你的网络不是多层 NAT 的那种，理论上您可以连到 mainnet 并且自动和主链同步数据了，如果您是第二次运行，连接主链，一开始可能有一阵子同步的block 数是不变的，也没有 peer 连过来，不必惊慌，等一下就好了。 Tips: 第一次连到 Chia Network 的同学们，客户端会自动生成一个钱包，及的保存那一串词，它们就是你的私钥哦。 万一，如果真的连不上的话，可能需要在路由上配置，UPnP，防火墙要允许 8444。 1.2.3 访问 Chia 的数据Chia 的客户端把数据存在了几个 SQLite 数据库里，它们的路径是我们安装客户端的用户的家目录：~/.chia/mainnet 下边就是运行起来 Chia 之后生成的主要的两个数据库的二进制文件： ~/.chia/mainnet/db ❯ ll -h total 4350416 -rw-r--r-- 1 weyl staff 2.0G May 6 12:06 blockchain_v1_mainnet.sqlite -rw-r--r-- 1 weyl staff 64K May 6 11:17 blockchain_v1_mainnet.sqlite-shm -rw-r--r-- 1 weyl staff 20M May 6 12:10 blockchain_v1_mainnet.sqlite-wal -rw-r--r-- 1 weyl staff 1.8M May 6 11:46 peer_table_node.sqlite -rw-r--r-- 1 weyl staff 32K May 5 17:30 peer_table_node.sqlite-shm -rw-r--r-- 1 weyl staff 5.4M May 6 11:46 peer_table_node.sqlite-wal ~/.chia/mainnet/wallet/db ❯ ll -h total 3055848 -rw-r--r-- 1 weyl staff 1.4G May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite -rw-r--r-- 1 weyl staff 32K May 7 15:24 blockchain_wallet_v1_mainnet_903996200.sqlite-shm -rw-r--r-- 1 weyl staff 4.0M May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite-wal -rw-r--r-- 1 weyl staff 16K May 7 15:24 wallet_peers.sqlite 然后，我们可以先用 SQLite Browser，一个 SQlite 数据库（文件）的浏览器来看看它。 SQlite 浏览器的官网是 https://sqlitebrowser.org/ 。在下载，安装之后，我们可以通过点击 Open Database/打开数据库 选择浏览上边列出来的两个 .sqlite 扩展名的数据库文件。 打开数据库之后，我们可以选择第一个标签 Database Schema 来看看表的结构。 我们还能像类似于 Excel 一样去看表的数据，还可以 Filter/过滤、Sort/排序任意列。 下一部分，我们来简单看看表里的数据。 Tips: 这里边，~/.chia/mainnet/wallet 和裸目录 ~/.chia/mainnet 下边的 db 里分别都有表文件，他们的信息是有重复的，大家可以分别打开看看哦，即使是相同的表的名字，比如 block_record 内里的信息也略有差别，如果大家知道为什么有这样的差别，欢迎浏览告诉大家哈，可能要仔细研究一下客户端、钱包等代码才行，幸运的是，它们相对比较好阅读，是 Python 写的： https://github.com/Chia-Network/chia-blockchain 。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#运行"},{"categories":["Nebula Graph"],"content":" 1.2 如何连接Chia?我们可以通过 Chia Network 的客户端来访问它，这个客户端是 Electron + Python 的程序，天然跨平台，既有 GUI 又有 CLI 的方式。 1.2.1 安装只需要按照官方的 Guide 来下载安装就好， https://github.com/Chia-Network/chia-blockchain/wiki/INSTALL，我在 M1 Mac 下安装的时候脚本出了点小问题，大概是因为拉取二进制 wheel 文件网络出问题走到了编译 wheel的逻辑，而那里是依赖 cargo的，如果大家遇到了这个问题，可以提前手动安装一下 rust，或者 cherry-pick 我的这个 PR 。 1.2.2 运行 按照官方 guide，比如 macOS 来说，最后一步执行npm run electron \u0026 就是运行它的GUI客户端。 如果大家像我一样喜欢 CLI，直接在执行完 . ./activate 之后就可以 chia --help了哈☺，里边有只启动部分服务的方式（相比 GUI 启动所有来说)。 在运行之后，如果你的网络不是多层 NAT 的那种，理论上您可以连到 mainnet 并且自动和主链同步数据了，如果您是第二次运行，连接主链，一开始可能有一阵子同步的block 数是不变的，也没有 peer 连过来，不必惊慌，等一下就好了。 Tips: 第一次连到 Chia Network 的同学们，客户端会自动生成一个钱包，及的保存那一串词，它们就是你的私钥哦。 万一，如果真的连不上的话，可能需要在路由上配置，UPnP，防火墙要允许 8444。 1.2.3 访问 Chia 的数据Chia 的客户端把数据存在了几个 SQLite 数据库里，它们的路径是我们安装客户端的用户的家目录：~/.chia/mainnet 下边就是运行起来 Chia 之后生成的主要的两个数据库的二进制文件： ~/.chia/mainnet/db ❯ ll -h total 4350416 -rw-r--r-- 1 weyl staff 2.0G May 6 12:06 blockchain_v1_mainnet.sqlite -rw-r--r-- 1 weyl staff 64K May 6 11:17 blockchain_v1_mainnet.sqlite-shm -rw-r--r-- 1 weyl staff 20M May 6 12:10 blockchain_v1_mainnet.sqlite-wal -rw-r--r-- 1 weyl staff 1.8M May 6 11:46 peer_table_node.sqlite -rw-r--r-- 1 weyl staff 32K May 5 17:30 peer_table_node.sqlite-shm -rw-r--r-- 1 weyl staff 5.4M May 6 11:46 peer_table_node.sqlite-wal ~/.chia/mainnet/wallet/db ❯ ll -h total 3055848 -rw-r--r-- 1 weyl staff 1.4G May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite -rw-r--r-- 1 weyl staff 32K May 7 15:24 blockchain_wallet_v1_mainnet_903996200.sqlite-shm -rw-r--r-- 1 weyl staff 4.0M May 7 15:32 blockchain_wallet_v1_mainnet_903996200.sqlite-wal -rw-r--r-- 1 weyl staff 16K May 7 15:24 wallet_peers.sqlite 然后，我们可以先用 SQLite Browser，一个 SQlite 数据库（文件）的浏览器来看看它。 SQlite 浏览器的官网是 https://sqlitebrowser.org/ 。在下载，安装之后，我们可以通过点击 Open Database/打开数据库 选择浏览上边列出来的两个 .sqlite 扩展名的数据库文件。 打开数据库之后，我们可以选择第一个标签 Database Schema 来看看表的结构。 我们还能像类似于 Excel 一样去看表的数据，还可以 Filter/过滤、Sort/排序任意列。 下一部分，我们来简单看看表里的数据。 Tips: 这里边，~/.chia/mainnet/wallet 和裸目录 ~/.chia/mainnet 下边的 db 里分别都有表文件，他们的信息是有重复的，大家可以分别打开看看哦，即使是相同的表的名字，比如 block_record 内里的信息也略有差别，如果大家知道为什么有这样的差别，欢迎浏览告诉大家哈，可能要仔细研究一下客户端、钱包等代码才行，幸运的是，它们相对比较好阅读，是 Python 写的： https://github.com/Chia-Network/chia-blockchain 。 ","date":"2021-05-26","objectID":"/nebula-chia/:1:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#访问-chia-的数据"},{"categories":["Nebula Graph"],"content":" 2 分析 Chia 的数据如果大家仔细看了上边表结构定义的截图，就能注意到一些表的主要信息是嵌套二进制 KV Byte，所以只从 SQLite 并不能看到所有 Chia 的数据，所以我们需要（用一个编程语言来）读取表里的 Byte。 幸运的是，这件事儿因为 Chia 是开源的，而且是 Python 的代码，使得我们可以直接交互式的做。 我花了一点点时间在 Chia 客户端代码里找到了需要的封装类，借助它，可以比较方便的分析 Chia 客户端在本地的全链数据。 如果您不感兴趣细节，可以直接看我分析的结论。 结论之后，我也给大家演示一下是怎么读取它们的。 ","date":"2021-05-26","objectID":"/nebula-chia/:2:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#分析-chia-的数据"},{"categories":["Nebula Graph"],"content":" 2.1 TL;DR, 结论我们可以从表中读取到区块链记录（Block Record ），Chia 币记录（Coin Record）。 从区块记录中，我们可以看到关键的涉及交易的信息： 关联的 Coin ，关联的 Puzzle（地址），Coin 的值(Amount) 从币记录中，我们可以看到关键的涉及区块的信息： 生成这个 Coin 所在区块链里的索引高度（Confirmed Index） 如果这个记录是花费 Coin 的，花费它的索引高度（Spent Index） ┌──────────────────────┐ ┌────────────────────────────────────────┐ │ │ │ │ │ Coin Record │ │ Block Record │ │ │ │ │ │ Coin Name │ │ Height ◄────────────────────────────┼─┐ │ │ │ │ │ ┌─┼───► Puzzle │ │ Header │ │ │ │ │ │ │ │ ├─┼───► Coin Parent │ │ Prev Header │ │ │ │ │ │ │ │ ├─┼───► Amount │ │ Block Body │ │ │ │ │ │ farmer_puzzle_hash │ │ │ │ Time Stamp │ │ fees │ │ │ │ │ │ pool_puzzle_hash │ └─────┼─┼─┬─ Confirmed Index │ │ prev_transaction_block_hash │ │ │ │ │ │ prev_transaction_block_height │ │ │ └─ Spent Index │ │ transactions_info ───────────────┼───────┘ │ │ │ ┌─── is_transaction_block │ │ Coinbase │ │ │ sub_epoch_summary ────────────────┼───────┐ │ │ │ │ │ │ └─ ────────────────────┘ │ │ is Peak │ │ │ └──is Block │ │ ┌─────────────────────┐ │ │ │ │ │ └────────────────────────────────────────┘ └─┼─► Sub Epoch Segment │ │ │ └─────────────────────┘ ","date":"2021-05-26","objectID":"/nebula-chia/:2:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#tldr-结论"},{"categories":["Nebula Graph"],"content":" 2.2 准备因为安装客户端之后，我们本地实际上已经有了相关的 Python 环境和依赖，只需要在里边跑起来就好。 # 注意，我们要 cd 到之前安装客户端时候克隆的仓库。 cd chia-blockchain # source activate 脚本来切换到仓库安装时候创建的 Python 虚拟环境，并进到 IPython 里。 source venv/bin/activate \u0026\u0026 pip install ipython \u0026\u0026 ipython 然后试着导入客户端里边带有的 Python 的 Chia 的封装类试试看。 In [1]: import sqlite3 ...: from chia.consensus.block_record import BlockRecord # 导入成功，没有报错 In [2]: !pwd # 我的安装克隆目录 /Users/weyl/chia-blockchain 恭喜你做好了准备，我们看看 Block Record 里都有什么。 ","date":"2021-05-26","objectID":"/nebula-chia/:2:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#准备"},{"categories":["Nebula Graph"],"content":" 2.3 Chia 链的数据 2.3.1 区块记录在上一步的 IPython 窗口下。 # 注意，这里的路径的前缀是我们自己的家目录，不同操作系统，不同的用户都会有所不同。 chia_db_path = \"/Users/weyl/.chia/mainnet/db/blockchain_v1_mainnet.sqlite\" cur = con.cursor() # 这里我们取第 201645 高的区块 rows = list(cur.execute('SELECT * FROM block_records WHERE height = 201645')) # 这里 0 表示 SELECT 结果的第一行，3 表示在 BlockRecord 这个表里边，Block 的二进制 BLOB 是第四列，参考本章底部的表定义部分 block_records_201645 = BlockRecord.from_bytes(rows[0][3]) dir(block_records_201645) # 可以查看一些属性 is_transaction_block，timestamp，reward_claims_incorporated In [174]: block_records_201645.is_transaction_block Out[174]: True In [182]: from datetime import datetime In [183]: datetime.fromtimestamp(block_records_201645.timestamp) Out[183]: datetime.datetime(2021, 4, 29, 10, 8, 1) In [190]: block_records_201645.reward_claims_incorporated[0].to_json_dict() Out[190]: {'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6', 'amount': 1750000000000} # 可以快速 print 看大部分信息 print(block_records_201645) block_records_201645 的打印结果如下。 注意，这里我截断了一些数据 {'challenge_block_info_hash': '0x4a562f1ffa7a06fe76b1df74dbdd6bdcfbf63139a6f1fc3291c606d7c976abf6', 'challenge_vdf_output': {'data': '0x0200a6b38d6b58d17129d71737088772561f22a44ef302fe45a70a763b878f998abfe35946df720bcb5d78e214b667bce801d597b46c867928c4b8926c342375a961f36cd63ec698bc25e5ce48c45d9a2074eded0e42d24dd1b50a59e699f671f0900100'}, 'deficit': 16, 'farmer_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'fees': 0, 'finished_challenge_slot_hashes': ['0x2b1a7b4859a8d3597b8e6cbe3b27ab97212be8b19e6867f2a4d0eef26c36340f'], 'finished_infused_challenge_slot_hashes': ['0xd0185a6493b10d84e696c6fc55ec1920e8a96791a604dedfe77635da460f354d'], 'finished_reward_slot_hashes': ['0xe2bcbf560471131a7fb87ffe3f9ddde03166a9b0092a50f1ed1599715857c365'], 'header_hash': '0x2791729e1c914f9c3908a0ad895b5846c86fc4e207cc463820123e9a299c39f3', 'height': 201645, 'infused_challenge_vdf_output': None, 'overflow': True, 'pool_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'prev_hash': '0xf126ecf64473beb9ae5b84137788100feb9d731c604877c0744cdc6025f4cbeb', 'prev_transaction_block_hash': '0x7103fe2f1aa96998f9ccf6fc98561b64c5f7a98cf942335c4c927fb2eaa9325a', 'prev_transaction_block_height': 201643, 'required_iters': 95752, 'reward_claims_incorporated': [{'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313aa', 'puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313a8', 'puzzle_hash': '0xcf178071f6aa6cb1c92f00943424bcc8cb774449bd60058fc08e9894f49a1ca4'}], 'reward_infusion_new_challenge': '0x660886f4ab030c07755f53362ae4253dfa93ea853cbc321218f58f159c75adaa', 'signage_point_index': 63, 'sub_epoch_summary_included': None, 'sub_slot_iters': 99614720, 'timestamp': 1619662081, 'total_iters': 660123219464, 'weight': 4121254} 另外，我们取的这个表的定义如下。 CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, #\u003c---- sub_epoch_summary blob, is_peak tinyint, is_block tinyint) 2.3.2 Chia 币记录类似的，我们可以获取一个 Coin 的记录，这里边，从表的定义可以看到，唯一二进制（不能直接从数据库查询中被人读懂）的字段就是是币值，不存在嵌套的结构，所以也并不需要封装的类才能看清楚里边的信息。 CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) 这里值得注意的信息主要","date":"2021-05-26","objectID":"/nebula-chia/:2:3","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#chia-链的数据"},{"categories":["Nebula Graph"],"content":" 2.3 Chia 链的数据 2.3.1 区块记录在上一步的 IPython 窗口下。 # 注意，这里的路径的前缀是我们自己的家目录，不同操作系统，不同的用户都会有所不同。 chia_db_path = \"/Users/weyl/.chia/mainnet/db/blockchain_v1_mainnet.sqlite\" cur = con.cursor() # 这里我们取第 201645 高的区块 rows = list(cur.execute('SELECT * FROM block_records WHERE height = 201645')) # 这里 0 表示 SELECT 结果的第一行，3 表示在 BlockRecord 这个表里边，Block 的二进制 BLOB 是第四列，参考本章底部的表定义部分 block_records_201645 = BlockRecord.from_bytes(rows[0][3]) dir(block_records_201645) # 可以查看一些属性 is_transaction_block，timestamp，reward_claims_incorporated In [174]: block_records_201645.is_transaction_block Out[174]: True In [182]: from datetime import datetime In [183]: datetime.fromtimestamp(block_records_201645.timestamp) Out[183]: datetime.datetime(2021, 4, 29, 10, 8, 1) In [190]: block_records_201645.reward_claims_incorporated[0].to_json_dict() Out[190]: {'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6', 'amount': 1750000000000} # 可以快速 print 看大部分信息 print(block_records_201645) block_records_201645 的打印结果如下。 注意，这里我截断了一些数据 {'challenge_block_info_hash': '0x4a562f1ffa7a06fe76b1df74dbdd6bdcfbf63139a6f1fc3291c606d7c976abf6', 'challenge_vdf_output': {'data': '0x0200a6b38d6b58d17129d71737088772561f22a44ef302fe45a70a763b878f998abfe35946df720bcb5d78e214b667bce801d597b46c867928c4b8926c342375a961f36cd63ec698bc25e5ce48c45d9a2074eded0e42d24dd1b50a59e699f671f0900100'}, 'deficit': 16, 'farmer_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'fees': 0, 'finished_challenge_slot_hashes': ['0x2b1a7b4859a8d3597b8e6cbe3b27ab97212be8b19e6867f2a4d0eef26c36340f'], 'finished_infused_challenge_slot_hashes': ['0xd0185a6493b10d84e696c6fc55ec1920e8a96791a604dedfe77635da460f354d'], 'finished_reward_slot_hashes': ['0xe2bcbf560471131a7fb87ffe3f9ddde03166a9b0092a50f1ed1599715857c365'], 'header_hash': '0x2791729e1c914f9c3908a0ad895b5846c86fc4e207cc463820123e9a299c39f3', 'height': 201645, 'infused_challenge_vdf_output': None, 'overflow': True, 'pool_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'prev_hash': '0xf126ecf64473beb9ae5b84137788100feb9d731c604877c0744cdc6025f4cbeb', 'prev_transaction_block_hash': '0x7103fe2f1aa96998f9ccf6fc98561b64c5f7a98cf942335c4c927fb2eaa9325a', 'prev_transaction_block_height': 201643, 'required_iters': 95752, 'reward_claims_incorporated': [{'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313aa', 'puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313a8', 'puzzle_hash': '0xcf178071f6aa6cb1c92f00943424bcc8cb774449bd60058fc08e9894f49a1ca4'}], 'reward_infusion_new_challenge': '0x660886f4ab030c07755f53362ae4253dfa93ea853cbc321218f58f159c75adaa', 'signage_point_index': 63, 'sub_epoch_summary_included': None, 'sub_slot_iters': 99614720, 'timestamp': 1619662081, 'total_iters': 660123219464, 'weight': 4121254} 另外，我们取的这个表的定义如下。 CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, #\u003c---- sub_epoch_summary blob, is_peak tinyint, is_block tinyint) 2.3.2 Chia 币记录类似的，我们可以获取一个 Coin 的记录，这里边，从表的定义可以看到，唯一二进制（不能直接从数据库查询中被人读懂）的字段就是是币值，不存在嵌套的结构，所以也并不需要封装的类才能看清楚里边的信息。 CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) 这里值得注意的信息主要","date":"2021-05-26","objectID":"/nebula-chia/:2:3","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#区块记录"},{"categories":["Nebula Graph"],"content":" 2.3 Chia 链的数据 2.3.1 区块记录在上一步的 IPython 窗口下。 # 注意，这里的路径的前缀是我们自己的家目录，不同操作系统，不同的用户都会有所不同。 chia_db_path = \"/Users/weyl/.chia/mainnet/db/blockchain_v1_mainnet.sqlite\" cur = con.cursor() # 这里我们取第 201645 高的区块 rows = list(cur.execute('SELECT * FROM block_records WHERE height = 201645')) # 这里 0 表示 SELECT 结果的第一行，3 表示在 BlockRecord 这个表里边，Block 的二进制 BLOB 是第四列，参考本章底部的表定义部分 block_records_201645 = BlockRecord.from_bytes(rows[0][3]) dir(block_records_201645) # 可以查看一些属性 is_transaction_block，timestamp，reward_claims_incorporated In [174]: block_records_201645.is_transaction_block Out[174]: True In [182]: from datetime import datetime In [183]: datetime.fromtimestamp(block_records_201645.timestamp) Out[183]: datetime.datetime(2021, 4, 29, 10, 8, 1) In [190]: block_records_201645.reward_claims_incorporated[0].to_json_dict() Out[190]: {'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6', 'amount': 1750000000000} # 可以快速 print 看大部分信息 print(block_records_201645) block_records_201645 的打印结果如下。 注意，这里我截断了一些数据 {'challenge_block_info_hash': '0x4a562f1ffa7a06fe76b1df74dbdd6bdcfbf63139a6f1fc3291c606d7c976abf6', 'challenge_vdf_output': {'data': '0x0200a6b38d6b58d17129d71737088772561f22a44ef302fe45a70a763b878f998abfe35946df720bcb5d78e214b667bce801d597b46c867928c4b8926c342375a961f36cd63ec698bc25e5ce48c45d9a2074eded0e42d24dd1b50a59e699f671f0900100'}, 'deficit': 16, 'farmer_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'fees': 0, 'finished_challenge_slot_hashes': ['0x2b1a7b4859a8d3597b8e6cbe3b27ab97212be8b19e6867f2a4d0eef26c36340f'], 'finished_infused_challenge_slot_hashes': ['0xd0185a6493b10d84e696c6fc55ec1920e8a96791a604dedfe77635da460f354d'], 'finished_reward_slot_hashes': ['0xe2bcbf560471131a7fb87ffe3f9ddde03166a9b0092a50f1ed1599715857c365'], 'header_hash': '0x2791729e1c914f9c3908a0ad895b5846c86fc4e207cc463820123e9a299c39f3', 'height': 201645, 'infused_challenge_vdf_output': None, 'overflow': True, 'pool_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'prev_hash': '0xf126ecf64473beb9ae5b84137788100feb9d731c604877c0744cdc6025f4cbeb', 'prev_transaction_block_hash': '0x7103fe2f1aa96998f9ccf6fc98561b64c5f7a98cf942335c4c927fb2eaa9325a', 'prev_transaction_block_height': 201643, 'required_iters': 95752, 'reward_claims_incorporated': [{'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313aa', 'puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313a8', 'puzzle_hash': '0xcf178071f6aa6cb1c92f00943424bcc8cb774449bd60058fc08e9894f49a1ca4'}], 'reward_infusion_new_challenge': '0x660886f4ab030c07755f53362ae4253dfa93ea853cbc321218f58f159c75adaa', 'signage_point_index': 63, 'sub_epoch_summary_included': None, 'sub_slot_iters': 99614720, 'timestamp': 1619662081, 'total_iters': 660123219464, 'weight': 4121254} 另外，我们取的这个表的定义如下。 CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, #\u003c---- sub_epoch_summary blob, is_peak tinyint, is_block tinyint) 2.3.2 Chia 币记录类似的，我们可以获取一个 Coin 的记录，这里边，从表的定义可以看到，唯一二进制（不能直接从数据库查询中被人读懂）的字段就是是币值，不存在嵌套的结构，所以也并不需要封装的类才能看清楚里边的信息。 CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) 这里值得注意的信息主要","date":"2021-05-26","objectID":"/nebula-chia/:2:3","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#chia-币记录"},{"categories":["Nebula Graph"],"content":" 2.3 Chia 链的数据 2.3.1 区块记录在上一步的 IPython 窗口下。 # 注意，这里的路径的前缀是我们自己的家目录，不同操作系统，不同的用户都会有所不同。 chia_db_path = \"/Users/weyl/.chia/mainnet/db/blockchain_v1_mainnet.sqlite\" cur = con.cursor() # 这里我们取第 201645 高的区块 rows = list(cur.execute('SELECT * FROM block_records WHERE height = 201645')) # 这里 0 表示 SELECT 结果的第一行，3 表示在 BlockRecord 这个表里边，Block 的二进制 BLOB 是第四列，参考本章底部的表定义部分 block_records_201645 = BlockRecord.from_bytes(rows[0][3]) dir(block_records_201645) # 可以查看一些属性 is_transaction_block，timestamp，reward_claims_incorporated In [174]: block_records_201645.is_transaction_block Out[174]: True In [182]: from datetime import datetime In [183]: datetime.fromtimestamp(block_records_201645.timestamp) Out[183]: datetime.datetime(2021, 4, 29, 10, 8, 1) In [190]: block_records_201645.reward_claims_incorporated[0].to_json_dict() Out[190]: {'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6', 'amount': 1750000000000} # 可以快速 print 看大部分信息 print(block_records_201645) block_records_201645 的打印结果如下。 注意，这里我截断了一些数据 {'challenge_block_info_hash': '0x4a562f1ffa7a06fe76b1df74dbdd6bdcfbf63139a6f1fc3291c606d7c976abf6', 'challenge_vdf_output': {'data': '0x0200a6b38d6b58d17129d71737088772561f22a44ef302fe45a70a763b878f998abfe35946df720bcb5d78e214b667bce801d597b46c867928c4b8926c342375a961f36cd63ec698bc25e5ce48c45d9a2074eded0e42d24dd1b50a59e699f671f0900100'}, 'deficit': 16, 'farmer_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'fees': 0, 'finished_challenge_slot_hashes': ['0x2b1a7b4859a8d3597b8e6cbe3b27ab97212be8b19e6867f2a4d0eef26c36340f'], 'finished_infused_challenge_slot_hashes': ['0xd0185a6493b10d84e696c6fc55ec1920e8a96791a604dedfe77635da460f354d'], 'finished_reward_slot_hashes': ['0xe2bcbf560471131a7fb87ffe3f9ddde03166a9b0092a50f1ed1599715857c365'], 'header_hash': '0x2791729e1c914f9c3908a0ad895b5846c86fc4e207cc463820123e9a299c39f3', 'height': 201645, 'infused_challenge_vdf_output': None, 'overflow': True, 'pool_puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba', 'prev_hash': '0xf126ecf64473beb9ae5b84137788100feb9d731c604877c0744cdc6025f4cbeb', 'prev_transaction_block_hash': '0x7103fe2f1aa96998f9ccf6fc98561b64c5f7a98cf942335c4c927fb2eaa9325a', 'prev_transaction_block_height': 201643, 'required_iters': 95752, 'reward_claims_incorporated': [{'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313ab', 'puzzle_hash': '0xbbb014f41d88c74b78501b36e4863d3382bfda9ae3c4d30a1b6df72b962502b6'}, {'amount': 1750000000000, 'parent_coin_info': '0xccd5bb71183532bff220ba46c268991a000000000000000000000000000313aa', 'puzzle_hash': '0x4bc6435b409bcbabe53870dae0f03755f6aabb4594c5915ec983acf12a5d1fba'}, {'amount': 250000000000, 'parent_coin_info': '0x3ff07eb358e8255a65c30a2dce0e5fbb000000000000000000000000000313a8', 'puzzle_hash': '0xcf178071f6aa6cb1c92f00943424bcc8cb774449bd60058fc08e9894f49a1ca4'}], 'reward_infusion_new_challenge': '0x660886f4ab030c07755f53362ae4253dfa93ea853cbc321218f58f159c75adaa', 'signage_point_index': 63, 'sub_epoch_summary_included': None, 'sub_slot_iters': 99614720, 'timestamp': 1619662081, 'total_iters': 660123219464, 'weight': 4121254} 另外，我们取的这个表的定义如下。 CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, #\u003c---- sub_epoch_summary blob, is_peak tinyint, is_block tinyint) 2.3.2 Chia 币记录类似的，我们可以获取一个 Coin 的记录，这里边，从表的定义可以看到，唯一二进制（不能直接从数据库查询中被人读懂）的字段就是是币值，不存在嵌套的结构，所以也并不需要封装的类才能看清楚里边的信息。 CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) 这里值得注意的信息主要","date":"2021-05-26","objectID":"/nebula-chia/:2:3","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#puzzles-address地址"},{"categories":["Nebula Graph"],"content":" 3 如何探索 Chia 链随着我们之前分析的信息，自然地，我们可以把 Chia 区块链中的信息取出来，用图（Graph）来表示，这里的图并不是（Graphic）图形、图画的意思，是数学、图论中的图。 在图的语境下，最主要的两个元素就是顶点（Vertex）和边（Edge）。 顶点表示一个实体，而边表示实体之间的某种关系，这种关系可以是对等的（无方向的）也可以是有方向的。 这里我们可以把这里的信息抽象映射到如图的图模型里： Block 顶点 Coin 顶点 Puzzle 顶点 spends 边（Block 到 Coin） confirms 边 （Block 到 Coin） belongs_to 边（Coin 到 Puzzle） 这里，我们应用的图是一种叫做属性图的形式，除了点和边的关系之外。这两种实体（点、边）还有其他信息只和它们的一个实例相关，所以再定义为顶点、边就不是很适合，这些信息就作为点、边的属性（preperty）存在。 这种为了处理实体之间关联、涉及实体、关联的属性信息的，也就是\"属性图\"的存储信息的方式在计算机领域越来越流行，甚至有专门为此结构而原生开发的数据库——图数据库（Graph Database）。 这里，我们用的就是一个叫做 Nebula Graph 的图数据库，它是一个现代的、为超大规模分部署架构设计的、原生存储、查询、计算图数据的项目，更棒的是，它是产生于社区的开源产品。 Tips: 安装 Nebula Graph 一般来说，面向超大规模数据的分布式系统，天然的都是不容易轻量部署的，大家如果第一次使用的话可以试试我写的一个叫做 nebula-up 的小工具，可以一行指令部署一个用来试用、学习的 Nebula Graph 集群，地址在这里： https://github.com/wey-gu/nebula-up/ 。 ","date":"2021-05-26","objectID":"/nebula-chia/:3:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#如何探索-chia-链"},{"categories":["Nebula Graph"],"content":" 3.1 Nebula Graph 导入 Chia 数据到图数据库我们分两步走，第一步这把 Chia Network 数据转换成 CSV 文件，第二步使用 Nebula 的 Nebula-Importer 把数据导入 Nebula Graph。 3.1.1 数据转换这部分的代码我开源在这里了: https://github.com/wey-gu/nebula-chia 使用它只需要在 Chia Network 的 python venv 下安装它: python3 -m pip install nebula-chia 然后调用 ChaiBatchConvertor 就可以在当前目录下生成两个 CSV 文件。 这里边有一些可以配置的参数，具体可以参考代码 nebulachia/convertor.py from nebulachia.convertor import ChiaBatchConvertor c = ChaiBatchConvertor( block_record_limit=0, coin_record_limit=0, write_batch_size=10000) c.convert_block_record() c.convert_coin_record() 生成的文件： $ ls -lth -rw-r--r-- 1 weyl staff 173M May 19 13:01 coin_record.csv -rw-r--r-- 1 weyl staff 77M May 19 12:59 block_record.csv 这里边字段的含义和类型，可以参考代码中 block_record_row 和 coin_record_row 的 __doc__ In [466]: print(c.coin_record_row.__doc__) Parse row and return a CSV block coin row list. CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) Coin Record CSV Head: 0 1(int) 2(int) 3(bool) coin_name|confirmed_index|spent_index|spent| 4(bool) 5 6 7(int) coinbase|puzzle_hash|coin_parent|amount| 8(timestamp) timestamp| 9 10 confirmed_hash|spent_hash In [467]: print(c.block_record_row.__doc__) Parse row and return a CSV block record row list. CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, sub_epoch_summary blob, is_peak tinyint, is_block tinyint) Block Record CSV Head: 0 1 2(int) 3(bool) 4(bool) header_hash|prev_hash|height|is_peak|is_block| 5(int) deficit| 6 challenge_block_info_hash| 7 farmer_puzzle_hash| 8(int) fees| 9 prev_transaction_block_hash| 10 prev_transaction_block_height| 11 12(int) required_iters|signage_point_index| 13(timestamp) timestamp 3.1.2 数据导入有了 CSV 文件，我们可以借助 Nebula-Importer 导入数据到图数据库中。 这里，我们写好了 nebula-importer 的配置文件，其中包涵了如下信息: 在 Nebula Graph 中创建需要的数据模型 Schema，这和我们前边做的图映射的信息是等价的 描述 CSV 文件之中的 Column 的数据到图模型（点，边，点或边的属性）映射关系 # 这里，我的 csv 文件和 配置文件都放在 /home/wei.gu/chia 之下 # 我使用 docker-compose 默认配置部署的 Nebula Graph, # 它创建了叫 nebula-docker-compose_nebula-net 的 docker 网络 docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v /home/wei.gu/chia/nebula-chia.yaml:/root/nebula-chia.yaml \\ -v /home/wei.gu/chia:/root \\ vesoft/nebula-importer:v2 \\ --config /root/nebula-chia.yaml 这里我展示一个导入的结果示例，我在单机部署的 Nebula Graph 里导入了我一两周之前取的全量 Chia Network 数据的结果。 ... 2021/05/19 09:55:09 [INFO] reader.go:180: Total lines of file(/root/coin_record.csv) is: 547557, error lines: 0 2021/05/19 09:55:09 [INFO] statsmgr.go:61: Done(/root/coin_record.csv): Time(4385.88s), Finished(4512927), Failed(0), Latency AVG(1305us), Batches Req AVG(2015us), Rows AVG(1028.42/s) 2021/05/19 09:55:10 --- END OF NEBULA IMPORTER --- ","date":"2021-05-26","objectID":"/nebula-chia/:3:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#nebula-graph-导入-chia-数据到图数据库"},{"categories":["Nebula Graph"],"content":" 3.1 Nebula Graph 导入 Chia 数据到图数据库我们分两步走，第一步这把 Chia Network 数据转换成 CSV 文件，第二步使用 Nebula 的 Nebula-Importer 把数据导入 Nebula Graph。 3.1.1 数据转换这部分的代码我开源在这里了: https://github.com/wey-gu/nebula-chia 使用它只需要在 Chia Network 的 python venv 下安装它: python3 -m pip install nebula-chia 然后调用 ChaiBatchConvertor 就可以在当前目录下生成两个 CSV 文件。 这里边有一些可以配置的参数，具体可以参考代码 nebulachia/convertor.py from nebulachia.convertor import ChiaBatchConvertor c = ChaiBatchConvertor( block_record_limit=0, coin_record_limit=0, write_batch_size=10000) c.convert_block_record() c.convert_coin_record() 生成的文件： $ ls -lth -rw-r--r-- 1 weyl staff 173M May 19 13:01 coin_record.csv -rw-r--r-- 1 weyl staff 77M May 19 12:59 block_record.csv 这里边字段的含义和类型，可以参考代码中 block_record_row 和 coin_record_row 的 __doc__ In [466]: print(c.coin_record_row.__doc__) Parse row and return a CSV block coin row list. CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) Coin Record CSV Head: 0 1(int) 2(int) 3(bool) coin_name|confirmed_index|spent_index|spent| 4(bool) 5 6 7(int) coinbase|puzzle_hash|coin_parent|amount| 8(timestamp) timestamp| 9 10 confirmed_hash|spent_hash In [467]: print(c.block_record_row.__doc__) Parse row and return a CSV block record row list. CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, sub_epoch_summary blob, is_peak tinyint, is_block tinyint) Block Record CSV Head: 0 1 2(int) 3(bool) 4(bool) header_hash|prev_hash|height|is_peak|is_block| 5(int) deficit| 6 challenge_block_info_hash| 7 farmer_puzzle_hash| 8(int) fees| 9 prev_transaction_block_hash| 10 prev_transaction_block_height| 11 12(int) required_iters|signage_point_index| 13(timestamp) timestamp 3.1.2 数据导入有了 CSV 文件，我们可以借助 Nebula-Importer 导入数据到图数据库中。 这里，我们写好了 nebula-importer 的配置文件，其中包涵了如下信息: 在 Nebula Graph 中创建需要的数据模型 Schema，这和我们前边做的图映射的信息是等价的 描述 CSV 文件之中的 Column 的数据到图模型（点，边，点或边的属性）映射关系 # 这里，我的 csv 文件和 配置文件都放在 /home/wei.gu/chia 之下 # 我使用 docker-compose 默认配置部署的 Nebula Graph, # 它创建了叫 nebula-docker-compose_nebula-net 的 docker 网络 docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v /home/wei.gu/chia/nebula-chia.yaml:/root/nebula-chia.yaml \\ -v /home/wei.gu/chia:/root \\ vesoft/nebula-importer:v2 \\ --config /root/nebula-chia.yaml 这里我展示一个导入的结果示例，我在单机部署的 Nebula Graph 里导入了我一两周之前取的全量 Chia Network 数据的结果。 ... 2021/05/19 09:55:09 [INFO] reader.go:180: Total lines of file(/root/coin_record.csv) is: 547557, error lines: 0 2021/05/19 09:55:09 [INFO] statsmgr.go:61: Done(/root/coin_record.csv): Time(4385.88s), Finished(4512927), Failed(0), Latency AVG(1305us), Batches Req AVG(2015us), Rows AVG(1028.42/s) 2021/05/19 09:55:10 --- END OF NEBULA IMPORTER --- ","date":"2021-05-26","objectID":"/nebula-chia/:3:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#数据转换"},{"categories":["Nebula Graph"],"content":" 3.1 Nebula Graph 导入 Chia 数据到图数据库我们分两步走，第一步这把 Chia Network 数据转换成 CSV 文件，第二步使用 Nebula 的 Nebula-Importer 把数据导入 Nebula Graph。 3.1.1 数据转换这部分的代码我开源在这里了: https://github.com/wey-gu/nebula-chia 使用它只需要在 Chia Network 的 python venv 下安装它: python3 -m pip install nebula-chia 然后调用 ChaiBatchConvertor 就可以在当前目录下生成两个 CSV 文件。 这里边有一些可以配置的参数，具体可以参考代码 nebulachia/convertor.py from nebulachia.convertor import ChiaBatchConvertor c = ChaiBatchConvertor( block_record_limit=0, coin_record_limit=0, write_batch_size=10000) c.convert_block_record() c.convert_coin_record() 生成的文件： $ ls -lth -rw-r--r-- 1 weyl staff 173M May 19 13:01 coin_record.csv -rw-r--r-- 1 weyl staff 77M May 19 12:59 block_record.csv 这里边字段的含义和类型，可以参考代码中 block_record_row 和 coin_record_row 的 __doc__ In [466]: print(c.coin_record_row.__doc__) Parse row and return a CSV block coin row list. CREATE TABLE coin_record( coin_name text PRIMARY KEY, confirmed_index bigint, spent_index bigint, spent int, coinbase int, puzzle_hash text, coin_parent text, amount blob, timestamp bigint) Coin Record CSV Head: 0 1(int) 2(int) 3(bool) coin_name|confirmed_index|spent_index|spent| 4(bool) 5 6 7(int) coinbase|puzzle_hash|coin_parent|amount| 8(timestamp) timestamp| 9 10 confirmed_hash|spent_hash In [467]: print(c.block_record_row.__doc__) Parse row and return a CSV block record row list. CREATE TABLE block_records( header_hash text PRIMARY KEY, prev_hash text, height bigint, block blob, sub_epoch_summary blob, is_peak tinyint, is_block tinyint) Block Record CSV Head: 0 1 2(int) 3(bool) 4(bool) header_hash|prev_hash|height|is_peak|is_block| 5(int) deficit| 6 challenge_block_info_hash| 7 farmer_puzzle_hash| 8(int) fees| 9 prev_transaction_block_hash| 10 prev_transaction_block_height| 11 12(int) required_iters|signage_point_index| 13(timestamp) timestamp 3.1.2 数据导入有了 CSV 文件，我们可以借助 Nebula-Importer 导入数据到图数据库中。 这里，我们写好了 nebula-importer 的配置文件，其中包涵了如下信息: 在 Nebula Graph 中创建需要的数据模型 Schema，这和我们前边做的图映射的信息是等价的 描述 CSV 文件之中的 Column 的数据到图模型（点，边，点或边的属性）映射关系 # 这里，我的 csv 文件和 配置文件都放在 /home/wei.gu/chia 之下 # 我使用 docker-compose 默认配置部署的 Nebula Graph, # 它创建了叫 nebula-docker-compose_nebula-net 的 docker 网络 docker run --rm -ti \\ --network=nebula-docker-compose_nebula-net \\ -v /home/wei.gu/chia/nebula-chia.yaml:/root/nebula-chia.yaml \\ -v /home/wei.gu/chia:/root \\ vesoft/nebula-importer:v2 \\ --config /root/nebula-chia.yaml 这里我展示一个导入的结果示例，我在单机部署的 Nebula Graph 里导入了我一两周之前取的全量 Chia Network 数据的结果。 ... 2021/05/19 09:55:09 [INFO] reader.go:180: Total lines of file(/root/coin_record.csv) is: 547557, error lines: 0 2021/05/19 09:55:09 [INFO] statsmgr.go:61: Done(/root/coin_record.csv): Time(4385.88s), Finished(4512927), Failed(0), Latency AVG(1305us), Batches Req AVG(2015us), Rows AVG(1028.42/s) 2021/05/19 09:55:10 --- END OF NEBULA IMPORTER --- ","date":"2021-05-26","objectID":"/nebula-chia/:3:1","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#数据导入"},{"categories":["Nebula Graph"],"content":" 3.2 探索 Chia 的图数据 3.2.1 用图数据库的 Queries导入 Chia 链的网络到 Nebula Graph 之后，我们可以在里边快速查询数据之间的关联。 比如这个查询表示从区块 524aa2013781ff4cd9d2b5dc... 查起，经过三种边 farmer_puzzle, spends, confirms 双向遍历的结果。 GO 5 STEPS FROM \\ \"524aa2013781ff4cd9d2b5dce40647b670d722e2de25bd2e2b79970a8ec435ee\" \\ OVER farmer_puzzle,spends,confirms BIDIRECT ... Got 419437 rows (time spent 735120/1170946 us) Wed, 19 May 2021 10:11:28 UTC 再比如，计算一个 Puzzle 地址上的余额（所有 coin 的总价值）比如这个puzzle bbe39134ccc32c08fdeff... GO 1 STEP FROM \"bbe39134ccc32c08fdeff4d2c19d1d1f4f7e48cdaf79d37397bc3136ce9b3cb7\" \\ OVER belongs_to REVERSELY \\ YIELD CASE $$.coin.is_spent \\ WHEN true THEN $$.coin.amount \\ WHEN false THEN -$$.coin.amount \\ END AS Amount | YIELD sum($-.Amount) 3.2.2 用 Nebula Studio 可视化探索Nebula Graph 为我们提供了图形化界面，有了它，我们可以用更符合人脑的方式地查看 Chia Network 中的数据。 比如，我们还是回到上边的那个区块，从这里查询。 我们就获得了这个 block 类型的一个点/ vertex。我们可以从他开始进一步探索，先鼠标单击这个点，在拓展条件里把方向选择双向，默认的边类型是所有的边类型，这样我们就可以把所有 步数内相关联的数据一下子全都找出来。 选择好拓展条件之后，点击拓展就可以。 这里，我们选择了步数为 1，点击拓展（或者双击要拓展的点），之后，我们可以快速双击其他的点继续拓展，这是我鼠标点了几次之后看到的样子： 我们接下来再试试拓展的步数为 2，点击拓展（或者双击要拓展的点），看起来找到了有意思的信息。 我们看到了一个有很多边的黑色的点。 通过查看这个点和我们开始查看的 block 之间的边，我们知道这个点正是 farm 这个 block 的地址，这个地址下边有非常多的 coin。 这只是一个开始，有了这个导入到 Nebula Graph 图数据的基础，我们可以做很多有意思的分析和洞察，大家可以自己试试看，得到更有意思的结果分享给其他同学。 ","date":"2021-05-26","objectID":"/nebula-chia/:3:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#探索-chia-的图数据"},{"categories":["Nebula Graph"],"content":" 3.2 探索 Chia 的图数据 3.2.1 用图数据库的 Queries导入 Chia 链的网络到 Nebula Graph 之后，我们可以在里边快速查询数据之间的关联。 比如这个查询表示从区块 524aa2013781ff4cd9d2b5dc... 查起，经过三种边 farmer_puzzle, spends, confirms 双向遍历的结果。 GO 5 STEPS FROM \\ \"524aa2013781ff4cd9d2b5dce40647b670d722e2de25bd2e2b79970a8ec435ee\" \\ OVER farmer_puzzle,spends,confirms BIDIRECT ... Got 419437 rows (time spent 735120/1170946 us) Wed, 19 May 2021 10:11:28 UTC 再比如，计算一个 Puzzle 地址上的余额（所有 coin 的总价值）比如这个puzzle bbe39134ccc32c08fdeff... GO 1 STEP FROM \"bbe39134ccc32c08fdeff4d2c19d1d1f4f7e48cdaf79d37397bc3136ce9b3cb7\" \\ OVER belongs_to REVERSELY \\ YIELD CASE $$.coin.is_spent \\ WHEN true THEN $$.coin.amount \\ WHEN false THEN -$$.coin.amount \\ END AS Amount | YIELD sum($-.Amount) 3.2.2 用 Nebula Studio 可视化探索Nebula Graph 为我们提供了图形化界面，有了它，我们可以用更符合人脑的方式地查看 Chia Network 中的数据。 比如，我们还是回到上边的那个区块，从这里查询。 我们就获得了这个 block 类型的一个点/ vertex。我们可以从他开始进一步探索，先鼠标单击这个点，在拓展条件里把方向选择双向，默认的边类型是所有的边类型，这样我们就可以把所有 步数内相关联的数据一下子全都找出来。 选择好拓展条件之后，点击拓展就可以。 这里，我们选择了步数为 1，点击拓展（或者双击要拓展的点），之后，我们可以快速双击其他的点继续拓展，这是我鼠标点了几次之后看到的样子： 我们接下来再试试拓展的步数为 2，点击拓展（或者双击要拓展的点），看起来找到了有意思的信息。 我们看到了一个有很多边的黑色的点。 通过查看这个点和我们开始查看的 block 之间的边，我们知道这个点正是 farm 这个 block 的地址，这个地址下边有非常多的 coin。 这只是一个开始，有了这个导入到 Nebula Graph 图数据的基础，我们可以做很多有意思的分析和洞察，大家可以自己试试看，得到更有意思的结果分享给其他同学。 ","date":"2021-05-26","objectID":"/nebula-chia/:3:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#用图数据库的-queries"},{"categories":["Nebula Graph"],"content":" 3.2 探索 Chia 的图数据 3.2.1 用图数据库的 Queries导入 Chia 链的网络到 Nebula Graph 之后，我们可以在里边快速查询数据之间的关联。 比如这个查询表示从区块 524aa2013781ff4cd9d2b5dc... 查起，经过三种边 farmer_puzzle, spends, confirms 双向遍历的结果。 GO 5 STEPS FROM \\ \"524aa2013781ff4cd9d2b5dce40647b670d722e2de25bd2e2b79970a8ec435ee\" \\ OVER farmer_puzzle,spends,confirms BIDIRECT ... Got 419437 rows (time spent 735120/1170946 us) Wed, 19 May 2021 10:11:28 UTC 再比如，计算一个 Puzzle 地址上的余额（所有 coin 的总价值）比如这个puzzle bbe39134ccc32c08fdeff... GO 1 STEP FROM \"bbe39134ccc32c08fdeff4d2c19d1d1f4f7e48cdaf79d37397bc3136ce9b3cb7\" \\ OVER belongs_to REVERSELY \\ YIELD CASE $$.coin.is_spent \\ WHEN true THEN $$.coin.amount \\ WHEN false THEN -$$.coin.amount \\ END AS Amount | YIELD sum($-.Amount) 3.2.2 用 Nebula Studio 可视化探索Nebula Graph 为我们提供了图形化界面，有了它，我们可以用更符合人脑的方式地查看 Chia Network 中的数据。 比如，我们还是回到上边的那个区块，从这里查询。 我们就获得了这个 block 类型的一个点/ vertex。我们可以从他开始进一步探索，先鼠标单击这个点，在拓展条件里把方向选择双向，默认的边类型是所有的边类型，这样我们就可以把所有 步数内相关联的数据一下子全都找出来。 选择好拓展条件之后，点击拓展就可以。 这里，我们选择了步数为 1，点击拓展（或者双击要拓展的点），之后，我们可以快速双击其他的点继续拓展，这是我鼠标点了几次之后看到的样子： 我们接下来再试试拓展的步数为 2，点击拓展（或者双击要拓展的点），看起来找到了有意思的信息。 我们看到了一个有很多边的黑色的点。 通过查看这个点和我们开始查看的 block 之间的边，我们知道这个点正是 farm 这个 block 的地址，这个地址下边有非常多的 coin。 这只是一个开始，有了这个导入到 Nebula Graph 图数据的基础，我们可以做很多有意思的分析和洞察，大家可以自己试试看，得到更有意思的结果分享给其他同学。 ","date":"2021-05-26","objectID":"/nebula-chia/:3:2","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#用-nebula-studio-可视化探索"},{"categories":["Nebula Graph"],"content":" 4 总结这篇文章里，在我们简单介绍了 Chia Network 之后，我们首次的带大家一起从安装一个 Chia 终端，到分析终端同步到本地的 Chia 全网数据，借助于 Chia 终端开源的 Python 代码库，我们分析了全网数据里的重要信息。 之后，我们开源了一个小工具 Nebula-Chia，有了它，就可以把 Chia 的全网数据转换成 CSV 格式，这样，就可以借助 nebula-importer 把所有的数据导入到一个先进的图数据库（Nebula Graph）中。 Nebula Graph 的项目地址是 https://github.com/vesoft-inc/nebula-graph Nebula-Chia 我也开源在 https://github.com/wey-gu/nebula-chia 在图数据库中，我们展示了做基本 Query 的例子和借助图数据库自带的可视化工具，我们可以轻易地获取 Chia 全网数据之间关联关系，有了这个作为基础，这些数据中洞察的潜力和可以尝试的有意思事情可以比较直观和高效地进一步探索了！ 是不是很酷？ ","date":"2021-05-26","objectID":"/nebula-chia/:4:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#总结"},{"categories":["Nebula Graph"],"content":" 5 引用 https://www.chia.net/faq/ https://chialisp.com/docs/ https://www.chiaexplorer.com/chia-coins https://docs.google.com/document/d/1tmRIb7lgi4QfKkNaxuKOBHRmwbVlGL4f7EsBDr_5xZE https://github.com/sipa/bech32/tree/master/ref/python https://github.com/Chia-Network/chia-blockchain/blob/main/README.md https://www.chia.net/assets/ChiaGreenPaper.pdf https://docs.nebula-graph.com.cn 题图版权：Icons8 Team ","date":"2021-05-26","objectID":"/nebula-chia/:5:0","series":null,"tags":["Nebula Graph","Chia Network"],"title":"用图数据库可视化探索 Chia Network 区块链数据","uri":"/nebula-chia/#引用"},{"categories":null,"content":" Nebula-Corp-Rel-Graph Nebula-Corp-Rel-Graph，基于图数据库的股权穿透系统 阅读全文 Nebula-Siwi Nebula-Siwi，基于图数据库的智能问答助手 阅读全文 Nebula-Holdshare Nebula-Holdshare，图数据库应用示例：股权关系穿透 阅读全文 Nebula-KIND Nebula-Kind，无需依赖，一键安装尝鲜基于 Nebula Operator 的 K8s Nebula Graph Cluster。注： KIND 是一个 K8s 的 SIG，代表 K8s in Docker。 阅读全文 Nebula-Up Nebula-up，一键拉起一个 Nebula 测试环境，支持 mscOS，Windows 10，CentOS 和 Ubuntu。 阅读全文 VSCode-nGQL VSCode-nGQL，Nebula Graph 的 VS Code 插件，ngql 语法高亮。 阅读全文 Nebula-Chia Nebula-Chia，将 Chia Network 全链导入 Nebula Graph 中的探索分享和转换工具（一并开源出来）。 阅读全文 IPython-nGQL Nebula Graph 的 Jupyter Notebook 和 IPython 插件，方便在 Notebook 之中嵌入 nGQL 的 query 和 结果的调试。 阅读全文 nebula-insights 本文介绍我们如何用公有云 Serverless 技术：Google Cloud Scheduler，Google Cloud Functions 和 BigQuery 搭建数据管道，收集探索开源社区洞察。并将全部代码开源在 GitHub。 阅读全文 ","date":"2021-05-26","objectID":"/projects/:0:0","series":null,"tags":null,"title":"个人项目","uri":"/projects/#"},{"categories":null,"content":" Nebula Operator Explained Nebula Graph K8s Operator 介绍 阅读全文 Nebula Config Explained Nebula Graph 配置详解 阅读全文 Nebula Index Demystified Nebula Graph 原生索引解谜 阅读全文 Nebula Data Import Options Nebula Graph 提供了好多种数据导入的工具，我们应该如何选择呢？ 阅读全文 Nebula Deployment Options Nebula Graph 有很多种分发、部署方式，我们应该如何选择它们呢？ 阅读全文 Nebula Intro 新手玩转 Nebula Graph 系列开篇。 阅读全文 ","date":"2021-05-26","objectID":"/sketch-notes/:0:0","series":null,"tags":null,"title":"手绘笔记","uri":"/sketch-notes/#"},{"categories":["sketches"],"content":"Nebula Graph Core Arch.","date":"2021-05-25","objectID":"/sketches/nebula-core-arch/","series":null,"tags":["Nebula Graph","Core"],"title":"Nebula Core Arch","uri":"/sketches/nebula-core-arch/"},{"categories":["sketches"],"content":" 1 Bilibili 上 下 ","date":"2021-05-25","objectID":"/sketches/nebula-core-arch/:1:0","series":null,"tags":["Nebula Graph","Core"],"title":"Nebula Core Arch","uri":"/sketches/nebula-core-arch/#bilibili"},{"categories":["sketches"],"content":" 2 Youtube 上 下 ","date":"2021-05-25","objectID":"/sketches/nebula-core-arch/:2:0","series":null,"tags":["Nebula Graph","Core"],"title":"Nebula Core Arch","uri":"/sketches/nebula-core-arch/#youtube"},{"categories":["Nebula Graph"],"content":"VSCode-ngql 是 Nebula Graph 的 VS Code 之中对 nGQL 语法高亮的插件。","date":"2021-05-05","objectID":"/vscode-ngql/","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/"},{"categories":["Nebula Graph"],"content":" VSCode-ngql 是 Nebula Graph 的 VS Code 之中对 nGQL 语法高亮的插件。 您可以从 这里 直接下载安装试用。 ","date":"2021-05-05","objectID":"/vscode-ngql/:0:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#"},{"categories":["Nebula Graph"],"content":" VS Code nGQL Syntax Highlight ","date":"2021-05-05","objectID":"/vscode-ngql/:0:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#vs-code-ngql-syntax-highlight"},{"categories":["Nebula Graph"],"content":" 1 DownloadSearch ngql from the market or click here. ","date":"2021-05-05","objectID":"/vscode-ngql/:1:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#download"},{"categories":["Nebula Graph"],"content":" 2 Features Highlighting all Keywords, Functions of a given .ngql file ","date":"2021-05-05","objectID":"/vscode-ngql/:2:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#features"},{"categories":["Nebula Graph"],"content":" 3 Release Notes","date":"2021-05-05","objectID":"/vscode-ngql/:3:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#release-notes"},{"categories":["Nebula Graph"],"content":" 3.1 0.0.1Initial release, only .ngql Syntax is supported. ","date":"2021-05-05","objectID":"/vscode-ngql/:3:1","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#001"},{"categories":["Nebula Graph"],"content":" 3.2 0.0.2Lower supported vscode version till ^1.50.1 ","date":"2021-05-05","objectID":"/vscode-ngql/:3:2","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#002"},{"categories":["Nebula Graph"],"content":" 4 Reference https://docs.nebula-graph.com.cn/ https://github.com/vesoft-inc/nebula-graph/blob/master/src/parser/scanner.lex ","date":"2021-05-05","objectID":"/vscode-ngql/:4:0","series":null,"tags":["Nebula Graph","vscode","ngql"],"title":"VSCode-ngql，Nebula Graph 的 VSCode 语法高亮插件。","uri":"/vscode-ngql/#reference"},{"categories":["Big Data","Cloud"],"content":"本文介绍我们如何用公有云 Serverless 技术：Google Cloud Scheduler，Google Cloud Functions 和 BigQuery 搭建数据管道，收集探索开源社区洞察。并将全部代码开源在 GitHub。","date":"2021-05-03","objectID":"/nebula-insights/","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/"},{"categories":["Big Data","Cloud"],"content":" 这是我首发在 Datawhale 的文章，介绍我们如何用公有云 Serverless 技术：Google Cloud Scheduler，Google Cloud Functions 和 BigQuery 搭建数据管道，收集探索开源社区洞察。并将全部代码开源在 GitHub。 引子 我们想要收集一些帮助 Nebula Graph 社区运营的 metrics，希望能从不同来源的数据自动化周期性收集、处理、并方便地展现出来做数据驱动分析的基础设施。 Nebula Graph 是一个现代的开源分布式图数据库(Graph Database)，欢迎同学们从: 官网: https://nebula-graph.com.cn Bilibili: https://space.bilibili.com/472621355 GitHub:https://github.com/vesoft-inc/nebula-graph 了解我们哈。 ","date":"2021-05-03","objectID":"/nebula-insights/:0:0","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#"},{"categories":["Big Data","Cloud"],"content":" 1 需求 方便增加新的数据 数据收集无需人为触发（自动、周期性） 每天数据量不超过1000条 数据可以生成 dashboard，也可以支持统计分期 query 高可用，数据安全 低预算，尽可能不需要运维人力 ","date":"2021-05-03","objectID":"/nebula-insights/:1:0","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#需求"},{"categories":["Big Data","Cloud"],"content":" 1.1 需求分析我们需要搭建一个系统能实现 一个能周期性触发获取数据的事件的服务: scheduler 一个触发之后，把数据 ETL 到数据库中的服务: ETL worker 一个数据仓库 一个能够把数据库作为源，允许用户 query，展示数据的界面: Data-UI 这个需求的特点是虽然数据量很小、但是要求服务高可用、安全。因为这种情况下自建服务器还需要保证HA和数据安全会一定会消耗昂贵运维人力，所以我们应该尽量避免在自己维护的服务器中搭建 scheduler, 和数据库。 最终，我们选择了尽量使用公有云的 aaS 的方案: ┌──────────────────────────┐ │ │ │ Google Cloud Scheduler │ │ │ └────────────┬─────────────┘ │ ┌─────────────────────┐ │ │ │ ┌────────────▼─────────────┐ ┌───────────► GitHub API Server │ │ │ │ │ │ │ Google Cloud Functions ├───┤ └─────────────────────┘ │ │ │ └────────────┬─────────────┘ │ ┌─────────────────────────┐ │ │ │ │ │ ├───────────► Docker Hub API Server │ ┌─────────▼─────────┐ │ │ │ │ │ │ │ │ │ Google BigQuery │ │ └─────────────────────────┘ │ │ ├───────────► ... └─────────▲─────────┘ │ ┌──────────────────┐ │ │ │ │ │ └───────────► Aliyun OSS API │ ┌──────────┴───────────┐ │ │ │ │ └──────────────────┘ │ Google Data Studio │ │ ┌──┐ │ │ ┌──┐ │ │ ┌──┐ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └──┴──┴─┴──┴─┴──┴──────┘ 因为我个人比较熟悉 Google Cloud Platform(GCP)的原因，加上GCP在大数据处理上比较领先，再加上Google提供的 free tier额度非常大方，以至于在我们这个数据量下，所有workload都会是免费的。 这个方案最后选择了全栈 Google Cloud，然而，这实际上只是一个参考，同学们完全可以在其他公有云提供商那里找到对应的服务。 这里我简单介绍一下， Google Cloud Scheduler是自解释的，不用多介绍了。 而 Google Cloud Functions是GCP的无服务器(serverless)的 Function as a Service服务，它的好处是我们可以把无状态的 event-driven 的 workload 代码放上去，它是按需付费（pay as you go)的，类似的服务还有 Google Cloud Run，后者的区别在于我们提供的是一个docker/container（这使得能支持的运行环境可以使任何能跑在容器里的东西），而 Cloud Functions是把我们的代码文件放上去。他们的效果是类似的，因为我准备用Python来做 ETL的东西，Clouf Functions已经支持了，我就直接选择它了。 在scheduler里边，我定义了每一天它发一个 pub/sub（类似于kafka，这里google可以保证至少发成功一次）消息给 Cloud Functions，然后 Cloud Functions会去做 ETL的工作。 这里，实际上我的设计里这个触发的函数调会把数据从API那里获取下来，在内存里处理好之后，存储到在对象存储里为 JSON 文件，然后再调用 Google BigQuery 的 API让 BigQuery直接从对对象存储里拉取 JSON 文件，导入记录到相应的表之中。 Google BigQuery 作为GCP 特别有竞争力的一个产品，是它数据仓库，BigQuery 可以无限扩容，支持海量数据导入，支持 SQL-like 的 query，还自带ML算法，通过SQL就能调用这些算法。它可以和很多GCP以及第三方的组件可以集成起来。 Google Data Studio 是GCP的数据 Insights产品，如果大家用过 Google Analytics 应该已经用过它了。 ","date":"2021-05-03","objectID":"/nebula-insights/:1:1","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#需求分析"},{"categories":["Big Data","Cloud"],"content":" 1.2 数据的获取，API我们第一阶段想要收集的数据来源是 GitHub 上，社区项目的统计数据、Docker Hub上，社区镜像的拉取计数，之后，会增加更多维度的数据。 Github API, ref: https://pygithub.readthedocs.io 这里我们利用了一个Github API的一个 Python 封装，下边是在 IDLE/iPython/Jupyter 里尝试的例子 # 实例化一个client g = Github(login_or_token=token, timeout=60, retry=Retry( total=10, status_forcelist=(500, 502, 504), backoff_factor=0.3)) # 配置好要获取的repo的信息 org_str = \"vesoft-inc\" org = g.get_organization(org_str) repos = org.get_repos() # 这里repos是一个迭代器，方便看到里边的东西，我们把它 list 一下可以看到所有的repo: list(repos) [Repository(full_name=\"vesoft-inc/nebula\"), Repository(full_name=\"vesoft-inc/nebula-docs\"), Repository(full_name=\"vesoft-inc/nebula-dev-docker\"), Repository(full_name=\"vesoft-inc/github-statistics\"), Repository(full_name=\"vesoft-inc/nebula-docker-compose\"), Repository(full_name=\"vesoft-inc/nebula-go\"), Repository(full_name=\"vesoft-inc/nebula-java\"), Repository(full_name=\"vesoft-inc/nebula-python\"), Repository(full_name=\"vesoft-inc/nebula-importer\"), Repository(full_name=\"vesoft-inc/nebula-third-party\"), Repository(full_name=\"vesoft-inc/nebula-storage\"), Repository(full_name=\"vesoft-inc/nebula-graph\"), Repository(full_name=\"vesoft-inc/nebula-common\"), Repository(full_name=\"vesoft-inc/nebula-stats-exporter\"), Repository(full_name=\"vesoft-inc/nebula-web-docker\"), Repository(full_name=\"vesoft-inc/nebula-bench\"), Repository(full_name=\"vesoft-inc/nebula-console\"), Repository(full_name=\"vesoft-inc/nebula-docs-cn\"), Repository(full_name=\"vesoft-inc/nebula-chaos\"), Repository(full_name=\"vesoft-inc/nebula-clients\"), Repository(full_name=\"vesoft-inc/nebula-spark-utils\"), Repository(full_name=\"vesoft-inc/nebula-node\"), Repository(full_name=\"vesoft-inc/nebula-rust\"), Repository(full_name=\"vesoft-inc/nebula-cpp\"), Repository(full_name=\"vesoft-inc/nebula-http-gateway\"), Repository(full_name=\"vesoft-inc/nebula-flink-connector\"), Repository(full_name=\"vesoft-inc/nebula-community\"), Repository(full_name=\"vesoft-inc/nebula-br\"), Repository(full_name=\"vesoft-inc/.github\")] # repo0 是 vesoft-inc/nebula 这个repo，我们可以通过 get_clones_traffic，get_views_traffic 来获取过去十几天的 clone，view 统计 In [16]: repo0.get_clones_traffic() Out[16]: {'count': 362, 'uniques': 150, 'clones': [Clones(uniques=5, timestamp=2021-04-06 00:00:00, count=16), Clones(uniques=8, timestamp=2021-04-07 00:00:00, count=23), Clones(uniques=13, timestamp=2021-04-08 00:00:00, count=30), Clones(uniques=33, timestamp=2021-04-09 00:00:00, count=45), Clones(uniques=2, timestamp=2021-04-10 00:00:00, count=13), Clones(uniques=6, timestamp=2021-04-11 00:00:00, count=19), Clones(uniques=15, timestamp=2021-04-12 00:00:00, count=28), Clones(uniques=40, timestamp=2021-04-13 00:00:00, count=54), Clones(uniques=9, timestamp=2021-04-14 00:00:00, count=21), Clones(uniques=10, timestamp=2021-04-15 00:00:00, count=34), Clones(uniques=10, timestamp=2021-04-16 00:00:00, count=23), Clones(uniques=5, timestamp=2021-04-17 00:00:00, count=17), Clones(uniques=2, timestamp=2021-04-18 00:00:00, count=13), Clones(uniques=9, timestamp=2021-04-19 00:00:00, count=23), Clones(uniques=3, timestamp=2021-04-20 00:00:00, count=3)]} In [17]: repo0.get_views_traffic() Out[17]: {'count': 6019, 'uniques': 1134, 'views': [View(uniques=52, timestamp=2021-04-06 00:00:00, count=169), View(uniques=143, timestamp=2021-04-07 00:00:00, count=569), View(uniques=152, timestamp=2021-04-08 00:00:00, count=635), View(uniques=134, timestamp=2021-04-09 00:00:00, count=648), View(uniques=81, timestamp=2021-04-10 00:00:00, count=318), View(uniques=42, timestamp=2021-04-11 00:00:00, count=197), View(uniques=127, timestamp=2021-04-12 00:00:00, count=515), View(uniques=149, timestamp=2021-04-13 00:00:00, count=580), View(uniques=134, timestamp=2021-04-14 00:00:00, count=762), View(uniques=141, timestamp=2021-04-15 00:00:00, count=385), View(uniques=113, timestamp=2021-04-16 00:00:00, count=284), View(uniques=48, timestamp=2021-04-17 00:00:00, count=168), View(uniques=35, timestamp=2021-04-18 00:00:00, count=135), View(uniques=124, timestamp=2021-04-19 00:00:00, co","date":"2021-05-03","objectID":"/nebula-insights/:1:2","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#数据的获取api"},{"categories":["Big Data","Cloud"],"content":" 2 实现","date":"2021-05-03","objectID":"/nebula-insights/:2:0","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#实现"},{"categories":["Big Data","Cloud"],"content":" 2.1 计划任务调度 with Cloud Scheduler前边提到，Scheduler --\u003e Functions 中间是通过消息队列实现的可靠事件触发，我们需要在 Google Cloud Pub/Sub里创建一个订阅消息，后边我们会把这个订阅消息从 Scheduler 定期发送，并且在 Function创建的时候定义为触发条件。 $ gcloud pubsub topics create nebula-insights-cron-topic $ gcloud pubsub subscriptions create cron-sub --topic nebula-insights-cron-topic 任务的创建非常直接，在 Scheduler Web Console 上直接图形化操作就可以了，记得要选择触发 Pub/Sub 消息为 cron-sub，消息主题为 nebula-insights-cron-topic ","date":"2021-05-03","objectID":"/nebula-insights/:2:1","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#计划任务调度-with-cloud-scheduler"},{"categories":["Big Data","Cloud"],"content":" 2.2 ETL Worker with Python + Google Functions当 Scheduler 每天定时发送消息之后，接收方就是我们要定义的 Google Functions了，它的定义如图 第一步，选择它的触发类型为 Pub/Sub，同时要定义消息的主题和名字。 第二步就是把代码放进去: ┌─────────────────────┐ │ │ ┌──────────────────────────┐ ┌───────────► GitHub API Server │ │ │ │ │ │ │ Google Cloud Functions ◄───► └─────────────────────┘ │ │ │ └────────────▲─────────────┘ │ ┌─────────────────────────┐ │ │ │ │ │ ├───────────► Docker Hub API Server │ ┌────────────▼────────────┐ │ │ │ │ │ │ │ │ │ Google Cloud Storage │ │ └─────────────────────────┘ │ │ ... └────────────┬────────────┘ │ ┌──────────────────┐ │ │ │ │ │ └───────────► Aliyun OSS API │ ┌─────────▼─────────┐ │ │ │ │ └──────────────────┘ │ Google BigQuery │ │ │ └───────────────────┘ 这部分的逻辑就是通过前边分析了的API取得信息，然后组装成需要的格式存到 Cloud Storage(对象存储），然后再导入到 BigQuery（数仓）之中，全部代码在GitHub上: https://github.com/wey-gu/nebula-insights/blob/main/functions/data-fetching-0/main.py 另外，可以参考这个官方教程 https://cloud.google.com/scheduler/docs/tut-pub-sub ","date":"2021-05-03","objectID":"/nebula-insights/:2:2","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#etl-worker-with-python--google-functions"},{"categories":["Big Data","Cloud"],"content":" 2.3 数仓表结构定义数仓的表结构比较直接，schema的图贴在下边了，值得注意的是，BigQuery支持嵌套的表结构（而不像一般关系型数据库那样需要把这样的逻辑结构用辅助表来表示），在我们这个场景下非常方便，比如release表中的 assets的三个嵌套字段。 更详细的信息可以参考GitHub上的介绍和代码: https://github.com/wey-gu/nebula-insights#data-etl-bigquery-and-gcs ","date":"2021-05-03","objectID":"/nebula-insights/:2:3","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#数仓表结构定义"},{"categories":["Big Data","Cloud"],"content":" 2.4 数据可视化到这里，我们就可以自动在BigQuery里存有每天收集的不同来源的统计数据啦，有了它，我们可以借助 Data Studio 来生成各式各样的可视化表示。 参考 https://cloud.google.com/bigquery/docs/visualize-data-studio ","date":"2021-05-03","objectID":"/nebula-insights/:2:4","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#数据可视化"},{"categories":["Big Data","Cloud"],"content":" 3 总结这样，我们实际上不需要任何认为维护的成本和投入，就搭建了一整个数据的流水线，并且只需要按照数据用量付费，在我们的数据量下，及时考虑未来增加数十个新的量度的收集，我们依然没有达到需要付费的用量，是不是很Cool？ 因为数据同时存在于对象存储与数仓里，我们可以方便随时把数据导入任意其他平台上。 BigQuery还有一些非常常用的，自带的机器学习的功能，只需要写一个SQL-Like的query就能触发然后获得预测结果，如果我们用到这些功能的话也会回到 datawhale 为同学们继续分享哈。 第一次做数据工程方面的分享，如果有错误的地方欢迎大家不吝指出哈~~ 谢谢！ ","date":"2021-05-03","objectID":"/nebula-insights/:3:0","series":null,"tags":["Nebula Graph","serverless","Cloud","FaaS"],"title":"Nebula-Insights，我们基于 Serverless 架构的数据管道方案与代码分享。","uri":"/nebula-insights/#总结"},{"categories":["Nebula Graph"],"content":"Nebula-up，一键拉起一个 Nebula 测试环境，包括 Nebula BR、Exchange、Algorithm、Dashboard、Studio","date":"2021-04-26","objectID":"/nebula-up/","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/"},{"categories":["Nebula Graph"],"content":" Update: the All-in-one mode is introduced! Check here and try it! Nebula-Up is PoC utility to enable developer to bootstrap an nebula-graph cluster with nebula-graph-studio(Web UI) + nebula-graph-console(Command UI) ready out of box in an oneliner run. All required packages will handled with nebula-up as well, including Docker on Linux(Ubuntu/CentOS), Docker Desktop on macOS(including both Intel and M1 chip based), and Docker Desktop Windows. Also, it’s optimized to leverage China Repo Mirrors(docker, brew, gitee, etc…) in case needed enable a smooth deployment for both Mainland China users and others. macOS and Linux with Shell: curl -fsSL nebula-up.siwei.io/install.sh | bash Note: you could specify the version of Nebula Graph like: curl -fsSL nebula-up.siwei.io/install.sh | bash -s -- v2.6 ","date":"2021-04-26","objectID":"/nebula-up/:0:0","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#"},{"categories":["Nebula Graph"],"content":" 1 All-in-one modeWith all-in-one mode, you could play with many Nebula Tools in one command, too: Supported tools: Nebula Dashboard Nebula Graph Studio Nebula Graph Console Nebula BR(backup \u0026 restore) Nebula Graph Spark utils Nebula Graph Spark Connector/PySpark Nebula Graph Algorithm Nebula Graph Exchange Nebula Graph Importer Nebula Graph Fulltext Search Nebula Bench ","date":"2021-04-26","objectID":"/nebula-up/:1:0","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#all-in-one-mode"},{"categories":["Nebula Graph"],"content":" 1.1 Install all in one # Install Nebula Core with all-in-one mode curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash ","date":"2021-04-26","objectID":"/nebula-up/:1:1","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#install-all-in-one"},{"categories":["Nebula Graph"],"content":" 1.2 Install Nebula Core and One of the coponent: # Install Core with Backup and Restore with MinIO curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 br # Install Core with Spark Connector, Nebula Algorithm, Nebula Exchange curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 spark # Install Core with Dashboard curl -fsSL nebula-up.siwei.io/all-in-one.sh | bash -s -- v3 dashboard ","date":"2021-04-26","objectID":"/nebula-up/:1:2","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#install-nebula-core-and-one-of-the-coponent"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be \u003chost-ip\u003e:9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#how-to-play-with-all-in-one-mode"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#console-and-basketballplayer-dataset-loading"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#monitor-the-whole-cluster-with-nebula-dashboard"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#access-nebula-graph-studio"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#query-data-with-nebula-spark-connector-in-pyspark-shell"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#run-nebula-exchange"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#run-nebula-graph-algorithm"},{"categories":["Nebula Graph"],"content":" 1.3 How to play with all-in-one mode: 1.3.1 Console and Basketballplayer Dataset LoadingThen you could call Nebula Console like: # Connect to nebula with console ~/.nebula-up/console.sh # Execute queryies like ~/.nebula-up/console.sh -e \"SHOW HOSTS\" # Load the sample dataset ~/.nebula-up/load-basketballplayer-dataset.sh # Make a Graph Query the sample dataset ~/.nebula-up/console.sh -e 'USE basketballplayer; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree \u003e=0 YIELD path AS p;' 1.3.2 Monitor the whole cluster with Nebula DashboardVisit http://127.0.0.1:7003 with user: root, password: nebula. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the dashboard here: http://nebula-demo.siwei.io:7003 . 1.3.3 Access Nebula Graph StudioVisit http://127.0.0.1:7001 with user: root, password: nebula, host: graphd:9669(for non-all-in-one case, this should be :9669). Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the studio here: http://nebula-demo.siwei.io:7001 . 1.3.4 Query Data with Nebula Spark Connector in PySpark ShellOr play in PySpark like: ~/.nebula-up/nebula-pyspark.sh # call Nebula Spark Connector Reader df = spark.read.format( \"com.vesoft.nebula.connector.NebulaDataSource\").option( \"type\", \"vertex\").option( \"spaceName\", \"basketballplayer\").option( \"label\", \"player\").option( \"returnCols\", \"name,age\").option( \"metaAddress\", \"metad0:9559\").option( \"partitionNumber\", 1).load() # show the dataframe with limit 2 df.show(n=2) The output may look like: ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.5 /_/ Using Python version 2.7.16 (default, Jan 14 2020 07:22:06) SparkSession available as 'spark'. \u003e\u003e\u003e df = spark.read.format( ... \"com.vesoft.nebula.connector.NebulaDataSource\").option( ... \"type\", \"vertex\").option( ... \"spaceName\", \"basketballplayer\").option( ... \"label\", \"player\").option( ... \"returnCols\", \"name,age\").option( ... \"metaAddress\", \"metad0:9559\").option( ... \"partitionNumber\", 1).load() \u003e\u003e\u003e df.show(n=2) +---------+--------------+---+ |_vertexId| name|age| +---------+--------------+---+ |player105| Danny Green| 31| |player109|Tiago Splitter| 34| +---------+--------------+---+ only showing top 2 rows 1.3.5 Run Nebula ExchangeOr run an example Nebula Exchange job to import data from CSV file: ~/.nebula-up/nebula-exchange-example.sh You could check the example configuration file in ~/.nebula-up/nebula-up/spark/exchange.conf 1.3.6 Run Nebula Graph Algorithm Reference: https://github.com/wey-gu/nebula-livejournal Load LiveJournal dataset with Nebula Importer: ~/.nebula-up/load-LiveJournal-dataset.sh Run Nebula Algorithm like: ~/.nebula-up/nebula-algo-pagerank-example.sh 1.3.7 Try Backup and Restore with MinIO as Storage # Create a full backup to MinIO(Be sure to run load-basketballplayer-dataset.sh before doing so) ~/.nebula-up/nebula-br-backup-full.sh # Show all backups ~/.nebula-up/nebula-br-show.sh # Restore to a backup named BACKUP_2022_05_08_11_38_08 ~/.nebula-up/nebula-br-restore-full.sh BACKUP_2022_05_08_11_38_08 Note, you could also browser files in MinIO with from http://127.0.0.1:9001 with user: minioadmin, password: minioadmin. Note, thanks to the sponsorship of Microsoft, we have a demo site of Nebula-UP on Azure: you could visit the MinIO site here: http://nebula-demo.siwei.io:9001 . Windows with PowerShell(Working In Progress): iwr nebula-up.siwei.io/install.ps1 -useb | iex TBD: Finished Windows(Docker Desktop instead of the WSL 1\u00262 in initial phase) part, leveraging chocolatey package manager as homebrew was used in macOS Fully optimized for CN users, for now, git/apt/yum repo were not optimised, newly installed docker repo, brew repo were automatically optimised for CN internet access Packaging similar content into homebrew/chocolatey? CI/UT ","date":"2021-04-26","objectID":"/nebula-up/:1:3","series":null,"tags":["Nebula Graph","nebula-up"],"title":"Nebula-Up，一键拉起一个 Nebula 测试环境","uri":"/nebula-up/#try-backup-and-restore-with-minio-as-storage"},{"categories":["Nebula Graph"],"content":"Nebula Graph 的 Jupyter Notebook 和 IPython 插件，方便在 Notebook 之中嵌入 nGQL 的 query 和 结果的调试。","date":"2021-03-07","objectID":"/ipython-ngql/","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/"},{"categories":["Nebula Graph"],"content":" Nebula Graph 的 Jupyter Notebook 和 IPython 插件，方便在 Notebook 之中嵌入 nGQL 的 query 和 结果的调试。 ipython-ngql is a python package to extend the ability to connect Nebula Graph from your Jupyter Notebook or iPython. It’s easier for data scientists to create, debug and share reusable and all-in-one Jupyter Notebooks with Nebula Graph interaction embedded. ipython-ngql is inspired by ipython-sql created by Catherine Devlin ","date":"2021-03-07","objectID":"/ipython-ngql/:0:0","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#"},{"categories":["Nebula Graph"],"content":" 1 Get Started","date":"2021-03-07","objectID":"/ipython-ngql/:1:0","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#get-started"},{"categories":["Nebula Graph"],"content":" 1.1 Installationipython-ngql could be installed either via pip or from this git repo itself. Install via pip pip install ipython-ngql Install inside the repo git clone git@github.com:wey-gu/ipython-ngql.git cd ipython-ngql python setup.py install ","date":"2021-03-07","objectID":"/ipython-ngql/:1:1","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#installation"},{"categories":["Nebula Graph"],"content":" 1.2 Load it in Jupyter Notebook or iPython %load_ext ngql ","date":"2021-03-07","objectID":"/ipython-ngql/:1:2","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#load-it-in-jupyter-notebook-or-ipython"},{"categories":["Nebula Graph"],"content":" 1.3 Connect to Nebula GraphArguments as below are needed to connect a Nebula Graph DB instance: Argument Description --address or -addr IP address of the Nebula Graph Instance --port or -P Port number of the Nebula Graph Instance --user or -u User name --password or -p Password Below is an exmple on connecting to 127.0.0.1:9669 with username: “user” and password: “password”. %ngql --address 127.0.0.1 --port 9669 --user user --password password ","date":"2021-03-07","objectID":"/ipython-ngql/:1:3","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#connect-to-nebula-graph"},{"categories":["Nebula Graph"],"content":" 1.4 Make QueriesNow two kind of iPtython Magics are supported: Option 1: The one line stype with %ngql: %ngql GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id; Option 2: The multiple lines stype with %%ngql %%ngql USE pokemon_club; SHOW TAGS; SHOW HOSTS; There will be other options in future, i.e. from a .ngql file. ","date":"2021-03-07","objectID":"/ipython-ngql/:1:4","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#make-queries"},{"categories":["Nebula Graph"],"content":" 1.5 Query String with Variablesipython-ngql supports taking variables from the local namespace, with the help of Jinja2 template framework, it’s supported to have queries like the below example. The actual query string should be GO FROM \"Sue\" OVER owns_pokemon ..., and \"{{ trainer }}\" was renderred as \"Sue\" by consuming the local variable trainer: In [8]: trainer = \"Sue\" In [9]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: Out[9]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey ","date":"2021-03-07","objectID":"/ipython-ngql/:1:5","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#query-string-with-variables"},{"categories":["Nebula Graph"],"content":" 1.6 Configure ngql_result_styleBy default, ipython-ngql will use pandas dataframe as output style to enable more human readable output, while it’s supported to use the raw thrift data format comes from the nebula2-python itself. This can be done ad-hoc with below one line: %config IPythonNGQL.ngql_result_style=\"raw\" After above line being executed, the output will be like: ResultSet(ExecutionResponse( error_code=0, latency_in_us=2844, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) The result are always stored in variable _ in Jupyter Notebook, thus, to tweak the result, just refer a new var to it like: In [10]: %config IPythonNGQL.ngql_result_style=\"raw\" In [11]: %%ngql USE pokemon_club; ...: GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id ...: | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[11]: ResultSet(ExecutionResponse( error_code=0, latency_in_us=3270, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) In [12]: r = _ In [13]: r.column_values(key='Trainer_Name')[0]._value.value Out[13]: b'Tom' ","date":"2021-03-07","objectID":"/ipython-ngql/:1:6","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#configure-ngql_result_style"},{"categories":["Nebula Graph"],"content":" 1.7 Get HelpDon’t remember anything or even relying on the cheatsheet here, oen takeaway for you: the help! In [7]: %ngql help Supported Configurations: ------------------------ \u003e How to config ngql_result_style in \"raw\", \"pandas\" %config IPythonNGQL.ngql_result_style=\"raw\" %config IPythonNGQL.ngql_result_style=\"pandas\" \u003e How to config ngql_verbose in True, False %config IPythonNGQL.ngql_verbose=True \u003e How to config max_connection_pool_size %config IPythonNGQL.max_connection_pool_size=10 Quick Start: ----------- \u003e Connect to Neubla Graph %ngql --address 127.0.0.1 --port 9669 --user user --password password \u003e Use Space %ngql USE nba \u003e Query %ngql SHOW TAGS; \u003e Multile Queries %%ngql SHOW TAGS; SHOW HOSTS; Reload ngql Magic %reload_ext ngql \u003e Variables in query, we are using Jinja2 here name = \"nba\" %ngql USE \"{{ name }}\" ","date":"2021-03-07","objectID":"/ipython-ngql/:1:7","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#get-help"},{"categories":["Nebula Graph"],"content":" 1.8 Examples 1.8.1 Jupyter NotebookPlease refer here:https://github.com/wey-gu/ipython-ngql/blob/main/examples/get_started.ipynb 1.8.2 iPython venv ❯ ipython In [1]: %load_ext ngql In [2]: %ngql --address 127.0.0.1 --port 9669 --user user --password password Connection Pool Created Out[2]: Name 0 pokemon_club In [3]: %ngql GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name Out[3]: Trainer_Name 0 Tom 1 Jerry 2 Sue 3 Tom 4 Wey In [4]: %%ngql ...: SHOW TAGS; ...: SHOW HOSTS; ...: ...: Out[4]: Host Port Status Leader count Leader distribution Partition distribution 0 storaged0 9779.0 ONLINE 0 No valid partition No valid partition 1 storaged1 9779.0 ONLINE 1 pokemon_club:1 pokemon_club:1 2 storaged2 9779.0 ONLINE 0 No valid partition No valid partition 3 Total NaN None 1 pokemon_club:1 pokemon_club:1 In [5]: trainer = \"Sue\" In [6]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: Out[6]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [7]: %ngql help Supported Configurations: ------------------------ \u003e How to config ngql_result_style in \"raw\", \"pandas\" %config IPythonNGQL.ngql_result_style=\"raw\" %config IPythonNGQL.ngql_result_style=\"pandas\" \u003e How to config ngql_verbose in True, False %config IPythonNGQL.ngql_verbose=True \u003e How to config max_connection_pool_size %config IPythonNGQL.max_connection_pool_size=10 Quick Start: ----------- \u003e Connect to Neubla Graph %ngql --address 127.0.0.1 --port 9669 --user user --password password \u003e Use Space %ngql USE nba \u003e Query %ngql SHOW TAGS; \u003e Multile Queries %%ngql SHOW TAGS; SHOW HOSTS; Reload ngql Magic %reload_ext ngql \u003e Variables in query, we are using Jinja2 here name = \"nba\" %ngql USE \"{{ name }}\" In [8]: trainer = \"Sue\" In [9]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[9]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [10]: %config IPythonNGQL.ngql_result_style=\"raw\" In [11]: %%ngql USE pokemon_club; ...: GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id ...: | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[11]: ResultSet(ExecutionResponse( error_code=0, latency_in_us=3270, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) In [12]: r = _ In [13]: r.column_values(key='Trainer_Name')[0]._value.value Out[13]: b'Tom' ","date":"2021-03-07","objectID":"/ipython-ngql/:1:8","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#examples"},{"categories":["Nebula Graph"],"content":" 1.8 Examples 1.8.1 Jupyter NotebookPlease refer here:https://github.com/wey-gu/ipython-ngql/blob/main/examples/get_started.ipynb 1.8.2 iPython venv ❯ ipython In [1]: %load_ext ngql In [2]: %ngql --address 127.0.0.1 --port 9669 --user user --password password Connection Pool Created Out[2]: Name 0 pokemon_club In [3]: %ngql GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name Out[3]: Trainer_Name 0 Tom 1 Jerry 2 Sue 3 Tom 4 Wey In [4]: %%ngql ...: SHOW TAGS; ...: SHOW HOSTS; ...: ...: Out[4]: Host Port Status Leader count Leader distribution Partition distribution 0 storaged0 9779.0 ONLINE 0 No valid partition No valid partition 1 storaged1 9779.0 ONLINE 1 pokemon_club:1 pokemon_club:1 2 storaged2 9779.0 ONLINE 0 No valid partition No valid partition 3 Total NaN None 1 pokemon_club:1 pokemon_club:1 In [5]: trainer = \"Sue\" In [6]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: Out[6]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [7]: %ngql help Supported Configurations: ------------------------ \u003e How to config ngql_result_style in \"raw\", \"pandas\" %config IPythonNGQL.ngql_result_style=\"raw\" %config IPythonNGQL.ngql_result_style=\"pandas\" \u003e How to config ngql_verbose in True, False %config IPythonNGQL.ngql_verbose=True \u003e How to config max_connection_pool_size %config IPythonNGQL.max_connection_pool_size=10 Quick Start: ----------- \u003e Connect to Neubla Graph %ngql --address 127.0.0.1 --port 9669 --user user --password password \u003e Use Space %ngql USE nba \u003e Query %ngql SHOW TAGS; \u003e Multile Queries %%ngql SHOW TAGS; SHOW HOSTS; Reload ngql Magic %reload_ext ngql \u003e Variables in query, we are using Jinja2 here name = \"nba\" %ngql USE \"{{ name }}\" In [8]: trainer = \"Sue\" In [9]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[9]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [10]: %config IPythonNGQL.ngql_result_style=\"raw\" In [11]: %%ngql USE pokemon_club; ...: GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id ...: | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[11]: ResultSet(ExecutionResponse( error_code=0, latency_in_us=3270, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) In [12]: r = _ In [13]: r.column_values(key='Trainer_Name')[0]._value.value Out[13]: b'Tom' ","date":"2021-03-07","objectID":"/ipython-ngql/:1:8","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#jupyter-notebook"},{"categories":["Nebula Graph"],"content":" 1.8 Examples 1.8.1 Jupyter NotebookPlease refer here:https://github.com/wey-gu/ipython-ngql/blob/main/examples/get_started.ipynb 1.8.2 iPython venv ❯ ipython In [1]: %load_ext ngql In [2]: %ngql --address 127.0.0.1 --port 9669 --user user --password password Connection Pool Created Out[2]: Name 0 pokemon_club In [3]: %ngql GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name Out[3]: Trainer_Name 0 Tom 1 Jerry 2 Sue 3 Tom 4 Wey In [4]: %%ngql ...: SHOW TAGS; ...: SHOW HOSTS; ...: ...: Out[4]: Host Port Status Leader count Leader distribution Partition distribution 0 storaged0 9779.0 ONLINE 0 No valid partition No valid partition 1 storaged1 9779.0 ONLINE 1 pokemon_club:1 pokemon_club:1 2 storaged2 9779.0 ONLINE 0 No valid partition No valid partition 3 Total NaN None 1 pokemon_club:1 pokemon_club:1 In [5]: trainer = \"Sue\" In [6]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: Out[6]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [7]: %ngql help Supported Configurations: ------------------------ \u003e How to config ngql_result_style in \"raw\", \"pandas\" %config IPythonNGQL.ngql_result_style=\"raw\" %config IPythonNGQL.ngql_result_style=\"pandas\" \u003e How to config ngql_verbose in True, False %config IPythonNGQL.ngql_verbose=True \u003e How to config max_connection_pool_size %config IPythonNGQL.max_connection_pool_size=10 Quick Start: ----------- \u003e Connect to Neubla Graph %ngql --address 127.0.0.1 --port 9669 --user user --password password \u003e Use Space %ngql USE nba \u003e Query %ngql SHOW TAGS; \u003e Multile Queries %%ngql SHOW TAGS; SHOW HOSTS; Reload ngql Magic %reload_ext ngql \u003e Variables in query, we are using Jinja2 here name = \"nba\" %ngql USE \"{{ name }}\" In [8]: trainer = \"Sue\" In [9]: %%ngql ...: GO FROM \"{{ trainer }}\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[9]: Trainer_Name 0 Jerry 1 Sue 2 Tom 3 Wey In [10]: %config IPythonNGQL.ngql_result_style=\"raw\" In [11]: %%ngql USE pokemon_club; ...: GO FROM \"Tom\" OVER owns_pokemon YIELD owns_pokemon._dst as pokemon_id ...: | GO FROM $-.pokemon_id OVER owns_pokemon REVERSELY YIELD owns_pokemon._dst AS Trainer_Name; ...: ...: Out[11]: ResultSet(ExecutionResponse( error_code=0, latency_in_us=3270, data=DataSet( column_names=[b'Trainer_Name'], rows=[Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Jerry')]), Row( values=[Value( sVal=b'Sue')]), Row( values=[Value( sVal=b'Tom')]), Row( values=[Value( sVal=b'Wey')])]), space_name=b'pokemon_club')) In [12]: r = _ In [13]: r.column_values(key='Trainer_Name')[0]._value.value Out[13]: b'Tom' ","date":"2021-03-07","objectID":"/ipython-ngql/:1:8","series":null,"tags":["Nebula Graph","iPython","Jupyter"],"title":"IPython-nGQL, Nebula Graph 的 Jupyter 插件","uri":"/ipython-ngql/#ipython"}]
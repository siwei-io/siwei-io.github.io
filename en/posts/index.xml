<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Posts - siwei.io</title>
        <link>https://siwei.io/en/posts/</link>
        <description>All Posts | siwei.io</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>weyl.gu@gmail.com (Wey Gu)</managingEditor>
            <webMaster>weyl.gu@gmail.com (Wey Gu)</webMaster><lastBuildDate>Wed, 07 Dec 2022 14:01:55 &#43;0800</lastBuildDate><atom:link href="https://siwei.io/en/posts/" rel="self" type="application/rss+xml" /><item>
    <title>Use ChatGPT and Nebulagraph to Predict Fifa World Cup</title>
    <link>https://siwei.io/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/</link>
    <pubDate>Wed, 07 Dec 2022 14:01:55 &#43;0800</pubDate><author>
        <name>Wey Gu</name>
    </author><guid>https://siwei.io/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/featured-image.webp" referrerpolicy="no-referrer">
            </div><blockquote>
<p>An attempt to use ChatGPT to generate code for a data scraper to predict sports events with the help of the NebulaGraph graph database and graph algorithms.</p>
</blockquote>
<blockquote>
<p>This post was initially published in <a href="https://www.nebula-graph.io/posts/predict-fifa-world-cup-with-chatgpt-and-nebulagraph" target="_blank" rel="noopener noreferrer">https://www.nebula-graph.io/posts/predict-fifa-world-cup-with-chatgpt-and-nebulagraph</a></p>
</blockquote>
<!--

> ChatGPT and Nebulagraph Predict Fifa World Cup

[TOC]

-->
<h2 id="the-hype" class="headerLink">
    <a href="#the-hype" class="header-mark"></a>1 The Hype</h2><p>In the hype for FIFA 2022 World Cup, when I saw <a href="https://cambridge-intelligence.com/fifa-world-cup-2022-prediction/" target="_blank" rel="noopener noreferrer">a blog post from Cambridge Intelligence</a>, where they leveraged limited information and correlations among players, teams, and clubs to predict the final winner team, I always would like to try similar things with NebulaGraph to share the ideas of graph algorithm to extract hidden information from the overall connections in a graph in the community.</p>
<p>The initial attempt was to make it done in like 2 hours, but I noticed the dataset need to be parsed carefully from <a href="https://en.wikipedia.org/wiki/2022_FIFA_World_Cup_squads" target="_blank" rel="noopener noreferrer">Wikipedia</a> and I happened to be not good at doing this job, so I put the idea on hold for a couple of days.</p>
<p>In the meantime, another hype, the OpenAI ChatGPT was announced, as I had been a user of DALL-E 2 already(to generate feature images of my blog posts), I gave it a try very quickly, too. And I witnessed how other guys(via Twitter, blogs, hacker news) tried to convince ChatGPT to do so many things that are hard to believe they could do:</p>
<ul>
<li>Help to implement a piece of code at any time</li>
<li>Simulate any prompt interface: shell, python, virtual machine, or even a language you create</li>
<li>Act out almost any given persona, and chat with you</li>
<li>Write poetry, rap, prose</li>
<li>Find a bug in a piece of code</li>
<li>Explain the meaning of a complex regular expression/Open Cypher Query</li>
</ul>
<p>ChatGPT&rsquo;s ability to contextualize and understand has never been greater before, so much so that everyone is talking about a new way of working: how to master asking/convincing/triggering machines to help us do our jobs, better and faster.</p>
<blockquote>
<p>I commented on this tweet, where they taught ChatGPT how to draw and render basic SVGs, then they started to ask him/her to draw any other complex things just after him/her learned in one second, that it&rsquo;s just like Kame-sennin(human) teaches Sun Wukong kung fu as a young <strong>Saiyan</strong>.</p>
<p>Be sure to check this Twitter thread, it&rsquo;s really interesting!</p>
<blockquote class="twitter-tweet" data-dnt="true"><p lang="en" dir="ltr">Hey, cool, directly rendering SVGs in <a href="https://twitter.com/hashtag/ChatGPT?src=hash&amp;ref_src=twsrc%5Etfw">#ChatGPT</a> ! <a href="https://t.co/VQX9kYIrxT">pic.twitter.com/VQX9kYIrxT</a></p>&mdash; Br‚çºd Sk·î±ggs (@brdskggs) <a href="https://twitter.com/brdskggs/status/1599533975357095936?ref_src=twsrc%5Etfw">December 4, 2022</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</blockquote>
<!--

https://twitter.com/brdskggs/status/1599533975357095936

-->
<p>So, after trying to get ChatGPT to help me write complex graph database query statements, explain the meaning of complex graph query statements, and explain the meaning of a large chunk of Bison code, and he/she had done them WELL, I realized: why not let ChatGPT write the code that extracts the data for me?</p>
<h2 id="grabbing-data" class="headerLink">
    <a href="#grabbing-data" class="header-mark"></a>2 Grabbing data</h2><p>I really tried it and the result is&hellip; good enough.</p>
<p>The whole process was basically like a coding interviewer, or a product manager, presenting my requirements, and ChatGPT giving me the code implementation. I then try to run the code, find the things that don&rsquo;t make sense in the code, point them out, and give suggestions, and ChatGPT really understands the points I point out and makes the appropriate corrections, like:</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/chatGPT-correction-process.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/chatGPT-correction-process.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/chatGPT-correction-process.webp">
        
    </a></p>
<p>I won&rsquo;t list this whole process, but I share the generated code and the whole discussion <a href="https://gist.github.com/wey-gu/78cb28bee130966e7d6e9d573b51deff" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>The final generated data is a CSV file.</p>
<ul>
<li>
<p>Raw version <a href="https://github.com/siwei-io/talks/files/10152775/world_cup_squads.csv" target="_blank" rel="noopener noreferrer">world_cup_squads.csv</a></p>
</li>
<li>
<p>Manually modified, separated columns for birthday and age <a href="https://github.com/siwei-io/talks/files/10152923/world_cup_squads.csv" target="_blank" rel="noopener noreferrer">world_cup_squads_v0.csv</a></p>
<p>It contains information/columns of team, group, number, position, player name, birthday, age, number of international matches played, number of goals scored, and club served.</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Team,Group,No.,Pos.,Player,DOB,Age,Caps,Goals,Club
</span></span><span class="line"><span class="cl">Ecuador,A,1,1GK,Hern√°n Gal√≠ndez,(1987-03-30)30 March 1987,35,12,0,Aucas
</span></span><span class="line"><span class="cl">Ecuador,A,2,2DF,F√©lix Torres,(1997-01-11)11 January 1997,25,17,2,Santos Laguna
</span></span><span class="line"><span class="cl">Ecuador,A,3,2DF,Piero Hincapi√©,(2002-01-09)9 January 2002,20,21,1,Bayer Leverkusen
</span></span><span class="line"><span class="cl">Ecuador,A,4,2DF,Robert Arboleda,(1991-10-22)22 October 1991,31,33,2,S√£o Paulo
</span></span><span class="line"><span class="cl">Ecuador,A,5,3MF,Jos√© Cifuentes,(1999-03-12)12 March 1999,23,11,0,Los Angeles FC
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>Final version with header removed <a href="https://github.com/siwei-io/talks/files/10152974/world_cup_squads_no_headers.csv" target="_blank" rel="noopener noreferrer">world_cup_squads_no_headers.csv</a></li>
</ul>
<h2 id="graph-algorithm-to-predict-the-2022-world-cup" class="headerLink">
    <a href="#graph-algorithm-to-predict-the-2022-world-cup" class="header-mark"></a>3 Graph algorithm to predict the 2022 World Cup</h2><p>With the help of ChatGPT, I could finally try to predict the winner of the game with Graph Magic, before that, I need to map the data into the graph view.</p>
<p>If you don&rsquo;t care about the process, just go to the <a href="#Result" rel="">predicted result</a> directly.</p>
<h3 id="graph-modeling" class="headerLink">
    <a href="#graph-modeling" class="header-mark"></a>3.1 Graph modeling</h3><blockquote>
<p>Prerequisites: This article uses <a href="https://github.com/vesoft-inc/nebula" target="_blank" rel="noopener noreferrer">NebulaGraph</a>(Open-Source) and <a href="https://docs.nebula-graph.io/3.3.0/nebula-explorer/about-explorer/ex-ug-what-is-explorer/" target="_blank" rel="noopener noreferrer">NebulaGraph Explorer</a>(Proprietary), which you can request a trial of on <a href="https://go.aws/3VZay2I" target="_blank" rel="noopener noreferrer">AWS</a>.</p>
</blockquote>
<p>Graph Modeling is the abstraction and representation of real-world information in the form of a &ldquo;vertex-&gt; edge&rdquo; graph, in our case, we will project the information parsed from Wikipedia as:</p>
<p>Vertices:</p>
<ul>
<li>player</li>
<li>team</li>
<li>group</li>
<li>club</li>
</ul>
<p>Edges:</p>
<ul>
<li>groupedin (the team belongs to which group)</li>
<li>belongto (players belong to the national team)</li>
<li>serve (players serve in the club)</li>
</ul>
<p>The age of the players, the number of international caps, and the number of goals scored are naturally fit as properties for the player tag(type of vertex).</p>
<p>The following is a screenshot of this schema in NebulaGraph Explorer (will just call it Explorer later).</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/schema_fifa.webp" title="schema_fifa" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/schema_fifa.webp">
        
    </a></p>
<p>Then, we can click the save icon in the upper right corner and the button: <code>Apply to Space</code>  to actually create a graph space with the defined schema</p>
<blockquote>
<p>Note: Refer to the document <a href="https://docs.nebula-graph.io/3.3.0/nebula-explorer/db-management/draft/" target="_blank" rel="noopener noreferrer">https://docs.nebula-graph.io/3.3.0/nebula-explorer/db-management/draft/</a></p>
</blockquote>
<h3 id="ingesting-into-nebulagraph" class="headerLink">
    <a href="#ingesting-into-nebulagraph" class="header-mark"></a>3.2 Ingesting into NebulaGraph</h3><p>With the graph modeling, we can upload the <a href="https://github.com/siwei-io/talks/files/10152974/world_cup_squads_no_headers.csv" target="_blank" rel="noopener noreferrer">CSV file</a> (the no-header version) into Explorer, by pointing and selecting the vid and properties that map the different columns to the vertices and edges.</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/importer_config_mapping.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/importer_config_mapping.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/importer_config_mapping.webp">
        
    </a></p>
<p>Click Import, we then import the whole graph to NebulaGraph, and after it succeeded, we could also get the whole CSV &ndash;&gt; Nebula Importer configuration file: [nebula_importer_config_fifa.yml](<a href="https://github.com/siwei-io/talks/files/10164014/config" target="_blank" rel="noopener noreferrer">https://github.com/siwei-io/talks/files/10164014/config</a> _fifa.yml.txt), so that you reuse it in the future whenever to re-import the same data or share it with others.</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/importer_log.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/importer_log.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/importer_log.webp">
        
    </a></p>
<blockquote>
<p>Note: Refer to the document <a href="https://docs.nebula-graph.io/3.3.0/nebula-explorer/db-management/11.import-data/" target="_blank" rel="noopener noreferrer">https://docs.nebula-graph.io/3.3.0/nebula-explorer/db-management/11.import-data/</a></p>
</blockquote>
<p>After importing, we can view the statistics on the schema view page, which will show us that 831 players participated in the 2022 Qatar World Cup, serving in 295 different clubs.</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/data_stats.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/data_stats.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/data_stats.webp">
        
    </a></p>
<blockquote>
<p>Note: refer to the documentation: <a href="https://docs.nebula-graph.io/3.3.0/nebula-explorer/db-management/10.create-schema/#view_statistics" target="_blank" rel="noopener noreferrer">https://docs.nebula-graph.io/3.3.0/nebula-explorer/db-management/10.create-schema/#view_statistics</a></p>
</blockquote>
<h3 id="explore-the-graph" class="headerLink">
    <a href="#explore-the-graph" class="header-mark"></a>3.3 Explore the graph</h3><p>Let&rsquo;s see what insights we could get from the information/ knowledge in form of a graph.</p>
<h4 id="querying-the-data" class="headerLink">
    <a href="#querying-the-data" class="header-mark"></a>3.3.1 Querying the data</h4><p>We could start by showing all the data and see what we will get.</p>
<p>First, with the help of NebulaGraph Explorer, I simply did drag and drop to draw any type of vertex type (TAG) and any type of edge between vertex types (TAG), here we know that all the vertices are connected with others, so no isolated vertices will be missed by this query pattern:</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query-builder-0.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query-builder-0.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query-builder-0.webp">
        
    </a></p>
<p>Let it generate the query statement for me. Here, it defaults to <code>LIMIT 100</code>, so let&rsquo;s change it to something larger (LIMIT 10000) and let it execute in the Console.</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query-builder-1.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query-builder-1.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query-builder-1.webp">
        
    </a></p>
<h4 id="initial-observation" class="headerLink">
    <a href="#initial-observation" class="header-mark"></a>3.3.2 Initial observation</h4><p>The result renders out like this, and you can see that it naturally forms a pattern of clusters.</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/bird_view.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/bird_view.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/bird_view.webp">
        
    </a></p>
<p>These peripheral clusters are mostly made up of players from clubs that are not traditionally strong ones (now we learned that they could win, though, who knows!), and many of those clubs have only one or two players and yet concentrated in one national team or region, so they are kind of isolated from other clusters.</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/edge_teams.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/edge_teams.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/edge_teams.webp">
        
    </a></p>
<h4 id="graph-algorithm-based-analysis" class="headerLink">
    <a href="#graph-algorithm-based-analysis" class="header-mark"></a>3.3.3 Graph algorithm based analysis</h4><p>After I clicked on the two buttons(Sized by Degrees, Colored by Louvain Algorithm) in Explorer (refer to the <a href="https://docs.nebula-graph.com.cn/3.3.0/nebula-explorer/graph-explorer/graph-algorithm/" target="_blank" rel="noopener noreferrer">document</a> for details), in the browser, we can see that the entire graph has become something like this:</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/Barcelona.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/Barcelona.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/Barcelona.webp">
        
    </a></p>
<p>Here, two graph algorithms are utilized to analyze the insights here.</p>
<ol>
<li>change the display size of vertices to highlight importance using their degrees</li>
<li>using Louvain&rsquo;s algorithm to distinguish the community of the vertices</li>
</ol>
<p>You can see that the big red circle is the famous Barcelona, and its players are marked in red, too.</p>
<h3 id="winner-prediction-algorithm" class="headerLink">
    <a href="#winner-prediction-algorithm" class="header-mark"></a>3.4 Winner Prediction Algorithm</h3><p>In order to be able to make full use of the graph magic(with the implied conditions, and information on the graph), my idea(<a href="https://cambridge-intelligence.com/fifa-world-cup-2022-prediction/" target="_blank" rel="noopener noreferrer">stolen/inspired from this post</a>) is to choose a graph algorithm that considers edges for node importance analysis, to find out the vertices that have higher importance, iterate and rank them globally, and thus get the top team rankings.</p>
<p>These methods actually reflect the fact that awesome players have greater community, and connectivity at the same time, and at the same time, to increase the differentiation between traditionally strong teams, I am going to take into account the information of appearances and goals scored.</p>
<p>Ultimately, my algorithm is.</p>
<ul>
<li>Take all the <code>(player)-serve-&gt;(club)</code> relationships and filter them for players with too few goals and too few goals per game (to balance out the disproportionate impact of older players from some weaker teams)</li>
<li>Explore outwards from all filtered players to get national teams</li>
<li>Run the Betweenness Centrality algorithm on the above subgraph to calculate the node importance scores</li>
</ul>
<blockquote>
<p>Note, <a href="https://en.wikipedia.org/wiki/Betweenness_centrality" target="_blank" rel="noopener noreferrer">Betweenness Centrality</a> is an algorithm to measure how a node is important in sense of bridging other nodes in the graph.</p>
</blockquote>
<h3 id="process-of-the-prediction" class="headerLink">
    <a href="#process-of-the-prediction" class="header-mark"></a>3.5 Process of the Prediction</h3><p>È¶ñÂÖàÔºåÊàë‰ª¨ÂèñÂá∫ÊâÄÊúâËøõÁêÉÊï∞Ë∂ÖËøá 10ÔºåÂú∫ÂùáËøõÁêÉË∂ÖËøá 0.2 ÁöÑ (ÁêÉÂëò)-ÊúçÂΩπ-&gt;(‰ø±‰πêÈÉ®) ÁöÑÂ≠êÂõæÔºö</p>
<p>First, we take out the subgraph in the pattern of <code>(player)-serve-&gt;(club)</code> for those who have scored more than 10 goals and have an average of more than 0.2 goals per game.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">MATCH ()-[e]-&gt;()
</span></span><span class="line"><span class="cl">WITH e LIMIT 10000
</span></span><span class="line"><span class="cl">WITH e AS e WHERE e.goals &gt; 10 AND toFloat(e.goals)/e.caps &gt; 0.2
</span></span><span class="line"><span class="cl">RETURN e
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Note: For convenience, I have included the number of goals and caps as properties in the serve edge, too.</p>
</blockquote>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query_step0.webp" title="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query_step0.webp" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/query_step0.webp">
        
    </a></p>
<p>Then, we select all the vertices on the graph, in the left toolbar, select the <code>belongto</code> edge of the outgoing direction, expand the graph outwards (traverse), and select the icon that marks the newly expanded vertices as flags.</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/treversal_step1.webp" title="treversal_step1" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/treversal_step1.webp">
        
    </a></p>
<p>Now that we have the final subgraph, we use the graph algorithm function within the browser to execute BNC (Betweenness Centrality):</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/bnc_step2.webp" title="bnc_step2" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/bnc_step2.webp">
        
    </a></p>
<p>The graph canvas then looks like this:</p>
<p><a class="lightgallery" href="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/bnc_predict.webp" title="bnc_predict" data-thumbnail="/en/chatgpt-and-nebulagraph-predict-fifa-world-cup/bnc_predict.webp">
        
    </a></p>
<h2 id="result" class="headerLink">
    <a href="#result" class="header-mark"></a>4 Result</h2><p>In the end, we sorted according to the value of Betweenness Centrality to get the final winning team: Brazil! üáßüá∑, followed by Belgium, Germany, England, France, and Argentina, so let&rsquo;s wait two weeks to come back and see if the prediction is accurate :D.</p>
<p>The sorted data is as follows:</p>
<table>
<thead>
<tr>
<th>Vertex</th>
<th><strong>Betweenness Centrality</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Brazil</strong>üáßüá∑</td>
<td>3499</td>
</tr>
<tr>
<td><strong>Paris Saint-Germain</strong></td>
<td>3073.3333333333300</td>
</tr>
<tr>
<td><strong>Neymar</strong></td>
<td>3000</td>
</tr>
<tr>
<td><strong>Tottenham Hotspur</strong></td>
<td>2740</td>
</tr>
<tr>
<td><strong>Belgium</strong>üáßüá™</td>
<td>2587.833333333330</td>
</tr>
<tr>
<td><strong>Richarlison</strong></td>
<td>2541</td>
</tr>
<tr>
<td><strong>Kevin De Bruyne</strong></td>
<td>2184</td>
</tr>
<tr>
<td><strong>Manchester City</strong></td>
<td>2125</td>
</tr>
<tr>
<td><strong>ƒ∞lkay G√ºndoƒüan</strong></td>
<td>2064</td>
</tr>
<tr>
<td><strong>Germany</strong>üá©üá™</td>
<td>2046</td>
</tr>
<tr>
<td><strong>Harry Kane (captain</strong></td>
<td>1869</td>
</tr>
<tr>
<td><strong>England</strong>üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø</td>
<td>1864</td>
</tr>
<tr>
<td><strong>France</strong>üá´üá∑</td>
<td>1858.6666666666700</td>
</tr>
<tr>
<td><strong>Argentina</strong>üá¶üá∑</td>
<td>1834.6666666666700</td>
</tr>
<tr>
<td><strong>Bayern Munich</strong></td>
<td>1567</td>
</tr>
<tr>
<td><strong>Kylian Mbapp√©</strong></td>
<td>1535.3333333333300</td>
</tr>
<tr>
<td><strong>Lionel Messi (captain</strong></td>
<td>1535.3333333333300</td>
</tr>
<tr>
<td><strong>Gabriel Jesus</strong></td>
<td>1344</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Feature Image Credit: The image was also generated with OpenAI, through the DALL-E 2 model &amp; DALL-E 2 Outpainting, see the <a href="https://user-images.githubusercontent.com/1651790/205881462-ff007725-e270-4b1e-9062-7702f01021c1.png" target="_blank" rel="noopener noreferrer">original image</a>.</p>
</blockquote>]]></description>
</item><item>
    <title>Tabular Data ETL to NebulaGraph with dbt</title>
    <link>https://siwei.io/en/nebulagraph-etl-dbt/</link>
    <pubDate>Wed, 23 Nov 2022 19:01:45 &#43;0800</pubDate><author>
        <name>Wey Gu</name>
    </author><guid>https://siwei.io/en/nebulagraph-etl-dbt/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/en/nebulagraph-etl-dbt/featured-image.webp" referrerpolicy="no-referrer">
            </div><blockquote>
<p>How could we model data in Tabular sources and ETL it to NebulaGraph? This article demonstrates an end-to-end example of doing so with dbt.</p>
</blockquote>
<!--

[TOC]

-->
<h2 id="task" class="headerLink">
    <a href="#task" class="header-mark"></a>1 Task</h2><p>Imagine we are building a Knowledge Graph for a content provider web service with NebulaGraph, thus leveraging it to support a Knowledge Base QA system, Recommendation System, and Reasoning system.</p>
<p>The knowledge information persisted in different data sources from some Service APIs, Databases, Data Warehouses, or even some files in S3.</p>
<p>We need to:</p>
<ul>
<li>Analyze data to extract needed knowledge</li>
<li>Model the Graph based on relationships we care</li>
<li>Extract the relationships and ingest them to NebulaGraph</li>
</ul>
<h2 id="data-analysis" class="headerLink">
    <a href="#data-analysis" class="header-mark"></a>2 Data Analysis</h2><p>Assume that we are fetching data from <a href="https://www.omdb.org/en/us/content/Help:DataDownload" target="_blank" rel="noopener noreferrer">OMDB</a> and <a href="https://grouplens.org/datasets/movielens/" target="_blank" rel="noopener noreferrer">MovieLens</a>.</p>
<p>OMDB is an open movie database, we now think of it as one of our services, and we can get the following information.</p>
<ul>
<li>Movies</li>
<li>Classification of movies</li>
<li>The crew in the movie (director, action director, actors, post-production, etc.)</li>
<li>Movie covers, promos, etc.</li>
</ul>
<p>MovieLens is an open dataset, we consider it as the user data of our services, the information we can obtain is:</p>
<ul>
<li>Users</li>
<li>Movies</li>
<li>User interaction on movie ratings</li>
</ul>
<h2 id="graph-modeling" class="headerLink">
    <a href="#graph-modeling" class="header-mark"></a>3 Graph Modeling</h2><p>We were building this Graph for a recommendation system and talked about some basic methods in <a href="siwei.io/recommendation-system-with-graphdb/" rel="">this</a> article, which:</p>
<p>In the Content-Base Filter method(CBF), the relationship of user-&gt; movie, movie-&gt; category, movie-&gt; actor, and movie-&gt; director are concerned.</p>
<p>And the collaborative filtering approach is concerned with the relationship between the user and -&gt; movie.</p>
<p>The recommendation reasoning service is concerned with all the above relationships.</p>
<p>To summarize, we need the following edges:</p>
<ul>
<li>watched(rate(double))</li>
<li>with_genre</li>
<li>directed_by</li>
<li>acted_by</li>
</ul>
<p>Accordingly, the vertex types will be:</p>
<ul>
<li>user(user_id)</li>
<li>movie(name)</li>
<li>person(name, birthdate)</li>
<li>genre(name)</li>
</ul>
<p><a class="lightgallery" href="/en/nebulagraph-etl-dbt/schema_0.webp" title="schema_0" data-thumbnail="/en/nebulagraph-etl-dbt/schema_0.webp">
        
    </a></p>
<h2 id="data-transform" class="headerLink">
    <a href="#data-transform" class="header-mark"></a>4 Data Transform</h2><p>With the source date finalized, let&rsquo;s see how they could be mapped and transformed into the graph.</p>
<h3 id="from-omdb" class="headerLink">
    <a href="#from-omdb" class="header-mark"></a>4.1 From OMDB</h3><p>First, there is the data in OMDB, which consists of many tables, such as the table <code>all_movies</code>, which stores all the movies and their names in different languages.</p>
<table>
<thead>
<tr>
<th>movie_id</th>
<th>name</th>
<th>language_iso_639_1</th>
<th>official_translation</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Cowboy Bebop</td>
<td>de</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>Cowboy Bebop</td>
<td>en</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>Ariel - Abgebrannt in Helsinki</td>
<td>de</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>Shadows in Paradise</td>
<td>en</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>Im Schatten des Paradieses</td>
<td>de</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>Schatten im Paradies</td>
<td>de</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>And the <code>all_casts</code> table holds all roles in the film industry.</p>
<table>
<thead>
<tr>
<th>movie_id</th>
<th>person_id</th>
<th>job_id</th>
<th>role</th>
<th>position</th>
</tr>
</thead>
<tbody>
<tr>
<td>11</td>
<td>1</td>
<td>21</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>11</td>
<td>1</td>
<td>13</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>11</td>
<td>2</td>
<td>15</td>
<td>Luke Skywalker</td>
<td>1</td>
</tr>
<tr>
<td>11</td>
<td>3</td>
<td>15</td>
<td>Han Solo</td>
<td>3</td>
</tr>
<tr>
<td>11</td>
<td>4</td>
<td>15</td>
<td>Leia Organa</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>But the name and other information of each person here, as well as the position he/she holds in the film, are in separate tables.</p>
<ul>
<li>
<p><code>job_names</code></p>
<p>For example, 1 stands for writer, and 2 stands for producer. Interestingly, like movie id and name, job_id to name is a one-to-many relationship, because the data in OMDB is multilingual.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>job_id</th>
<th>name</th>
<th>language_iso_639_1</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Autoren</td>
<td>de</td>
</tr>
<tr>
<td>1</td>
<td>Writing Department</td>
<td>en</td>
</tr>
<tr>
<td>1</td>
<td>Departamento de redacci√≥n</td>
<td>es</td>
</tr>
<tr>
<td>1</td>
<td>D√©partement √©criture</td>
<td>fr</td>
</tr>
<tr>
<td>1</td>
<td>Scenariusz</td>
<td>pl</td>
</tr>
<tr>
<td>2</td>
<td>Produzenten</td>
<td>de</td>
</tr>
<tr>
<td>2</td>
<td>Production Department</td>
<td>en</td>
</tr>
</tbody>
</table>
<ul>
<li><code>all_people</code></li>
</ul>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>birthday</th>
<th>deathday</th>
<th>gender</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>George Lucas</td>
<td>1944-05-14</td>
<td>\N</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>Mark Hamill</td>
<td>1951-09-25</td>
<td>\N</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>Harrison Ford</td>
<td>1942-07-13</td>
<td>\N</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>Carrie Fisher</td>
<td>1956-10-21</td>
<td>2016-12-27</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>Peter Cushing</td>
<td>1913-05-26</td>
<td>1994-08-11</td>
<td>0</td>
</tr>
<tr>
<td>6</td>
<td>Anthony Daniels</td>
<td>1946-02-21</td>
<td>\N</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>This is a typical case in RDBMS where the data source is a table structure, so for the relationship <code>movie &lt;-[directed_by]-(person)</code>, it involves four tables <code>all_movies</code>, <code>all_casts</code>, <code>all_people</code>, <code>job_names</code>:</p>
<ul>
<li>directed_by
<ul>
<li>Starting from person_id in all_casts</li>
<li>To movie_id in all_casts
<ul>
<li>Where job_id is &ldquo;director&rdquo; in job_names</li>
</ul>
</li>
</ul>
</li>
<li>movie
<ul>
<li>person_id in all_casts</li>
<li>Name from all_movies by id, language is &ldquo;en&rdquo;</li>
</ul>
</li>
<li>person
<ul>
<li>movie_id in all_casts</li>
<li>Name, birthday in all_people</li>
</ul>
</li>
</ul>
<p>Till now, all tables we cared about in OMDB are:</p>
<p><a class="lightgallery" href="/en/nebulagraph-etl-dbt/modeling_omdb.webp" title="modeling_omdb" data-thumbnail="/en/nebulagraph-etl-dbt/modeling_omdb.webp">
        
    </a></p>
<h3 id="from-movielens-dataset" class="headerLink">
    <a href="#from-movielens-dataset" class="header-mark"></a>4.2 From MovieLens dataset</h3><p>While the above is just about one data source, in real scenarios, we also need to collect and aggregate data from other sources. For example, now also need to extract knowledge from the MovieLens dataset.</p>
<p>Here, the only relationship we utilize is <code>user -&gt; movie</code>.</p>
<ul>
<li><code>movies.csv</code></li>
</ul>
<table>
<thead>
<tr>
<th>movieId</th>
<th>title</th>
<th>genres</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Toy Story (1995)</td>
<td>Adventure</td>
</tr>
<tr>
<td>2</td>
<td>Jumanji (1995)</td>
<td>Adventure</td>
</tr>
<tr>
<td>3</td>
<td>Grumpier Old Men (1995)</td>
<td>Comedy</td>
</tr>
<tr>
<td>4</td>
<td>Waiting to Exhale (1995)</td>
<td>Comedy</td>
</tr>
</tbody>
</table>
<ul>
<li><code>ratings.csv</code></li>
</ul>
<table>
<thead>
<tr>
<th>userId</th>
<th>movieId</th>
<th>rating</th>
<th>timestamp</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>4</td>
<td>964982703</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>4</td>
<td>964981247</td>
</tr>
<tr>
<td>1</td>
<td>6</td>
<td>4</td>
<td>964982224</td>
</tr>
</tbody>
</table>
<p>From the preview of the data in the two tables, naturally, we need one type of relationship: <code>watched</code> and vertex: <code>user</code>:</p>
<ul>
<li>watched
<ul>
<li>Starting from the userId in <code>ratings.csv</code></li>
<li>To movieId in <code>ratings.csv</code></li>
<li>With rating from rating in <code>ratings.csv</code></li>
</ul>
</li>
<li>user
<ul>
<li>With userId from <code>ratings.csv</code></li>
</ul>
</li>
</ul>
<p>However, you must have noticed that movieId in the MovieLens dataset and movie id in OMDB are two different systems, if we need to associate them, we need to convert movieId in MovieLens to movie id in OMDB, and the condition of association between them is a movie title.</p>
<p>However, by observation, we know that:</p>
<ol>
<li>the titles in OMDB movies are multilingual</li>
<li>the titles in MovieLens have the year information like <code>(1995)</code> at the end of the title</li>
</ol>
<p>So our conclusion is</p>
<ul>
<li>watched
<ul>
<li>Starting from the userId in <code>ratings.csv</code></li>
<li>To movieId in <code>ratings.csv</code>
<ul>
<li>Get the movie title with movieId from <code>movies.csv</code> and find its movie_id from OMDB
<ul>
<li>Where we should match the title in language: English with the suffix of the year being removed</li>
</ul>
</li>
</ul>
</li>
<li>With rating from rating in <code>ratings.csv</code></li>
</ul>
</li>
<li>user
<ul>
<li>With userId from <code>ratings.csv</code></li>
</ul>
</li>
</ul>
<p>Now the modeling puts the two tables like this figure:</p>
<p><a class="lightgallery" href="/en/nebulagraph-etl-dbt/modeling_omdb_movielens.webp" title="modeling_omdb_movielens" data-thumbnail="/en/nebulagraph-etl-dbt/modeling_omdb_movielens.webp">
        
    </a></p>
<h3 id="graph-modeling-property-graph" class="headerLink">
    <a href="#graph-modeling-property-graph" class="header-mark"></a>4.3 Graph Modeling (Property Graph)</h3><p>To summarize, we need to aggregate different tables (or CSV files in table form) from multiple data sources, such that the correspondence is shown in the figure: where the blue dashed line indicates the source of data information for the vertices in the graph, and the pink dashed line indicates the source of edge information.</p>
<p><a class="lightgallery" href="/en/nebulagraph-etl-dbt/schema_mapping_to_graph.webp" title="schema_mapping_to_graph" data-thumbnail="/en/nebulagraph-etl-dbt/schema_mapping_to_graph.webp">
        
    </a></p>
<p>Then, we have to format the ids of individuals in different tables, for example, user_id, which is a self-incrementing number that we want to convert to a globally unique vertex_id. A convenient way to do this is to add a string prefix to the existing id, such as <code>u_</code>.</p>
<p>Eventually, for the relationship <code>user -[watched]-&gt; movie</code>, we can process the table structure data as follows.</p>
<table>
<thead>
<tr>
<th>user_id</th>
<th>rating</th>
<th>title</th>
<th>omdb_movie_id</th>
</tr>
</thead>
<tbody>
<tr>
<td>u_1</td>
<td>5</td>
<td>Seven (a.k.a. Se7en)</td>
<td>807</td>
</tr>
<tr>
<td>u_1</td>
<td>5</td>
<td>Star Wars: Episode IV - A New Hope</td>
<td>11</td>
</tr>
<tr>
<td>u_1</td>
<td>5</td>
<td>Star Wars: Episode IV - A New Hope</td>
<td>10</td>
</tr>
<tr>
<td>u_1</td>
<td>4</td>
<td>Mask, The</td>
<td>832</td>
</tr>
<tr>
<td>u_1</td>
<td>3</td>
<td>Mrs. Doubtfire</td>
<td>832</td>
</tr>
</tbody>
</table>
<p>Where, in each row, three variables exist to construct the graph structure:</p>
<ul>
<li><code>user</code> vertex id</li>
<li><code>movie</code> vertex id</li>
<li>the rating value as the property of the <code>watched</code> edge</li>
</ul>
<h2 id="tooling" class="headerLink">
    <a href="#tooling" class="header-mark"></a>5 Tooling</h2><p>At this point, we have completed the data analysis and graph modeling design, before we start the &ldquo;extract correlations, import graph database&rdquo;, let&rsquo;s introduce the tools we will use.</p>
<p>&ldquo;Extracting relationships&rdquo; can be simply considered as Extract and Transform in ETL, which is essentially the engineering of data mapping and transformation, and there are many different tools and open-source projects available on the market. Here we use one of my personal favorite tools: dbt.</p>
<h3 id="dbt" class="headerLink">
    <a href="#dbt" class="header-mark"></a>5.1 dbt</h3><p>dbt is an open-source data conversion tool with a very mature community and ecology, which can perform efficient, controlled, and high-quality data conversion work in most of the mainstream data warehouses, whether it is for ad-hoc tasks or complex orchestration, dbt can be very competent.</p>
<p>One of the features of dbt is that it uses a SQL-like language to describe the rules of data transformation. With GitOps, it is very elegant to collaborate and maintain complex data processing operations in large data teams. And the built-in data testing capabilities allow you to control the quality of your data and make it reproducible and controllable.</p>
<p>dbt not only has many integrated subprojects but also can be combined with many other excellent open source projects (meltano, AirFlow, Amundsen, Superset, etc.) to form a set of modern data infrastructure systems, feel free to check my previous article: data lineage and metadata governance reference architecture <a href="https://siwei.io/en/data-lineage-oss-ref-solution" target="_blank" rel="noopener noreferrer">https://siwei.io/en/data-lineage-oss-ref-solution</a>, where the whole solution looks like:</p>
<p><a class="lightgallery" href="https://user-images.githubusercontent.com/1651790/168849779-4826f50e-ff87-4e78-b17f-076f91182c43.svg" title="https://user-images.githubusercontent.com/1651790/168849779-4826f50e-ff87-4e78-b17f-076f91182c43.svg" data-thumbnail="https://user-images.githubusercontent.com/1651790/168849779-4826f50e-ff87-4e78-b17f-076f91182c43.svg">
        
    </a></p>
<p>In short, dbt is a command line tool written in python, and we can create a project folder, which contains a YAML formatted configuration file, to specify where the source information for the data transformation is and where the target is (where the processed data is stored, maybe Postgres, Big Query, Spark, etc.). In the data source, we use the YAML file along with the <code>.SQL</code> file to describe the information about &ldquo;what data to fetch from, how to do the transformation, and what to output&rdquo;.</p>
<p><a class="lightgallery" href="/en/nebulagraph-etl-dbt/starter-project-dbt-cli.webp" title="starter-project-dbt-cli" data-thumbnail="/en/nebulagraph-etl-dbt/starter-project-dbt-cli.webp">
        
    </a></p>
<p>You can see that the information in the models/example is the core data transformation rules, and all the other data is metadata related to this transformation. DataOps.</p>
<blockquote>
<p>Notes.</p>
<p>You can refer to the dbt documentation to get a hands-on understanding of it: <a href="https://docs.getdbt.com/docs/get-started/getting-started-dbt-core" target="_blank" rel="noopener noreferrer">https://docs.getdbt.com/docs/get-started/getting-started-dbt-core</a></p>
</blockquote>
<h3 id="nebulagraph-data-ingestion" class="headerLink">
    <a href="#nebulagraph-data-ingestion" class="header-mark"></a>5.2 NebulaGraph data ingestion</h3><p>After processing the data by dbt, we can get intermediate data that maps directly to different types of vertices, edges, and table structures of their attributes, either in the form of CSV files, tables in DWs, or even data frames in Spark, and there are different options for importing them into NebulaGraph, of which NebulaGraph Exchange, Nebula-Importer, and Nebula-Spark-Connector can be used to import the data.</p>
<blockquote>
<p>Notes.</p>
<p>You can learn more about the different tools for NebulaGraph data import at <a href="https://siwei.io/en/sketches/nebula-data-import-options" target="_blank" rel="noopener noreferrer">https://siwei.io/en/sketches/nebula-data-import-options</a> to know how to choose one of them c.</p>
</blockquote>
<p>Here, I will use the simplest one, Nebula-Importer, as an example.</p>
<p>Nebula-Importer is an open-source tool written in Golang that compiles into a single file binary, it gets the correspondence of vertices and edges from a given CSV file to a NebulaGraph for reading and importing via a preconfigured YAML format file.</p>
<blockquote>
<p>Notes.</p>
<p>Nebula-Importer code: <a href="https://github.com/vesoft-inc/nebula-importer/" target="_blank" rel="noopener noreferrer">https://github.com/vesoft-inc/nebula-importer/</a></p>
<p>Nebula-Importer documentation: <a href="https://docs.nebula-graph.io/master/nebula-importer/use-importer/" target="_blank" rel="noopener noreferrer">https://docs.nebula-graph.io/master/nebula-importer/use-importer/</a></p>
</blockquote>
<h2 id="dbt--nebula-importer-in-actions" class="headerLink">
    <a href="#dbt--nebula-importer-in-actions" class="header-mark"></a>6 dbt + Nebula-Importer in Actions</h2><p>Now let&rsquo;s use dbt + Nebula-Importer to end-to-end demonstrate how to extract, transform and import multiple data sources into NebulaGraph, the whole project code has been open-sourced, the repository is at <a href="https://github.com/wey-gu/movie-recommendation-dataset" target="_blank" rel="noopener noreferrer">https://github.com/wey-gu/movie-recommendation-dataset</a>, feel free to check for details there.</p>
<p>The whole process is as follows.</p>
<ul>
<li>Preprocess and import raw data into the data warehouse(EL)</li>
<li>Use dbt to transform the data (Transform), and export it to CSV files</li>
<li>Import CSV into NebulaGraph using Nebula Importer (L)</li>
</ul>
<p><a class="lightgallery" href="/en/nebulagraph-etl-dbt/ETL_dbt_nebulagraph_importer.webp" title="ETL_dbt_nebulagraph_importer" data-thumbnail="/en/nebulagraph-etl-dbt/ETL_dbt_nebulagraph_importer.webp">
        
    </a></p>
<h3 id="preparing-the-dbt-environment" class="headerLink">
    <a href="#preparing-the-dbt-environment" class="header-mark"></a>6.1 Preparing the dbt environment</h3><p>dbt is a python project, we install dbt and dbt-postgres in a virtual python3 environment.</p>
<h3 id="setup-env-with-dbt" class="headerLink">
    <a href="#setup-env-with-dbt" class="header-mark"></a>6.2 Setup env with dbt</h3><p>dbt is written in python, we could install it in a python virtual env, together with dbt-Postgres, as we will use Postgres as the DW in this sample project.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python3 -m venv .venv
</span></span><span class="line"><span class="cl"><span class="nb">source</span> .venv/bin/activate
</span></span><span class="line"><span class="cl">pip install dbt-postgres
</span></span></code></pre></td></tr></table>
</div>
</div><p>Create a dbt project:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">dbt init dbt_project
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> dbt_project
</span></span></code></pre></td></tr></table>
</div>
</div><p>Let&rsquo;s see the files in this project:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">$ tree .
</span></span><span class="line"><span class="cl">.
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- README.md                      <span class="c1"># README of the project</span>
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- analyses
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- dbt_project.yml                <span class="c1"># dbt project conf</span>
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- macros
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- models                         <span class="c1"># transforms</span>
</span></span><span class="line"><span class="cl"><span class="p">|</span>   <span class="se">\-</span>- example
</span></span><span class="line"><span class="cl"><span class="p">|</span>       <span class="p">|</span>-- my_first_dbt_model.sql <span class="c1"># meta data to describe transform rules from the source data with SELECT</span>
</span></span><span class="line"><span class="cl"><span class="p">|</span>       <span class="p">|</span>-- my_second_dbt_model.sql
</span></span><span class="line"><span class="cl"><span class="p">|</span>       <span class="se">\-</span>- schema.yml             <span class="c1"># the meta data of the rules</span>
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- seeds                          <span class="c1"># for CSV-file data sources</span>
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- snapshots
</span></span><span class="line"><span class="cl"><span class="se">\-</span>- tests
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="m">7</span> directories, <span class="m">5</span> files
</span></span></code></pre></td></tr></table>
</div>
</div><p>Finally, let&rsquo;s bootstrap a Postgress as the DW, if you already have one, you may skip this step, please ensure the configurations and dbt-plugins are aligned if you chose to use your own DW.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker run --rm --name postgres <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    -e <span class="nv">POSTGRES_PASSWORD</span><span class="o">=</span>nebula <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    -e <span class="nv">POSTGRES_USER</span><span class="o">=</span>nebula <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    -e <span class="nv">POSTGRES_DB</span><span class="o">=</span>warehouse -d <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    -p 5432:5432 postgres
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="data-download-and-preprocess" class="headerLink">
    <a href="#data-download-and-preprocess" class="header-mark"></a>6.3 Data download and preprocess</h3><p>Let&rsquo;s create a folder named <code>raw_data</code> and change the directory to it.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">mkdir -p raw_data
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> raw_data
</span></span></code></pre></td></tr></table>
</div>
</div><p>And we assumed it was under our dbt project:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">tree ..
</span></span><span class="line"><span class="cl">..
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- README.md
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- analyses
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- dbt_project.yml
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- macros
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- models
</span></span><span class="line"><span class="cl"><span class="p">|</span>   <span class="se">\-</span>- example
</span></span><span class="line"><span class="cl"><span class="p">|</span>       <span class="p">|</span>-- my_first_dbt_model.sql
</span></span><span class="line"><span class="cl"><span class="p">|</span>       <span class="p">|</span>-- my_second_dbt_model.sql
</span></span><span class="line"><span class="cl"><span class="p">|</span>       <span class="se">\-</span>- schema.yml
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- raw_data                       <span class="c1"># &lt;--- newly created data</span>
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- seeds
</span></span><span class="line"><span class="cl"><span class="p">|</span>-- snapshots
</span></span><span class="line"><span class="cl"><span class="se">\-</span>- tests
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="m">8</span> directories, <span class="m">5</span> files
</span></span></code></pre></td></tr></table>
</div>
</div><p>Download and decompress the OMDB data:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">wget www.omdb.org/data/all_people.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/all_people_aliases.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/people_links.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/all_casts.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/job_names.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/all_characters.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/movie_categories.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/movie_keywords.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/category_names.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/all_categories.csv.bz2
</span></span><span class="line"><span class="cl">wget www.omdb.org/data/all_movie_aliases_iso.csv.bz2
</span></span><span class="line"><span class="cl">bunzip2 *.bz2
</span></span></code></pre></td></tr></table>
</div>
</div><p>Then for the MovieLens dataset:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip
</span></span><span class="line"><span class="cl">unzip ml-latest-small.zip
</span></span><span class="line"><span class="cl">rm *.zip
</span></span></code></pre></td></tr></table>
</div>
</div><p>Before we do the Transform with dbt, we do some simple preprocess and then put them under <code>seeds</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">grep -v <span class="s1">&#39;\\&#34;&#39;</span> raw_data/all_movie_aliases_iso.csv &gt; seeds/all_movie_aliases_iso.csv
</span></span><span class="line"><span class="cl">grep -v <span class="s1">&#39;\\&#34;&#39;</span> raw_data/all_casts.csv &gt; seeds/all_casts.csv
</span></span><span class="line"><span class="cl">grep -v <span class="s1">&#39;\\&#34;&#39;</span> raw_data/all_characters.csv &gt; seeds/all_characters.csv
</span></span><span class="line"><span class="cl">grep -v <span class="s1">&#39;\\&#34;&#39;</span> raw_data/all_people.csv &gt; seeds/all_people.csv
</span></span><span class="line"><span class="cl">grep -v <span class="s1">&#39;\\&#34;&#39;</span> raw_data/category_names.csv &gt; seeds/category_names.csv
</span></span><span class="line"><span class="cl">grep -v <span class="s1">&#39;\\&#34;&#39;</span> raw_data/job_names.csv &gt; seeds/job_names.csv
</span></span><span class="line"><span class="cl">cp raw_data/movie_categories.csv seeds/movie_categories.csv
</span></span><span class="line"><span class="cl">cp raw_data/movie_keywords.csv seeds/movie_keywords.csv
</span></span><span class="line"><span class="cl">cp raw_data/all_categories.csv seeds/all_categories.csv
</span></span><span class="line"><span class="cl">cp raw_data/ml-latest-small/ratings.csv seeds/movielens_ratings.csv
</span></span><span class="line"><span class="cl">cp raw_data/ml-latest-small/movies.csv seeds/movielens_movies.csv
</span></span></code></pre></td></tr></table>
</div>
</div><p>With the above files being placed, we could load them into DW in one command:</p>
<blockquote>
<p>Refer to the documentation of dbt <code>seeds</code> <a href="https://docs.getdbt.com/docs/build/seeds" target="_blank" rel="noopener noreferrer">https://docs.getdbt.com/docs/build/seeds</a></p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">dbt seed
</span></span></code></pre></td></tr></table>
</div>
</div><p>It may take a while if you like me are using a local Postgres, and it should be faster in production-level cases (i.e. load to Big Query from the file in Cloud Storage), it should be like this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">$ dbt seed
</span></span><span class="line"><span class="cl">05:58:27  Running with <span class="nv">dbt</span><span class="o">=</span>1.3.0
</span></span><span class="line"><span class="cl">05:58:27  Found <span class="m">2</span> models, <span class="m">4</span> tests, <span class="m">0</span> snapshots, <span class="m">0</span> analyses, <span class="m">289</span> macros, <span class="m">0</span> operations, <span class="m">11</span> seed files, <span class="m">0</span> sources, <span class="m">0</span> exposures, <span class="m">0</span> metrics
</span></span><span class="line"><span class="cl">05:58:28  
</span></span><span class="line"><span class="cl">05:58:28  Concurrency: <span class="m">8</span> threads <span class="o">(</span><span class="nv">target</span><span class="o">=</span><span class="s1">&#39;dev&#39;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">05:58:28  
</span></span><span class="line"><span class="cl">05:58:28  <span class="m">1</span> of <span class="m">11</span> START seed file public.all_casts ....................................... <span class="o">[</span>RUN<span class="o">]</span>
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">07:10:11  <span class="m">1</span> of <span class="m">11</span> OK loaded seed file public.all_casts ................................... <span class="o">[</span>INSERT <span class="m">1082228</span> in 4303.78s<span class="o">]</span>
</span></span><span class="line"><span class="cl">07:10:11  
</span></span><span class="line"><span class="cl">07:10:11  Finished running <span class="m">11</span> seeds in <span class="m">1</span> hours <span class="m">11</span> minutes and 43.93 seconds <span class="o">(</span>4303.93s<span class="o">)</span>.
</span></span><span class="line"><span class="cl">07:10:11  
</span></span><span class="line"><span class="cl">07:10:11  Completed successfully
</span></span><span class="line"><span class="cl">07:10:11  
</span></span><span class="line"><span class="cl">07:10:11  Done. <span class="nv">PASS</span><span class="o">=</span><span class="m">11</span> <span class="nv">WARN</span><span class="o">=</span><span class="m">0</span> <span class="nv">ERROR</span><span class="o">=</span><span class="m">0</span> <span class="nv">SKIP</span><span class="o">=</span><span class="m">0</span> <span class="nv">TOTAL</span><span class="o">=</span><span class="m">11</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="compose-the-transform-model" class="headerLink">
    <a href="#compose-the-transform-model" class="header-mark"></a>6.4 Compose the Transform model</h3><p>We create transform under <code>models</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">mkdir models/movie_recommedation
</span></span><span class="line"><span class="cl">touch models/movie_recommedation/user_watched_movies.sql
</span></span><span class="line"><span class="cl">touch models/movie_recommedation/schema.yml
</span></span></code></pre></td></tr></table>
</div>
</div><p>The files are like this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">$ tree models
</span></span><span class="line"><span class="cl">models
</span></span><span class="line"><span class="cl"><span class="se">\-</span>- movie_recommedation
</span></span><span class="line"><span class="cl">    <span class="p">|</span>-- user_watched_movies.sql
</span></span><span class="line"><span class="cl">    <span class="se">\-</span>- schema.yml
</span></span></code></pre></td></tr></table>
</div>
</div><p>Now there is only one transform rule under this model: to handle the edge of <code>user_watched_movies</code> in the <code>user_watched_movies.sql</code></p>
<p>As we planned to output three columns: user_id, movie_id, rating, thus the <code>schema.yml</code> is like:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="m">2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">models</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">user_watched_movies</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;The edges between users and movies they have watched&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">columns</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">user_id</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;user id&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">tests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span>- <span class="l">not_null</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">movie_id</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;movie id&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">tests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span>- <span class="l">not_null</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">rating</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;rating given by user to movie&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">tests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span>- <span class="l">not_null</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>Please be noted the <code>tests</code> are about the validation and constraint of the data, with which, we could control the data quality quite easily. And here <code>not_null</code> ensures there is no NULL if tests are performed.</p>
<p>Then, let&rsquo;s compose the <code>user_watched_movies.sql</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="line"><span class="cl"><span class="err">{{</span><span class="w"> </span><span class="n">config</span><span class="p">(</span><span class="n">materialized</span><span class="o">=</span><span class="s1">&#39;table&#39;</span><span class="p">)</span><span class="w"> </span><span class="err">}}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="cm">/*
</span></span></span><span class="line"><span class="cl"><span class="cm"> JOIN the movieielens_ratings table with the movieielens_movies table, and removing the movie title tailing the year of release
</span></span></span><span class="line"><span class="cl"><span class="cm"> */</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">WITH</span><span class="w"> </span><span class="n">user_watched_movies</span><span class="w"> </span><span class="k">AS</span><span class="p">(</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">SELECT</span><span class="w"> </span><span class="n">moveielens_ratings</span><span class="p">.</span><span class="s2">&#34;userId&#34;</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">moveielens_ratings</span><span class="p">.</span><span class="s2">&#34;movieId&#34;</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">moveielens_ratings</span><span class="p">.</span><span class="n">rating</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">REGEXP_REPLACE</span><span class="p">(</span><span class="n">moveielens_movies</span><span class="p">.</span><span class="n">title</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39; \(\d{4}\)$&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">title</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">moveielens_movies</span><span class="p">.</span><span class="n">genres</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">movielens_genres</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">FROM</span><span class="w"> </span><span class="n">moveielens_ratings</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">JOIN</span><span class="w"> </span><span class="n">moveielens_movies</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">moveielens_movies</span><span class="p">.</span><span class="s2">&#34;movieId&#34;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">moveielens_ratings</span><span class="p">.</span><span class="s2">&#34;movieId&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="cm">/* 
</span></span></span><span class="line"><span class="cl"><span class="cm"> JOIN user_watched_movies table with all_movie_aliase_iso table where language is English
</span></span></span><span class="line"><span class="cl"><span class="cm"> the join condition is the movie title
</span></span></span><span class="line"><span class="cl"><span class="cm"> */</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">SELECT</span><span class="w"> </span><span class="n">concat</span><span class="p">(</span><span class="s1">&#39;u_&#39;</span><span class="p">,</span><span class="n">user_watched_movies</span><span class="p">.</span><span class="s2">&#34;userId&#34;</span><span class="p">)</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">user_id</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">user_watched_movies</span><span class="p">.</span><span class="n">rating</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">user_watched_movies</span><span class="p">.</span><span class="n">title</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">all_movie_aliases_iso</span><span class="p">.</span><span class="s2">&#34;movie_id&#34;</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">OMDB_movie_id</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">user_watched_movies</span><span class="p">.</span><span class="n">movielens_genres</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">FROM</span><span class="w"> </span><span class="n">user_watched_movies</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">JOIN</span><span class="w"> </span><span class="n">all_movie_aliases_iso</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">user_watched_movies</span><span class="p">.</span><span class="n">title</span><span class="w"> </span><span class="k">LIKE</span><span class="w"> </span><span class="n">CONCAT</span><span class="p">(</span><span class="n">all_movie_aliases_iso</span><span class="p">.</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;%&#39;</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">AND</span><span class="w"> </span><span class="n">all_movie_aliases_iso</span><span class="p">.</span><span class="n">language_iso_639_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;en&#39;</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>And what this SQL does is the part marked by the green circle:</p>
<ul>
<li>Select the user id, movie id, rating, and movie title (remove the year part) from <code>moveielens_ratings</code> and save it as the intermediate table of <code>user_watched_movies</code>
<ul>
<li>movie title is <code>JOIN</code>ed from <code>moveielens_movies</code>, obtained by the same matching condition as <code>movie_id</code></li>
</ul>
</li>
<li>Select user id (prefix <code>u_</code>), rating, title, OMDB_movie_id from <code>user_watched_movies</code>
<ul>
<li>OMDB_movie_id is <code>JOIN</code>ed from <code>all_movie_aliases_iso</code>, obtained by matching the Chinese and English titles of OMDB movies with similar movie names</li>
<li>output the final fields</li>
</ul>
</li>
</ul>
<p><a class="lightgallery" href="/en/nebulagraph-etl-dbt/transform_select_joins_user_watched_movies.webp" title="transform_select_joins_user_watched_movies" data-thumbnail="/en/nebulagraph-etl-dbt/transform_select_joins_user_watched_movies.webp">
        
    </a></p>
<blockquote>
<p>Tips: we could add <code>LIMIT</code> to debug the SQL query fast from a Postgres Console</p>
</blockquote>
<p>Then we could run it from dbt to transform and test the rule:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">dbt run -m user_watched_movies
</span></span></code></pre></td></tr></table>
</div>
</div><p>After that, we should be able to see a table after the Transform in Postgres (DW).</p>
<p>Similarly, following the same method for all other parts of the Transform rules, we could have other models:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">$ tree models
</span></span><span class="line"><span class="cl">models
</span></span><span class="line"><span class="cl"><span class="se">\-</span>- movie_recommedation
</span></span><span class="line"><span class="cl">    <span class="p">|</span>-- acted_by.sql
</span></span><span class="line"><span class="cl">    <span class="p">|</span>-- directed_by.sql
</span></span><span class="line"><span class="cl">    <span class="p">|</span>-- genres.sql
</span></span><span class="line"><span class="cl">    <span class="p">|</span>-- movies.sql
</span></span><span class="line"><span class="cl">    <span class="p">|</span>-- people.sql
</span></span><span class="line"><span class="cl">    <span class="p">|</span>-- schema.yml
</span></span><span class="line"><span class="cl">    <span class="p">|</span>-- user_watched_movies.sql
</span></span><span class="line"><span class="cl">    <span class="se">\-</span>- with_genre.sql
</span></span></code></pre></td></tr></table>
</div>
</div><p>Then run them all:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">dbt run -m acted_by
</span></span><span class="line"><span class="cl">dbt run -m directed_by
</span></span><span class="line"><span class="cl">dbt run -m with_genre
</span></span><span class="line"><span class="cl">dbt run -m people
</span></span><span class="line"><span class="cl">dbt run -m genres
</span></span><span class="line"><span class="cl">dbt run -m movies
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="export-data-to-csv" class="headerLink">
    <a href="#export-data-to-csv" class="header-mark"></a>6.5 Export data to CSV</h3><p>NebulaGraph Exchange itself supports directly importing many data sources (Postgres, Clickhouse, MySQL, Hive, etc.) into NebulaGraph, but in this example, the amount of data we process is very small for NebulaGraph, so we just go with the most lightweight one: Nebula-Importer. Nebula-Importer can only CSV files, so we are doing so.</p>
<p>First, we enter the Postgres console and execute the <code>COPY</code> command</p>
<blockquote>
<p>Refer to Postgres documentation: <a href="https://www.postgresql.org/docs/current/sql-copy.html" target="_blank" rel="noopener noreferrer">https://www.postgresql.org/docs/current/sql-copy.html</a></p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="line"><span class="cl"><span class="k">COPY</span><span class="w"> </span><span class="n">acted_by</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="s1">&#39;/tmp/acted_by.csv&#39;</span><span class="w">  </span><span class="k">WITH</span><span class="w"> </span><span class="k">DELIMITER</span><span class="w"> </span><span class="s1">&#39;,&#39;</span><span class="w"> </span><span class="n">CSV</span><span class="w"> </span><span class="n">HEADER</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">COPY</span><span class="w"> </span><span class="n">directed_by</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="s1">&#39;/tmp/directed_by.csv&#39;</span><span class="w">  </span><span class="k">WITH</span><span class="w"> </span><span class="k">DELIMITER</span><span class="w"> </span><span class="s1">&#39;,&#39;</span><span class="w"> </span><span class="n">CSV</span><span class="w"> </span><span class="n">HEADER</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">COPY</span><span class="w"> </span><span class="n">with_genre</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="s1">&#39;/tmp/with_genre.csv&#39;</span><span class="w">  </span><span class="k">WITH</span><span class="w"> </span><span class="k">DELIMITER</span><span class="w"> </span><span class="s1">&#39;,&#39;</span><span class="w"> </span><span class="n">CSV</span><span class="w"> </span><span class="n">HEADER</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">COPY</span><span class="w"> </span><span class="n">people</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="s1">&#39;/tmp/people.csv&#39;</span><span class="w">  </span><span class="k">WITH</span><span class="w"> </span><span class="k">DELIMITER</span><span class="w"> </span><span class="s1">&#39;,&#39;</span><span class="w"> </span><span class="n">CSV</span><span class="w"> </span><span class="n">HEADER</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">COPY</span><span class="w"> </span><span class="n">movies</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="s1">&#39;/tmp/movies.csv&#39;</span><span class="w">  </span><span class="k">WITH</span><span class="w"> </span><span class="k">DELIMITER</span><span class="w"> </span><span class="s1">&#39;,&#39;</span><span class="w"> </span><span class="n">CSV</span><span class="w"> </span><span class="n">HEADER</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">COPY</span><span class="w"> </span><span class="n">genres</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="s1">&#39;/tmp/genres.csv&#39;</span><span class="w">  </span><span class="k">WITH</span><span class="w"> </span><span class="k">DELIMITER</span><span class="w"> </span><span class="s1">&#39;,&#39;</span><span class="w"> </span><span class="n">CSV</span><span class="w"> </span><span class="n">HEADER</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">-- for user_watched_movies, we don&#39;t output HEADER, as we will parse it in importer in a no-header way.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">COPY</span><span class="w"> </span><span class="n">user_watched_movies</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="s1">&#39;/tmp/user_watched_movies.csv&#39;</span><span class="w">  </span><span class="k">WITH</span><span class="w"> </span><span class="k">DELIMITER</span><span class="w"> </span><span class="s1">&#39;,&#39;</span><span class="w"> </span><span class="n">CSV</span><span class="p">;</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>Then copy the CSV files into <code>to_nebulagraph</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">mkdir -p to_nebulagraph
</span></span><span class="line"><span class="cl">docker cp postgres:/tmp/. to_nebulagraph/
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="ingest-data-into-nebulagraph" class="headerLink">
    <a href="#ingest-data-into-nebulagraph" class="header-mark"></a>6.6 Ingest data into NebulaGraph</h3><h4 id="bootstrap-a-nebulagraph-cluster" class="headerLink">
    <a href="#bootstrap-a-nebulagraph-cluster" class="header-mark"></a>6.6.1 Bootstrap a NebulaGraph cluster</h4><p>We can use Nebula-Up to have a NebulaGraph playground cluster with the oneliner.</p>
<blockquote>
<p>Note:</p>
<ul>
<li>
<p>Nebula-UP: <a href="https://github.com/wey-gu/nebula-up" target="_blank" rel="noopener noreferrer">https://github.com/wey-gu/nebula-up</a></p>
</li>
<li>
<p>Dataset repository: <a href="https://github.com/wey-gu/movie-recommendation-dataset" target="_blank" rel="noopener noreferrer">https://github.com/wey-gu/movie-recommendation-dataset</a></p>
</li>
</ul>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">curl -fsSL nebula-up.siwei.io/install.sh <span class="p">|</span> bash
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="define-the-data-schema" class="headerLink">
    <a href="#define-the-data-schema" class="header-mark"></a>6.6.2 Define the Data Schema</h4><p>First, we need to create a graph space, and then create tag(type of vertex) and edge type on it:</p>
<p>Access the Nebula-Console(CLI client for NebulaGraph):</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">~/.nebula-up/console.sh
</span></span></code></pre></td></tr></table>
</div>
</div><p>Run the following DDL(Data Definition Language):</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="line"><span class="cl"><span class="k">CREATE</span><span class="w"> </span><span class="k">SPACE</span><span class="w"> </span><span class="n">moviegraph</span><span class="p">(</span><span class="n">partition_num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">replica_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">vid_type</span><span class="o">=</span><span class="n">fixed_string</span><span class="p">(</span><span class="mi">32</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">:</span><span class="n">sleep</span><span class="w"> </span><span class="mi">20</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">USE</span><span class="w"> </span><span class="n">moviegraph</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">CREATE</span><span class="w"> </span><span class="n">TAG</span><span class="w"> </span><span class="n">person</span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="n">birthdate</span><span class="w"> </span><span class="n">string</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">CREATE</span><span class="w"> </span><span class="n">TAG</span><span class="w"> </span><span class="n">movie</span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">string</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">CREATE</span><span class="w"> </span><span class="n">TAG</span><span class="w"> </span><span class="n">genre</span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="n">string</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">CREATE</span><span class="w"> </span><span class="n">TAG</span><span class="w"> </span><span class="k">user</span><span class="p">(</span><span class="n">user_id</span><span class="w"> </span><span class="n">string</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">CREATE</span><span class="w"> </span><span class="n">EDGE</span><span class="w"> </span><span class="n">acted_by</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">CREATE</span><span class="w"> </span><span class="n">EDGE</span><span class="w"> </span><span class="n">directed_by</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">CREATE</span><span class="w"> </span><span class="n">EDGE</span><span class="w"> </span><span class="n">with_genre</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">CREATE</span><span class="w"> </span><span class="n">EDGE</span><span class="w"> </span><span class="n">watched</span><span class="p">(</span><span class="n">rate</span><span class="w"> </span><span class="nb">float</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">exit</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="create-a-nebula-importer-conf-file" class="headerLink">
    <a href="#create-a-nebula-importer-conf-file" class="header-mark"></a>6.6.3 Create a Nebula-Importer conf file</h4><p>This conf is a YAML file that describes the correspondence between the CSV file and the vertex or edge data in the cluster.</p>
<p>Please refer to the document: <a href="https://docs.nebula-graph.io/master/nebula-importer/use-importer/" target="_blank" rel="noopener noreferrer">https://docs.nebula-graph.io/master/nebula-importer/use-importer/</a> for details.</p>
<p>I already created one for it, which can be downloaded at <a href="https://github.com/wey-gu/movie-recommendation-dataset/blob/main/nebula-importer.yaml" target="_blank" rel="noopener noreferrer">https://github.com/wey-gu/movie-recommendation-dataset/blob/main/nebula-importer.yaml</a>.</p>
<p>Here, we will directly download the configuration file.</p>
<blockquote>
<p>Note that this file should not be part of the dbt project file.:</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">cd</span> ..
</span></span><span class="line"><span class="cl">wget https://raw.githubusercontent.com/wey-gu/movie-recommendation-dataset/main/nebula-importer.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="ingesting-the-data" class="headerLink">
    <a href="#ingesting-the-data" class="header-mark"></a>6.6.4 Ingesting the data</h4><p>Let&rsquo;s use the Nebula-Importer in docker to avoid any installation:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker run --rm -ti <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --network<span class="o">=</span>nebula-net <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    -v <span class="si">${</span><span class="nv">PWD</span><span class="si">}</span>:/root/ <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    -v <span class="si">${</span><span class="nv">PWD</span><span class="si">}</span>/dbt_project/to_nebulagraph/:/data <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    vesoft/nebula-importer:v3.2.0 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --config /root/nebula-importer.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><p>After it&rsquo;s executed, all data are in NebulaGraph, and we could check the data from Nebula-Console:</p>
<p>First, access the console again:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">~/.nebula-up/console.sh
</span></span></code></pre></td></tr></table>
</div>
</div><p>Enter the graph space and execute <code>SHOW STATS</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-SQL" data-lang="SQL"><span class="line"><span class="cl"><span class="n">USE</span><span class="w"> </span><span class="n">moviegraph</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">SHOW</span><span class="w"> </span><span class="n">STATS</span><span class="p">;</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>The result should be like this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-SQL" data-lang="SQL"><span class="line"><span class="cl"><span class="p">(</span><span class="n">root</span><span class="o">@</span><span class="n">nebula</span><span class="p">)</span><span class="w"> </span><span class="p">[</span><span class="n">moviegraph</span><span class="p">]</span><span class="o">&gt;</span><span class="w"> </span><span class="k">SHOW</span><span class="w"> </span><span class="n">STATS</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">+</span><span class="c1">---------+---------------+---------+
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="o">|</span><span class="w"> </span><span class="k">Type</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="n">Name</span><span class="w">          </span><span class="o">|</span><span class="w"> </span><span class="k">Count</span><span class="w">   </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">+</span><span class="c1">---------+---------------+---------+
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Tag&#34;</span><span class="w">   </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;genre&#34;</span><span class="w">       </span><span class="o">|</span><span class="w"> </span><span class="mi">14397</span><span class="w">   </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Tag&#34;</span><span class="w">   </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;movie&#34;</span><span class="w">       </span><span class="o">|</span><span class="w"> </span><span class="mi">20701</span><span class="w">   </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Tag&#34;</span><span class="w">   </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;person&#34;</span><span class="w">      </span><span class="o">|</span><span class="w"> </span><span class="mi">263907</span><span class="w">  </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Tag&#34;</span><span class="w">   </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;user&#34;</span><span class="w">        </span><span class="o">|</span><span class="w"> </span><span class="mi">610</span><span class="w">     </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Edge&#34;</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;acted_by&#34;</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="mi">673763</span><span class="w">  </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Edge&#34;</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;directed_by&#34;</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">101949</span><span class="w">  </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Edge&#34;</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;watched&#34;</span><span class="w">     </span><span class="o">|</span><span class="w"> </span><span class="mi">31781</span><span class="w">   </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Edge&#34;</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;with_genre&#34;</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="mi">194009</span><span class="w">  </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Space&#34;</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;vertices&#34;</span><span class="w">    </span><span class="o">|</span><span class="w"> </span><span class="mi">299615</span><span class="w">  </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;Space&#34;</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="s2">&#34;edges&#34;</span><span class="w">       </span><span class="o">|</span><span class="w"> </span><span class="mi">1001502</span><span class="w"> </span><span class="o">|</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="o">+</span><span class="c1">---------+---------------+---------+
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">Got</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="k">rows</span><span class="w"> </span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="n">spent</span><span class="w"> </span><span class="mi">1693</span><span class="o">/</span><span class="mi">15136</span><span class="w"> </span><span class="n">us</span><span class="p">)</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>With Nebula-Studio, we can also explore this graph in the visual interface, for example, by executing this query, we could see the reason why it recommended the movie with id 1891 to the user with id u_124.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-SQL" data-lang="SQL"><span class="line"><span class="cl"><span class="n">FIND</span><span class="w"> </span><span class="n">NOLOOP</span><span class="w"> </span><span class="n">PATH</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="s2">&#34;u_124&#34;</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="s2">&#34;1891&#34;</span><span class="w"> </span><span class="n">over</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">BIDIRECT</span><span class="w"> </span><span class="n">UPTO</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="n">STEPS</span><span class="w"> </span><span class="n">yield</span><span class="w"> </span><span class="n">path</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="o">`</span><span class="n">p</span><span class="o">`</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="k">LIMIT</span><span class="w"> </span><span class="mi">20</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>The result could be: Most of the cast and crew of the once-favorite Star Wars movies are also involved in this and the same &ldquo;Oscar-winning&rdquo; and &ldquo;classic&rdquo; movie.</p>
<p><a class="lightgallery" href="/en/nebulagraph-etl-dbt/reasoning_movie.webp" title="reasoning_movie" data-thumbnail="/en/nebulagraph-etl-dbt/reasoning_movie.webp">
        
    </a></p>
<blockquote>
<p>In another article, I used the same graph to demonstrate the application of more graph databases and graph algorithms in recommendation systems. If you are interested, please read <a href="https://siwei.io/recommendation-system-with-graphdb/" target="_blank" rel="noopener noreferrer">https://siwei.io/recommendation-system-with-graphdb/</a>.</p>
</blockquote>
<h2 id="summary" class="headerLink">
    <a href="#summary" class="header-mark"></a>7 Summary</h2><p>When we plan to leverage graph databases for massive data to transform knowledge and analyze insights, the first step is often to transform, process, and model multiple data sources into graph data. For beginners who have no idea where to start, a feasible idea is to start from all relevant information, picture the most concerning relationship, and then list the vertices that can be obtained and the required properties attached. After determining the initial modeling, you can use the ETL tool to clean the original data, ETL into table structure which will be mapped to the graph, and finally, use the import tool to import NebulaGraph for further model iterations.</p>
<p>With the help of dbt, we can version control, test, iterate our modeling and data transformation, and gradually evolve and enrich the constructed knowledge graph with grace.</p>
<blockquote>
<p>Feature image credit: <a href="https://unsplash.com/photos/Bu4lHKIHr-E" target="_blank" rel="noopener noreferrer">Claudio</a></p>
</blockquote>]]></description>
</item></channel>
</rss>
